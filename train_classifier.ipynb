{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import itertools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "from cebra_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_model_path = 'models/cebra_model_complete.pt'\n",
    "\n",
    "data_directory = '/mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/'\n",
    "neural_data_paths = [ data_directory + 'brain/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "behavior_data_paths = [  data_directory + 'camera1/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "dino_paths = [ data_directory + 'dino/' + \\\n",
    "                        file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "label_paths = list(filter(lambda x : x.endswith('.pickle') , iter(os.listdir('.'))))\n",
    "\n",
    "neural_data_paths.sort()\n",
    "behavior_data_paths.sort()\n",
    "dino_paths.sort()\n",
    "label_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "solver = torch.load('models/cebra_model_complete.pt')\n",
    "model_group = solver.model.eval()\n",
    "prototype = nn.Sequential(nn.Linear(8, 4))\n",
    "classifiers = nn.ModuleList([prototype for i in range(len(model_group))])\n",
    "for param in model_group.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(classifiers.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_epoch(data, names, labels, model_group, criterion, optimizer, session):\n",
    "    # train the linear classifier on the labelled data\n",
    "    running_loss = 0.0\n",
    "    num_iter= 0\n",
    "    for data, names in zip(data, names):\n",
    "        # check if the data is labelled\n",
    "        if names in labels:\n",
    "            # do a forward pass\n",
    "            output = model_group[session](torch.from_numpy(data).float())\n",
    "            tiled_label = np.tile(labels[names], data.shape[0]).reshape(data.shape[0], 4)\n",
    "            vid_label = torch.from_numpy(tiled_label).float()\n",
    "\n",
    "            loss = criterion(output, vid_label)\n",
    "\n",
    "            # do a backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_iter += 1\n",
    "            \n",
    "    return (running_loss / num_iter)\n",
    "            \n",
    "\n",
    "def validation_run(data, names, labels, model_group, criterion, session):\n",
    "    # train the linear classifier on the labelled data\n",
    "    running_loss = 0.0\n",
    "    num_iter= 0\n",
    "    for data, names in zip(data, names):\n",
    "        # check if the data is labelled\n",
    "        if names in labels:\n",
    "            # do a forward pass\n",
    "            output = model_group[session](torch.from_numpy(data).float())\n",
    "            tiled_label = np.tile(labels[names], data.shape[0]).reshape(data.shape[0], 4)\n",
    "            vid_label = torch.from_numpy(tiled_label).float()\n",
    "\n",
    "            loss = criterion(output, vid_label)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            num_iter += 1\n",
    "            \n",
    "    return (running_loss / num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session:  0\n",
      "2020_11_17_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_17_MV1_run\n",
      "Epoch:  0  Loss:  0.7627572660197579  Validation Loss:  0.7653615040438516\n",
      "Epoch:  1  Loss:  0.759804057848962  Validation Loss:  0.762681074653353\n",
      "Epoch:  2  Loss:  0.7568258493432501  Validation Loss:  0.7600436040333339\n",
      "Epoch:  3  Loss:  0.7539088822089101  Validation Loss:  0.7574676070894514\n",
      "Epoch:  4  Loss:  0.7510619104191025  Validation Loss:  0.7549553641251155\n",
      "Epoch:  5  Loss:  0.7482846986625997  Validation Loss:  0.7525052453790392\n",
      "Epoch:  6  Loss:  0.7455745138828224  Validation Loss:  0.7501143821648188\n",
      "Epoch:  7  Loss:  0.742927943360749  Validation Loss:  0.7477795328412737\n",
      "Epoch:  8  Loss:  0.7403413170321858  Validation Loss:  0.7454974293708801\n",
      "Epoch:  9  Loss:  0.7378109032508886  Validation Loss:  0.743264753477914\n",
      "Epoch:  10  Loss:  0.7353332212185972  Validation Loss:  0.7410784448896136\n",
      "Epoch:  11  Loss:  0.732904931097799  Validation Loss:  0.738935638325555\n",
      "Epoch:  12  Loss:  0.7305229049158323  Validation Loss:  0.7368335153375353\n",
      "Epoch:  13  Loss:  0.7281841918190509  Validation Loss:  0.7347696423530579\n",
      "Epoch:  14  Loss:  0.7258861251351958  Validation Loss:  0.7327415440763746\n",
      "Epoch:  15  Loss:  0.7236261359323257  Validation Loss:  0.7307472126824516\n",
      "Epoch:  16  Loss:  0.7214019487819401  Validation Loss:  0.7287844785622188\n",
      "Epoch:  17  Loss:  0.7192113910806123  Validation Loss:  0.726851601260049\n",
      "Epoch:  18  Loss:  0.7170524752535526  Validation Loss:  0.7249467960425786\n",
      "Epoch:  19  Loss:  0.714923380675474  Validation Loss:  0.7230685131890433\n",
      "Epoch:  20  Loss:  0.7128224740096178  Validation Loss:  0.7212153366633824\n",
      "Epoch:  21  Loss:  0.7107481408458185  Validation Loss:  0.7193859645298549\n",
      "Epoch:  22  Loss:  0.7086991179045907  Validation Loss:  0.7175792140620095\n",
      "Epoch:  23  Loss:  0.7066740481209416  Validation Loss:  0.7157938284533364\n",
      "Epoch:  24  Loss:  0.7046716492887922  Validation Loss:  0.7140288429600852\n",
      "Epoch:  25  Loss:  0.7026910180164174  Validation Loss:  0.7122835619109017\n",
      "Epoch:  26  Loss:  0.7007310817026979  Validation Loss:  0.7105567736285073\n",
      "Epoch:  27  Loss:  0.6987907671815411  Validation Loss:  0.7088477739265987\n",
      "Epoch:  28  Loss:  0.6968693758639114  Validation Loss:  0.7071559326989311\n",
      "Epoch:  29  Loss:  0.694966108878077  Validation Loss:  0.7054805125508989\n",
      "Epoch:  30  Loss:  0.693080204923006  Validation Loss:  0.7038209642682757\n",
      "Epoch:  31  Loss:  0.6912111091952753  Validation Loss:  0.7021765777042934\n",
      "Epoch:  32  Loss:  0.6893581493770907  Validation Loss:  0.7005470505782536\n",
      "Epoch:  33  Loss:  0.6875207421338954  Validation Loss:  0.6989317383084979\n",
      "Epoch:  34  Loss:  0.6856984563913391  Validation Loss:  0.6973301861967359\n",
      "Epoch:  35  Loss:  0.6838906218090328  Validation Loss:  0.6957419795649392\n",
      "Epoch:  36  Loss:  0.6820969677649403  Validation Loss:  0.6941667710031781\n",
      "Epoch:  37  Loss:  0.6803169699641766  Validation Loss:  0.6926041722297669\n",
      "Epoch:  38  Loss:  0.6785502803834129  Validation Loss:  0.6910538375377655\n",
      "Epoch:  39  Loss:  0.6767965278354301  Validation Loss:  0.689515494448798\n",
      "Epoch:  40  Loss:  0.6750554284213278  Validation Loss:  0.6879887929984502\n",
      "Epoch:  41  Loss:  0.6733265894849153  Validation Loss:  0.6864734811442239\n",
      "Epoch:  42  Loss:  0.6716097613081548  Validation Loss:  0.6849693604878017\n",
      "Epoch:  43  Loss:  0.6699047097097641  Validation Loss:  0.683476150887353\n",
      "Epoch:  44  Loss:  0.6682110680223077  Validation Loss:  0.6819935653890882\n",
      "Epoch:  45  Loss:  0.6665286625166075  Validation Loss:  0.6805214353970119\n",
      "Epoch:  46  Loss:  0.6648572705933268  Validation Loss:  0.6790596238204412\n",
      "Epoch:  47  Loss:  0.6631967193707471  Validation Loss:  0.6776079569544111\n",
      "Epoch:  48  Loss:  0.6615467215601302  Validation Loss:  0.676166136775698\n",
      "Epoch:  49  Loss:  0.6599071011724065  Validation Loss:  0.6747340168271746\n",
      "Epoch:  50  Loss:  0.65827774832034  Validation Loss:  0.6733115145138332\n",
      "Epoch:  51  Loss:  0.6566584734555104  Validation Loss:  0.6718985225473132\n",
      "Epoch:  52  Loss:  0.6550490347695012  Validation Loss:  0.6704947148050581\n",
      "Epoch:  53  Loss:  0.653449398363936  Validation Loss:  0.6691002096448626\n",
      "Epoch:  54  Loss:  0.6518593789276919  Validation Loss:  0.6677146647657667\n",
      "Epoch:  55  Loss:  0.6502788126186172  Validation Loss:  0.6663380418504987\n",
      "Epoch:  56  Loss:  0.6487075983065564  Validation Loss:  0.6649702795914241\n",
      "Epoch:  57  Loss:  0.6471456345788675  Validation Loss:  0.6636111983231135\n",
      "Epoch:  58  Loss:  0.6455927711527495  Validation Loss:  0.6622607324804578\n",
      "Epoch:  59  Loss:  0.6440488955985878  Validation Loss:  0.6609187407152993\n",
      "Epoch:  60  Loss:  0.642513872322878  Validation Loss:  0.6595851710864475\n",
      "Epoch:  61  Loss:  0.6409876332463811  Validation Loss:  0.6582598720278059\n",
      "Epoch:  62  Loss:  0.6394700413631602  Validation Loss:  0.65694277712277\n",
      "Epoch:  63  Loss:  0.6379611034528904  Validation Loss:  0.6556338863713401\n",
      "Epoch:  64  Loss:  0.6364606689502843  Validation Loss:  0.6543329409190587\n",
      "Epoch:  65  Loss:  0.6349685480244351  Validation Loss:  0.6530399969645909\n",
      "Epoch:  66  Loss:  0.6334848042347985  Validation Loss:  0.6517550102302007\n",
      "Epoch:  67  Loss:  0.6320092745866821  Validation Loss:  0.6504777772086007\n",
      "Epoch:  68  Loss:  0.6305419754643011  Validation Loss:  0.6492083362170629\n",
      "Epoch:  69  Loss:  0.6290827229689647  Validation Loss:  0.6479465339865004\n",
      "Epoch:  70  Loss:  0.6276315074961333  Validation Loss:  0.6466924905776977\n",
      "Epoch:  71  Loss:  0.6261883098367266  Validation Loss:  0.6454458585807256\n",
      "Epoch:  72  Loss:  0.6247528870523823  Validation Loss:  0.6442067359175001\n",
      "Epoch:  73  Loss:  0.6233252860358541  Validation Loss:  0.6429750859737396\n",
      "Epoch:  74  Loss:  0.6219055415329775  Validation Loss:  0.6417508116790227\n",
      "Epoch:  75  Loss:  0.6204934656902512  Validation Loss:  0.6405338823795319\n",
      "Epoch:  76  Loss:  0.6190889223491977  Validation Loss:  0.6393240332603455\n",
      "Epoch:  77  Loss:  0.617691966029705  Validation Loss:  0.6381214882646288\n",
      "Epoch:  78  Loss:  0.6163024915055642  Validation Loss:  0.6369260038648333\n",
      "Epoch:  79  Loss:  0.6149204887485052  Validation Loss:  0.6357376047543117\n",
      "Epoch:  80  Loss:  0.6135457920802148  Validation Loss:  0.6345562108925411\n",
      "Epoch:  81  Loss:  0.6121785221224147  Validation Loss:  0.6333817728928157\n",
      "Epoch:  82  Loss:  0.6108183634789635  Validation Loss:  0.6322141472782408\n",
      "Epoch:  83  Loss:  0.6094654681275806  Validation Loss:  0.6310533685343606\n",
      "Epoch:  84  Loss:  0.6081195888926068  Validation Loss:  0.6298992885010583\n",
      "Epoch:  85  Loss:  0.6067808295878189  Validation Loss:  0.628751853959901\n",
      "Epoch:  86  Loss:  0.6054489269358287  Validation Loss:  0.6276108013732092\n",
      "Epoch:  87  Loss:  0.6041238108799921  Validation Loss:  0.6264761724642345\n",
      "Epoch:  88  Loss:  0.6028054167309078  Validation Loss:  0.6253479570150375\n",
      "Epoch:  89  Loss:  0.6014939070595384  Validation Loss:  0.624225999202047\n",
      "Epoch:  90  Loss:  0.600188749802621  Validation Loss:  0.623109797494752\n",
      "Epoch:  91  Loss:  0.5988896836601727  Validation Loss:  0.6219991283757346\n",
      "Epoch:  92  Loss:  0.5975965358917182  Validation Loss:  0.6208939501217433\n",
      "Epoch:  93  Loss:  0.5963095118649198  Validation Loss:  0.6197944619825908\n",
      "Epoch:  94  Loss:  0.5950285857322657  Validation Loss:  0.6187003076076507\n",
      "Epoch:  95  Loss:  0.593753514979123  Validation Loss:  0.6176115159477507\n",
      "Epoch:  96  Loss:  0.5924843935322422  Validation Loss:  0.6165283569267818\n",
      "Epoch:  97  Loss:  0.5912214091038817  Validation Loss:  0.6154511592217854\n",
      "Epoch:  98  Loss:  0.5899649554801778  Validation Loss:  0.6143802655594689\n",
      "Epoch:  99  Loss:  0.5887151829439317  Validation Loss:  0.6133156567811966\n",
      "Epoch:  100  Loss:  0.5874718434720243  Validation Loss:  0.6122571732316698\n",
      "Epoch:  101  Loss:  0.586234943985374  Validation Loss:  0.6112048200198582\n",
      "Epoch:  102  Loss:  0.5850046743148876  Validation Loss:  0.6101587661675044\n",
      "Epoch:  103  Loss:  0.5837809466072733  Validation Loss:  0.6091188899108342\n",
      "Epoch:  104  Loss:  0.5825639420776005  Validation Loss:  0.6080853679350444\n",
      "Epoch:  105  Loss:  0.5813536060647377  Validation Loss:  0.6070581802300045\n",
      "Epoch:  106  Loss:  0.5801496781161611  Validation Loss:  0.6060367711952754\n",
      "Epoch:  107  Loss:  0.5789519638811808  Validation Loss:  0.6050211876630783\n",
      "Epoch:  108  Loss:  0.5777603629358572  Validation Loss:  0.6040112533739634\n",
      "Epoch:  109  Loss:  0.5765748889807841  Validation Loss:  0.6030069564070021\n",
      "Epoch:  110  Loss:  0.5753954610835884  Validation Loss:  0.602008364881788\n",
      "Epoch:  111  Loss:  0.5742222603180962  Validation Loss:  0.6010152757167816\n",
      "Epoch:  112  Loss:  0.5730551385201549  Validation Loss:  0.6000278370721\n",
      "Epoch:  113  Loss:  0.5718940711134418  Validation Loss:  0.5990455159119197\n",
      "Epoch:  114  Loss:  0.5707388079561894  Validation Loss:  0.5980682820081711\n",
      "Epoch:  115  Loss:  0.5695892524380255  Validation Loss:  0.5970957577228546\n",
      "Epoch:  116  Loss:  0.5684454909998093  Validation Loss:  0.596127952848162\n",
      "Epoch:  117  Loss:  0.5673073439801474  Validation Loss:  0.5951642666544233\n",
      "Epoch:  118  Loss:  0.5661746571414279  Validation Loss:  0.5942044615745544\n",
      "Epoch:  119  Loss:  0.5650472835906873  Validation Loss:  0.5932480318205697\n",
      "Epoch:  120  Loss:  0.5639250856157728  Validation Loss:  0.592294476713453\n",
      "Epoch:  121  Loss:  0.5628077430182724  Validation Loss:  0.5913431623152324\n",
      "Epoch:  122  Loss:  0.561694938283396  Validation Loss:  0.5903940239122936\n",
      "Epoch:  123  Loss:  0.5605867400553555  Validation Loss:  0.589447603055409\n",
      "Epoch:  124  Loss:  0.5594833419786245  Validation Loss:  0.5885047516652516\n",
      "Epoch:  125  Loss:  0.5583851263986379  Validation Loss:  0.587566305909838\n",
      "Epoch:  126  Loss:  0.5572922886547884  Validation Loss:  0.5866328516176769\n",
      "Epoch:  127  Loss:  0.5562050907532751  Validation Loss:  0.5857048728636333\n",
      "Epoch:  128  Loss:  0.5551236236547407  Validation Loss:  0.584782441173281\n",
      "Epoch:  129  Loss:  0.5540478729523753  Validation Loss:  0.583865823490279\n",
      "Epoch:  130  Loss:  0.5529779372339565  Validation Loss:  0.5829548346144813\n",
      "Epoch:  131  Loss:  0.5519136181939834  Validation Loss:  0.5820493651287896\n",
      "Epoch:  132  Loss:  0.5508549264256988  Validation Loss:  0.5811495572328568\n",
      "Epoch:  133  Loss:  0.5498018485109953  Validation Loss:  0.5802552534001214\n",
      "Epoch:  134  Loss:  0.5487544845913259  Validation Loss:  0.5793665604931968\n",
      "Epoch:  135  Loss:  0.547712764892533  Validation Loss:  0.5784832596778869\n",
      "Epoch:  136  Loss:  0.5466765700640837  Validation Loss:  0.5776053662811007\n",
      "Epoch:  137  Loss:  0.5456458890890058  Validation Loss:  0.5767329288380486\n",
      "Epoch:  138  Loss:  0.5446208769111271  Validation Loss:  0.5758660512311118\n",
      "Epoch:  139  Loss:  0.5436014025979697  Validation Loss:  0.5750045210123063\n",
      "Epoch:  140  Loss:  0.5425875713757429  Validation Loss:  0.5741485276392528\n",
      "Epoch:  141  Loss:  0.5415792525944552  Validation Loss:  0.5732977083751134\n",
      "Epoch:  142  Loss:  0.5405762271858504  Validation Loss:  0.5724520095757075\n",
      "Epoch:  143  Loss:  0.5395784971273341  Validation Loss:  0.5716114159141268\n",
      "Epoch:  144  Loss:  0.5385860160911252  Validation Loss:  0.5707758520330701\n",
      "Epoch:  145  Loss:  0.5375987715065762  Validation Loss:  0.5699452838727406\n",
      "Epoch:  146  Loss:  0.5366167163396899  Validation Loss:  0.569119644165039\n",
      "Epoch:  147  Loss:  0.5356397795451195  Validation Loss:  0.5682988843747547\n",
      "Epoch:  148  Loss:  0.5346679770833508  Validation Loss:  0.5674829776797976\n",
      "Epoch:  149  Loss:  0.5337012429937932  Validation Loss:  0.5666719334466117\n",
      "Epoch:  150  Loss:  0.5327397241694103  Validation Loss:  0.5658658662012646\n",
      "Epoch:  151  Loss:  0.5317832837455081  Validation Loss:  0.5650644796235221\n",
      "Epoch:  152  Loss:  0.5308317642358807  Validation Loss:  0.5642677068710327\n",
      "Epoch:  153  Loss:  0.5298852145106872  Validation Loss:  0.5634757786989212\n",
      "Epoch:  154  Loss:  0.5289436784965732  Validation Loss:  0.5626884243318013\n",
      "Epoch:  155  Loss:  0.5280069176337165  Validation Loss:  0.5619054892233439\n",
      "Epoch:  156  Loss:  0.5270748080518008  Validation Loss:  0.5611269422939845\n",
      "Epoch:  157  Loss:  0.5261472774342904  Validation Loss:  0.5603526911565235\n",
      "Epoch:  158  Loss:  0.5252242490861088  Validation Loss:  0.559582577432905\n",
      "Epoch:  159  Loss:  0.5243055717357527  Validation Loss:  0.5588165236370904\n",
      "Epoch:  160  Loss:  0.5233910780099896  Validation Loss:  0.5580543828862053\n",
      "Epoch:  161  Loss:  0.5224805446032664  Validation Loss:  0.5572959367718016\n",
      "Epoch:  162  Loss:  0.5215738031536482  Validation Loss:  0.5565412219081606\n",
      "Epoch:  163  Loss:  0.5206707783784912  Validation Loss:  0.5557898947170803\n",
      "Epoch:  164  Loss:  0.5197713284695883  Validation Loss:  0.5550417120967592\n",
      "Epoch:  165  Loss:  0.5188756066758485  Validation Loss:  0.5542965825114932\n",
      "Epoch:  166  Loss:  0.5179836378560811  Validation Loss:  0.5535541415214539\n",
      "Epoch:  167  Loss:  0.5170954851460118  Validation Loss:  0.5528141949857984\n",
      "Epoch:  168  Loss:  0.516211297980982  Validation Loss:  0.552076632635934\n",
      "Epoch:  169  Loss:  0.5153310800333158  Validation Loss:  0.5513408341578074\n",
      "Epoch:  170  Loss:  0.5144544120930947  Validation Loss:  0.5506060383149556\n",
      "Epoch:  171  Loss:  0.5135809557415297  Validation Loss:  0.5498714472566332\n",
      "Epoch:  172  Loss:  0.5127102830116218  Validation Loss:  0.549136015347072\n",
      "Epoch:  173  Loss:  0.511841937263995  Validation Loss:  0.5483985045126506\n",
      "Epoch:  174  Loss:  0.5109753535257131  Validation Loss:  0.547657265833446\n",
      "Epoch:  175  Loss:  0.5101097086312082  Validation Loss:  0.5469102833952223\n",
      "Epoch:  176  Loss:  0.5092441710815611  Validation Loss:  0.5461552722113473\n",
      "Epoch:  177  Loss:  0.5083777794340776  Validation Loss:  0.5453898140362331\n",
      "Epoch:  178  Loss:  0.5075097144780001  Validation Loss:  0.5446123659610749\n",
      "Epoch:  179  Loss:  0.5066396942918334  Validation Loss:  0.543823207276208\n",
      "Epoch:  180  Loss:  0.5057683683119679  Validation Loss:  0.5430247298308781\n",
      "Epoch:  181  Loss:  0.5048970020777807  Validation Loss:  0.5422210012163434\n",
      "Epoch:  182  Loss:  0.5040273544912655  Validation Loss:  0.5414161609751837\n",
      "Epoch:  183  Loss:  0.5031609023916778  Validation Loss:  0.5406133681535721\n",
      "Epoch:  184  Loss:  0.5022986176737112  Validation Loss:  0.5398146365370069\n",
      "Epoch:  185  Loss:  0.5014411489262965  Validation Loss:  0.5390211301190513\n",
      "Epoch:  186  Loss:  0.500588749116066  Validation Loss:  0.5382333159446716\n",
      "Epoch:  187  Loss:  0.49974155694387534  Validation Loss:  0.537451531631606\n",
      "Epoch:  188  Loss:  0.4988996883704199  Validation Loss:  0.5366757856948036\n",
      "Epoch:  189  Loss:  0.49806312983634915  Validation Loss:  0.5359061488083431\n",
      "Epoch:  190  Loss:  0.4972319272457141  Validation Loss:  0.5351424779210772\n",
      "Epoch:  191  Loss:  0.49640583285788226  Validation Loss:  0.5343844894851957\n",
      "Epoch:  192  Loss:  0.49558475712464317  Validation Loss:  0.5336321771144867\n",
      "Epoch:  193  Loss:  0.49476881982025944  Validation Loss:  0.5328854369265693\n",
      "Epoch:  194  Loss:  0.4939579380349525  Validation Loss:  0.5321441484349114\n",
      "Epoch:  195  Loss:  0.4931519254688968  Validation Loss:  0.5314081860440117\n",
      "Epoch:  196  Loss:  0.4923508003424694  Validation Loss:  0.5306774914264679\n",
      "Epoch:  197  Loss:  0.4915544488136237  Validation Loss:  0.5299519083329609\n",
      "Epoch:  198  Loss:  0.4907627999782562  Validation Loss:  0.5292313550199781\n",
      "Epoch:  199  Loss:  0.48997581457074785  Validation Loss:  0.5285157429320472\n",
      "Epoch:  200  Loss:  0.489193475924397  Validation Loss:  0.5278051018714904\n",
      "Epoch:  201  Loss:  0.4884158190675256  Validation Loss:  0.5270993858575821\n",
      "Epoch:  202  Loss:  0.48764294428283006  Validation Loss:  0.5263987290007728\n",
      "Epoch:  203  Loss:  0.4868747197903728  Validation Loss:  0.525702805178506\n",
      "Epoch:  204  Loss:  0.4861109924824882  Validation Loss:  0.5250115650040763\n",
      "Epoch:  205  Loss:  0.48535183086214473  Validation Loss:  0.5243251255580357\n",
      "Epoch:  206  Loss:  0.4845971980648583  Validation Loss:  0.5236433284623282\n",
      "Epoch:  207  Loss:  0.4838470250226875  Validation Loss:  0.5229661409343992\n",
      "Epoch:  208  Loss:  0.4831012714813106  Validation Loss:  0.5222934701613018\n",
      "Epoch:  209  Loss:  0.4823599180904045  Validation Loss:  0.5216253289154598\n",
      "Epoch:  210  Loss:  0.48162295114937553  Validation Loss:  0.5209616090570177\n",
      "Epoch:  211  Loss:  0.4808903470706036  Validation Loss:  0.5203024280922753\n",
      "Epoch:  212  Loss:  0.48016222534586467  Validation Loss:  0.5196478720222201\n",
      "Epoch:  213  Loss:  0.4794385541954312  Validation Loss:  0.5189977650131498\n",
      "Epoch:  214  Loss:  0.47871926822368566  Validation Loss:  0.5183520730052675\n",
      "Epoch:  215  Loss:  0.4780042487863116  Validation Loss:  0.5177107095718384\n",
      "Epoch:  216  Loss:  0.47729347116574294  Validation Loss:  0.5170736372470855\n",
      "Epoch:  217  Loss:  0.4765869099381976  Validation Loss:  0.516440891793796\n",
      "Epoch:  218  Loss:  0.47588464222248134  Validation Loss:  0.5158125455890383\n",
      "Epoch:  219  Loss:  0.4751866776231341  Validation Loss:  0.5151885130575725\n",
      "Epoch:  220  Loss:  0.47449291034897356  Validation Loss:  0.5145687047924314\n",
      "Epoch:  221  Loss:  0.4738032973208134  Validation Loss:  0.5139530956745147\n",
      "Epoch:  222  Loss:  0.4731178179171413  Validation Loss:  0.5133416401488441\n",
      "Epoch:  223  Loss:  0.4724364253864469  Validation Loss:  0.5127343105418342\n",
      "Epoch:  224  Loss:  0.4717590909151104  Validation Loss:  0.5121310349021639\n",
      "Epoch:  225  Loss:  0.47108576323183793  Validation Loss:  0.511531805566379\n",
      "Epoch:  226  Loss:  0.4704164180427931  Validation Loss:  0.5109365871974401\n",
      "Epoch:  227  Loss:  0.4697510591615433  Validation Loss:  0.5103453291313989\n",
      "Epoch:  228  Loss:  0.46908962966706513  Validation Loss:  0.5097580083778926\n",
      "Epoch:  229  Loss:  0.4684320813954159  Validation Loss:  0.5091745380844389\n",
      "Epoch:  230  Loss:  0.46777833736903296  Validation Loss:  0.5085948462997164\n",
      "Epoch:  231  Loss:  0.467128326825056  Validation Loss:  0.5080188998154231\n",
      "Epoch:  232  Loss:  0.46648201558262253  Validation Loss:  0.5074466769184385\n",
      "Epoch:  233  Loss:  0.4658394121163264  Validation Loss:  0.506878205708095\n",
      "Epoch:  234  Loss:  0.46520066685021205  Validation Loss:  0.5063136330672673\n",
      "Epoch:  235  Loss:  0.46456574892263275  Validation Loss:  0.505752872143473\n",
      "Epoch:  236  Loss:  0.4639346853816679  Validation Loss:  0.5051960123436792\n",
      "Epoch:  237  Loss:  0.4633075340664217  Validation Loss:  0.5046430455786841\n",
      "Epoch:  238  Loss:  0.4626842973780293  Validation Loss:  0.5040940220866884\n",
      "Epoch:  239  Loss:  0.4620649779294904  Validation Loss:  0.5035489216446877\n",
      "Epoch:  240  Loss:  0.46144959401180397  Validation Loss:  0.503007760643959\n",
      "Epoch:  241  Loss:  0.4608382194245596  Validation Loss:  0.5024705891098294\n",
      "Epoch:  242  Loss:  0.4602308079812199  Validation Loss:  0.5019372546247074\n",
      "Epoch:  243  Loss:  0.4596272869415193  Validation Loss:  0.5014078059366771\n",
      "Epoch:  244  Loss:  0.4590276264325137  Validation Loss:  0.5008821832282203\n",
      "Epoch:  245  Loss:  0.4584318109174475  Validation Loss:  0.5003604358860425\n",
      "Epoch:  246  Loss:  0.4578398157493763  Validation Loss:  0.4998424598148891\n",
      "Epoch:  247  Loss:  0.4572515829479525  Validation Loss:  0.49932824543544224\n",
      "Epoch:  248  Loss:  0.45666711032390594  Validation Loss:  0.4988177765692983\n",
      "Epoch:  249  Loss:  0.45608636546191444  Validation Loss:  0.49831097977502004\n",
      "Epoch:  250  Loss:  0.45550926206236203  Validation Loss:  0.49780782759189607\n",
      "Epoch:  251  Loss:  0.45493585252648844  Validation Loss:  0.4973083579114505\n",
      "Epoch:  252  Loss:  0.45436621496180224  Validation Loss:  0.496812672487327\n",
      "Epoch:  253  Loss:  0.45380023432568917  Validation Loss:  0.4963205314108304\n",
      "Epoch:  254  Loss:  0.453237720363513  Validation Loss:  0.49583177715539933\n",
      "Epoch:  255  Loss:  0.4526785482868764  Validation Loss:  0.49534627816506793\n",
      "Epoch:  256  Loss:  0.4521226151294618  Validation Loss:  0.4948638909629413\n",
      "Epoch:  257  Loss:  0.45156975097565855  Validation Loss:  0.49438445823533195\n",
      "Epoch:  258  Loss:  0.4510197775765053  Validation Loss:  0.49390774965286255\n",
      "Epoch:  259  Loss:  0.4504724596207741  Validation Loss:  0.4934334880539349\n",
      "Epoch:  260  Loss:  0.44992752747513104  Validation Loss:  0.4929613722222192\n",
      "Epoch:  261  Loss:  0.4493847588227258  Validation Loss:  0.4924912608095578\n",
      "Epoch:  262  Loss:  0.44884395302754443  Validation Loss:  0.4920229564820017\n",
      "Epoch:  263  Loss:  0.4483049868548651  Validation Loss:  0.49155646626438415\n",
      "Epoch:  264  Loss:  0.447767977183464  Validation Loss:  0.491092023892062\n",
      "Epoch:  265  Loss:  0.4472331627144068  Validation Loss:  0.4906300597957202\n",
      "Epoch:  266  Loss:  0.44670105488944395  Validation Loss:  0.49017105506999153\n",
      "Epoch:  267  Loss:  0.4461720527913333  Validation Loss:  0.4897153513772147\n",
      "Epoch:  268  Loss:  0.44564647796029727  Validation Loss:  0.4892632267304829\n",
      "Epoch:  269  Loss:  0.4451244809616233  Validation Loss:  0.4888147575514657\n",
      "Epoch:  270  Loss:  0.44460617394243934  Validation Loss:  0.4883699868406568\n",
      "Epoch:  271  Loss:  0.4440915763943116  Validation Loss:  0.48792895142521175\n",
      "Epoch:  272  Loss:  0.44358071663650855  Validation Loss:  0.48749166961227147\n",
      "Epoch:  273  Loss:  0.44307363570018965  Validation Loss:  0.48705813246113916\n",
      "Epoch:  274  Loss:  0.44257029749770865  Validation Loss:  0.48662831570420945\n",
      "Epoch:  275  Loss:  0.4420707145997133  Validation Loss:  0.4862022225345884\n",
      "Epoch:  276  Loss:  0.4415748498592332  Validation Loss:  0.48577984337295804\n",
      "Epoch:  277  Loss:  0.4410826371744346  Validation Loss:  0.485361096901553\n",
      "Epoch:  278  Loss:  0.4405940310649962  Validation Loss:  0.48494596694196973\n",
      "Epoch:  279  Loss:  0.4401090099207033  Validation Loss:  0.4845344058104924\n",
      "Epoch:  280  Loss:  0.4396275473996926  Validation Loss:  0.4841264009475708\n",
      "Epoch:  281  Loss:  0.4391496413126941  Validation Loss:  0.4837219761950629\n",
      "Epoch:  282  Loss:  0.438675280360249  Validation Loss:  0.48332110877547946\n",
      "Epoch:  283  Loss:  0.4382044461101152  Validation Loss:  0.48292376505477086\n",
      "Epoch:  284  Loss:  0.4377371271922125  Validation Loss:  0.4825299486517906\n",
      "Epoch:  285  Loss:  0.4372733849061044  Validation Loss:  0.4821397500378745\n",
      "Epoch:  286  Loss:  0.43681318507092826  Validation Loss:  0.48175305894442966\n",
      "Epoch:  287  Loss:  0.4363564423757707  Validation Loss:  0.48136982023715974\n",
      "Epoch:  288  Loss:  0.4359031237697149  Validation Loss:  0.4809900158217975\n",
      "Epoch:  289  Loss:  0.4354532163290051  Validation Loss:  0.4806136122771672\n",
      "Epoch:  290  Loss:  0.4350067152513712  Validation Loss:  0.4802406210984502\n",
      "Epoch:  291  Loss:  0.43456362060743486  Validation Loss:  0.47987104760749\n",
      "Epoch:  292  Loss:  0.4341239134706027  Validation Loss:  0.47950484773942403\n",
      "Epoch:  293  Loss:  0.4336875756911192  Validation Loss:  0.4791420459747314\n",
      "Epoch:  294  Loss:  0.43325459844128217  Validation Loss:  0.4787825546094349\n",
      "Epoch:  295  Loss:  0.4328249476108506  Validation Loss:  0.478426385138716\n",
      "Epoch:  296  Loss:  0.4323986224936083  Validation Loss:  0.4780735324536051\n",
      "Epoch:  297  Loss:  0.43197561073077234  Validation Loss:  0.4777239963412285\n",
      "Epoch:  298  Loss:  0.4315558933957493  Validation Loss:  0.47737773592982974\n",
      "Epoch:  299  Loss:  0.43113944358170314  Validation Loss:  0.47703474164009096\n",
      "Epoch:  300  Loss:  0.43072623989028386  Validation Loss:  0.47669496706553866\n",
      "Epoch:  301  Loss:  0.43031628542884265  Validation Loss:  0.4763584458402225\n",
      "Epoch:  302  Loss:  0.4299095857058656  Validation Loss:  0.47602519605840954\n",
      "Epoch:  303  Loss:  0.4295061388851907  Validation Loss:  0.4756952113338879\n",
      "Epoch:  304  Loss:  0.4291059319018188  Validation Loss:  0.4753684631415776\n",
      "Epoch:  305  Loss:  0.42870894335739984  Validation Loss:  0.47504491316420694\n",
      "Epoch:  306  Loss:  0.4283151539722325  Validation Loss:  0.4747245205300195\n",
      "Epoch:  307  Loss:  0.4279245495513717  Validation Loss:  0.47440726778336934\n",
      "Epoch:  308  Loss:  0.4275371207021424  Validation Loss:  0.47409317387001854\n",
      "Epoch:  309  Loss:  0.42715284750924853  Validation Loss:  0.4737822415573256\n",
      "Epoch:  310  Loss:  0.426771715071529  Validation Loss:  0.4734744416815894\n",
      "Epoch:  311  Loss:  0.42639372925057795  Validation Loss:  0.4731697874409812\n",
      "Epoch:  312  Loss:  0.42601886921301835  Validation Loss:  0.47286824818168366\n",
      "Epoch:  313  Loss:  0.42564712125825654  Validation Loss:  0.4725698615823473\n",
      "Epoch:  314  Loss:  0.4252785134230745  Validation Loss:  0.4722746595740318\n",
      "Epoch:  315  Loss:  0.42491319012867895  Validation Loss:  0.4719828028764044\n",
      "Epoch:  316  Loss:  0.4245510364736991  Validation Loss:  0.4716940224170685\n",
      "Epoch:  317  Loss:  0.4241919533760062  Validation Loss:  0.47140829754727226\n",
      "Epoch:  318  Loss:  0.42383592445138507  Validation Loss:  0.4711256431681769\n",
      "Epoch:  319  Loss:  0.42348291763762164  Validation Loss:  0.470846012873309\n",
      "Epoch:  320  Loss:  0.4231329296861215  Validation Loss:  0.47056938516242164\n",
      "Epoch:  321  Loss:  0.42278591645837393  Validation Loss:  0.4702957225697381\n",
      "Epoch:  322  Loss:  0.42244189440921587  Validation Loss:  0.4700250376548086\n",
      "Epoch:  323  Loss:  0.4221008581007826  Validation Loss:  0.4697573482990265\n",
      "Epoch:  324  Loss:  0.42176273458094393  Validation Loss:  0.4694925016590527\n",
      "Epoch:  325  Loss:  0.4214274946829719  Validation Loss:  0.4692306454692568\n",
      "Epoch:  326  Loss:  0.4210952434212111  Validation Loss:  0.4689717411994934\n",
      "Epoch:  327  Loss:  0.4207659315017727  Validation Loss:  0.4687157635177885\n",
      "Epoch:  328  Loss:  0.4204395717071696  Validation Loss:  0.46846277415752413\n",
      "Epoch:  329  Loss:  0.42011623543585647  Validation Loss:  0.4682129197887012\n",
      "Epoch:  330  Loss:  0.41979579048416626  Validation Loss:  0.46796594624008453\n",
      "Epoch:  331  Loss:  0.41947821608934355  Validation Loss:  0.4677218075309481\n",
      "Epoch:  332  Loss:  0.41916349466660574  Validation Loss:  0.4674805375082152\n",
      "Epoch:  333  Loss:  0.4188516360323576  Validation Loss:  0.46724214873143605\n",
      "Epoch:  334  Loss:  0.41854263227697797  Validation Loss:  0.467006610759667\n",
      "Epoch:  335  Loss:  0.41823644378173974  Validation Loss:  0.4667738954935755\n",
      "Epoch:  336  Loss:  0.41793307499580473  Validation Loss:  0.46654400825500486\n",
      "Epoch:  337  Loss:  0.4176325019078232  Validation Loss:  0.4663169220089912\n",
      "Epoch:  338  Loss:  0.41733471554884977  Validation Loss:  0.4660926141909191\n",
      "Epoch:  339  Loss:  0.41703967990185975  Validation Loss:  0.4658711073654039\n",
      "Epoch:  340  Loss:  0.41674740450077147  Validation Loss:  0.46565235895769935\n",
      "Epoch:  341  Loss:  0.4164578578483437  Validation Loss:  0.46543634427445274\n",
      "Epoch:  342  Loss:  0.4161710520914946  Validation Loss:  0.4652231461235455\n",
      "Epoch:  343  Loss:  0.4158870747304076  Validation Loss:  0.4650127010686057\n",
      "Epoch:  344  Loss:  0.41560579108965906  Validation Loss:  0.46480482199362344\n",
      "Epoch:  345  Loss:  0.4153271186125787  Validation Loss:  0.46459942225899015\n",
      "Epoch:  346  Loss:  0.41505103462962745  Validation Loss:  0.46439660659858156\n",
      "Epoch:  347  Loss:  0.41477754323685906  Validation Loss:  0.46419633477926253\n",
      "Epoch:  348  Loss:  0.41450660636922193  Validation Loss:  0.4639985976474626\n",
      "Epoch:  349  Loss:  0.4142381974023665  Validation Loss:  0.46380334815808705\n",
      "Epoch:  350  Loss:  0.4139722914774836  Validation Loss:  0.46361057949917656\n",
      "Epoch:  351  Loss:  0.41370885794479134  Validation Loss:  0.46342026250702995\n",
      "Epoch:  352  Loss:  0.4134478560556168  Validation Loss:  0.46323233140366415\n",
      "Epoch:  353  Loss:  0.41318922415728815  Validation Loss:  0.46304671998534885\n",
      "Epoch:  354  Loss:  0.4129329017977014  Validation Loss:  0.46286337290491375\n",
      "Epoch:  355  Loss:  0.4126788270416983  Validation Loss:  0.4626822135278157\n",
      "Epoch:  356  Loss:  0.4124269236885541  Validation Loss:  0.46250312945672445\n",
      "Epoch:  357  Loss:  0.4121770848171406  Validation Loss:  0.46232596380370006\n",
      "Epoch:  358  Loss:  0.4119291061897413  Validation Loss:  0.4621504342981747\n",
      "Epoch:  359  Loss:  0.4116827690912084  Validation Loss:  0.46197636404207776\n",
      "Epoch:  360  Loss:  0.41143798220779093  Validation Loss:  0.4618036253111703\n",
      "Epoch:  361  Loss:  0.4111945752001487  Validation Loss:  0.4616319745779037\n",
      "Epoch:  362  Loss:  0.41095228005924495  Validation Loss:  0.461461036333016\n",
      "Epoch:  363  Loss:  0.4107106999622137  Validation Loss:  0.46129034055130824\n",
      "Epoch:  364  Loss:  0.41046940100983986  Validation Loss:  0.46111938506364825\n",
      "Epoch:  365  Loss:  0.410227990122203  Validation Loss:  0.4609477664743151\n",
      "Epoch:  366  Loss:  0.40998622252477857  Validation Loss:  0.4607753187417984\n",
      "Epoch:  367  Loss:  0.40974411650856524  Validation Loss:  0.4606023207306862\n",
      "Epoch:  368  Loss:  0.4095021508881266  Validation Loss:  0.4604294429932322\n",
      "Epoch:  369  Loss:  0.40926097884279855  Validation Loss:  0.4602574757167271\n",
      "Epoch:  370  Loss:  0.4090212411225125  Validation Loss:  0.4600870907306671\n",
      "Epoch:  371  Loss:  0.4087833880813201  Validation Loss:  0.4599187101636614\n",
      "Epoch:  372  Loss:  0.4085476857508528  Validation Loss:  0.45975257073129927\n",
      "Epoch:  373  Loss:  0.40831427156077743  Validation Loss:  0.4595887841922896\n",
      "Epoch:  374  Loss:  0.40808316323711974  Validation Loss:  0.45942735012088504\n",
      "Epoch:  375  Loss:  0.4078543256103145  Validation Loss:  0.45926817038229534\n",
      "Epoch:  376  Loss:  0.40762768212652883  Validation Loss:  0.45911120836223873\n",
      "Epoch:  377  Loss:  0.4074031768534421  Validation Loss:  0.4589563993471009\n",
      "Epoch:  378  Loss:  0.4071807799887318  Validation Loss:  0.45880374780723027\n",
      "Epoch:  379  Loss:  0.4069605505014483  Validation Loss:  0.4586533714618002\n",
      "Epoch:  380  Loss:  0.40674257539742364  Validation Loss:  0.4585053831338882\n",
      "Epoch:  381  Loss:  0.4065269178123836  Validation Loss:  0.458359837106296\n",
      "Epoch:  382  Loss:  0.40631362026054146  Validation Loss:  0.45821673231465476\n",
      "Epoch:  383  Loss:  0.4061026905808969  Validation Loss:  0.45807609281369616\n",
      "Epoch:  384  Loss:  0.4058941339994494  Validation Loss:  0.45793791306870324\n",
      "Epoch:  385  Loss:  0.40568788632114916  Validation Loss:  0.45780206258807865\n",
      "Epoch:  386  Loss:  0.40548392946686224  Validation Loss:  0.45766859906060353\n",
      "Epoch:  387  Loss:  0.40528227431231767  Validation Loss:  0.4575375131198338\n",
      "Epoch:  388  Loss:  0.4050828830749503  Validation Loss:  0.4574088237115315\n",
      "Epoch:  389  Loss:  0.4048857582265167  Validation Loss:  0.4572824942214148\n",
      "Epoch:  390  Loss:  0.40469086848164054  Validation Loss:  0.4571584991046361\n",
      "Epoch:  391  Loss:  0.4044981845323508  Validation Loss:  0.4570368055786405\n",
      "Epoch:  392  Loss:  0.40430771280521466  Validation Loss:  0.45691744663885664\n",
      "Epoch:  393  Loss:  0.4041194749104468  Validation Loss:  0.4568004889147622\n",
      "Epoch:  394  Loss:  0.40393347381415523  Validation Loss:  0.45668592772313527\n",
      "Epoch:  395  Loss:  0.4037497046434484  Validation Loss:  0.45657375561339514\n",
      "Epoch:  396  Loss:  0.4035680478359286  Validation Loss:  0.45646382847002576\n",
      "Epoch:  397  Loss:  0.40338843305246525  Validation Loss:  0.45635614054543633\n",
      "Epoch:  398  Loss:  0.4032108408014921  Validation Loss:  0.4562506984387125\n",
      "Epoch:  399  Loss:  0.4030352415631733  Validation Loss:  0.45614747192178456\n",
      "Epoch:  400  Loss:  0.40286156965940484  Validation Loss:  0.45604643566267833\n",
      "Epoch:  401  Loss:  0.4026897547510563  Validation Loss:  0.45594755602734427\n",
      "Epoch:  402  Loss:  0.4025197490979145  Validation Loss:  0.45585082918405534\n",
      "Epoch:  403  Loss:  0.4023515275586838  Validation Loss:  0.45575633602482934\n",
      "Epoch:  404  Loss:  0.40218503123493554  Validation Loss:  0.4556640292916979\n",
      "Epoch:  405  Loss:  0.40202016372816257  Validation Loss:  0.4555739311235292\n",
      "Epoch:  406  Loss:  0.401856773978726  Validation Loss:  0.4554859067712511\n",
      "Epoch:  407  Loss:  0.4016947468733901  Validation Loss:  0.4554000656519617\n",
      "Epoch:  408  Loss:  0.4015338882027079  Validation Loss:  0.4553163664681571\n",
      "Epoch:  409  Loss:  0.4013739720481267  Validation Loss:  0.45523478197199957\n",
      "Epoch:  410  Loss:  0.40121478266060634  Validation Loss:  0.45515544371945516\n",
      "Epoch:  411  Loss:  0.40105606410740674  Validation Loss:  0.45507831424474715\n",
      "Epoch:  412  Loss:  0.4008975845377592  Validation Loss:  0.455003416963986\n",
      "Epoch:  413  Loss:  0.4007392621718312  Validation Loss:  0.45493072250059674\n",
      "Epoch:  414  Loss:  0.40058120195334557  Validation Loss:  0.4548600805657251\n",
      "Epoch:  415  Loss:  0.40042378982943944  Validation Loss:  0.45479152351617813\n",
      "Epoch:  416  Loss:  0.40026749882370377  Validation Loss:  0.45472507902554105\n",
      "Epoch:  417  Loss:  0.40011269525046594  Validation Loss:  0.4546606527907508\n",
      "Epoch:  418  Loss:  0.399959611666711  Validation Loss:  0.45459815348897664\n",
      "Epoch:  419  Loss:  0.3998083534398915  Validation Loss:  0.4545375664319311\n",
      "Epoch:  420  Loss:  0.39965901230748796  Validation Loss:  0.45447896889277867\n",
      "Epoch:  421  Loss:  0.39951165945609035  Validation Loss:  0.4544223155294146\n",
      "Epoch:  422  Loss:  0.39936618542219227  Validation Loss:  0.4543674253991672\n",
      "Epoch:  423  Loss:  0.3992225808131186  Validation Loss:  0.4543144017457962\n",
      "Epoch:  424  Loss:  0.3990809158267568  Validation Loss:  0.45426335143191476\n",
      "Epoch:  425  Loss:  0.3989411656042976  Validation Loss:  0.4542141724910055\n",
      "Epoch:  426  Loss:  0.3988032146793971  Validation Loss:  0.4541668236255646\n",
      "Epoch:  427  Loss:  0.39866711086289014  Validation Loss:  0.45412141127245764\n",
      "Epoch:  428  Loss:  0.39853281919707617  Validation Loss:  0.45407785177230836\n",
      "Epoch:  429  Loss:  0.3984002970971202  Validation Loss:  0.4540362421955381\n",
      "Epoch:  430  Loss:  0.3982695728116691  Validation Loss:  0.45399651633841653\n",
      "Epoch:  431  Loss:  0.398140536382865  Validation Loss:  0.4539586254528591\n",
      "Epoch:  432  Loss:  0.3980131857626811  Validation Loss:  0.453922624034541\n",
      "Epoch:  433  Loss:  0.39788749475049745  Validation Loss:  0.4538885467818805\n",
      "Epoch:  434  Loss:  0.3977634139111822  Validation Loss:  0.45385630343641553\n",
      "Epoch:  435  Loss:  0.3976408952926572  Validation Loss:  0.4538259031517165\n",
      "Epoch:  436  Loss:  0.3975199364231661  Validation Loss:  0.45379741000277657\n",
      "Epoch:  437  Loss:  0.3974004960596844  Validation Loss:  0.4537708103656769\n",
      "Epoch:  438  Loss:  0.39728252617951254  Validation Loss:  0.45374614745378494\n",
      "Epoch:  439  Loss:  0.39716601110465155  Validation Loss:  0.45372349194117956\n",
      "Epoch:  440  Loss:  0.39705088875870004  Validation Loss:  0.45370287214006694\n",
      "Epoch:  441  Loss:  0.39693708795506805  Validation Loss:  0.4536842631442206\n",
      "Epoch:  442  Loss:  0.3968245333404903  Validation Loss:  0.4536677296672549\n",
      "Epoch:  443  Loss:  0.39671314708994465  Validation Loss:  0.4536532631942204\n",
      "Epoch:  444  Loss:  0.3966027837229001  Validation Loss:  0.45364092141389845\n",
      "Epoch:  445  Loss:  0.39649331583795955  Validation Loss:  0.4536307228463037\n",
      "Epoch:  446  Loss:  0.3963846411750215  Validation Loss:  0.4536228514143399\n",
      "Epoch:  447  Loss:  0.396276583250665  Validation Loss:  0.4536174156836101\n",
      "Epoch:  448  Loss:  0.3961689731379821  Validation Loss:  0.45361463470118385\n",
      "Epoch:  449  Loss:  0.39606153216407197  Validation Loss:  0.45361473145229475\n",
      "Epoch:  450  Loss:  0.39595397226335877  Validation Loss:  0.4536179988511971\n",
      "Epoch:  451  Loss:  0.3958458967542196  Validation Loss:  0.4536248576428209\n",
      "Epoch:  452  Loss:  0.3957368273164424  Validation Loss:  0.4536357147353036\n",
      "Epoch:  453  Loss:  0.3956260893723411  Validation Loss:  0.45365101088370596\n",
      "Epoch:  454  Loss:  0.39551311872581735  Validation Loss:  0.45367140823176927\n",
      "Epoch:  455  Loss:  0.3953974102204445  Validation Loss:  0.45369732997247153\n",
      "Epoch:  456  Loss:  0.3952787405859803  Validation Loss:  0.45372852055089813\n",
      "Epoch:  457  Loss:  0.3951572368354029  Validation Loss:  0.45376410824911934\n",
      "Epoch:  458  Loss:  0.3950334002056393  Validation Loss:  0.4538026139140129\n",
      "Epoch:  459  Loss:  0.3949078966938489  Validation Loss:  0.4538422149206911\n",
      "Epoch:  460  Loss:  0.3947813545499368  Validation Loss:  0.4538818558411939\n",
      "Epoch:  461  Loss:  0.394654618161267  Validation Loss:  0.4539213282721383\n",
      "Epoch:  462  Loss:  0.39452852121602866  Validation Loss:  0.4539609640836716\n",
      "Epoch:  463  Loss:  0.39440381756467274  Validation Loss:  0.45400130078196527\n",
      "Epoch:  464  Loss:  0.3942810541363124  Validation Loss:  0.45404283393706596\n",
      "Epoch:  465  Loss:  0.3941605594980208  Validation Loss:  0.4540857620537281\n",
      "Epoch:  466  Loss:  0.39404249600889557  Validation Loss:  0.45413036942481994\n",
      "Epoch:  467  Loss:  0.3939270071014409  Validation Loss:  0.4541767868612494\n",
      "Epoch:  468  Loss:  0.3938140703179825  Validation Loss:  0.45422495252319744\n",
      "Epoch:  469  Loss:  0.39370371387185643  Validation Loss:  0.4542750358581543\n",
      "Epoch:  470  Loss:  0.39359581774162455  Validation Loss:  0.4543268745498998\n",
      "Epoch:  471  Loss:  0.39349036667301757  Validation Loss:  0.4543806099465915\n",
      "Epoch:  472  Loss:  0.39338734184537455  Validation Loss:  0.45443625418203215\n",
      "Epoch:  473  Loss:  0.39328671956514294  Validation Loss:  0.45449382088014056\n",
      "Epoch:  474  Loss:  0.3931884194649226  Validation Loss:  0.45455318497759956\n",
      "Epoch:  475  Loss:  0.3930923368481663  Validation Loss:  0.4546142928302288\n",
      "Epoch:  476  Loss:  0.39299847510471164  Validation Loss:  0.4546772375702858\n",
      "Epoch:  477  Loss:  0.39290682579527536  Validation Loss:  0.45474201323730606\n",
      "Epoch:  478  Loss:  0.3928172663913519  Validation Loss:  0.45480840035847253\n",
      "Epoch:  479  Loss:  0.39272977694233446  Validation Loss:  0.4548765010067395\n",
      "Epoch:  480  Loss:  0.39264438266014035  Validation Loss:  0.45494635392512595\n",
      "Epoch:  481  Loss:  0.392561016524855  Validation Loss:  0.45501787109034403\n",
      "Epoch:  482  Loss:  0.3924796114459422  Validation Loss:  0.4550909892788955\n",
      "Epoch:  483  Loss:  0.3924002217667363  Validation Loss:  0.45516587176493234\n",
      "Epoch:  484  Loss:  0.3923227636946886  Validation Loss:  0.4552422722535474\n",
      "Epoch:  485  Loss:  0.39224718804184294  Validation Loss:  0.4553203212363379\n",
      "Epoch:  486  Loss:  0.3921735190314139  Validation Loss:  0.4553999554898058\n",
      "Epoch:  487  Loss:  0.3921016041560196  Validation Loss:  0.4554809320185866\n",
      "Epoch:  488  Loss:  0.3920313797149613  Validation Loss:  0.4555632112281663\n",
      "Epoch:  489  Loss:  0.39196275428855587  Validation Loss:  0.4556466156882899\n",
      "Epoch:  490  Loss:  0.3918957692963817  Validation Loss:  0.4557313705129283\n",
      "Epoch:  491  Loss:  0.3918304145689259  Validation Loss:  0.4558173716068268\n",
      "Epoch:  492  Loss:  0.39176668978839124  Validation Loss:  0.4559047271098409\n",
      "Epoch:  493  Loss:  0.39170452521593085  Validation Loss:  0.4559931915785585\n",
      "Epoch:  494  Loss:  0.39164391078796434  Validation Loss:  0.4560829404209341\n",
      "Epoch:  495  Loss:  0.3915848141597911  Validation Loss:  0.45617380546672004\n",
      "Epoch:  496  Loss:  0.391527215063007  Validation Loss:  0.45626571221011025\n",
      "Epoch:  497  Loss:  0.39147094555940676  Validation Loss:  0.4563584653394563\n",
      "Epoch:  498  Loss:  0.3914159158536043  Validation Loss:  0.4564519149916513\n",
      "Epoch:  499  Loss:  0.3913620835373187  Validation Loss:  0.4565460173147065\n",
      "Epoch:  500  Loss:  0.3913093642177175  Validation Loss:  0.4566406104181494\n",
      "Epoch:  501  Loss:  0.3912575564466382  Validation Loss:  0.4567353903182915\n",
      "Epoch:  502  Loss:  0.3912064767491196  Validation Loss:  0.4568301016730922\n",
      "Epoch:  503  Loss:  0.3911558936275012  Validation Loss:  0.4569243293787752\n",
      "Epoch:  504  Loss:  0.39110551753315315  Validation Loss:  0.4570176387471812\n",
      "Epoch:  505  Loss:  0.39105493818979126  Validation Loss:  0.4571092974926744\n",
      "Epoch:  506  Loss:  0.3910036519593537  Validation Loss:  0.45719858227031573\n",
      "Epoch:  507  Loss:  0.39095119591714084  Validation Loss:  0.45728482444371493\n",
      "Epoch:  508  Loss:  0.3908970525832538  Validation Loss:  0.45736721881798337\n",
      "Epoch:  509  Loss:  0.3908409373878868  Validation Loss:  0.4574456903551306\n",
      "Epoch:  510  Loss:  0.39078299312794945  Validation Loss:  0.45752062084419387\n",
      "Epoch:  511  Loss:  0.3907237414853268  Validation Loss:  0.45759303899747983\n",
      "Epoch:  512  Loss:  0.3906639214093086  Validation Loss:  0.4576641330761569\n",
      "Epoch:  513  Loss:  0.3906042320539036  Validation Loss:  0.4577348930495126\n",
      "Epoch:  514  Loss:  0.3905451736320252  Validation Loss:  0.4578059645635741\n",
      "Epoch:  515  Loss:  0.3904870203321014  Validation Loss:  0.45787762658936637\n",
      "Epoch:  516  Loss:  0.3904298514975191  Validation Loss:  0.4579499425632613\n",
      "Epoch:  517  Loss:  0.390373711973005  Validation Loss:  0.45802295761448997\n",
      "Epoch:  518  Loss:  0.3903185918715328  Validation Loss:  0.4580966257623264\n",
      "Epoch:  519  Loss:  0.3902643811646231  Validation Loss:  0.458170655050448\n",
      "Epoch:  520  Loss:  0.39021086774024916  Validation Loss:  0.4582447899239404\n",
      "Epoch:  521  Loss:  0.3901578943593807  Validation Loss:  0.4583187255476202\n",
      "Epoch:  522  Loss:  0.3901052660710439  Validation Loss:  0.45839217017803874\n",
      "Epoch:  523  Loss:  0.39005273026171455  Validation Loss:  0.458464672097138\n",
      "Epoch:  524  Loss:  0.3899999365422398  Validation Loss:  0.4585355678839343\n",
      "Epoch:  525  Loss:  0.3899464777789975  Validation Loss:  0.458604239991733\n",
      "Epoch:  526  Loss:  0.3898918703198433  Validation Loss:  0.45866979690534726\n",
      "Epoch:  527  Loss:  0.38983538693867587  Validation Loss:  0.4587309024163655\n",
      "Epoch:  528  Loss:  0.389776239710114  Validation Loss:  0.4587863028049469\n",
      "Epoch:  529  Loss:  0.3897135444868232  Validation Loss:  0.4588345617055893\n",
      "Epoch:  530  Loss:  0.3896462839644102  Validation Loss:  0.4588741399347782\n",
      "Epoch:  531  Loss:  0.38957369352262733  Validation Loss:  0.4589041763118335\n",
      "Epoch:  532  Loss:  0.3894956630623736  Validation Loss:  0.4589251737509455\n",
      "Epoch:  533  Loss:  0.38941294911772156  Validation Loss:  0.4589388944208622\n",
      "Epoch:  534  Loss:  0.38932706242630266  Validation Loss:  0.4589480503329209\n",
      "Epoch:  535  Loss:  0.38923964384607795  Validation Loss:  0.458955125191382\n",
      "Epoch:  536  Loss:  0.3891520637895259  Validation Loss:  0.4589619125638689\n",
      "Epoch:  537  Loss:  0.3890652632190718  Validation Loss:  0.45896963551640513\n",
      "Epoch:  538  Loss:  0.3889797524465204  Validation Loss:  0.4589788531618459\n",
      "Epoch:  539  Loss:  0.38889585347113453  Validation Loss:  0.45898989556091174\n",
      "Epoch:  540  Loss:  0.3888136395981526  Validation Loss:  0.459002865425178\n",
      "Epoch:  541  Loss:  0.3887331850155835  Validation Loss:  0.4590177936213357\n",
      "Epoch:  542  Loss:  0.3886544620397532  Validation Loss:  0.4590346184160028\n",
      "Epoch:  543  Loss:  0.3885774684460807  Validation Loss:  0.45905329776661735\n",
      "Epoch:  544  Loss:  0.38850213869770556  Validation Loss:  0.45907377398439814\n",
      "Epoch:  545  Loss:  0.38842842911515757  Validation Loss:  0.4590959431869643\n",
      "Epoch:  546  Loss:  0.3883562761742922  Validation Loss:  0.45911970543009895\n",
      "Epoch:  547  Loss:  0.38828564622390893  Validation Loss:  0.4591450345303331\n",
      "Epoch:  548  Loss:  0.38821647069041765  Validation Loss:  0.45917178083743365\n",
      "Epoch:  549  Loss:  0.3881486922996869  Validation Loss:  0.459199873570885\n",
      "Epoch:  550  Loss:  0.3880822341447758  Validation Loss:  0.4592292353510857\n",
      "Epoch:  551  Loss:  0.38801709947427865  Validation Loss:  0.4592597863503865\n",
      "Epoch:  552  Loss:  0.38795322684738875  Validation Loss:  0.45929151230624743\n",
      "Epoch:  553  Loss:  0.38789058589681064  Validation Loss:  0.459324306675366\n",
      "Epoch:  554  Loss:  0.38782912295011546  Validation Loss:  0.45935810676642824\n",
      "Epoch:  555  Loss:  0.387768780874415  Validation Loss:  0.4593928220016616\n",
      "Epoch:  556  Loss:  0.38770952301709005  Validation Loss:  0.4594283645706517\n",
      "Epoch:  557  Loss:  0.38765128698394197  Validation Loss:  0.45946464112826757\n",
      "Epoch:  558  Loss:  0.3875939971039081  Validation Loss:  0.4595015306557928\n",
      "Epoch:  559  Loss:  0.3875375833203442  Validation Loss:  0.459538955028568\n",
      "Epoch:  560  Loss:  0.3874819618760127  Validation Loss:  0.459576752781868\n",
      "Epoch:  561  Loss:  0.3874270288865148  Validation Loss:  0.45961481439215796\n",
      "Epoch:  562  Loss:  0.3873726952626807  Validation Loss:  0.45965294327054707\n",
      "Epoch:  563  Loss:  0.38731880401265567  Validation Loss:  0.45969092324376104\n",
      "Epoch:  564  Loss:  0.3872652008988281  Validation Loss:  0.4597285379256521\n",
      "Epoch:  565  Loss:  0.38721177024298936  Validation Loss:  0.4597655682691506\n",
      "Epoch:  566  Loss:  0.38715840547711927  Validation Loss:  0.4598018670720713\n",
      "Epoch:  567  Loss:  0.3871050230205342  Validation Loss:  0.4598372561591012\n",
      "Epoch:  568  Loss:  0.3870516760866224  Validation Loss:  0.45987166655915124\n",
      "Epoch:  569  Loss:  0.3869983867446393  Validation Loss:  0.4599049758698259\n",
      "Epoch:  570  Loss:  0.38694519976869013  Validation Loss:  0.4599369228950569\n",
      "Epoch:  571  Loss:  0.3868920185130919  Validation Loss:  0.4599672217454229\n",
      "Epoch:  572  Loss:  0.3868387699904035  Validation Loss:  0.4599954443318503\n",
      "Epoch:  573  Loss:  0.3867851674415489  Validation Loss:  0.46002083527190346\n",
      "Epoch:  574  Loss:  0.3867308400324171  Validation Loss:  0.46004249336464065\n",
      "Epoch:  575  Loss:  0.3866753638920626  Validation Loss:  0.46005930804780554\n",
      "Epoch:  576  Loss:  0.38661829728227093  Validation Loss:  0.4600702287895339\n",
      "Epoch:  577  Loss:  0.3865591736060183  Validation Loss:  0.4600736416876316\n",
      "Epoch:  578  Loss:  0.3864971839986141  Validation Loss:  0.4600675567984581\n",
      "Epoch:  579  Loss:  0.3864315837551067  Validation Loss:  0.46004985932792936\n",
      "Epoch:  580  Loss:  0.3863618534535028  Validation Loss:  0.4600186988711357\n",
      "Epoch:  581  Loss:  0.38628775245064245  Validation Loss:  0.45997296763317924\n",
      "Epoch:  582  Loss:  0.3862095374561034  Validation Loss:  0.4599126752998148\n",
      "Epoch:  583  Loss:  0.38612799455910496  Validation Loss:  0.45983944205301147\n",
      "Epoch:  584  Loss:  0.3860441052235698  Validation Loss:  0.4597561966095652\n",
      "Epoch:  585  Loss:  0.38595907227687926  Validation Loss:  0.45966677559273583\n",
      "Epoch:  586  Loss:  0.38587398029051684  Validation Loss:  0.4595746400100844\n",
      "Epoch:  587  Loss:  0.38578966408261756  Validation Loss:  0.45948230528405737\n",
      "Epoch:  588  Loss:  0.3857065297274793  Validation Loss:  0.45939115924494606\n",
      "Epoch:  589  Loss:  0.3856248352058691  Validation Loss:  0.45930207212056434\n",
      "Epoch:  590  Loss:  0.3855447133570486  Validation Loss:  0.45921542740293914\n",
      "Epoch:  591  Loss:  0.3854662584255657  Validation Loss:  0.4591314271092415\n",
      "Epoch:  592  Loss:  0.3853894035680599  Validation Loss:  0.45904990913612503\n",
      "Epoch:  593  Loss:  0.3853140320823091  Validation Loss:  0.45897082718355314\n",
      "Epoch:  594  Loss:  0.3852401433680295  Validation Loss:  0.4588941634765693\n",
      "Epoch:  595  Loss:  0.38516771856924936  Validation Loss:  0.4588198333978653\n",
      "Epoch:  596  Loss:  0.3850967735758325  Validation Loss:  0.45874774307012556\n",
      "Epoch:  597  Loss:  0.38502720114885347  Validation Loss:  0.45867772017206465\n",
      "Epoch:  598  Loss:  0.3849589423192621  Validation Loss:  0.45860962101391384\n",
      "Epoch:  599  Loss:  0.3848918988876998  Validation Loss:  0.4585433948252882\n",
      "Epoch:  600  Loss:  0.38482607579767986  Validation Loss:  0.4584789664617607\n",
      "Epoch:  601  Loss:  0.3847615003444572  Validation Loss:  0.4584163835006101\n",
      "Epoch:  602  Loss:  0.3846982311086632  Validation Loss:  0.4583555983645575\n",
      "Epoch:  603  Loss:  0.3846361181606049  Validation Loss:  0.4582964115909168\n",
      "Epoch:  604  Loss:  0.384575117644258  Validation Loss:  0.4582386870469366\n",
      "Epoch:  605  Loss:  0.3845151940369493  Validation Loss:  0.4581824962581907\n",
      "Epoch:  606  Loss:  0.3844563984687294  Validation Loss:  0.45812776993427956\n",
      "Epoch:  607  Loss:  0.38439865096061715  Validation Loss:  0.4580744454903262\n",
      "Epoch:  608  Loss:  0.3843419632711117  Validation Loss:  0.4580225783799376\n",
      "Epoch:  609  Loss:  0.38428639394553354  Validation Loss:  0.4579721447612558\n",
      "Epoch:  610  Loss:  0.3842318103564859  Validation Loss:  0.4579229322927339\n",
      "Epoch:  611  Loss:  0.3841781585843642  Validation Loss:  0.4578748810504164\n",
      "Epoch:  612  Loss:  0.3841254977041511  Validation Loss:  0.45782812918935506\n",
      "Epoch:  613  Loss:  0.3840737658159993  Validation Loss:  0.4577825621834823\n",
      "Epoch:  614  Loss:  0.38402302873925576  Validation Loss:  0.4577382842344897\n",
      "Epoch:  615  Loss:  0.38397329671405506  Validation Loss:  0.4576952984290464\n",
      "Epoch:  616  Loss:  0.38392452048181924  Validation Loss:  0.45765342616609167\n",
      "Epoch:  617  Loss:  0.38387662719635035  Validation Loss:  0.4576127445059163\n",
      "Epoch:  618  Loss:  0.3838295873025017  Validation Loss:  0.4575731092265674\n",
      "Epoch:  619  Loss:  0.3837833860050445  Validation Loss:  0.4575345435312816\n",
      "Epoch:  620  Loss:  0.383737977541171  Validation Loss:  0.45749692991375923\n",
      "Epoch:  621  Loss:  0.3836933792837988  Validation Loss:  0.4574603583131518\n",
      "Epoch:  622  Loss:  0.3836496103713863  Validation Loss:  0.4574248185115201\n",
      "Epoch:  623  Loss:  0.383606593049533  Validation Loss:  0.4573901711830071\n",
      "Epoch:  624  Loss:  0.38356419748039605  Validation Loss:  0.4573562019637653\n",
      "Epoch:  625  Loss:  0.3835223510649532  Validation Loss:  0.4573228468852384\n",
      "Epoch:  626  Loss:  0.38348104956590734  Validation Loss:  0.4572902586843286\n",
      "Epoch:  627  Loss:  0.3834404078493186  Validation Loss:  0.4572585373052529\n",
      "Epoch:  628  Loss:  0.3834004004914049  Validation Loss:  0.45722764677235056\n",
      "Epoch:  629  Loss:  0.38336097816296666  Validation Loss:  0.4571975270552295\n",
      "Epoch:  630  Loss:  0.38332209047548016  Validation Loss:  0.4571682490408421\n",
      "Epoch:  631  Loss:  0.38328374152499917  Validation Loss:  0.45713971448796137\n",
      "Epoch:  632  Loss:  0.38324579024484373  Validation Loss:  0.45711186123745784\n",
      "Epoch:  633  Loss:  0.38320818847107097  Validation Loss:  0.45708463404859817\n",
      "Epoch:  634  Loss:  0.38317088426148155  Validation Loss:  0.4570580634687628\n",
      "Epoch:  635  Loss:  0.3831337551581916  Validation Loss:  0.4570319516318185\n",
      "Epoch:  636  Loss:  0.383096646641103  Validation Loss:  0.45700627767613955\n",
      "Epoch:  637  Loss:  0.38305940599096894  Validation Loss:  0.45698095677154404\n",
      "Epoch:  638  Loss:  0.38302178673834597  Validation Loss:  0.4569557807275227\n",
      "Epoch:  639  Loss:  0.3829834703797413  Validation Loss:  0.4569305562547275\n",
      "Epoch:  640  Loss:  0.3829440828677602  Validation Loss:  0.45690507888793946\n",
      "Epoch:  641  Loss:  0.3829032122311999  Validation Loss:  0.45687909722328185\n",
      "Epoch:  642  Loss:  0.3828603449096612  Validation Loss:  0.45685228439314024\n",
      "Epoch:  643  Loss:  0.3828149804783658  Validation Loss:  0.4568242746804442\n",
      "Epoch:  644  Loss:  0.3827669094735977  Validation Loss:  0.45679505446127483\n",
      "Epoch:  645  Loss:  0.38271632098473646  Validation Loss:  0.4567648523620197\n",
      "Epoch:  646  Loss:  0.38266380537318956  Validation Loss:  0.45673400280731064\n",
      "Epoch:  647  Loss:  0.38261018216751197  Validation Loss:  0.45670292835150444\n",
      "Epoch:  648  Loss:  0.38255614759091516  Validation Loss:  0.4566719093493053\n",
      "Epoch:  649  Loss:  0.3825022494199717  Validation Loss:  0.4566411398351192\n",
      "Epoch:  650  Loss:  0.38244877949851386  Validation Loss:  0.4566106573811599\n",
      "Epoch:  651  Loss:  0.38239589672518004  Validation Loss:  0.45658042164785523\n",
      "Epoch:  652  Loss:  0.38234356098689176  Validation Loss:  0.4565501806991441\n",
      "Epoch:  653  Loss:  0.38229161698671316  Validation Loss:  0.4565195864864758\n",
      "Epoch:  654  Loss:  0.3822400322740112  Validation Loss:  0.4564886998917375\n",
      "Epoch:  655  Loss:  0.38218878149562535  Validation Loss:  0.45645733986582077\n",
      "Epoch:  656  Loss:  0.38213771754672743  Validation Loss:  0.4564252396779401\n",
      "Epoch:  657  Loss:  0.3820867660627546  Validation Loss:  0.45639212184718675\n",
      "Epoch:  658  Loss:  0.3820357657439336  Validation Loss:  0.45635758712887764\n",
      "Epoch:  659  Loss:  0.38198445472530845  Validation Loss:  0.45632115272539003\n",
      "Epoch:  660  Loss:  0.3819326172578391  Validation Loss:  0.456282566594226\n",
      "Epoch:  661  Loss:  0.3818801821196249  Validation Loss:  0.4562419128205095\n",
      "Epoch:  662  Loss:  0.3818272493461862  Validation Loss:  0.45619975913848193\n",
      "Epoch:  663  Loss:  0.3817741485639206  Validation Loss:  0.4561568005808762\n",
      "Epoch:  664  Loss:  0.38172115915194504  Validation Loss:  0.4561137057840824\n",
      "Epoch:  665  Loss:  0.3816685818877265  Validation Loss:  0.4560709564813546\n",
      "Epoch:  666  Loss:  0.38161650741411046  Validation Loss:  0.45602873265743255\n",
      "Epoch:  667  Loss:  0.38156503982736034  Validation Loss:  0.455987179598638\n",
      "Epoch:  668  Loss:  0.3815142142264199  Validation Loss:  0.4559464035289628\n",
      "Epoch:  669  Loss:  0.3814640851664882  Validation Loss:  0.45590646362730436\n",
      "Epoch:  670  Loss:  0.3814144894763192  Validation Loss:  0.4558668752866132\n",
      "Epoch:  671  Loss:  0.38136540607536007  Validation Loss:  0.4558279577110495\n",
      "Epoch:  672  Loss:  0.38131701285946423  Validation Loss:  0.45578985288739204\n",
      "Epoch:  673  Loss:  0.38126930562664546  Validation Loss:  0.4557526297867298\n",
      "Epoch:  674  Loss:  0.38122226746302645  Validation Loss:  0.4557161830365658\n",
      "Epoch:  675  Loss:  0.3811758463557863  Validation Loss:  0.45568047421319147\n",
      "Epoch:  676  Loss:  0.38113007246035535  Validation Loss:  0.4556455247104168\n",
      "Epoch:  677  Loss:  0.3810849091241145  Validation Loss:  0.4556112487401281\n",
      "Epoch:  678  Loss:  0.3810403480490237  Validation Loss:  0.4555776025567736\n",
      "Epoch:  679  Loss:  0.3809963764525703  Validation Loss:  0.45554469600319863\n",
      "Epoch:  680  Loss:  0.3809530042924022  Validation Loss:  0.45551249821271217\n",
      "Epoch:  681  Loss:  0.3809101340753772  Validation Loss:  0.45548085070082117\n",
      "Epoch:  682  Loss:  0.3808675137882549  Validation Loss:  0.4554492323526314\n",
      "Epoch:  683  Loss:  0.3808252780005265  Validation Loss:  0.4554181720529284\n",
      "Epoch:  684  Loss:  0.38078355316019735  Validation Loss:  0.4553878175360816\n",
      "Epoch:  685  Loss:  0.38074236635065756  Validation Loss:  0.45535809025168417\n",
      "Epoch:  686  Loss:  0.38070151852487955  Validation Loss:  0.4553288495966366\n",
      "Epoch:  687  Loss:  0.3806611225715181  Validation Loss:  0.4553002279783998\n",
      "Epoch:  688  Loss:  0.38062118784793747  Validation Loss:  0.4552723137395723\n",
      "Epoch:  689  Loss:  0.38058172830190706  Validation Loss:  0.4552449893738542\n",
      "Epoch:  690  Loss:  0.38054247581845774  Validation Loss:  0.4552178215767656\n",
      "Epoch:  691  Loss:  0.38050318304537595  Validation Loss:  0.4551905872566359\n",
      "Epoch:  692  Loss:  0.38046402371183957  Validation Loss:  0.4551637923078878\n",
      "Epoch:  693  Loss:  0.3804249861652817  Validation Loss:  0.45513739181416374\n",
      "Epoch:  694  Loss:  0.380386012036936  Validation Loss:  0.4551112943461963\n",
      "Epoch:  695  Loss:  0.3803471277745979  Validation Loss:  0.45508564178432737\n",
      "Epoch:  696  Loss:  0.3803081360261587  Validation Loss:  0.4550601747419153\n",
      "Epoch:  697  Loss:  0.38026871362709885  Validation Loss:  0.4550343942429338\n",
      "Epoch:  698  Loss:  0.3802286382605679  Validation Loss:  0.4550082706979343\n",
      "Epoch:  699  Loss:  0.38018785081627243  Validation Loss:  0.45498214257614955\n",
      "Epoch:  700  Loss:  0.3801462438081113  Validation Loss:  0.4549560537295682\n",
      "Epoch:  701  Loss:  0.38010350113372665  Validation Loss:  0.45492971135037286\n",
      "Epoch:  702  Loss:  0.38005912279206994  Validation Loss:  0.4549025253525802\n",
      "Epoch:  703  Loss:  0.38001276171320425  Validation Loss:  0.454874579927751\n",
      "Epoch:  704  Loss:  0.37996450447923197  Validation Loss:  0.4548462099262646\n",
      "Epoch:  705  Loss:  0.37991471111915687  Validation Loss:  0.4548176571726799\n",
      "Epoch:  706  Loss:  0.3798637615772785  Validation Loss:  0.4547886734562261\n",
      "Epoch:  707  Loss:  0.3798118375277067  Validation Loss:  0.4547591690506254\n",
      "Epoch:  708  Loss:  0.3797596181738433  Validation Loss:  0.4547298636819635\n",
      "Epoch:  709  Loss:  0.3797075059176621  Validation Loss:  0.45470074809023314\n",
      "Epoch:  710  Loss:  0.3796552533363279  Validation Loss:  0.454670890633549\n",
      "Epoch:  711  Loss:  0.37960293846672744  Validation Loss:  0.4546409323811531\n",
      "Epoch:  712  Loss:  0.37955085445919307  Validation Loss:  0.4546110309660435\n",
      "Epoch:  713  Loss:  0.37949877136973975  Validation Loss:  0.45458049444215637\n",
      "Epoch:  714  Loss:  0.37944672256708145  Validation Loss:  0.4545499790992056\n",
      "Epoch:  715  Loss:  0.37939471956254184  Validation Loss:  0.4545189900057656\n",
      "Epoch:  716  Loss:  0.3793424451591279  Validation Loss:  0.4544874115714005\n",
      "Epoch:  717  Loss:  0.3792899472382961  Validation Loss:  0.4544552023921694\n",
      "Epoch:  718  Loss:  0.3792369730099683  Validation Loss:  0.45442212862627845\n",
      "Epoch:  719  Loss:  0.37918338917584216  Validation Loss:  0.4543877187584128\n",
      "Epoch:  720  Loss:  0.3791289523032039  Validation Loss:  0.4543520621955395\n",
      "Epoch:  721  Loss:  0.3790734148632859  Validation Loss:  0.45431446390492575\n",
      "Epoch:  722  Loss:  0.3790164830348503  Validation Loss:  0.4542748296899455\n",
      "Epoch:  723  Loss:  0.3789578634203893  Validation Loss:  0.45423288536923273\n",
      "Epoch:  724  Loss:  0.37889713956422716  Validation Loss:  0.4541877878563745\n",
      "Epoch:  725  Loss:  0.3788336535906905  Validation Loss:  0.45413864946791105\n",
      "Epoch:  726  Loss:  0.3787666629134761  Validation Loss:  0.454084423077958\n",
      "Epoch:  727  Loss:  0.3786954645296974  Validation Loss:  0.4540245007191386\n",
      "Epoch:  728  Loss:  0.3786194273998952  Validation Loss:  0.45395813829132486\n",
      "Epoch:  729  Loss:  0.3785383228159629  Validation Loss:  0.4538853118462222\n",
      "Epoch:  730  Loss:  0.37845239392812785  Validation Loss:  0.45380656293460303\n",
      "Epoch:  731  Loss:  0.3783625587821007  Validation Loss:  0.4537229816828455\n",
      "Epoch:  732  Loss:  0.37827001783943853  Validation Loss:  0.45363611014825955\n",
      "Epoch:  733  Loss:  0.3781755994210876  Validation Loss:  0.45354665155921664\n",
      "Epoch:  734  Loss:  0.3780799629210861  Validation Loss:  0.45345518993479866\n",
      "Epoch:  735  Loss:  0.37798324018999296  Validation Loss:  0.45336150814379966\n",
      "Epoch:  736  Loss:  0.37788540283791827  Validation Loss:  0.4532654232212475\n",
      "Epoch:  737  Loss:  0.3777862274533764  Validation Loss:  0.4531665635960443\n",
      "Epoch:  738  Loss:  0.3776854168252922  Validation Loss:  0.45306418112346103\n",
      "Epoch:  739  Loss:  0.3775823624778133  Validation Loss:  0.45295702761837414\n",
      "Epoch:  740  Loss:  0.3774764293813592  Validation Loss:  0.4528442242315837\n",
      "Epoch:  741  Loss:  0.37736673621346034  Validation Loss:  0.45272391608783175\n",
      "Epoch:  742  Loss:  0.3772519984728352  Validation Loss:  0.45259396614772934\n",
      "Epoch:  743  Loss:  0.3771310470186139  Validation Loss:  0.4524524658918381\n",
      "Epoch:  744  Loss:  0.3770024496797137  Validation Loss:  0.45229677206703595\n",
      "Epoch:  745  Loss:  0.376864818917914  Validation Loss:  0.4521248310804367\n",
      "Epoch:  746  Loss:  0.3767175472107544  Validation Loss:  0.45193649030157496\n",
      "Epoch:  747  Loss:  0.3765612312755878  Validation Loss:  0.4517334377127034\n",
      "Epoch:  748  Loss:  0.3763977895839519  Validation Loss:  0.45151962403740203\n",
      "Epoch:  749  Loss:  0.3762296164205289  Validation Loss:  0.45129912953291623\n",
      "Epoch:  750  Loss:  0.3760592858020163  Validation Loss:  0.4510759330221585\n",
      "Epoch:  751  Loss:  0.3758887176830057  Validation Loss:  0.45085268318653104\n",
      "Epoch:  752  Loss:  0.3757189215995124  Validation Loss:  0.45063057690858843\n",
      "Epoch:  753  Loss:  0.3755505090994293  Validation Loss:  0.450410502829722\n",
      "Epoch:  754  Loss:  0.3753837510519683  Validation Loss:  0.45019279505525317\n",
      "Epoch:  755  Loss:  0.37521876709014884  Validation Loss:  0.4499776942389352\n",
      "Epoch:  756  Loss:  0.37505564591472185  Validation Loss:  0.44976512757795195\n",
      "Epoch:  757  Loss:  0.37489426630368167  Validation Loss:  0.4495550441954817\n",
      "Epoch:  758  Loss:  0.3747345806580584  Validation Loss:  0.4493472007768495\n",
      "Epoch:  759  Loss:  0.37457650938728976  Validation Loss:  0.4491416970533984\n",
      "Epoch:  760  Loss:  0.37441996545023265  Validation Loss:  0.448938127713544\n",
      "Epoch:  761  Loss:  0.3742647138534564  Validation Loss:  0.44873642431838173\n",
      "Epoch:  762  Loss:  0.3741106128593757  Validation Loss:  0.4485364732997758\n",
      "Epoch:  763  Loss:  0.3739576435767079  Validation Loss:  0.44833816822086064\n",
      "Epoch:  764  Loss:  0.37380568086394766  Validation Loss:  0.4481413528323174\n",
      "Epoch:  765  Loss:  0.3736545595371328  Validation Loss:  0.4479457932923521\n",
      "Epoch:  766  Loss:  0.3735041182964899  Validation Loss:  0.4477512948215008\n",
      "Epoch:  767  Loss:  0.373354220877609  Validation Loss:  0.44755772831184526\n",
      "Epoch:  768  Loss:  0.37320464817692317  Validation Loss:  0.44736493421452384\n",
      "Epoch:  769  Loss:  0.3730550990638575  Validation Loss:  0.44717244974204473\n",
      "Epoch:  770  Loss:  0.37290553324877934  Validation Loss:  0.44698021954723766\n",
      "Epoch:  771  Loss:  0.3727554934920293  Validation Loss:  0.4467876542891775\n",
      "Epoch:  772  Loss:  0.372604490809531  Validation Loss:  0.4465941917683397\n",
      "Epoch:  773  Loss:  0.37245194532718706  Validation Loss:  0.4463992630796773\n",
      "Epoch:  774  Loss:  0.3722973926725546  Validation Loss:  0.4462025020803724\n",
      "Epoch:  775  Loss:  0.3721401939318643  Validation Loss:  0.44600376774157796\n",
      "Epoch:  776  Loss:  0.3719801156300504  Validation Loss:  0.4458040589732783\n",
      "Epoch:  777  Loss:  0.37181693975818103  Validation Loss:  0.4456050564135824\n",
      "Epoch:  778  Loss:  0.37165110342875474  Validation Loss:  0.44540926995021957\n",
      "Epoch:  779  Loss:  0.3714831603152492  Validation Loss:  0.4452185118837016\n",
      "Epoch:  780  Loss:  0.3713135011317606  Validation Loss:  0.4450332680983203\n",
      "Epoch:  781  Loss:  0.3711427353781546  Validation Loss:  0.44485275873116087\n",
      "Epoch:  782  Loss:  0.3709712978717275  Validation Loss:  0.44467551835945673\n",
      "Epoch:  783  Loss:  0.3707990096219908  Validation Loss:  0.44449945060270174\n",
      "Epoch:  784  Loss:  0.37062582980964986  Validation Loss:  0.44432320977960316\n",
      "Epoch:  785  Loss:  0.3704516021490662  Validation Loss:  0.4441461299146925\n",
      "Epoch:  786  Loss:  0.37027653582146947  Validation Loss:  0.44396779398833003\n",
      "Epoch:  787  Loss:  0.37010074230308215  Validation Loss:  0.44378842040896416\n",
      "Epoch:  788  Loss:  0.36992498865059764  Validation Loss:  0.44360875423465457\n",
      "Epoch:  789  Loss:  0.3697499443922563  Validation Loss:  0.4434295007160732\n",
      "Epoch:  790  Loss:  0.36957630112555356  Validation Loss:  0.4432514504662582\n",
      "Epoch:  791  Loss:  0.3694043913723733  Validation Loss:  0.4430746523397309\n",
      "Epoch:  792  Loss:  0.3692343064817772  Validation Loss:  0.44289914422801563\n",
      "Epoch:  793  Loss:  0.3690660427108195  Validation Loss:  0.4427249197449003\n",
      "Epoch:  794  Loss:  0.3688996538025508  Validation Loss:  0.44255220964550973\n",
      "Epoch:  795  Loss:  0.3687351838601709  Validation Loss:  0.4423809602856636\n",
      "Epoch:  796  Loss:  0.3685726522693137  Validation Loss:  0.44221128629786627\n",
      "Epoch:  797  Loss:  0.3684118382668043  Validation Loss:  0.4420427971652576\n",
      "Epoch:  798  Loss:  0.3682526602140535  Validation Loss:  0.4418754486101014\n",
      "Epoch:  799  Loss:  0.36809503855580966  Validation Loss:  0.44170921168157035\n",
      "Epoch:  800  Loss:  0.36793892251513016  Validation Loss:  0.4415440038910934\n",
      "Epoch:  801  Loss:  0.3677843012162859  Validation Loss:  0.4413800182087081\n",
      "Epoch:  802  Loss:  0.3676311103582947  Validation Loss:  0.44121692915047916\n",
      "Epoch:  803  Loss:  0.36747929852861927  Validation Loss:  0.44105502303157534\n",
      "Epoch:  804  Loss:  0.3673287070051754  Validation Loss:  0.4408936224877834\n",
      "Epoch:  805  Loss:  0.36717902883110454  Validation Loss:  0.4407326200178691\n",
      "Epoch:  806  Loss:  0.36703019211360066  Validation Loss:  0.4405717843345233\n",
      "Epoch:  807  Loss:  0.36688184589853784  Validation Loss:  0.4404106921383313\n",
      "Epoch:  808  Loss:  0.36673382150618383  Validation Loss:  0.4402491656797273\n",
      "Epoch:  809  Loss:  0.3665858179825177  Validation Loss:  0.44008678602320805\n",
      "Epoch:  810  Loss:  0.36643739976871637  Validation Loss:  0.4399229598896844\n",
      "Epoch:  811  Loss:  0.3662881307762946  Validation Loss:  0.4397571919219834\n",
      "Epoch:  812  Loss:  0.3661375265056488  Validation Loss:  0.4395889398242746\n",
      "Epoch:  813  Loss:  0.36598487163042004  Validation Loss:  0.4394172005355358\n",
      "Epoch:  814  Loss:  0.3658297496949327  Validation Loss:  0.439241782362972\n",
      "Epoch:  815  Loss:  0.3656722257770068  Validation Loss:  0.4390632365431104\n",
      "Epoch:  816  Loss:  0.36551301548548787  Validation Loss:  0.43888256262455666\n",
      "Epoch:  817  Loss:  0.3653529760961849  Validation Loss:  0.43870070140276635\n",
      "Epoch:  818  Loss:  0.3651930509020367  Validation Loss:  0.43851860516837665\n",
      "Epoch:  819  Loss:  0.3650340538171795  Validation Loss:  0.43833698864494053\n",
      "Epoch:  820  Loss:  0.3648764858313646  Validation Loss:  0.43815627949578423\n",
      "Epoch:  821  Loss:  0.3647206140002368  Validation Loss:  0.4379764410001891\n",
      "Epoch:  822  Loss:  0.36456653779434367  Validation Loss:  0.437797426538808\n",
      "Epoch:  823  Loss:  0.36441431547651926  Validation Loss:  0.4376192092895508\n",
      "Epoch:  824  Loss:  0.36426396378408676  Validation Loss:  0.43744161490883143\n",
      "Epoch:  825  Loss:  0.364115350725244  Validation Loss:  0.4372641011008194\n",
      "Epoch:  826  Loss:  0.3639684703324643  Validation Loss:  0.43708655280726294\n",
      "Epoch:  827  Loss:  0.3638232734884131  Validation Loss:  0.4369082878742899\n",
      "Epoch:  828  Loss:  0.3636795527067795  Validation Loss:  0.43672859817743304\n",
      "Epoch:  829  Loss:  0.363537195946368  Validation Loss:  0.43654683764491764\n",
      "Epoch:  830  Loss:  0.36339614053049357  Validation Loss:  0.4363620930484363\n",
      "Epoch:  831  Loss:  0.36325628656487896  Validation Loss:  0.4361731976270676\n",
      "Epoch:  832  Loss:  0.36311749937410037  Validation Loss:  0.43597880080342294\n",
      "Epoch:  833  Loss:  0.36297966751724625  Validation Loss:  0.4357774120356355\n",
      "Epoch:  834  Loss:  0.3628426537412038  Validation Loss:  0.4355675648365702\n",
      "Epoch:  835  Loss:  0.3627063529610069  Validation Loss:  0.4353487633168697\n",
      "Epoch:  836  Loss:  0.3625708537008525  Validation Loss:  0.43512216795768055\n",
      "Epoch:  837  Loss:  0.3624365265123652  Validation Loss:  0.43489031993917054\n",
      "Epoch:  838  Loss:  0.3623036993623345  Validation Loss:  0.434656022382634\n",
      "Epoch:  839  Loss:  0.36217260883317737  Validation Loss:  0.43442187468920435\n",
      "Epoch:  840  Loss:  0.362043449840557  Validation Loss:  0.4341893521802766\n",
      "Epoch:  841  Loss:  0.36191624946786327  Validation Loss:  0.43395930698939733\n",
      "Epoch:  842  Loss:  0.36179095400735667  Validation Loss:  0.4337319338960307\n",
      "Epoch:  843  Loss:  0.36166756981498255  Validation Loss:  0.4335076102188655\n",
      "Epoch:  844  Loss:  0.36154608820428213  Validation Loss:  0.43328619131020135\n",
      "Epoch:  845  Loss:  0.3614264259476797  Validation Loss:  0.43306774401238984\n",
      "Epoch:  846  Loss:  0.3613086568800759  Validation Loss:  0.43285236560872625\n",
      "Epoch:  847  Loss:  0.361192716947664  Validation Loss:  0.43263978745256154\n",
      "Epoch:  848  Loss:  0.361078540331097  Validation Loss:  0.4324301428028515\n",
      "Epoch:  849  Loss:  0.3609662411902188  Validation Loss:  0.4322234357041972\n",
      "Epoch:  850  Loss:  0.3608557685362219  Validation Loss:  0.4320193384374891\n",
      "Epoch:  851  Loss:  0.3607469898829528  Validation Loss:  0.43181780321257457\n",
      "Epoch:  852  Loss:  0.3606399275115316  Validation Loss:  0.43161884429199354\n",
      "Epoch:  853  Loss:  0.3605345989008085  Validation Loss:  0.43142251329762593\n",
      "Epoch:  854  Loss:  0.3604310003078379  Validation Loss:  0.4312286577054432\n",
      "Epoch:  855  Loss:  0.36032904246689584  Validation Loss:  0.43103727059704916\n",
      "Epoch:  856  Loss:  0.3602287777792221  Validation Loss:  0.43084841924054285\n",
      "Epoch:  857  Loss:  0.3601302868593926  Validation Loss:  0.4306622519024781\n",
      "Epoch:  858  Loss:  0.3600335565364756  Validation Loss:  0.4304788453238351\n",
      "Epoch:  859  Loss:  0.3599385731451884  Validation Loss:  0.43029801632676806\n",
      "Epoch:  860  Loss:  0.35984516839421754  Validation Loss:  0.4301198063152177\n",
      "Epoch:  861  Loss:  0.35975340075826195  Validation Loss:  0.4299441532364913\n",
      "Epoch:  862  Loss:  0.359663219990041  Validation Loss:  0.42977106156093736\n",
      "Epoch:  863  Loss:  0.3595746579399041  Validation Loss:  0.42960062793322973\n",
      "Epoch:  864  Loss:  0.3594876661967327  Validation Loss:  0.42943297220127924\n",
      "Epoch:  865  Loss:  0.35940225708399903  Validation Loss:  0.4292680664786271\n",
      "Epoch:  866  Loss:  0.3593183937725298  Validation Loss:  0.4291060606283801\n",
      "Epoch:  867  Loss:  0.35923601316191006  Validation Loss:  0.42894707907523427\n",
      "Epoch:  868  Loss:  0.3591550575542789  Validation Loss:  0.4287913305418832\n",
      "Epoch:  869  Loss:  0.3590755640259851  Validation Loss:  0.42863908229129655\n",
      "Epoch:  870  Loss:  0.3589975054583278  Validation Loss:  0.42849065991384644\n",
      "Epoch:  871  Loss:  0.3589208241887567  Validation Loss:  0.42834660964352744\n",
      "Epoch:  872  Loss:  0.3588455926044292  Validation Loss:  0.4282075579677309\n",
      "Epoch:  873  Loss:  0.3587716191442092  Validation Loss:  0.42807394840887614\n",
      "Epoch:  874  Loss:  0.35869871606052767  Validation Loss:  0.4279467241040298\n",
      "Epoch:  875  Loss:  0.3586268068348627  Validation Loss:  0.42782699721200124\n",
      "Epoch:  876  Loss:  0.35855571081711785  Validation Loss:  0.42771615524377143\n",
      "Epoch:  877  Loss:  0.35848537009756715  Validation Loss:  0.42761543755020415\n",
      "Epoch:  878  Loss:  0.35841567214066383  Validation Loss:  0.4275255045720509\n",
      "Epoch:  879  Loss:  0.3583466797643363  Validation Loss:  0.4274456824575152\n",
      "Epoch:  880  Loss:  0.35827856860454615  Validation Loss:  0.4273741064327104\n",
      "Epoch:  881  Loss:  0.35821164318170595  Validation Loss:  0.42730840508426937\n",
      "Epoch:  882  Loss:  0.358146167514731  Validation Loss:  0.4272464483976364\n",
      "Epoch:  883  Loss:  0.358082320346934  Validation Loss:  0.42718663439154625\n",
      "Epoch:  884  Loss:  0.35802012667836736  Validation Loss:  0.42712812668510847\n",
      "Epoch:  885  Loss:  0.3579596082958  Validation Loss:  0.4270705326327256\n",
      "Epoch:  886  Loss:  0.3579007396342065  Validation Loss:  0.4270135118493012\n",
      "Epoch:  887  Loss:  0.3578434617245367  Validation Loss:  0.42695691330092295\n",
      "Epoch:  888  Loss:  0.35778775987749417  Validation Loss:  0.4269006806824889\n",
      "Epoch:  889  Loss:  0.3577335468047603  Validation Loss:  0.426844789407083\n",
      "Epoch:  890  Loss:  0.35768081480857883  Validation Loss:  0.4267892728958811\n",
      "Epoch:  891  Loss:  0.35762948627579266  Validation Loss:  0.42673408527459417\n",
      "Epoch:  892  Loss:  0.3575794588403679  Validation Loss:  0.4266791808818068\n",
      "Epoch:  893  Loss:  0.35753069426069894  Validation Loss:  0.42662454481635775\n",
      "Epoch:  894  Loss:  0.35748309910438636  Validation Loss:  0.4265701167285442\n",
      "Epoch:  895  Loss:  0.3574365715350585  Validation Loss:  0.4265157909265586\n",
      "Epoch:  896  Loss:  0.3573909607402521  Validation Loss:  0.42646139657923154\n",
      "Epoch:  897  Loss:  0.35734608303314136  Validation Loss:  0.4264067328401974\n",
      "Epoch:  898  Loss:  0.35730169847678234  Validation Loss:  0.42635147230965753\n",
      "Epoch:  899  Loss:  0.35725747038261585  Validation Loss:  0.42629520552498956\n",
      "Epoch:  900  Loss:  0.35721297138392644  Validation Loss:  0.4262375052486147\n",
      "Epoch:  901  Loss:  0.3571677508441758  Validation Loss:  0.42617780949388234\n",
      "Epoch:  902  Loss:  0.3571212596096699  Validation Loss:  0.4261154272726604\n",
      "Epoch:  903  Loss:  0.35707284813808604  Validation Loss:  0.4260496995278767\n",
      "Epoch:  904  Loss:  0.3570220318238882  Validation Loss:  0.42598017092261997\n",
      "Epoch:  905  Loss:  0.3569686726018151  Validation Loss:  0.425906811441694\n",
      "Epoch:  906  Loss:  0.35691316016194946  Validation Loss:  0.4258300108569009\n",
      "Epoch:  907  Loss:  0.3568563299933316  Validation Loss:  0.42575035925422394\n",
      "Epoch:  908  Loss:  0.3567991189976439  Validation Loss:  0.42566824193511693\n",
      "Epoch:  909  Loss:  0.3567422567315011  Validation Loss:  0.4255836559193475\n",
      "Epoch:  910  Loss:  0.35668618489780696  Validation Loss:  0.42549616949898855\n",
      "Epoch:  911  Loss:  0.35663108640654956  Validation Loss:  0.4254049701350076\n",
      "Epoch:  912  Loss:  0.3565770449090343  Validation Loss:  0.4253089549286025\n",
      "Epoch:  913  Loss:  0.35652402964954694  Validation Loss:  0.425206689962319\n",
      "Epoch:  914  Loss:  0.3564719686646597  Validation Loss:  0.4250966129558427\n",
      "Epoch:  915  Loss:  0.35642083684838777  Validation Loss:  0.4249777891806194\n",
      "Epoch:  916  Loss:  0.35637072237182005  Validation Loss:  0.42485051495688303\n",
      "Epoch:  917  Loss:  0.35632181778479527  Validation Loss:  0.4247166837964739\n",
      "Epoch:  918  Loss:  0.3562743680383922  Validation Loss:  0.42457912393978664\n",
      "Epoch:  919  Loss:  0.35622859276583974  Validation Loss:  0.42444067682538716\n",
      "Epoch:  920  Loss:  0.3561846875890171  Validation Loss:  0.4243031891328948\n",
      "Epoch:  921  Loss:  0.3561426492946408  Validation Loss:  0.4241678201726505\n",
      "Epoch:  922  Loss:  0.35610243289674065  Validation Loss:  0.42403517684766223\n",
      "Epoch:  923  Loss:  0.3560640403374111  Validation Loss:  0.4239056157214301\n",
      "Epoch:  924  Loss:  0.35602747341750357  Validation Loss:  0.42377927622624806\n",
      "Epoch:  925  Loss:  0.35599270498300617  Validation Loss:  0.4236561792237418\n",
      "Epoch:  926  Loss:  0.3559596247582639  Validation Loss:  0.4235361705933298\n",
      "Epoch:  927  Loss:  0.3559282154056698  Validation Loss:  0.42341936911855427\n",
      "Epoch:  928  Loss:  0.3558985070806544  Validation Loss:  0.4233056779418673\n",
      "Epoch:  929  Loss:  0.35587037863183363  Validation Loss:  0.4231950766273907\n",
      "Epoch:  930  Loss:  0.3558438743036505  Validation Loss:  0.42308763286897116\n",
      "Epoch:  931  Loss:  0.3558189152823805  Validation Loss:  0.42298330196312495\n",
      "Epoch:  932  Loss:  0.3557954984959833  Validation Loss:  0.4228822284511157\n",
      "Epoch:  933  Loss:  0.3557735809005832  Validation Loss:  0.4227844768336841\n",
      "Epoch:  934  Loss:  0.3557531092474811  Validation Loss:  0.4226901412010193\n",
      "Epoch:  935  Loss:  0.3557341043347431  Validation Loss:  0.42259960153273174\n",
      "Epoch:  936  Loss:  0.35571651217214306  Validation Loss:  0.4225130281278065\n",
      "Epoch:  937  Loss:  0.3557001945884872  Validation Loss:  0.4224308179957526\n",
      "Epoch:  938  Loss:  0.35568519399205656  Validation Loss:  0.42235366702079774\n",
      "Epoch:  939  Loss:  0.355671401060588  Validation Loss:  0.4222821723137583\n",
      "Epoch:  940  Loss:  0.3556586523403489  Validation Loss:  0.4222173099006925\n",
      "Epoch:  941  Loss:  0.3556469333892185  Validation Loss:  0.4221603625587055\n",
      "Epoch:  942  Loss:  0.35563616648810736  Validation Loss:  0.42211291193962097\n",
      "Epoch:  943  Loss:  0.3556262537201434  Validation Loss:  0.4220762776476996\n",
      "Epoch:  944  Loss:  0.35561706567121343  Validation Loss:  0.42205112533909933\n",
      "Epoch:  945  Loss:  0.35560864888096305  Validation Loss:  0.42203667270285744\n",
      "Epoch:  946  Loss:  0.35560127404205044  Validation Loss:  0.42203080079385213\n",
      "Epoch:  947  Loss:  0.35559515047694834  Validation Loss:  0.4220305419393948\n",
      "Epoch:  948  Loss:  0.35559045855326676  Validation Loss:  0.42203347086906434\n",
      "Epoch:  949  Loss:  0.3555872977062424  Validation Loss:  0.4220380759664944\n",
      "Epoch:  950  Loss:  0.35558574304196505  Validation Loss:  0.4220435144645827\n",
      "Epoch:  951  Loss:  0.3555859090380759  Validation Loss:  0.4220494040421077\n",
      "Epoch:  952  Loss:  0.3555877701648604  Validation Loss:  0.42205546902758734\n",
      "Epoch:  953  Loss:  0.3555912850733617  Validation Loss:  0.42206155168158666\n",
      "Epoch:  954  Loss:  0.3555963872380166  Validation Loss:  0.42206763944455555\n",
      "Epoch:  955  Loss:  0.35560305843844797  Validation Loss:  0.4220737352967262\n",
      "Epoch:  956  Loss:  0.3556112829966568  Validation Loss:  0.4220797577074596\n",
      "Epoch:  957  Loss:  0.35562098478253984  Validation Loss:  0.42208574137517385\n",
      "Epoch:  958  Loss:  0.3556322563810371  Validation Loss:  0.4220917620829174\n",
      "Epoch:  959  Loss:  0.35564504443751693  Validation Loss:  0.422097601209368\n",
      "Epoch:  960  Loss:  0.35565919708019184  Validation Loss:  0.4221030942031315\n",
      "Epoch:  961  Loss:  0.355674723136764  Validation Loss:  0.4221079845513616\n",
      "Epoch:  962  Loss:  0.355691588744168  Validation Loss:  0.42211204384054457\n",
      "Epoch:  963  Loss:  0.3557097902653907  Validation Loss:  0.42211500108242034\n",
      "Epoch:  964  Loss:  0.3557292723683949  Validation Loss:  0.4221163977469717\n",
      "Epoch:  965  Loss:  0.3557499792621034  Validation Loss:  0.4221157359225409\n",
      "Epoch:  966  Loss:  0.3557718809323288  Validation Loss:  0.4221122603331293\n",
      "Epoch:  967  Loss:  0.3557949570400455  Validation Loss:  0.4221051339592252\n",
      "Epoch:  968  Loss:  0.35581914992270314  Validation Loss:  0.42209314831665584\n",
      "Epoch:  969  Loss:  0.355844331719864  Validation Loss:  0.4220747749720301\n",
      "Epoch:  970  Loss:  0.3558703988649269  Validation Loss:  0.42204858234950476\n",
      "Epoch:  971  Loss:  0.3558973204256234  Validation Loss:  0.4220135582344873\n",
      "Epoch:  972  Loss:  0.3559251068539529  Validation Loss:  0.4219697969300406\n",
      "Epoch:  973  Loss:  0.35595387040297566  Validation Loss:  0.4219190152628081\n",
      "Epoch:  974  Loss:  0.35598379405330144  Validation Loss:  0.42186405126537596\n",
      "Epoch:  975  Loss:  0.35601511767125243  Validation Loss:  0.42180774616343636\n",
      "Epoch:  976  Loss:  0.35604804567109916  Validation Loss:  0.4217522404023579\n",
      "Epoch:  977  Loss:  0.35608261202183944  Validation Loss:  0.4216988472001893\n",
      "Epoch:  978  Loss:  0.3561188172884462  Validation Loss:  0.4216483237487929\n",
      "Epoch:  979  Loss:  0.3561566874243637  Validation Loss:  0.42160115305866513\n",
      "Epoch:  980  Loss:  0.35619617800859477  Validation Loss:  0.4215575565184866\n",
      "Epoch:  981  Loss:  0.35623724250149386  Validation Loss:  0.4215176495058196\n",
      "Epoch:  982  Loss:  0.3562797912136073  Validation Loss:  0.4214815054621015\n",
      "Epoch:  983  Loss:  0.35632370384101053  Validation Loss:  0.4214492827653885\n",
      "Epoch:  984  Loss:  0.3563688203551193  Validation Loss:  0.42142121493816376\n",
      "Epoch:  985  Loss:  0.3564149963700376  Validation Loss:  0.4213976117117064\n",
      "Epoch:  986  Loss:  0.3564622567445746  Validation Loss:  0.421379003567355\n",
      "Epoch:  987  Loss:  0.3565105168034115  Validation Loss:  0.4213660906468119\n",
      "Epoch:  988  Loss:  0.35655964988667815  Validation Loss:  0.42135987750121523\n",
      "Epoch:  989  Loss:  0.35660945465214444  Validation Loss:  0.4213616615959576\n",
      "Epoch:  990  Loss:  0.3566597236841211  Validation Loss:  0.4213730213897569\n",
      "Epoch:  991  Loss:  0.3567102164806913  Validation Loss:  0.42139525200639455\n",
      "Epoch:  992  Loss:  0.3567606051103764  Validation Loss:  0.42142845349652425\n",
      "Epoch:  993  Loss:  0.35681062251753154  Validation Loss:  0.4214704830731664\n",
      "Epoch:  994  Loss:  0.3568603521769081  Validation Loss:  0.42151762545108795\n",
      "Epoch:  995  Loss:  0.3569098768570412  Validation Loss:  0.42156621643475123\n",
      "Epoch:  996  Loss:  0.3569592399196037  Validation Loss:  0.4216138267091342\n",
      "Epoch:  997  Loss:  0.3570085704609116  Validation Loss:  0.4216594398021698\n",
      "Epoch:  998  Loss:  0.3570581767090124  Validation Loss:  0.42170320004224776\n",
      "Epoch:  999  Loss:  0.35710825661629864  Validation Loss:  0.42174559086561203\n",
      "Epoch:  1000  Loss:  0.3571592097951903  Validation Loss:  0.4217872108731951\n",
      "Epoch:  1001  Loss:  0.3572114223693784  Validation Loss:  0.4218284960303988\n",
      "Epoch:  1002  Loss:  0.3572650592403389  Validation Loss:  0.42186974648918424\n",
      "Epoch:  1003  Loss:  0.35732016610025796  Validation Loss:  0.42191107613699774\n",
      "Epoch:  1004  Loss:  0.35737652377494705  Validation Loss:  0.4219525530934334\n",
      "Epoch:  1005  Loss:  0.3574342381262101  Validation Loss:  0.4219942469682012\n",
      "Epoch:  1006  Loss:  0.3574934457715654  Validation Loss:  0.4220361224242619\n",
      "Epoch:  1007  Loss:  0.3575541435683508  Validation Loss:  0.42207814816917694\n",
      "Epoch:  1008  Loss:  0.35761611311921576  Validation Loss:  0.422120189666748\n",
      "Epoch:  1009  Loss:  0.3576793091203929  Validation Loss:  0.4221621717725481\n",
      "Epoch:  1010  Loss:  0.35774389583776345  Validation Loss:  0.4222039288708142\n",
      "Epoch:  1011  Loss:  0.3578098305099383  Validation Loss:  0.42224528257335936\n",
      "Epoch:  1012  Loss:  0.35787680995831556  Validation Loss:  0.4222859431590353\n",
      "Epoch:  1013  Loss:  0.3579450431169492  Validation Loss:  0.4223257024373327\n",
      "Epoch:  1014  Loss:  0.3580145148728131  Validation Loss:  0.42236415637390956\n",
      "Epoch:  1015  Loss:  0.35808494627052007  Validation Loss:  0.4224008445228849\n",
      "Epoch:  1016  Loss:  0.3581565506579752  Validation Loss:  0.42243527280432835\n",
      "Epoch:  1017  Loss:  0.35822905109250713  Validation Loss:  0.4224666891353471\n",
      "Epoch:  1018  Loss:  0.3583025985278224  Validation Loss:  0.4224944674542972\n",
      "Epoch:  1019  Loss:  0.3583770421867687  Validation Loss:  0.4225178422672408\n",
      "Epoch:  1020  Loss:  0.3584524461231525  Validation Loss:  0.42253625031028474\n",
      "Epoch:  1021  Loss:  0.3585287167633314  Validation Loss:  0.4225494284714971\n",
      "Epoch:  1022  Loss:  0.3586061044609377  Validation Loss:  0.4225579076579639\n",
      "Epoch:  1023  Loss:  0.3586844734106019  Validation Loss:  0.42256273393120086\n",
      "Epoch:  1024  Loss:  0.35876385415617323  Validation Loss:  0.422565713099071\n",
      "Epoch:  1025  Loss:  0.3588445026657028  Validation Loss:  0.42256880892174586\n",
      "Epoch:  1026  Loss:  0.35892634814101937  Validation Loss:  0.4225739357726915\n",
      "Epoch:  1027  Loss:  0.3590093641343275  Validation Loss:  0.4225827808891024\n",
      "Epoch:  1028  Loss:  0.3590933644517338  Validation Loss:  0.4225969265614237\n",
      "Epoch:  1029  Loss:  0.35917819866919404  Validation Loss:  0.42261796189205986\n",
      "Epoch:  1030  Loss:  0.35926353528883787  Validation Loss:  0.4226476645895413\n",
      "Epoch:  1031  Loss:  0.3593492143173918  Validation Loss:  0.4226881695645196\n",
      "Epoch:  1032  Loss:  0.3594350156625865  Validation Loss:  0.4227410797561918\n",
      "Epoch:  1033  Loss:  0.3595205603688249  Validation Loss:  0.42280681154557637\n",
      "Epoch:  1034  Loss:  0.35960572703754734  Validation Loss:  0.422883560189179\n",
      "Epoch:  1035  Loss:  0.35969051150207837  Validation Loss:  0.4229676855461938\n",
      "Epoch:  1036  Loss:  0.35977473689057815  Validation Loss:  0.423055474460125\n",
      "Epoch:  1037  Loss:  0.3598583094175393  Validation Loss:  0.4231443281684603\n",
      "Epoch:  1038  Loss:  0.3599410221616239  Validation Loss:  0.42323255411216193\n",
      "Epoch:  1039  Loss:  0.36002229941540986  Validation Loss:  0.4233191019722394\n",
      "Epoch:  1040  Loss:  0.3601016549137531  Validation Loss:  0.4234032577701977\n",
      "Epoch:  1041  Loss:  0.36017830189652916  Validation Loss:  0.4234844071524484\n",
      "Epoch:  1042  Loss:  0.36025136829270005  Validation Loss:  0.42356181144714355\n",
      "Epoch:  1043  Loss:  0.3603195133155556  Validation Loss:  0.42363470516034535\n",
      "Epoch:  1044  Loss:  0.3603812263333967  Validation Loss:  0.42370204095329556\n",
      "Epoch:  1045  Loss:  0.3604345958309151  Validation Loss:  0.4237626211983817\n",
      "Epoch:  1046  Loss:  0.3604775903772969  Validation Loss:  0.4238152429461479\n",
      "Epoch:  1047  Loss:  0.36050856237021667  Validation Loss:  0.42385898062161037\n",
      "Epoch:  1048  Loss:  0.3605270397394754  Validation Loss:  0.42389356770685743\n",
      "Epoch:  1049  Loss:  0.3605342627772223  Validation Loss:  0.42391958854028156\n",
      "Epoch:  1050  Loss:  0.3605331089612432  Validation Loss:  0.42393799339021954\n",
      "Epoch:  1051  Loss:  0.3605267987432073  Validation Loss:  0.4239496207662991\n",
      "Epoch:  1052  Loss:  0.36051816306125495  Validation Loss:  0.4239550914083208\n",
      "Epoch:  1053  Loss:  0.3605090454926988  Validation Loss:  0.42395492089646203\n",
      "Epoch:  1054  Loss:  0.3605005069860915  Validation Loss:  0.42394984321934837\n",
      "Epoch:  1055  Loss:  0.3604932588776706  Validation Loss:  0.42394121289253234\n",
      "Epoch:  1056  Loss:  0.36048760561722715  Validation Loss:  0.4239306994846889\n",
      "Epoch:  1057  Loss:  0.36048365871629445  Validation Loss:  0.4239204206636974\n",
      "Epoch:  1058  Loss:  0.3604815085705423  Validation Loss:  0.4239124185272625\n",
      "Epoch:  1059  Loss:  0.3604809883010896  Validation Loss:  0.42390861575092587\n",
      "Epoch:  1060  Loss:  0.3604820675406411  Validation Loss:  0.4239109677927835\n",
      "Epoch:  1061  Loss:  0.3604845694173569  Validation Loss:  0.4239213671003069\n",
      "Epoch:  1062  Loss:  0.36048825692509023  Validation Loss:  0.42394149005413057\n",
      "Epoch:  1063  Loss:  0.3604930428814549  Validation Loss:  0.42397244636501585\n",
      "Epoch:  1064  Loss:  0.3604987544400432  Validation Loss:  0.42401399676288876\n",
      "Epoch:  1065  Loss:  0.3605053171656708  Validation Loss:  0.4240643328854016\n",
      "Epoch:  1066  Loss:  0.36051271682808184  Validation Loss:  0.42412067226001193\n",
      "Epoch:  1067  Loss:  0.3605210339712306  Validation Loss:  0.4241803671632494\n",
      "Epoch:  1068  Loss:  0.3605303018225878  Validation Loss:  0.4242414221167564\n",
      "Epoch:  1069  Loss:  0.36054063754341614  Validation Loss:  0.42430258840322493\n",
      "Epoch:  1070  Loss:  0.3605520552580391  Validation Loss:  0.4243628882936069\n",
      "Epoch:  1071  Loss:  0.36056438003671115  Validation Loss:  0.4244217378752572\n",
      "Epoch:  1072  Loss:  0.36057753454876174  Validation Loss:  0.4244787629161562\n",
      "Epoch:  1073  Loss:  0.3605915165696099  Validation Loss:  0.4245335397975785\n",
      "Epoch:  1074  Loss:  0.36060616073873936  Validation Loss:  0.42458577368940625\n",
      "Epoch:  1075  Loss:  0.36062150159012085  Validation Loss:  0.4246350435273988\n",
      "Epoch:  1076  Loss:  0.3606374177958163  Validation Loss:  0.42468093165329523\n",
      "Epoch:  1077  Loss:  0.360653942124256  Validation Loss:  0.424723034458501\n",
      "Epoch:  1078  Loss:  0.36067094788025905  Validation Loss:  0.42476069650479725\n",
      "Epoch:  1079  Loss:  0.36068831956217073  Validation Loss:  0.4247936725616455\n",
      "Epoch:  1080  Loss:  0.36070623697262805  Validation Loss:  0.4248217908399446\n",
      "Epoch:  1081  Loss:  0.36072446285830856  Validation Loss:  0.4248451122215816\n",
      "Epoch:  1082  Loss:  0.3607430144508868  Validation Loss:  0.42486458740064076\n",
      "Epoch:  1083  Loss:  0.3607621024499572  Validation Loss:  0.42488154705081665\n",
      "Epoch:  1084  Loss:  0.36078162466603997  Validation Loss:  0.42489750108548574\n",
      "Epoch:  1085  Loss:  0.36080133229917827  Validation Loss:  0.4249143019318581\n",
      "Epoch:  1086  Loss:  0.3608212641912614  Validation Loss:  0.42493397103888647\n",
      "Epoch:  1087  Loss:  0.360841450674274  Validation Loss:  0.42495819692100795\n",
      "Epoch:  1088  Loss:  0.3608615335200635  Validation Loss:  0.4249884850212506\n",
      "Epoch:  1089  Loss:  0.3608811156585883  Validation Loss:  0.4250259937984603\n",
      "Epoch:  1090  Loss:  0.3608999799989976  Validation Loss:  0.4250712181840624\n",
      "Epoch:  1091  Loss:  0.36091803349731094  Validation Loss:  0.4251237926738603\n",
      "Epoch:  1092  Loss:  0.3609350411247868  Validation Loss:  0.425182067496436\n",
      "Epoch:  1093  Loss:  0.36095050612897106  Validation Loss:  0.4252436935901642\n",
      "Epoch:  1094  Loss:  0.3609639088760055  Validation Loss:  0.4253064602613449\n",
      "Epoch:  1095  Loss:  0.36097479216154155  Validation Loss:  0.42536845334938594\n",
      "Epoch:  1096  Loss:  0.3609827478632543  Validation Loss:  0.4254283172743661\n",
      "Epoch:  1097  Loss:  0.3609878433541664  Validation Loss:  0.42548545598983767\n",
      "Epoch:  1098  Loss:  0.3609904734797387  Validation Loss:  0.4255395416702543\n",
      "Epoch:  1099  Loss:  0.3609912495406883  Validation Loss:  0.4255905115178653\n",
      "Epoch:  1100  Loss:  0.3609909489044646  Validation Loss:  0.42563844876629964\n",
      "Epoch:  1101  Loss:  0.36099034512494976  Validation Loss:  0.4256833329796791\n",
      "Epoch:  1102  Loss:  0.36098993901534104  Validation Loss:  0.42572501621076037\n",
      "Epoch:  1103  Loss:  0.36099010374026275  Validation Loss:  0.4257632540804999\n",
      "Epoch:  1104  Loss:  0.36099118792332746  Validation Loss:  0.4257979141814368\n",
      "Epoch:  1105  Loss:  0.36099340251130513  Validation Loss:  0.42582896564688\n",
      "Epoch:  1106  Loss:  0.3609966660068498  Validation Loss:  0.4258563703724316\n",
      "Epoch:  1107  Loss:  0.36100085962440165  Validation Loss:  0.4258807020527976\n",
      "Epoch:  1108  Loss:  0.3610060092114724  Validation Loss:  0.4259029007383755\n",
      "Epoch:  1109  Loss:  0.3610121213711833  Validation Loss:  0.42592432562794\n",
      "Epoch:  1110  Loss:  0.3610191661599688  Validation Loss:  0.4259465177144323\n",
      "Epoch:  1111  Loss:  0.36102715713717926  Validation Loss:  0.42597110143729616\n",
      "Epoch:  1112  Loss:  0.3610359910186998  Validation Loss:  0.4259996209825788\n",
      "Epoch:  1113  Loss:  0.36104571127213575  Validation Loss:  0.42603346194539754\n",
      "Epoch:  1114  Loss:  0.3610564150022104  Validation Loss:  0.42607375979423523\n",
      "Epoch:  1115  Loss:  0.36106807865661467  Validation Loss:  0.42612098434141704\n",
      "Epoch:  1116  Loss:  0.36108055756696594  Validation Loss:  0.4261748895049095\n",
      "Epoch:  1117  Loss:  0.36109368100550504  Validation Loss:  0.42623461059161594\n",
      "Epoch:  1118  Loss:  0.3611074797985678  Validation Loss:  0.42629881309611456\n",
      "Epoch:  1119  Loss:  0.36112192954638556  Validation Loss:  0.4263659845505442\n",
      "Epoch:  1120  Loss:  0.3611371028832915  Validation Loss:  0.4264347274388586\n",
      "Epoch:  1121  Loss:  0.3611530457839582  Validation Loss:  0.426503937797887\n",
      "Epoch:  1122  Loss:  0.36116974564242704  Validation Loss:  0.42657273411750796\n",
      "Epoch:  1123  Loss:  0.36118715493034975  Validation Loss:  0.42664042328085217\n",
      "Epoch:  1124  Loss:  0.36120525959402466  Validation Loss:  0.42670648161854063\n",
      "Epoch:  1125  Loss:  0.36122406362357296  Validation Loss:  0.4267704148377691\n",
      "Epoch:  1126  Loss:  0.3612434936078239  Validation Loss:  0.4268318553056036\n",
      "Epoch:  1127  Loss:  0.3612637201686041  Validation Loss:  0.42689055310828344\n",
      "Epoch:  1128  Loss:  0.3612847814415868  Validation Loss:  0.4269462153315544\n",
      "Epoch:  1129  Loss:  0.36130659600004766  Validation Loss:  0.4269987440535\n",
      "Epoch:  1130  Loss:  0.3613291426221906  Validation Loss:  0.42704818291323526\n",
      "Epoch:  1131  Loss:  0.36135233010019735  Validation Loss:  0.42709492232118335\n",
      "Epoch:  1132  Loss:  0.3613761560682437  Validation Loss:  0.4271396089877401\n",
      "Epoch:  1133  Loss:  0.36140062684696433  Validation Loss:  0.42718324320656914\n",
      "Epoch:  1134  Loss:  0.3614257427894674  Validation Loss:  0.42722701941217694\n",
      "Epoch:  1135  Loss:  0.36145151374746837  Validation Loss:  0.4272722316639764\n",
      "Epoch:  1136  Loss:  0.36147788703724104  Validation Loss:  0.4273201597588403\n",
      "Epoch:  1137  Loss:  0.36150482551181484  Validation Loss:  0.4273719351206507\n",
      "Epoch:  1138  Loss:  0.36153232814717634  Validation Loss:  0.4274285220674106\n",
      "Epoch:  1139  Loss:  0.3615603270759515  Validation Loss:  0.4274904276643481\n",
      "Epoch:  1140  Loss:  0.3615887903771694  Validation Loss:  0.4275576983179365\n",
      "Epoch:  1141  Loss:  0.361617722499992  Validation Loss:  0.4276298829487392\n",
      "Epoch:  1142  Loss:  0.3616471102734878  Validation Loss:  0.42770608919007436\n",
      "Epoch:  1143  Loss:  0.361676966162372  Validation Loss:  0.42778522478682657\n",
      "Epoch:  1144  Loss:  0.3617072972641172  Validation Loss:  0.427866116804736\n",
      "Epoch:  1145  Loss:  0.36173811812677653  Validation Loss:  0.42794776005404334\n",
      "Epoch:  1146  Loss:  0.36176942278282337  Validation Loss:  0.42802924386092595\n",
      "Epoch:  1147  Loss:  0.3618013054768056  Validation Loss:  0.4281099410993712\n",
      "Epoch:  1148  Loss:  0.3618337938570863  Validation Loss:  0.42818920144012995\n",
      "Epoch:  1149  Loss:  0.36186679731613086  Validation Loss:  0.4282665058970451\n",
      "Epoch:  1150  Loss:  0.36190024134813326  Validation Loss:  0.4283413861479078\n",
      "Epoch:  1151  Loss:  0.3619340664190704  Validation Loss:  0.42841347903013227\n",
      "Epoch:  1152  Loss:  0.3619681703394623  Validation Loss:  0.4284825427191598\n",
      "Epoch:  1153  Loss:  0.362002536160121  Validation Loss:  0.4285485261252948\n",
      "Epoch:  1154  Loss:  0.3620371074896853  Validation Loss:  0.42861156229461944\n",
      "Epoch:  1155  Loss:  0.36207188093831755  Validation Loss:  0.4286720456821578\n",
      "Epoch:  1156  Loss:  0.3621067929818732  Validation Loss:  0.42873066174132485\n",
      "Epoch:  1157  Loss:  0.36214180993384093  Validation Loss:  0.4287883011358125\n",
      "Epoch:  1158  Loss:  0.36217688084072414  Validation Loss:  0.42884598204067775\n",
      "Epoch:  1159  Loss:  0.36221190880966414  Validation Loss:  0.42890475392341615\n",
      "Epoch:  1160  Loss:  0.3622467836356276  Validation Loss:  0.42896557365145\n",
      "Epoch:  1161  Loss:  0.3622813583550295  Validation Loss:  0.42902926568474087\n",
      "Epoch:  1162  Loss:  0.3623154202908701  Validation Loss:  0.4290963766830308\n",
      "Epoch:  1163  Loss:  0.36234877608116206  Validation Loss:  0.4291671361242022\n",
      "Epoch:  1164  Loss:  0.3623811452168424  Validation Loss:  0.42924138520445143\n",
      "Epoch:  1165  Loss:  0.36241220785260764  Validation Loss:  0.42931850999593735\n",
      "Epoch:  1166  Loss:  0.36244156275174066  Validation Loss:  0.4293975331953594\n",
      "Epoch:  1167  Loss:  0.3624686923284101  Validation Loss:  0.42947719757046016\n",
      "Epoch:  1168  Loss:  0.3624930290319908  Validation Loss:  0.4295560653720583\n",
      "Epoch:  1169  Loss:  0.36251393627922684  Validation Loss:  0.42963255345821383\n",
      "Epoch:  1170  Loss:  0.362530885396693  Validation Loss:  0.42970507889986037\n",
      "Epoch:  1171  Loss:  0.3625437326340879  Validation Loss:  0.42977202598537717\n",
      "Epoch:  1172  Loss:  0.3625528473777794  Validation Loss:  0.4298319578170776\n",
      "Epoch:  1173  Loss:  0.3625590357382151  Validation Loss:  0.42988370039633345\n",
      "Epoch:  1174  Loss:  0.3625631837695131  Validation Loss:  0.429926774757249\n",
      "Epoch:  1175  Loss:  0.36256604666393516  Validation Loss:  0.4299617997237614\n",
      "Epoch:  1176  Loss:  0.36256810210609886  Validation Loss:  0.42999038078955243\n",
      "Epoch:  1177  Loss:  0.362569659206822  Validation Loss:  0.4300146424344608\n",
      "Epoch:  1178  Loss:  0.36257083304402954  Validation Loss:  0.43003655650785994\n",
      "Epoch:  1179  Loss:  0.3625715928620072  Validation Loss:  0.4300576229180608\n",
      "Epoch:  1180  Loss:  0.36257178502342713  Validation Loss:  0.4300788027899606\n",
      "Epoch:  1181  Loss:  0.36257125348982655  Validation Loss:  0.43010070792266303\n",
      "Epoch:  1182  Loss:  0.362569700520468  Validation Loss:  0.4301235437393188\n",
      "Epoch:  1183  Loss:  0.3625665404502814  Validation Loss:  0.4301473640969821\n",
      "Epoch:  1184  Loss:  0.36256119294612893  Validation Loss:  0.4301720551082066\n",
      "Epoch:  1185  Loss:  0.3625529445531244  Validation Loss:  0.4301974639296532\n",
      "Epoch:  1186  Loss:  0.36254093700675605  Validation Loss:  0.4302233798163278\n",
      "Epoch:  1187  Loss:  0.36252440303846556  Validation Loss:  0.4302497359258788\n",
      "Epoch:  1188  Loss:  0.3625028468491907  Validation Loss:  0.4302767089435032\n",
      "Epoch:  1189  Loss:  0.36247636547303314  Validation Loss:  0.43030490215335576\n",
      "Epoch:  1190  Loss:  0.36244584535252994  Validation Loss:  0.4303352094122342\n",
      "Epoch:  1191  Loss:  0.3624126327122557  Validation Loss:  0.430368589929172\n",
      "Epoch:  1192  Loss:  0.36237818006231887  Validation Loss:  0.4304057666233608\n",
      "Epoch:  1193  Loss:  0.3623436257172535  Validation Loss:  0.43044703155756\n",
      "Epoch:  1194  Loss:  0.36230976053323793  Validation Loss:  0.4304922310369355\n",
      "Epoch:  1195  Loss:  0.3622770578516603  Validation Loss:  0.4305407296333994\n",
      "Epoch:  1196  Loss:  0.36224574051903324  Validation Loss:  0.4305914944836072\n",
      "Epoch:  1197  Loss:  0.3622158572642724  Validation Loss:  0.43064324983528685\n",
      "Epoch:  1198  Loss:  0.36218748757200786  Validation Loss:  0.43069463819265363\n",
      "Epoch:  1199  Loss:  0.36216053384316477  Validation Loss:  0.43074423032147546\n",
      "Epoch:  1200  Loss:  0.36213497559747426  Validation Loss:  0.4307908724461283\n",
      "Epoch:  1201  Loss:  0.36211069238976845  Validation Loss:  0.43083369114569253\n",
      "Epoch:  1202  Loss:  0.36208758125372975  Validation Loss:  0.43087237988199506\n",
      "Epoch:  1203  Loss:  0.3620656950143276  Validation Loss:  0.43090721645525526\n",
      "Epoch:  1204  Loss:  0.3620449319411228  Validation Loss:  0.4309390140431268\n",
      "Epoch:  1205  Loss:  0.36202525834760396  Validation Loss:  0.430968899173396\n",
      "Epoch:  1206  Loss:  0.3620067591209547  Validation Loss:  0.43099808373621534\n",
      "Epoch:  1207  Loss:  0.36198938694469174  Validation Loss:  0.4310276363577161\n",
      "Epoch:  1208  Loss:  0.3619730890997778  Validation Loss:  0.43105840874569756\n",
      "Epoch:  1209  Loss:  0.3619578369491473  Validation Loss:  0.43109110678945267\n",
      "Epoch:  1210  Loss:  0.3619436751962838  Validation Loss:  0.4311262705496379\n",
      "Epoch:  1211  Loss:  0.36193055648939304  Validation Loss:  0.43116427468402047\n",
      "Epoch:  1212  Loss:  0.36191837757967094  Validation Loss:  0.4312054548944746\n",
      "Epoch:  1213  Loss:  0.36190709722409314  Validation Loss:  0.43125009536743164\n",
      "Epoch:  1214  Loss:  0.3618966718138112  Validation Loss:  0.4312984079122543\n",
      "Epoch:  1215  Loss:  0.3618870902965419  Validation Loss:  0.43135059135300774\n",
      "Epoch:  1216  Loss:  0.3618784096639303  Validation Loss:  0.43140671593802316\n",
      "Epoch:  1217  Loss:  0.3618705361657798  Validation Loss:  0.4314667233398983\n",
      "Epoch:  1218  Loss:  0.3618634266522823  Validation Loss:  0.4315303263919694\n",
      "Epoch:  1219  Loss:  0.3618570750146681  Validation Loss:  0.43159707827227456\n",
      "Epoch:  1220  Loss:  0.361851444000034  Validation Loss:  0.43166625797748565\n",
      "Epoch:  1221  Loss:  0.3618465461790279  Validation Loss:  0.43173694142273494\n",
      "Epoch:  1222  Loss:  0.3618424403794569  Validation Loss:  0.4318081034081323\n",
      "Epoch:  1223  Loss:  0.3618390413257183  Validation Loss:  0.4318785922867911\n",
      "Epoch:  1224  Loss:  0.3618362815388571  Validation Loss:  0.4319474090422903\n",
      "Epoch:  1225  Loss:  0.3618341781799262  Validation Loss:  0.4320136589663369\n",
      "Epoch:  1226  Loss:  0.36183266394652464  Validation Loss:  0.4320767643196242\n",
      "Epoch:  1227  Loss:  0.36183161013075527  Validation Loss:  0.43213647242103304\n",
      "Epoch:  1228  Loss:  0.36183094123810955  Validation Loss:  0.43219296165875026\n",
      "Epoch:  1229  Loss:  0.3618306186032521  Validation Loss:  0.43224673782076156\n",
      "Epoch:  1230  Loss:  0.3618306487586826  Validation Loss:  0.43229853830167225\n",
      "Epoch:  1231  Loss:  0.36183086129443903  Validation Loss:  0.4323491469025612\n",
      "Epoch:  1232  Loss:  0.36183113445885373  Validation Loss:  0.4323992963348116\n",
      "Epoch:  1233  Loss:  0.3618313475242723  Validation Loss:  0.4324495817933764\n",
      "Epoch:  1234  Loss:  0.36183128880239773  Validation Loss:  0.4325004590409143\n",
      "Epoch:  1235  Loss:  0.36183073325744736  Validation Loss:  0.4325522001300539\n",
      "Epoch:  1236  Loss:  0.36182933844520015  Validation Loss:  0.43260490681443897\n",
      "Epoch:  1237  Loss:  0.36182672170242425  Validation Loss:  0.43265853226184847\n",
      "Epoch:  1238  Loss:  0.36182236064101847  Validation Loss:  0.43271286146981375\n",
      "Epoch:  1239  Loss:  0.3618156604857241  Validation Loss:  0.4327675291470119\n",
      "Epoch:  1240  Loss:  0.36180590456837164  Validation Loss:  0.43282202673809866\n",
      "Epoch:  1241  Loss:  0.3617924937704728  Validation Loss:  0.43287587399993627\n",
      "Epoch:  1242  Loss:  0.36177497794984076  Validation Loss:  0.43292874289410455\n",
      "Epoch:  1243  Loss:  0.36175337938759566  Validation Loss:  0.4329806223511696\n",
      "Epoch:  1244  Loss:  0.36172845737205295  Validation Loss:  0.43303185552358625\n",
      "Epoch:  1245  Loss:  0.3617013816796773  Validation Loss:  0.4330826999885695\n",
      "Epoch:  1246  Loss:  0.36167334397963435  Validation Loss:  0.4331332387668746\n",
      "Epoch:  1247  Loss:  0.36164524949981136  Validation Loss:  0.433183208320822\n",
      "Epoch:  1248  Loss:  0.36161769315671016  Validation Loss:  0.4332322041903223\n",
      "Epoch:  1249  Loss:  0.3615909889693509  Validation Loss:  0.4332798061626298\n",
      "Epoch:  1250  Loss:  0.3615652912106559  Validation Loss:  0.43332568194184984\n",
      "Epoch:  1251  Loss:  0.361540657472554  Validation Loss:  0.43336978022541317\n",
      "Epoch:  1252  Loss:  0.3615171077056519  Validation Loss:  0.4334122400198664\n",
      "Epoch:  1253  Loss:  0.36149464130966585  Validation Loss:  0.43345344215631487\n",
      "Epoch:  1254  Loss:  0.3614732839908645  Validation Loss:  0.4334939181804657\n",
      "Epoch:  1255  Loss:  0.36145307466175886  Validation Loss:  0.4335342967084476\n",
      "Epoch:  1256  Loss:  0.36143395513013643  Validation Loss:  0.4335751167365483\n",
      "Epoch:  1257  Loss:  0.36141585908229884  Validation Loss:  0.43361695877143314\n",
      "Epoch:  1258  Loss:  0.36139876208316657  Validation Loss:  0.4336602775113923\n",
      "Epoch:  1259  Loss:  0.36138264118071417  Validation Loss:  0.43370545378753117\n",
      "Epoch:  1260  Loss:  0.36136746046384927  Validation Loss:  0.4337527830685888\n",
      "Epoch:  1261  Loss:  0.3613531730751291  Validation Loss:  0.43380254613501684\n",
      "Epoch:  1262  Loss:  0.3613397725173647  Validation Loss:  0.4338548928499222\n",
      "Epoch:  1263  Loss:  0.361327197067263  Validation Loss:  0.4339099464671952\n",
      "Epoch:  1264  Loss:  0.3613154523392424  Validation Loss:  0.4339677723390715\n",
      "Epoch:  1265  Loss:  0.36130451576969635  Validation Loss:  0.4340283306581633\n",
      "Epoch:  1266  Loss:  0.361294401341705  Validation Loss:  0.4340914587889399\n",
      "Epoch:  1267  Loss:  0.36128509422472865  Validation Loss:  0.4341569457735334\n",
      "Epoch:  1268  Loss:  0.36127657210233655  Validation Loss:  0.4342243777854102\n",
      "Epoch:  1269  Loss:  0.3612688296779072  Validation Loss:  0.4342932982104165\n",
      "Epoch:  1270  Loss:  0.3612618699881703  Validation Loss:  0.43436314186879565\n",
      "Epoch:  1271  Loss:  0.3612556577223172  Validation Loss:  0.4344333263380187\n",
      "Epoch:  1272  Loss:  0.36125019574052347  Validation Loss:  0.4345032979335104\n",
      "Epoch:  1273  Loss:  0.36124546091420956  Validation Loss:  0.43457252383232114\n",
      "Epoch:  1274  Loss:  0.3612414554326455  Validation Loss:  0.43464063107967377\n",
      "Epoch:  1275  Loss:  0.36123822678886885  Validation Loss:  0.4347074508666992\n",
      "Epoch:  1276  Loss:  0.3612357500887595  Validation Loss:  0.4347729137965611\n",
      "Epoch:  1277  Loss:  0.361233964385862  Validation Loss:  0.4348371935742242\n",
      "Epoch:  1278  Loss:  0.36123287437651397  Validation Loss:  0.4349005786435945\n",
      "Epoch:  1279  Loss:  0.3612324734929049  Validation Loss:  0.434963487301554\n",
      "Epoch:  1280  Loss:  0.3612327625118726  Validation Loss:  0.43502637382064546\n",
      "Epoch:  1281  Loss:  0.36123372222433725  Validation Loss:  0.4350896939635277\n",
      "Epoch:  1282  Loss:  0.36123534638028576  Validation Loss:  0.4351538653884615\n",
      "Epoch:  1283  Loss:  0.36123763889921784  Validation Loss:  0.4352192333766392\n",
      "Epoch:  1284  Loss:  0.3612405867514452  Validation Loss:  0.43528614533799037\n",
      "Epoch:  1285  Loss:  0.3612441710456853  Validation Loss:  0.4353548462901797\n",
      "Epoch:  1286  Loss:  0.3612483875799518  Validation Loss:  0.4354255469782012\n",
      "Epoch:  1287  Loss:  0.36125320619881435  Validation Loss:  0.43549834213086536\n",
      "Epoch:  1288  Loss:  0.36125862838532685  Validation Loss:  0.43557332349675043\n",
      "Epoch:  1289  Loss:  0.361264639273639  Validation Loss:  0.43565044275351933\n",
      "Epoch:  1290  Loss:  0.3612712229032652  Validation Loss:  0.43572960304362435\n",
      "Epoch:  1291  Loss:  0.36127836709197664  Validation Loss:  0.43581060618162154\n",
      "Epoch:  1292  Loss:  0.3612860603990713  Validation Loss:  0.43589316372360504\n",
      "Epoch:  1293  Loss:  0.3612943003174818  Validation Loss:  0.43597690697227204\n",
      "Epoch:  1294  Loss:  0.3613030610703179  Validation Loss:  0.4360613949596882\n",
      "Epoch:  1295  Loss:  0.3613123379612421  Validation Loss:  0.43614618267331806\n",
      "Epoch:  1296  Loss:  0.3613220901356489  Validation Loss:  0.43623078241944313\n",
      "Epoch:  1297  Loss:  0.36133230057372867  Validation Loss:  0.43631481773086955\n",
      "Epoch:  1298  Loss:  0.3613429297979974  Validation Loss:  0.43639793917536734\n",
      "Epoch:  1299  Loss:  0.36135394874765975  Validation Loss:  0.43647994015898023\n",
      "Epoch:  1300  Loss:  0.36136531282516454  Validation Loss:  0.43656072339841295\n",
      "Epoch:  1301  Loss:  0.3613769828002035  Validation Loss:  0.4366403276366847\n",
      "Epoch:  1302  Loss:  0.3613889146401984  Validation Loss:  0.43671888868723596\n",
      "Epoch:  1303  Loss:  0.3614010363817215  Validation Loss:  0.4367966204881668\n",
      "Epoch:  1304  Loss:  0.3614132749313992  Validation Loss:  0.436873776784965\n",
      "Epoch:  1305  Loss:  0.3614255414472372  Validation Loss:  0.4369506140904767\n",
      "Epoch:  1306  Loss:  0.3614377021012713  Validation Loss:  0.4370273310158934\n",
      "Epoch:  1307  Loss:  0.3614496003606873  Validation Loss:  0.4371041040335383\n",
      "Epoch:  1308  Loss:  0.3614610319877688  Validation Loss:  0.4371809863618442\n",
      "Epoch:  1309  Loss:  0.36147178314025935  Validation Loss:  0.437257947240557\n",
      "Epoch:  1310  Loss:  0.36148157722859586  Validation Loss:  0.4373348578810692\n",
      "Epoch:  1311  Loss:  0.361490090134867  Validation Loss:  0.43741150296160153\n",
      "Epoch:  1312  Loss:  0.3614970245067542  Validation Loss:  0.4374876534300191\n",
      "Epoch:  1313  Loss:  0.36150216346527164  Validation Loss:  0.43756325777087896\n",
      "Epoch:  1314  Loss:  0.36150546901598923  Validation Loss:  0.43763843200036456\n",
      "Epoch:  1315  Loss:  0.36150709423126204  Validation Loss:  0.43771355641739706\n",
      "Epoch:  1316  Loss:  0.36150741372345746  Validation Loss:  0.4377893428717341\n",
      "Epoch:  1317  Loss:  0.361506959803014  Validation Loss:  0.4378665804862976\n",
      "Epoch:  1318  Loss:  0.36150627329027485  Validation Loss:  0.43794586562684606\n",
      "Epoch:  1319  Loss:  0.36150583010431714  Validation Loss:  0.43802747470991954\n",
      "Epoch:  1320  Loss:  0.3615059111779335  Validation Loss:  0.43811135047248434\n",
      "Epoch:  1321  Loss:  0.36150672576297516  Validation Loss:  0.4381971151701042\n",
      "Epoch:  1322  Loss:  0.3615083614302472  Validation Loss:  0.4382842604603086\n",
      "Epoch:  1323  Loss:  0.3615108510541125  Validation Loss:  0.4383721470832825\n",
      "Epoch:  1324  Loss:  0.3615142085117186  Validation Loss:  0.4384601520640509\n",
      "Epoch:  1325  Loss:  0.36151843821691676  Validation Loss:  0.4385476330561297\n",
      "Epoch:  1326  Loss:  0.3615235060594658  Validation Loss:  0.43863409268004555\n",
      "Epoch:  1327  Loss:  0.3615293885223673  Validation Loss:  0.43871916362217495\n",
      "Epoch:  1328  Loss:  0.36153607038666286  Validation Loss:  0.4388026252388954\n",
      "Epoch:  1329  Loss:  0.3615435255576649  Validation Loss:  0.43888443346534456\n",
      "Epoch:  1330  Loss:  0.36155176155657565  Validation Loss:  0.4389647799943175\n",
      "Epoch:  1331  Loss:  0.36156075091158607  Validation Loss:  0.43904403703553335\n",
      "Epoch:  1332  Loss:  0.3615704889616695  Validation Loss:  0.4391227494393076\n",
      "Epoch:  1333  Loss:  0.3615809761658664  Validation Loss:  0.43920154869556427\n",
      "Epoch:  1334  Loss:  0.36159221831514937  Validation Loss:  0.43928109843816077\n",
      "Epoch:  1335  Loss:  0.3616041937993036  Validation Loss:  0.4393620765634945\n",
      "Epoch:  1336  Loss:  0.3616168984516537  Validation Loss:  0.4394450602786882\n",
      "Epoch:  1337  Loss:  0.361630301410553  Validation Loss:  0.43953057559473174\n",
      "Epoch:  1338  Loss:  0.3616444029231772  Validation Loss:  0.43961899716939246\n",
      "Epoch:  1339  Loss:  0.3616591810615142  Validation Loss:  0.4397105485200882\n",
      "Epoch:  1340  Loss:  0.36167461802891643  Validation Loss:  0.4398052766919136\n",
      "Epoch:  1341  Loss:  0.36169071894545124  Validation Loss:  0.43990303874015807\n",
      "Epoch:  1342  Loss:  0.3617074557390258  Validation Loss:  0.44000342807599474\n",
      "Epoch:  1343  Loss:  0.36172483875570705  Validation Loss:  0.4401059277355671\n",
      "Epoch:  1344  Loss:  0.3617428286592542  Validation Loss:  0.44020980511392865\n",
      "Epoch:  1345  Loss:  0.3617614155273302  Validation Loss:  0.44031436783926825\n",
      "Epoch:  1346  Loss:  0.36178061553228524  Validation Loss:  0.4404189597283091\n",
      "Epoch:  1347  Loss:  0.3618004202348361  Validation Loss:  0.44052290692925455\n",
      "Epoch:  1348  Loss:  0.3618208394513876  Validation Loss:  0.44062570982745713\n",
      "Epoch:  1349  Loss:  0.3618418749121693  Validation Loss:  0.4407269329896995\n",
      "Epoch:  1350  Loss:  0.3618635170832629  Validation Loss:  0.44082631639071873\n",
      "Epoch:  1351  Loss:  0.36188576649433063  Validation Loss:  0.44092380074518067\n",
      "Epoch:  1352  Loss:  0.3619086148120216  Validation Loss:  0.44101952718836923\n",
      "Epoch:  1353  Loss:  0.36193206411967344  Validation Loss:  0.44111385866999625\n",
      "Epoch:  1354  Loss:  0.3619561240218262  Validation Loss:  0.44120732481990543\n",
      "Epoch:  1355  Loss:  0.36198080663008714  Validation Loss:  0.4413005954452923\n",
      "Epoch:  1356  Loss:  0.3620061058356864  Validation Loss:  0.4413943541901452\n",
      "Epoch:  1357  Loss:  0.362032032690907  Validation Loss:  0.441489290446043\n",
      "Epoch:  1358  Loss:  0.36205857476634434  Validation Loss:  0.44158603878957886\n",
      "Epoch:  1359  Loss:  0.3620857323091742  Validation Loss:  0.4416851611009666\n",
      "Epoch:  1360  Loss:  0.3621134826498574  Validation Loss:  0.4417870605630534\n",
      "Epoch:  1361  Loss:  0.36214180749739516  Validation Loss:  0.4418920310480254\n",
      "Epoch:  1362  Loss:  0.36217071642101656  Validation Loss:  0.44200017473527364\n",
      "Epoch:  1363  Loss:  0.36220018894045275  Validation Loss:  0.4421113828463214\n",
      "Epoch:  1364  Loss:  0.3622302224427038  Validation Loss:  0.44222534054092\n",
      "Epoch:  1365  Loss:  0.36226081074837824  Validation Loss:  0.44234156225408827\n",
      "Epoch:  1366  Loss:  0.3622919619789621  Validation Loss:  0.44245941128049576\n",
      "Epoch:  1367  Loss:  0.36232368189011704  Validation Loss:  0.442578149586916\n",
      "Epoch:  1368  Loss:  0.3623559966118415  Validation Loss:  0.4426970523382936\n",
      "Epoch:  1369  Loss:  0.3623889233404991  Validation Loss:  0.44281542162810056\n",
      "Epoch:  1370  Loss:  0.36242243545174035  Validation Loss:  0.44293267407587594\n",
      "Epoch:  1371  Loss:  0.36245650607403984  Validation Loss:  0.4430483030421393\n",
      "Epoch:  1372  Loss:  0.36249112376669573  Validation Loss:  0.4431620314717293\n",
      "Epoch:  1373  Loss:  0.36252629357915356  Validation Loss:  0.44327371131096566\n",
      "Epoch:  1374  Loss:  0.362562005059414  Validation Loss:  0.4433834781604154\n",
      "Epoch:  1375  Loss:  0.3625982666820711  Validation Loss:  0.44349166985069005\n",
      "Epoch:  1376  Loss:  0.36263508413216516  Validation Loss:  0.44359877982309887\n",
      "Epoch:  1377  Loss:  0.3626724747826138  Validation Loss:  0.44370549438255175\n",
      "Epoch:  1378  Loss:  0.36271043206560666  Validation Loss:  0.44381248110107013\n",
      "Epoch:  1379  Loss:  0.3627489703173321  Validation Loss:  0.44392048610108237\n",
      "Epoch:  1380  Loss:  0.36278808099257437  Validation Loss:  0.4440301581152848\n",
      "Epoch:  1381  Loss:  0.36282775981872567  Validation Loss:  0.4441420664744718\n",
      "Epoch:  1382  Loss:  0.3628679807717201  Validation Loss:  0.4442567036620208\n",
      "Epoch:  1383  Loss:  0.36290874409873336  Validation Loss:  0.44437436312437056\n",
      "Epoch:  1384  Loss:  0.36295004602150893  Validation Loss:  0.444495231871094\n",
      "Epoch:  1385  Loss:  0.36299187976037156  Validation Loss:  0.4446192128317697\n",
      "Epoch:  1386  Loss:  0.3630342380766055  Validation Loss:  0.4447460483227457\n",
      "Epoch:  1387  Loss:  0.3630771282442373  Validation Loss:  0.4448752673608916\n",
      "Epoch:  1388  Loss:  0.36312054969829405  Validation Loss:  0.44500622525811195\n",
      "Epoch:  1389  Loss:  0.3631645000729516  Validation Loss:  0.44513820612004823\n",
      "Epoch:  1390  Loss:  0.36320898819591196  Validation Loss:  0.44527045616081784\n",
      "Epoch:  1391  Loss:  0.363254004709811  Validation Loss:  0.44540223085454533\n",
      "Epoch:  1392  Loss:  0.363299534254447  Validation Loss:  0.4455328820007188\n",
      "Epoch:  1393  Loss:  0.3633455772535496  Validation Loss:  0.4456619113683701\n",
      "Epoch:  1394  Loss:  0.3633921340249161  Validation Loss:  0.44578891854201047\n",
      "Epoch:  1395  Loss:  0.3634391771320483  Validation Loss:  0.44591376377003533\n",
      "Epoch:  1396  Loss:  0.36348672408910726  Validation Loss:  0.44603651112743786\n",
      "Epoch:  1397  Loss:  0.36353476221951264  Validation Loss:  0.4461574354342052\n",
      "Epoch:  1398  Loss:  0.36358329145264284  Validation Loss:  0.44627700980220525\n",
      "Epoch:  1399  Loss:  0.3636322926853505  Validation Loss:  0.44639577642083167\n",
      "Epoch:  1400  Loss:  0.3636817432127858  Validation Loss:  0.4465144489492689\n",
      "Epoch:  1401  Loss:  0.3637316813824866  Validation Loss:  0.44663390187280516\n",
      "Epoch:  1402  Loss:  0.3637821396097753  Validation Loss:  0.44675488365548\n",
      "Epoch:  1403  Loss:  0.3638331313480698  Validation Loss:  0.4468780335571085\n",
      "Epoch:  1404  Loss:  0.363884623263967  Validation Loss:  0.44700385704636575\n",
      "Epoch:  1405  Loss:  0.3639366149690479  Validation Loss:  0.4471327217561858\n",
      "Epoch:  1406  Loss:  0.36398910021329944  Validation Loss:  0.44726482927799227\n",
      "Epoch:  1407  Loss:  0.36404207889078916  Validation Loss:  0.44740016449775016\n",
      "Epoch:  1408  Loss:  0.3640955395608152  Validation Loss:  0.44753846057823726\n",
      "Epoch:  1409  Loss:  0.3641494781273236  Validation Loss:  0.44767928059612\n",
      "Epoch:  1410  Loss:  0.3642038915182742  Validation Loss:  0.4478219663458211\n",
      "Epoch:  1411  Loss:  0.36425879587070636  Validation Loss:  0.4479658231139183\n",
      "Epoch:  1412  Loss:  0.3643141958103361  Validation Loss:  0.44811004985656055\n",
      "Epoch:  1413  Loss:  0.3643701039431219  Validation Loss:  0.4482538934264864\n",
      "Epoch:  1414  Loss:  0.3644264975642141  Validation Loss:  0.44839665783303123\n",
      "Epoch:  1415  Loss:  0.364483372718802  Validation Loss:  0.4485377289354801\n",
      "Epoch:  1416  Loss:  0.3645407266879534  Validation Loss:  0.44867671291743005\n",
      "Epoch:  1417  Loss:  0.3645985457004529  Validation Loss:  0.448813361035926\n",
      "Epoch:  1418  Loss:  0.36465680009522145  Validation Loss:  0.4489477151206562\n",
      "Epoch:  1419  Loss:  0.3647155011717177  Validation Loss:  0.4490800273205553\n",
      "Epoch:  1420  Loss:  0.3647746482590363  Validation Loss:  0.44921074860862326\n",
      "Epoch:  1421  Loss:  0.3648342435111367  Validation Loss:  0.4493405658219542\n",
      "Epoch:  1422  Loss:  0.36489429042378874  Validation Loss:  0.4494701225842748\n",
      "Epoch:  1423  Loss:  0.3649547169276323  Validation Loss:  0.44959999205810686\n",
      "Epoch:  1424  Loss:  0.3650155149718031  Validation Loss:  0.4497311371777739\n",
      "Epoch:  1425  Loss:  0.36507676280505286  Validation Loss:  0.4498642975730555\n",
      "Epoch:  1426  Loss:  0.36513848500370416  Validation Loss:  0.45000004885452133\n",
      "Epoch:  1427  Loss:  0.36520066705501475  Validation Loss:  0.45013885466115816\n",
      "Epoch:  1428  Loss:  0.3652632872428374  Validation Loss:  0.45028092179979595\n",
      "Epoch:  1429  Loss:  0.36532635220560417  Validation Loss:  0.4504263071077211\n",
      "Epoch:  1430  Loss:  0.3653898433698297  Validation Loss:  0.4505747792976243\n",
      "Epoch:  1431  Loss:  0.36545377358864833  Validation Loss:  0.4507259547710419\n",
      "Epoch:  1432  Loss:  0.3655181451572626  Validation Loss:  0.45087918075067657\n",
      "Epoch:  1433  Loss:  0.3655829750248606  Validation Loss:  0.45103372974055156\n",
      "Epoch:  1434  Loss:  0.36564825782419946  Validation Loss:  0.45118875939931186\n",
      "Epoch:  1435  Loss:  0.3657139826442393  Validation Loss:  0.4513434126973152\n",
      "Epoch:  1436  Loss:  0.36578005598195923  Validation Loss:  0.45149665102362635\n",
      "Epoch:  1437  Loss:  0.3658464541438067  Validation Loss:  0.45164811568600793\n",
      "Epoch:  1438  Loss:  0.3659132544604523  Validation Loss:  0.45179739658321655\n",
      "Epoch:  1439  Loss:  0.36598045629630155  Validation Loss:  0.4519442066550255\n",
      "Epoch:  1440  Loss:  0.36604806710193505  Validation Loss:  0.45208852546555656\n",
      "Epoch:  1441  Loss:  0.36611606759765136  Validation Loss:  0.4522305678044047\n",
      "Epoch:  1442  Loss:  0.36618448571429996  Validation Loss:  0.4523708028452737\n",
      "Epoch:  1443  Loss:  0.3662533102936654  Validation Loss:  0.45250984228083063\n",
      "Epoch:  1444  Loss:  0.36632248208421103  Validation Loss:  0.45264812665326254\n",
      "Epoch:  1445  Loss:  0.36639198244182986  Validation Loss:  0.4527867779135704\n",
      "Epoch:  1446  Loss:  0.36646192054754184  Validation Loss:  0.4529266316975866\n",
      "Epoch:  1447  Loss:  0.3665322709422541  Validation Loss:  0.4530683578125068\n",
      "Epoch:  1448  Loss:  0.3666030130397652  Validation Loss:  0.4532125494309834\n",
      "Epoch:  1449  Loss:  0.36667412512392794  Validation Loss:  0.4533596334712846\n",
      "Epoch:  1450  Loss:  0.3667455088541406  Validation Loss:  0.45350961493594305\n",
      "Epoch:  1451  Loss:  0.3668171546964849  Validation Loss:  0.453662892218147\n",
      "Epoch:  1452  Loss:  0.36688914951554974  Validation Loss:  0.45381932748215537\n",
      "Epoch:  1453  Loss:  0.3669614995260374  Validation Loss:  0.453978546921696\n",
      "Epoch:  1454  Loss:  0.3670341416275332  Validation Loss:  0.4541395233145782\n",
      "Epoch:  1455  Loss:  0.3671070237012836  Validation Loss:  0.4543018117547035\n",
      "Epoch:  1456  Loss:  0.3671802501966603  Validation Loss:  0.45446461609431676\n",
      "Epoch:  1457  Loss:  0.367253774503396  Validation Loss:  0.4546267677630697\n",
      "Epoch:  1458  Loss:  0.3673275008938889  Validation Loss:  0.4547876958336149\n",
      "Epoch:  1459  Loss:  0.36740154239803696  Validation Loss:  0.45494677094476565\n",
      "Epoch:  1460  Loss:  0.36747577316811864  Validation Loss:  0.4551031479878085\n",
      "Epoch:  1461  Loss:  0.3675502143199975  Validation Loss:  0.4552568328167711\n",
      "Epoch:  1462  Loss:  0.36762479438459705  Validation Loss:  0.45540731038366045\n",
      "Epoch:  1463  Loss:  0.3676994906217566  Validation Loss:  0.45555483411465375\n",
      "Epoch:  1464  Loss:  0.36777424879407433  Validation Loss:  0.4556998709482806\n",
      "Epoch:  1465  Loss:  0.36784910961491235  Validation Loss:  0.455842794158629\n",
      "Epoch:  1466  Loss:  0.3679239935290192  Validation Loss:  0.4559843901012625\n",
      "Epoch:  1467  Loss:  0.3679988218286026  Validation Loss:  0.4561253119792257\n",
      "Epoch:  1468  Loss:  0.3680735455375712  Validation Loss:  0.4562662962291922\n",
      "Epoch:  1469  Loss:  0.3681480566048509  Validation Loss:  0.4564078787607806\n",
      "Epoch:  1470  Loss:  0.36822221830699114  Validation Loss:  0.45655041549886977\n",
      "Epoch:  1471  Loss:  0.3682959133061752  Validation Loss:  0.456694322185857\n",
      "Epoch:  1472  Loss:  0.3683689590102123  Validation Loss:  0.4568394648177283\n",
      "Epoch:  1473  Loss:  0.3684411172123882  Validation Loss:  0.4569856271147728\n",
      "Epoch:  1474  Loss:  0.3685121037313158  Validation Loss:  0.4571320156965937\n",
      "Epoch:  1475  Loss:  0.3685816147527988  Validation Loss:  0.45727772106017384\n",
      "Epoch:  1476  Loss:  0.36864935161801876  Validation Loss:  0.45742170267871446\n",
      "Epoch:  1477  Loss:  0.3687151249551095  Validation Loss:  0.45756295397877694\n",
      "Epoch:  1478  Loss:  0.3687788058443092  Validation Loss:  0.4577006018587521\n",
      "Epoch:  1479  Loss:  0.3688404267715617  Validation Loss:  0.45783403856413707\n",
      "Epoch:  1480  Loss:  0.3689000825463878  Validation Loss:  0.45796273169772966\n",
      "Epoch:  1481  Loss:  0.3689578876817396  Validation Loss:  0.45808637493423054\n",
      "Epoch:  1482  Loss:  0.3690140303489156  Validation Loss:  0.4582051057900701\n",
      "Epoch:  1483  Loss:  0.3690689514033602  Validation Loss:  0.45831982376320024\n",
      "Epoch:  1484  Loss:  0.3691231857332008  Validation Loss:  0.45843166219336645\n",
      "Epoch:  1485  Loss:  0.3691772512420659  Validation Loss:  0.45854158529213496\n",
      "Epoch:  1486  Loss:  0.3692315130790263  Validation Loss:  0.4586505350257669\n",
      "Epoch:  1487  Loss:  0.36928627887184584  Validation Loss:  0.4587592337812696\n",
      "Epoch:  1488  Loss:  0.3693416486913559  Validation Loss:  0.4588681003877095\n",
      "Epoch:  1489  Loss:  0.3693976671704184  Validation Loss:  0.4589777072625501\n",
      "Epoch:  1490  Loss:  0.36945441538264967  Validation Loss:  0.4590884746185371\n",
      "Epoch:  1491  Loss:  0.3695118526146875  Validation Loss:  0.4592006292726312\n",
      "Epoch:  1492  Loss:  0.3695699431673045  Validation Loss:  0.45931454247662\n",
      "Epoch:  1493  Loss:  0.3696287086860264  Validation Loss:  0.4594305055482047\n",
      "Epoch:  1494  Loss:  0.369688106197599  Validation Loss:  0.4595485920352595\n",
      "Epoch:  1495  Loss:  0.36974802083596237  Validation Loss:  0.4596687233873776\n",
      "Epoch:  1496  Loss:  0.36980843536944186  Validation Loss:  0.45979089619857927\n",
      "Epoch:  1497  Loss:  0.3698693499745916  Validation Loss:  0.45991502585155625\n",
      "Epoch:  1498  Loss:  0.36993072619794104  Validation Loss:  0.4600406467914581\n",
      "Epoch:  1499  Loss:  0.3699925238204793  Validation Loss:  0.4601676220340388\n",
      "Training session:  1\n",
      "2020_11_23_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_23_MV1_run\n",
      "Epoch:  0  Loss:  0.39038433306144943  Validation Loss:  0.40791882195255974\n",
      "Epoch:  1  Loss:  0.3903755604317694  Validation Loss:  0.40780510306358336\n",
      "Epoch:  2  Loss:  0.3903578216379339  Validation Loss:  0.40770553702657875\n",
      "Epoch:  3  Loss:  0.39033662076249265  Validation Loss:  0.407617891647599\n",
      "Epoch:  4  Loss:  0.39031090208075264  Validation Loss:  0.40753882906653666\n",
      "Epoch:  5  Loss:  0.39028203681562884  Validation Loss:  0.4074665540998632\n",
      "Epoch:  6  Loss:  0.39025260508060455  Validation Loss:  0.4073997600512071\n",
      "Epoch:  7  Loss:  0.3902245871496923  Validation Loss:  0.4073376814072782\n",
      "Epoch:  8  Loss:  0.3901982487151117  Validation Loss:  0.40727954533967103\n",
      "Epoch:  9  Loss:  0.39017424922097815  Validation Loss:  0.4072246554222974\n",
      "Epoch:  10  Loss:  0.3901526710752285  Validation Loss:  0.4071728538383137\n",
      "Epoch:  11  Loss:  0.3901335888739788  Validation Loss:  0.40712394402785734\n",
      "Epoch:  12  Loss:  0.3901167138959422  Validation Loss:  0.40707761320200836\n",
      "Epoch:  13  Loss:  0.39010187089443205  Validation Loss:  0.4070333804596554\n",
      "Epoch:  14  Loss:  0.3900888475956339  Validation Loss:  0.40699137598276136\n",
      "Epoch:  15  Loss:  0.3900775288993662  Validation Loss:  0.40695128467949954\n",
      "Epoch:  16  Loss:  0.3900677154009992  Validation Loss:  0.4069127701900222\n",
      "Epoch:  17  Loss:  0.3900592756993843  Validation Loss:  0.40687601173465904\n",
      "Epoch:  18  Loss:  0.390052113478834  Validation Loss:  0.40684080760587343\n",
      "Epoch:  19  Loss:  0.39004605010603416  Validation Loss:  0.40680679800835523\n",
      "Epoch:  20  Loss:  0.3900409795569651  Validation Loss:  0.4067740959199992\n",
      "Epoch:  21  Loss:  0.3900368158564423  Validation Loss:  0.4067425798286091\n",
      "Epoch:  22  Loss:  0.3900333689017729  Validation Loss:  0.4067121440714056\n",
      "Epoch:  23  Loss:  0.39003052652785275  Validation Loss:  0.4066824642094699\n",
      "Epoch:  24  Loss:  0.3900281037345077  Validation Loss:  0.4066534997387366\n",
      "Epoch:  25  Loss:  0.39002600849577873  Validation Loss:  0.4066253690557046\n",
      "Epoch:  26  Loss:  0.3900241075591607  Validation Loss:  0.4065979222005064\n",
      "Epoch:  27  Loss:  0.39002217122099614  Validation Loss:  0.4065708795731718\n",
      "Epoch:  28  Loss:  0.3900199230421673  Validation Loss:  0.40654396292838185\n",
      "Epoch:  29  Loss:  0.3900171037876245  Validation Loss:  0.406517015803944\n",
      "Epoch:  30  Loss:  0.39001344406243527  Validation Loss:  0.406489924680103\n",
      "Epoch:  31  Loss:  0.3900086246656649  Validation Loss:  0.40646260448477484\n",
      "Epoch:  32  Loss:  0.39000230553475296  Validation Loss:  0.40643473782322626\n",
      "Epoch:  33  Loss:  0.38999399727944173  Validation Loss:  0.40640586573969234\n",
      "Epoch:  34  Loss:  0.38998318594513515  Validation Loss:  0.406375599313866\n",
      "Epoch:  35  Loss:  0.389969435830911  Validation Loss:  0.40634360652078283\n",
      "Epoch:  36  Loss:  0.3899524242588968  Validation Loss:  0.40630959082733503\n",
      "Epoch:  37  Loss:  0.38993199598608597  Validation Loss:  0.4062733831730756\n",
      "Epoch:  38  Loss:  0.3899082712603338  Validation Loss:  0.4062348635359244\n",
      "Epoch:  39  Loss:  0.3898814151232893  Validation Loss:  0.40619406375018036\n",
      "Epoch:  40  Loss:  0.3898517523299564  Validation Loss:  0.4061511864716357\n",
      "Epoch:  41  Loss:  0.3898197214711796  Validation Loss:  0.40610636499795044\n",
      "Epoch:  42  Loss:  0.3897857323740468  Validation Loss:  0.40605980943549763\n",
      "Epoch:  43  Loss:  0.3897501028848417  Validation Loss:  0.4060117624022744\n",
      "Epoch:  44  Loss:  0.38971323375449035  Validation Loss:  0.40596247721802103\n",
      "Epoch:  45  Loss:  0.3896753672623273  Validation Loss:  0.4059121014042334\n",
      "Epoch:  46  Loss:  0.38963662494312634  Validation Loss:  0.4058605813167312\n",
      "Epoch:  47  Loss:  0.3895969893444668  Validation Loss:  0.40580789920958604\n",
      "Epoch:  48  Loss:  0.3895564084477497  Validation Loss:  0.4057539330287413\n",
      "Epoch:  49  Loss:  0.3895149176093665  Validation Loss:  0.4056988636201078\n",
      "Epoch:  50  Loss:  0.3894725962570219  Validation Loss:  0.40564299672842025\n",
      "Epoch:  51  Loss:  0.3894297370630683  Validation Loss:  0.40558659759434784\n",
      "Epoch:  52  Loss:  0.38938655659104837  Validation Loss:  0.4055301503701644\n",
      "Epoch:  53  Loss:  0.3893434968410116  Validation Loss:  0.4054739896546711\n",
      "Epoch:  54  Loss:  0.3893008338456804  Validation Loss:  0.40541847212748094\n",
      "Epoch:  55  Loss:  0.38925878662954677  Validation Loss:  0.40536370995369825\n",
      "Epoch:  56  Loss:  0.38921740145394296  Validation Loss:  0.40530993383039127\n",
      "Epoch:  57  Loss:  0.3891768254791245  Validation Loss:  0.40525717762383545\n",
      "Epoch:  58  Loss:  0.3891369870892077  Validation Loss:  0.40520548075437546\n",
      "Epoch:  59  Loss:  0.3890979401541479  Validation Loss:  0.40515497746792706\n",
      "Epoch:  60  Loss:  0.38905957237337574  Validation Loss:  0.40510552715171466\n",
      "Epoch:  61  Loss:  0.3890217499299483  Validation Loss:  0.4050571159882979\n",
      "Epoch:  62  Loss:  0.3889843678384116  Validation Loss:  0.40500982945615593\n",
      "Epoch:  63  Loss:  0.3889473414782322  Validation Loss:  0.40496356771750885\n",
      "Epoch:  64  Loss:  0.38891042109691737  Validation Loss:  0.40491825260899283\n",
      "Epoch:  65  Loss:  0.3888734053255934  Validation Loss:  0.40487391474572093\n",
      "Epoch:  66  Loss:  0.3888362134722146  Validation Loss:  0.4048306028951298\n",
      "Epoch:  67  Loss:  0.3887986808337949  Validation Loss:  0.4047882120717656\n",
      "Epoch:  68  Loss:  0.3887606726902904  Validation Loss:  0.404746796597134\n",
      "Epoch:  69  Loss:  0.3887221566429644  Validation Loss:  0.4047061032869599\n",
      "Epoch:  70  Loss:  0.38868303046082003  Validation Loss:  0.4046663635156371\n",
      "Epoch:  71  Loss:  0.38864380780494573  Validation Loss:  0.4046276106075807\n",
      "Epoch:  72  Loss:  0.38860473384459815  Validation Loss:  0.404589798504656\n",
      "Epoch:  73  Loss:  0.3885661080705397  Validation Loss:  0.4045529356056994\n",
      "Epoch:  74  Loss:  0.3885283392261375  Validation Loss:  0.40451705198396337\n",
      "Epoch:  75  Loss:  0.3884913547246745  Validation Loss:  0.40448213842782105\n",
      "Epoch:  76  Loss:  0.3884552824000517  Validation Loss:  0.4044482256878506\n",
      "Epoch:  77  Loss:  0.38842030438509856  Validation Loss:  0.4044153861024163\n",
      "Epoch:  78  Loss:  0.3883864152612108  Validation Loss:  0.4043835297226906\n",
      "Epoch:  79  Loss:  0.38835355957800693  Validation Loss:  0.4043526671149514\n",
      "Epoch:  80  Loss:  0.3883217734820915  Validation Loss:  0.4043228020722216\n",
      "Epoch:  81  Loss:  0.38829101665001925  Validation Loss:  0.4042938854206692\n",
      "Epoch:  82  Loss:  0.3882612681750095  Validation Loss:  0.4042659028009935\n",
      "Epoch:  83  Loss:  0.3882325593720783  Validation Loss:  0.4042388681660999\n",
      "Epoch:  84  Loss:  0.3882048397353201  Validation Loss:  0.40421281240203166\n",
      "Epoch:  85  Loss:  0.3881780735922582  Validation Loss:  0.40418768470937555\n",
      "Epoch:  86  Loss:  0.3881522400812669  Validation Loss:  0.40416328446431593\n",
      "Epoch:  87  Loss:  0.3881272106008096  Validation Loss:  0.4041397562081164\n",
      "Epoch:  88  Loss:  0.38810318340406275  Validation Loss:  0.40411718745123254\n",
      "Epoch:  89  Loss:  0.3880800595111919  Validation Loss:  0.40409551466053184\n",
      "Epoch:  90  Loss:  0.3880578079232664  Validation Loss:  0.4040747586976398\n",
      "Epoch:  91  Loss:  0.38803639773166543  Validation Loss:  0.4040549173951149\n",
      "Epoch:  92  Loss:  0.38801583286487695  Validation Loss:  0.40403602340004663\n",
      "Epoch:  93  Loss:  0.3879961449765798  Validation Loss:  0.4040180875496431\n",
      "Epoch:  94  Loss:  0.3879773069285985  Validation Loss:  0.40400108681483704\n",
      "Epoch:  95  Loss:  0.38795927866841806  Validation Loss:  0.40398497188633137\n",
      "Epoch:  96  Loss:  0.38794204951687294  Validation Loss:  0.4039697657931935\n",
      "Epoch:  97  Loss:  0.38792552135207437  Validation Loss:  0.4039551847360351\n",
      "Epoch:  98  Loss:  0.38790950964797627  Validation Loss:  0.4039414771578529\n",
      "Epoch:  99  Loss:  0.3878942481270342  Validation Loss:  0.4039288188923489\n",
      "Epoch:  100  Loss:  0.3878798684613271  Validation Loss:  0.4039172899993983\n",
      "Epoch:  101  Loss:  0.38786622683207195  Validation Loss:  0.40390676896680483\n",
      "Epoch:  102  Loss:  0.38785328178694756  Validation Loss:  0.4038972482085228\n",
      "Epoch:  103  Loss:  0.38784101883118804  Validation Loss:  0.4038888281041926\n",
      "Epoch:  104  Loss:  0.3878293476773031  Validation Loss:  0.40388109982013704\n",
      "Epoch:  105  Loss:  0.3878180421437278  Validation Loss:  0.40387429134412245\n",
      "Epoch:  106  Loss:  0.3878072896915855  Validation Loss:  0.40386858961798927\n",
      "Epoch:  107  Loss:  0.3877970876341516  Validation Loss:  0.4038639648394151\n",
      "Epoch:  108  Loss:  0.3877874021503058  Validation Loss:  0.4038604354316538\n",
      "Epoch:  109  Loss:  0.3877781823729024  Validation Loss:  0.40385798771273007\n",
      "Epoch:  110  Loss:  0.38776928786978576  Validation Loss:  0.4038564661687071\n",
      "Epoch:  111  Loss:  0.38776054919669123  Validation Loss:  0.40385602143677796\n",
      "Epoch:  112  Loss:  0.3877520572281245  Validation Loss:  0.403856837478551\n",
      "Epoch:  113  Loss:  0.3877437706698071  Validation Loss:  0.4038589526306499\n",
      "Epoch:  114  Loss:  0.3877355248639078  Validation Loss:  0.40386215529658576\n",
      "Epoch:  115  Loss:  0.387727038742918  Validation Loss:  0.40386680649085477\n",
      "Epoch:  116  Loss:  0.3877183922989802  Validation Loss:  0.40387309749018063\n",
      "Epoch:  117  Loss:  0.387709361201886  Validation Loss:  0.40388093089515514\n",
      "Epoch:  118  Loss:  0.3876995864239606  Validation Loss:  0.4038907313888723\n",
      "Epoch:  119  Loss:  0.3876890751900095  Validation Loss:  0.4039028904654763\n",
      "Epoch:  120  Loss:  0.3876774901467742  Validation Loss:  0.40391734567555515\n",
      "Epoch:  121  Loss:  0.3876643447713418  Validation Loss:  0.4039347137917172\n",
      "Epoch:  122  Loss:  0.3876494211003636  Validation Loss:  0.4039551054889506\n",
      "Epoch:  123  Loss:  0.38763232642050943  Validation Loss:  0.40397905734452333\n",
      "Epoch:  124  Loss:  0.38761293851968015  Validation Loss:  0.4040064422921701\n",
      "Epoch:  125  Loss:  0.38759104295661956  Validation Loss:  0.40403717796910893\n",
      "Epoch:  126  Loss:  0.38756684812180925  Validation Loss:  0.40407096960327843\n",
      "Epoch:  127  Loss:  0.38754080895221593  Validation Loss:  0.4041071355342865\n",
      "Epoch:  128  Loss:  0.3875131545193268  Validation Loss:  0.4041450763290579\n",
      "Epoch:  129  Loss:  0.38748424911137785  Validation Loss:  0.40418430295857516\n",
      "Epoch:  130  Loss:  0.3874543764600248  Validation Loss:  0.4042243988676505\n",
      "Epoch:  131  Loss:  0.38742377374208337  Validation Loss:  0.4042650282382965\n",
      "Epoch:  132  Loss:  0.38739257019126055  Validation Loss:  0.4043057845397429\n",
      "Epoch:  133  Loss:  0.38736095293001693  Validation Loss:  0.4043465034528212\n",
      "Epoch:  134  Loss:  0.387329075620933  Validation Loss:  0.40438690889965406\n",
      "Epoch:  135  Loss:  0.387297046500625  Validation Loss:  0.40442678914828734\n",
      "Epoch:  136  Loss:  0.3872648553189003  Validation Loss:  0.4044659221714193\n",
      "Epoch:  137  Loss:  0.38723246369398  Validation Loss:  0.40450407686558637\n",
      "Epoch:  138  Loss:  0.3871997648342089  Validation Loss:  0.40454105003313584\n",
      "Epoch:  139  Loss:  0.38716657893224193  Validation Loss:  0.4045765448700298\n",
      "Epoch:  140  Loss:  0.3871327363406167  Validation Loss:  0.4046103432774544\n",
      "Epoch:  141  Loss:  0.38709800624937724  Validation Loss:  0.40464207150719383\n",
      "Epoch:  142  Loss:  0.3870621287461483  Validation Loss:  0.40467142245986243\n",
      "Epoch:  143  Loss:  0.38702484518289565  Validation Loss:  0.4046981168064204\n",
      "Epoch:  144  Loss:  0.38698593082301547  Validation Loss:  0.4047220068899068\n",
      "Epoch:  145  Loss:  0.3869453047712644  Validation Loss:  0.4047431150620634\n",
      "Epoch:  146  Loss:  0.3869030451684287  Validation Loss:  0.4047616885467009\n",
      "Epoch:  147  Loss:  0.38685938600789416  Validation Loss:  0.40477821108969775\n",
      "Epoch:  148  Loss:  0.38681473998409327  Validation Loss:  0.40479332587935707\n",
      "Epoch:  149  Loss:  0.3867695351215926  Validation Loss:  0.4048075250603936\n",
      "Epoch:  150  Loss:  0.3867241772964145  Validation Loss:  0.4048214542594823\n",
      "Epoch:  151  Loss:  0.386679011267243  Validation Loss:  0.4048352681777694\n",
      "Epoch:  152  Loss:  0.3866341500797055  Validation Loss:  0.40484931380911304\n",
      "Epoch:  153  Loss:  0.3865898112681779  Validation Loss:  0.4048637996343049\n",
      "Epoch:  154  Loss:  0.3865461328715989  Validation Loss:  0.4048787752335722\n",
      "Epoch:  155  Loss:  0.38650304751865794  Validation Loss:  0.4048942043022676\n",
      "Epoch:  156  Loss:  0.3864606829529459  Validation Loss:  0.4049102478406646\n",
      "Epoch:  157  Loss:  0.3864189943806692  Validation Loss:  0.40492684969847853\n",
      "Epoch:  158  Loss:  0.38637801336519645  Validation Loss:  0.40494401624256915\n",
      "Epoch:  159  Loss:  0.3863377578330762  Validation Loss:  0.4049618829380382\n",
      "Epoch:  160  Loss:  0.38629815975824994  Validation Loss:  0.4049801979552616\n",
      "Epoch:  161  Loss:  0.3862592460079627  Validation Loss:  0.40499910989945587\n",
      "Epoch:  162  Loss:  0.3862208805526748  Validation Loss:  0.4050184400244193\n",
      "Epoch:  163  Loss:  0.38618312712871666  Validation Loss:  0.4050383680246093\n",
      "Epoch:  164  Loss:  0.3861459303534392  Validation Loss:  0.4050586900250478\n",
      "Epoch:  165  Loss:  0.38610934362267  Validation Loss:  0.4050796902315183\n",
      "Epoch:  166  Loss:  0.3860733316251726  Validation Loss:  0.40510103194551034\n",
      "Epoch:  167  Loss:  0.38603778452132687  Validation Loss:  0.4051228318702091\n",
      "Epoch:  168  Loss:  0.3860028628824335  Validation Loss:  0.4051452419297262\n",
      "Epoch:  169  Loss:  0.3859684880710009  Validation Loss:  0.40516806122931565\n",
      "Epoch:  170  Loss:  0.3859346171220144  Validation Loss:  0.405191335556182\n",
      "Epoch:  171  Loss:  0.3859013684997053  Validation Loss:  0.40521524514664303\n",
      "Epoch:  172  Loss:  0.38586864387898734  Validation Loss:  0.40523950613357806\n",
      "Epoch:  173  Loss:  0.3858363745564764  Validation Loss:  0.4052641567858783\n",
      "Epoch:  174  Loss:  0.3858045692922491  Validation Loss:  0.4052893041209741\n",
      "Epoch:  175  Loss:  0.3857733612485004  Validation Loss:  0.4053150371394374\n",
      "Epoch:  176  Loss:  0.3857426561640971  Validation Loss:  0.40534110834652726\n",
      "Epoch:  177  Loss:  0.38571236648342827  Validation Loss:  0.4053675219416618\n",
      "Epoch:  178  Loss:  0.3856824591755867  Validation Loss:  0.40539424148472875\n",
      "Epoch:  179  Loss:  0.38565298190171066  Validation Loss:  0.4054214821620421\n",
      "Epoch:  180  Loss:  0.38562407658407183  Validation Loss:  0.40544927418231963\n",
      "Epoch:  181  Loss:  0.3855956559831446  Validation Loss:  0.4054773938249458\n",
      "Epoch:  182  Loss:  0.38556764378692165  Validation Loss:  0.4055058713663708\n",
      "Epoch:  183  Loss:  0.38554004146294163  Validation Loss:  0.4055346545170654\n",
      "Epoch:  184  Loss:  0.3855128452859142  Validation Loss:  0.40556379353458233\n",
      "Epoch:  185  Loss:  0.3854860642191136  Validation Loss:  0.40559329668229277\n",
      "Epoch:  186  Loss:  0.38545978033181394  Validation Loss:  0.40562341118400747\n",
      "Epoch:  187  Loss:  0.38543397849707894  Validation Loss:  0.4056538827717304\n",
      "Epoch:  188  Loss:  0.38540856829195314  Validation Loss:  0.40568469898267223\n",
      "Epoch:  189  Loss:  0.3853835423787435  Validation Loss:  0.4057158989662474\n",
      "Epoch:  190  Loss:  0.38535892703767977  Validation Loss:  0.40574744905937804\n",
      "Epoch:  191  Loss:  0.38533470687089544  Validation Loss:  0.4057793526486917\n",
      "Epoch:  192  Loss:  0.38531088562625826  Validation Loss:  0.4058116463097659\n",
      "Epoch:  193  Loss:  0.38528747152198445  Validation Loss:  0.405844304507429\n",
      "Epoch:  194  Loss:  0.38526446290991523  Validation Loss:  0.4058773330666802\n",
      "Epoch:  195  Loss:  0.38524191905603267  Validation Loss:  0.40591092509302223\n",
      "Epoch:  196  Loss:  0.38521985617099386  Validation Loss:  0.4059449556198987\n",
      "Epoch:  197  Loss:  0.38519820272922517  Validation Loss:  0.4059793457388878\n",
      "Epoch:  198  Loss:  0.3851769279575709  Validation Loss:  0.40601408942179246\n",
      "Epoch:  199  Loss:  0.38515603765845297  Validation Loss:  0.406049171699719\n",
      "Epoch:  200  Loss:  0.38513551821762865  Validation Loss:  0.40608460131016644\n",
      "Epoch:  201  Loss:  0.38511538250428257  Validation Loss:  0.40612037215720526\n",
      "Epoch:  202  Loss:  0.385095618913571  Validation Loss:  0.40615648877891625\n",
      "Epoch:  203  Loss:  0.38507618393861887  Validation Loss:  0.4061928969215263\n",
      "Epoch:  204  Loss:  0.38505706823233404  Validation Loss:  0.40622962591322986\n",
      "Epoch:  205  Loss:  0.38503830855091414  Validation Loss:  0.4062667100944302\n",
      "Epoch:  206  Loss:  0.3850199182150942  Validation Loss:  0.4063041120090268\n",
      "Epoch:  207  Loss:  0.3850018142976544  Validation Loss:  0.40634187995032833\n",
      "Epoch:  208  Loss:  0.38498405929316176  Validation Loss:  0.4063799688084559\n",
      "Epoch:  209  Loss:  0.3849666985372702  Validation Loss:  0.40641854120926424\n",
      "Epoch:  210  Loss:  0.3849497772075913  Validation Loss:  0.4064576012844389\n",
      "Epoch:  211  Loss:  0.384933303296566  Validation Loss:  0.4064969935200431\n",
      "Epoch:  212  Loss:  0.38491719947619873  Validation Loss:  0.4065367345782844\n",
      "Epoch:  213  Loss:  0.38490145443515345  Validation Loss:  0.40657675198533316\n",
      "Epoch:  214  Loss:  0.38488601071364953  Validation Loss:  0.4066170606423508\n",
      "Epoch:  215  Loss:  0.3848709116605195  Validation Loss:  0.4066577269949696\n",
      "Epoch:  216  Loss:  0.38485619976665036  Validation Loss:  0.40669872415336694\n",
      "Epoch:  217  Loss:  0.38484184046586356  Validation Loss:  0.40674001242626795\n",
      "Epoch:  218  Loss:  0.384827751079292  Validation Loss:  0.40678161159157755\n",
      "Epoch:  219  Loss:  0.3848140094316367  Validation Loss:  0.40682355524464087\n",
      "Epoch:  220  Loss:  0.3848006289565202  Validation Loss:  0.4068658150732517\n",
      "Epoch:  221  Loss:  0.3847875546776887  Validation Loss:  0.40690836269747127\n",
      "Epoch:  222  Loss:  0.3847747789639415  Validation Loss:  0.40695121030915865\n",
      "Epoch:  223  Loss:  0.38476235405965287  Validation Loss:  0.406994411891157\n",
      "Epoch:  224  Loss:  0.38475021065184567  Validation Loss:  0.407037863406268\n",
      "Epoch:  225  Loss:  0.38473838793508935  Validation Loss:  0.4070816558870402\n",
      "Epoch:  226  Loss:  0.38472687886519863  Validation Loss:  0.4071257291869684\n",
      "Epoch:  227  Loss:  0.38471565528800994  Validation Loss:  0.40717012082988563\n",
      "Epoch:  228  Loss:  0.3847047607555534  Validation Loss:  0.40721479268236593\n",
      "Epoch:  229  Loss:  0.38469413220882415  Validation Loss:  0.40725978436795146\n",
      "Epoch:  230  Loss:  0.38468380742000813  Validation Loss:  0.4073050459677523\n",
      "Epoch:  231  Loss:  0.3846737718040293  Validation Loss:  0.40735064385966824\n",
      "Epoch:  232  Loss:  0.3846640416392774  Validation Loss:  0.4073964927684177\n",
      "Epoch:  233  Loss:  0.3846546440865054  Validation Loss:  0.4074428233910691\n",
      "Epoch:  234  Loss:  0.3846456235105341  Validation Loss:  0.4074895715848966\n",
      "Epoch:  235  Loss:  0.3846369623009003  Validation Loss:  0.4075366115028208\n",
      "Epoch:  236  Loss:  0.3846285698088733  Validation Loss:  0.4075839214026928\n",
      "Epoch:  237  Loss:  0.3846204301624587  Validation Loss:  0.407631486451084\n",
      "Epoch:  238  Loss:  0.3846125420521606  Validation Loss:  0.40767932073636487\n",
      "Epoch:  239  Loss:  0.384604900849588  Validation Loss:  0.4077274058352817\n",
      "Epoch:  240  Loss:  0.3845975103477637  Validation Loss:  0.40777573307806797\n",
      "Epoch:  241  Loss:  0.3845903411959157  Validation Loss:  0.40782432156530296\n",
      "Epoch:  242  Loss:  0.38458339804501246  Validation Loss:  0.40787310525774956\n",
      "Epoch:  243  Loss:  0.3845766466449608  Validation Loss:  0.40792211090976543\n",
      "Epoch:  244  Loss:  0.38457008934382236  Validation Loss:  0.4079713048582727\n",
      "Epoch:  245  Loss:  0.3845637003354954  Validation Loss:  0.40802068676460873\n",
      "Epoch:  246  Loss:  0.38455745162385885  Validation Loss:  0.408070230754939\n",
      "Epoch:  247  Loss:  0.38455134016094783  Validation Loss:  0.40811991928653285\n",
      "Epoch:  248  Loss:  0.38454531638911277  Validation Loss:  0.4081697182221846\n",
      "Epoch:  249  Loss:  0.38453937166116453  Validation Loss:  0.4082196148959073\n",
      "Epoch:  250  Loss:  0.3845334422181953  Validation Loss:  0.4082696034827016\n",
      "Epoch:  251  Loss:  0.3845275192098184  Validation Loss:  0.4083195712756027\n",
      "Epoch:  252  Loss:  0.3845215195507714  Validation Loss:  0.4083695160394365\n",
      "Epoch:  253  Loss:  0.38451540126945033  Validation Loss:  0.40841938209804624\n",
      "Epoch:  254  Loss:  0.38450907685539937  Validation Loss:  0.4084691027348692\n",
      "Epoch:  255  Loss:  0.3845024438292691  Validation Loss:  0.4085186266086318\n",
      "Epoch:  256  Loss:  0.38449538907769953  Validation Loss:  0.408567822995511\n",
      "Epoch:  257  Loss:  0.38448778212522017  Validation Loss:  0.40861661115830594\n",
      "Epoch:  258  Loss:  0.38447947414083916  Validation Loss:  0.4086648781191219\n",
      "Epoch:  259  Loss:  0.3844703352361014  Validation Loss:  0.40871254510500216\n",
      "Epoch:  260  Loss:  0.38446025478117396  Validation Loss:  0.4087595312432809\n",
      "Epoch:  261  Loss:  0.3844491316965132  Validation Loss:  0.40880573710257356\n",
      "Epoch:  262  Loss:  0.38443700495091354  Validation Loss:  0.4088512889363549\n",
      "Epoch:  263  Loss:  0.3844240083838954  Validation Loss:  0.4088963042606007\n",
      "Epoch:  264  Loss:  0.3844103821073518  Validation Loss:  0.40894099819389257\n",
      "Epoch:  265  Loss:  0.38439641549731746  Validation Loss:  0.40898555517196655\n",
      "Epoch:  266  Loss:  0.3843823560936884  Validation Loss:  0.40903018326921897\n",
      "Epoch:  267  Loss:  0.3843684092841365  Validation Loss:  0.4090750243853439\n",
      "Epoch:  268  Loss:  0.3843547448741667  Validation Loss:  0.40912014828486876\n",
      "Epoch:  269  Loss:  0.38434146446260536  Validation Loss:  0.4091656257483092\n",
      "Epoch:  270  Loss:  0.38432863158258523  Validation Loss:  0.4092115007340908\n",
      "Epoch:  271  Loss:  0.3843162763750914  Validation Loss:  0.4092577834698287\n",
      "Epoch:  272  Loss:  0.3843044238108577  Validation Loss:  0.40930447910319673\n",
      "Epoch:  273  Loss:  0.38429308316924354  Validation Loss:  0.40935161526907576\n",
      "Epoch:  274  Loss:  0.38428225018309825  Validation Loss:  0.40939917489886285\n",
      "Epoch:  275  Loss:  0.3842719416952494  Validation Loss:  0.40944713950157163\n",
      "Epoch:  276  Loss:  0.38426212284601097  Validation Loss:  0.40949551354755054\n",
      "Epoch:  277  Loss:  0.38425280192133154  Validation Loss:  0.40954429893331096\n",
      "Epoch:  278  Loss:  0.38424397548942857  Validation Loss:  0.40959350182251497\n",
      "Epoch:  279  Loss:  0.3842356260753039  Validation Loss:  0.4096430805596438\n",
      "Epoch:  280  Loss:  0.38422774496403606  Validation Loss:  0.4096930488944054\n",
      "Epoch:  281  Loss:  0.3842203405318838  Validation Loss:  0.40974343432621524\n",
      "Epoch:  282  Loss:  0.3842134011062709  Validation Loss:  0.40979417819868436\n",
      "Epoch:  283  Loss:  0.38420693982731213  Validation Loss:  0.4098453435708176\n",
      "Epoch:  284  Loss:  0.38420096988027747  Validation Loss:  0.40989700278097935\n",
      "Epoch:  285  Loss:  0.3841955132105134  Validation Loss:  0.40994908660650253\n",
      "Epoch:  286  Loss:  0.3841905452311039  Validation Loss:  0.4100016162476756\n",
      "Epoch:  287  Loss:  0.3841860387361411  Validation Loss:  0.410054504329508\n",
      "Epoch:  288  Loss:  0.38418195277000916  Validation Loss:  0.41010774306275627\n",
      "Epoch:  289  Loss:  0.3841782945123586  Validation Loss:  0.4101613392884081\n",
      "Epoch:  290  Loss:  0.38417505545146535  Validation Loss:  0.4102152850140225\n",
      "Epoch:  291  Loss:  0.3841722208216335  Validation Loss:  0.41026958735151725\n",
      "Epoch:  292  Loss:  0.3841698024986368  Validation Loss:  0.41032424223693936\n",
      "Epoch:  293  Loss:  0.38416778375253535  Validation Loss:  0.4103792195293036\n",
      "Epoch:  294  Loss:  0.3841661812003815  Validation Loss:  0.41043454842133953\n",
      "Epoch:  295  Loss:  0.384164979150801  Validation Loss:  0.41049020432613115\n",
      "Epoch:  296  Loss:  0.38416415265563764  Validation Loss:  0.4105461948974566\n",
      "Epoch:  297  Loss:  0.3841637427608172  Validation Loss:  0.41060252311554823\n",
      "Epoch:  298  Loss:  0.38416371377128544  Validation Loss:  0.41065916805104774\n",
      "Epoch:  299  Loss:  0.38416406148762416  Validation Loss:  0.4107161603190682\n",
      "Epoch:  300  Loss:  0.3841648265945189  Validation Loss:  0.4107734716751359\n",
      "Epoch:  301  Loss:  0.38416595510912666  Validation Loss:  0.4108310802416368\n",
      "Epoch:  302  Loss:  0.38416745495615584  Validation Loss:  0.41088899434967474\n",
      "Epoch:  303  Loss:  0.38416934659083685  Validation Loss:  0.41094726290215144\n",
      "Epoch:  304  Loss:  0.38417163604136667  Validation Loss:  0.4110058539970355\n",
      "Epoch:  305  Loss:  0.3841742880868189  Validation Loss:  0.4110647145997394\n",
      "Epoch:  306  Loss:  0.3841772909643072  Validation Loss:  0.41112390052188524\n",
      "Epoch:  307  Loss:  0.38418066946394513  Validation Loss:  0.4111834003166719\n",
      "Epoch:  308  Loss:  0.38418443668069263  Validation Loss:  0.4112432104620067\n",
      "Epoch:  309  Loss:  0.38418857285922225  Validation Loss:  0.41130334267562085\n",
      "Epoch:  310  Loss:  0.3841930708650387  Validation Loss:  0.41136378144676033\n",
      "Epoch:  311  Loss:  0.3841979410612222  Validation Loss:  0.41142454289577224\n",
      "Epoch:  312  Loss:  0.3842032015097864  Validation Loss:  0.4114856333895163\n",
      "Epoch:  313  Loss:  0.38420882332279827  Validation Loss:  0.41154701526869425\n",
      "Epoch:  314  Loss:  0.38421483445122384  Validation Loss:  0.41160872090946543\n",
      "Epoch:  315  Loss:  0.38422123177936585  Validation Loss:  0.4116707373749126\n",
      "Epoch:  316  Loss:  0.3842279725341183  Validation Loss:  0.4117330114949833\n",
      "Epoch:  317  Loss:  0.3842350788527366  Validation Loss:  0.4117956072769382\n",
      "Epoch:  318  Loss:  0.38424254116235357  Validation Loss:  0.41185850805856966\n",
      "Epoch:  319  Loss:  0.3842503525316715  Validation Loss:  0.41192167970267207\n",
      "Epoch:  320  Loss:  0.38425851217047735  Validation Loss:  0.411985127560117\n",
      "Epoch:  321  Loss:  0.3842670232396234  Validation Loss:  0.41204888366840103\n",
      "Epoch:  322  Loss:  0.38427586002331793  Validation Loss:  0.4121129165318879\n",
      "Epoch:  323  Loss:  0.38428504271714975  Validation Loss:  0.41217722032557835\n",
      "Epoch:  324  Loss:  0.384294557063417  Validation Loss:  0.41224180615761064\n",
      "Epoch:  325  Loss:  0.38430441295107204  Validation Loss:  0.4123066619038582\n",
      "Epoch:  326  Loss:  0.38431460298597814  Validation Loss:  0.412371804903854\n",
      "Epoch:  327  Loss:  0.3843251267617399  Validation Loss:  0.4124371800910343\n",
      "Epoch:  328  Loss:  0.3843359604816545  Validation Loss:  0.41250281584533777\n",
      "Epoch:  329  Loss:  0.384347132469217  Validation Loss:  0.41256874386559833\n",
      "Epoch:  330  Loss:  0.3843586419116367  Validation Loss:  0.41263494938611983\n",
      "Epoch:  331  Loss:  0.3843704842031002  Validation Loss:  0.4127013997598128\n",
      "Epoch:  332  Loss:  0.384382617721955  Validation Loss:  0.41276811171661726\n",
      "Epoch:  333  Loss:  0.3843950785809394  Validation Loss:  0.41283509440042754\n",
      "Epoch:  334  Loss:  0.3844078607970115  Validation Loss:  0.41290233311328023\n",
      "Epoch:  335  Loss:  0.3844209630155202  Validation Loss:  0.4129698333415118\n",
      "Epoch:  336  Loss:  0.38443438521388806  Validation Loss:  0.4130375942723318\n",
      "Epoch:  337  Loss:  0.38444810481459807  Validation Loss:  0.4131055959246375\n",
      "Epoch:  338  Loss:  0.38446212091454957  Validation Loss:  0.413173860040578\n",
      "Epoch:  339  Loss:  0.38447643083830674  Validation Loss:  0.4132423704320734\n",
      "Epoch:  340  Loss:  0.3844910362904722  Validation Loss:  0.4133111228319732\n",
      "Epoch:  341  Loss:  0.3845059479389227  Validation Loss:  0.413380115005103\n",
      "Epoch:  342  Loss:  0.3845211536482428  Validation Loss:  0.41344936449419367\n",
      "Epoch:  343  Loss:  0.384536634329142  Validation Loss:  0.4135188181291927\n",
      "Epoch:  344  Loss:  0.38455240843874033  Validation Loss:  0.41358849927783015\n",
      "Epoch:  345  Loss:  0.38456845636846443  Validation Loss:  0.41365838504650376\n",
      "Epoch:  346  Loss:  0.3845847809630813  Validation Loss:  0.4137284975160252\n",
      "Epoch:  347  Loss:  0.3846013898537918  Validation Loss:  0.41379880688407206\n",
      "Epoch:  348  Loss:  0.3846182737386588  Validation Loss:  0.4138693128119815\n",
      "Epoch:  349  Loss:  0.38463541539103696  Validation Loss:  0.4139399929480119\n",
      "Epoch:  350  Loss:  0.3846527945701823  Validation Loss:  0.4140108468180353\n",
      "Epoch:  351  Loss:  0.38467041871538665  Validation Loss:  0.4140818643299016\n",
      "Epoch:  352  Loss:  0.3846883084060568  Validation Loss:  0.4141530688513409\n",
      "Epoch:  353  Loss:  0.38470642999040355  Validation Loss:  0.4142244112762538\n",
      "Epoch:  354  Loss:  0.38472479301871676  Validation Loss:  0.4142959211360325\n",
      "Epoch:  355  Loss:  0.38474338709404976  Validation Loss:  0.4143675605004484\n",
      "Epoch:  356  Loss:  0.38476220144692697  Validation Loss:  0.4144393440674652\n",
      "Epoch:  357  Loss:  0.38478123818834625  Validation Loss:  0.4145112370902842\n",
      "Epoch:  358  Loss:  0.38480047695338726  Validation Loss:  0.4145832025869326\n",
      "Epoch:  359  Loss:  0.38481989536773076  Validation Loss:  0.4146552549167113\n",
      "Epoch:  360  Loss:  0.38483948931097983  Validation Loss:  0.4147273470732299\n",
      "Epoch:  361  Loss:  0.3848592316336704  Validation Loss:  0.41479946774515236\n",
      "Epoch:  362  Loss:  0.3848791033932657  Validation Loss:  0.4148715764284134\n",
      "Epoch:  363  Loss:  0.38489909327842975  Validation Loss:  0.41494365713813086\n",
      "Epoch:  364  Loss:  0.3849191720287005  Validation Loss:  0.4150156523016366\n",
      "Epoch:  365  Loss:  0.38493931734878006  Validation Loss:  0.41508752351457423\n",
      "Epoch:  366  Loss:  0.3849594962754936  Validation Loss:  0.4151592403650284\n",
      "Epoch:  367  Loss:  0.38497966383442733  Validation Loss:  0.4152307010509751\n",
      "Epoch:  368  Loss:  0.38499977128072216  Validation Loss:  0.4153018167750402\n",
      "Epoch:  369  Loss:  0.38501977221758077  Validation Loss:  0.41537252915176476\n",
      "Epoch:  370  Loss:  0.38503957344501305  Validation Loss:  0.4154427229680798\n",
      "Epoch:  371  Loss:  0.38505910303105007  Validation Loss:  0.4155122488059781\n",
      "Epoch:  372  Loss:  0.38507827265244543  Validation Loss:  0.41558094674890694\n",
      "Epoch:  373  Loss:  0.3850969442702604  Validation Loss:  0.4156486490233378\n",
      "Epoch:  374  Loss:  0.38511498229521696  Validation Loss:  0.4157150958749381\n",
      "Epoch:  375  Loss:  0.38513224753692293  Validation Loss:  0.4157800538296049\n",
      "Epoch:  376  Loss:  0.3851485278231628  Validation Loss:  0.4158432871103287\n",
      "Epoch:  377  Loss:  0.385163711654869  Validation Loss:  0.4159045692194592\n",
      "Epoch:  378  Loss:  0.385177645516215  Validation Loss:  0.4159638016738675\n",
      "Epoch:  379  Loss:  0.38519032525293756  Validation Loss:  0.4160210353406993\n",
      "Epoch:  380  Loss:  0.385201833024621  Validation Loss:  0.4160765222527764\n",
      "Epoch:  381  Loss:  0.3852123911972299  Validation Loss:  0.416130673343485\n",
      "Epoch:  382  Loss:  0.38522230028880367  Validation Loss:  0.41618393178690566\n",
      "Epoch:  383  Loss:  0.3852319124860294  Validation Loss:  0.41623674495653673\n",
      "Epoch:  384  Loss:  0.3852415050972592  Validation Loss:  0.4162894759665836\n",
      "Epoch:  385  Loss:  0.3852513095759081  Validation Loss:  0.41634232943708244\n",
      "Epoch:  386  Loss:  0.38526146725723237  Validation Loss:  0.41639549935405906\n",
      "Epoch:  387  Loss:  0.3852720860730518  Validation Loss:  0.41644906042651697\n",
      "Epoch:  388  Loss:  0.38528323776342654  Validation Loss:  0.4165031087669459\n",
      "Epoch:  389  Loss:  0.38529493956629074  Validation Loss:  0.41655766266313465\n",
      "Epoch:  390  Loss:  0.3853072231691895  Validation Loss:  0.4166127237406644\n",
      "Epoch:  391  Loss:  0.38532007917987576  Validation Loss:  0.4166683389381929\n",
      "Epoch:  392  Loss:  0.38533350101700337  Validation Loss:  0.41672447154467757\n",
      "Epoch:  393  Loss:  0.3853474937605135  Validation Loss:  0.41678113625808194\n",
      "Epoch:  394  Loss:  0.38536205094194775  Validation Loss:  0.4168383082205599\n",
      "Epoch:  395  Loss:  0.3853771526818023  Validation Loss:  0.4168959621678699\n",
      "Epoch:  396  Loss:  0.38539280731118086  Validation Loss:  0.4169540907848965\n",
      "Epoch:  397  Loss:  0.3854089962149208  Validation Loss:  0.4170126841149547\n",
      "Epoch:  398  Loss:  0.38542571177311014  Validation Loss:  0.4170717363330451\n",
      "Epoch:  399  Loss:  0.3854429469076973  Validation Loss:  0.4171312357214364\n",
      "Epoch:  400  Loss:  0.38546069894324647  Validation Loss:  0.4171911409632726\n",
      "Epoch:  401  Loss:  0.38547894842922686  Validation Loss:  0.417251485044306\n",
      "Epoch:  402  Loss:  0.38549769323206307  Validation Loss:  0.41731223186308686\n",
      "Epoch:  403  Loss:  0.3855169315455538  Validation Loss:  0.4173733728853139\n",
      "Epoch:  404  Loss:  0.3855366432305538  Validation Loss:  0.4174348895522681\n",
      "Epoch:  405  Loss:  0.38555681723536867  Validation Loss:  0.4174968015063893\n",
      "Epoch:  406  Loss:  0.3855774682692506  Validation Loss:  0.41755909296599303\n",
      "Epoch:  407  Loss:  0.3855985807311354  Validation Loss:  0.4176217851991003\n",
      "Epoch:  408  Loss:  0.3856201600847822  Validation Loss:  0.41768485470251604\n",
      "Epoch:  409  Loss:  0.3856421866200187  Validation Loss:  0.41774831983176147\n",
      "Epoch:  410  Loss:  0.38566466595864657  Validation Loss:  0.4178121296519583\n",
      "Epoch:  411  Loss:  0.3856875877037193  Validation Loss:  0.417876292087815\n",
      "Epoch:  412  Loss:  0.38571094431434616  Validation Loss:  0.41794080422683194\n",
      "Epoch:  413  Loss:  0.3857347320765257  Validation Loss:  0.4180056769739498\n",
      "Epoch:  414  Loss:  0.3857589531238332  Validation Loss:  0.41807088127190417\n",
      "Epoch:  415  Loss:  0.38578359917031996  Validation Loss:  0.4181364257904616\n",
      "Epoch:  416  Loss:  0.3858086618735935  Validation Loss:  0.41820231608369135\n",
      "Epoch:  417  Loss:  0.3858340962705287  Validation Loss:  0.41826853704723443\n",
      "Epoch:  418  Loss:  0.3858599001259515  Validation Loss:  0.4183350938287648\n",
      "Epoch:  419  Loss:  0.38588608731374596  Validation Loss:  0.4184019589965994\n",
      "Epoch:  420  Loss:  0.38591265468434854  Validation Loss:  0.41846918443387204\n",
      "Epoch:  421  Loss:  0.3859395931390199  Validation Loss:  0.41853672713041307\n",
      "Epoch:  422  Loss:  0.38596691590818494  Validation Loss:  0.41860461214726624\n",
      "Epoch:  423  Loss:  0.385994619797125  Validation Loss:  0.418672848763791\n",
      "Epoch:  424  Loss:  0.3860227885345618  Validation Loss:  0.41874150755730544\n",
      "Epoch:  425  Loss:  0.38605137200969636  Validation Loss:  0.4188104462217201\n",
      "Epoch:  426  Loss:  0.3860803411539757  Validation Loss:  0.4188796946948225\n",
      "Epoch:  427  Loss:  0.3861097085656542  Validation Loss:  0.41894928616556254\n",
      "Epoch:  428  Loss:  0.38613948601890696  Validation Loss:  0.41901916665109723\n",
      "Epoch:  429  Loss:  0.3861696301310351  Validation Loss:  0.41908936168659816\n",
      "Epoch:  430  Loss:  0.3862001801191857  Validation Loss:  0.41915986226363616\n",
      "Epoch:  431  Loss:  0.38623112070966853  Validation Loss:  0.4192306644537232\n",
      "Epoch:  432  Loss:  0.3862624326438615  Validation Loss:  0.4193017780103467\n",
      "Epoch:  433  Loss:  0.38629414004584156  Validation Loss:  0.4193732067265294\n",
      "Epoch:  434  Loss:  0.3863262252938567  Validation Loss:  0.4194449156522751\n",
      "Epoch:  435  Loss:  0.38635869266634637  Validation Loss:  0.41951692212711683\n",
      "Epoch:  436  Loss:  0.38639152951990113  Validation Loss:  0.4195892137559977\n",
      "Epoch:  437  Loss:  0.386424733608058  Validation Loss:  0.4196617971767079\n",
      "Epoch:  438  Loss:  0.3864583108122602  Validation Loss:  0.41973467618227006\n",
      "Epoch:  439  Loss:  0.3864922572265972  Validation Loss:  0.4198078427125107\n",
      "Epoch:  440  Loss:  0.38652656810979047  Validation Loss:  0.419881306249987\n",
      "Epoch:  441  Loss:  0.3865612374675093  Validation Loss:  0.4199550652368502\n",
      "Epoch:  442  Loss:  0.38659625598652797  Validation Loss:  0.4200291141190312\n",
      "Epoch:  443  Loss:  0.3866316317044424  Validation Loss:  0.42010347490960903\n",
      "Epoch:  444  Loss:  0.3866673853474133  Validation Loss:  0.42017813941294496\n",
      "Epoch:  445  Loss:  0.3867034880387964  Validation Loss:  0.4202530759302053\n",
      "Epoch:  446  Loss:  0.3867399573551886  Validation Loss:  0.4203282963145863\n",
      "Epoch:  447  Loss:  0.38677677743588434  Validation Loss:  0.4204037813977762\n",
      "Epoch:  448  Loss:  0.38681395850849876  Validation Loss:  0.42047954174605284\n",
      "Epoch:  449  Loss:  0.38685148476876996  Validation Loss:  0.4205555820329623\n",
      "Epoch:  450  Loss:  0.3868893665684895  Validation Loss:  0.4206318934532729\n",
      "Epoch:  451  Loss:  0.3869275919189959  Validation Loss:  0.42070849016308787\n",
      "Epoch:  452  Loss:  0.38696617534892125  Validation Loss:  0.4207853525876999\n",
      "Epoch:  453  Loss:  0.3870051047567165  Validation Loss:  0.4208624977279793\n",
      "Epoch:  454  Loss:  0.38704438845090794  Validation Loss:  0.42093992869962343\n",
      "Epoch:  455  Loss:  0.3870839850469069  Validation Loss:  0.42101765769449145\n",
      "Epoch:  456  Loss:  0.3871239344956297  Validation Loss:  0.4210956666279923\n",
      "Epoch:  457  Loss:  0.3871642233634537  Validation Loss:  0.42117393267425624\n",
      "Epoch:  458  Loss:  0.38720485001350896  Validation Loss:  0.42125247561118817\n",
      "Epoch:  459  Loss:  0.3872458220431299  Validation Loss:  0.4213312976739623\n",
      "Epoch:  460  Loss:  0.38728714353884713  Validation Loss:  0.4214103878899054\n",
      "Epoch:  461  Loss:  0.38732881374431377  Validation Loss:  0.42148976346308537\n",
      "Epoch:  462  Loss:  0.38737082335759293  Validation Loss:  0.421569418839433\n",
      "Epoch:  463  Loss:  0.3874131721190431  Validation Loss:  0.42164931751110335\n",
      "Epoch:  464  Loss:  0.3874558396750327  Validation Loss:  0.4217294802042571\n",
      "Epoch:  465  Loss:  0.387498827233459  Validation Loss:  0.4218099382790652\n",
      "Epoch:  466  Loss:  0.38754212983855696  Validation Loss:  0.4218906282701276\n",
      "Epoch:  467  Loss:  0.3875857571647926  Validation Loss:  0.42197160307656634\n",
      "Epoch:  468  Loss:  0.3876297117069815  Validation Loss:  0.4220527896149592\n",
      "Epoch:  469  Loss:  0.38767398767399064  Validation Loss:  0.42213422330943023\n",
      "Epoch:  470  Loss:  0.38771858005361126  Validation Loss:  0.4222159156067805\n",
      "Epoch:  471  Loss:  0.38776349733498966  Validation Loss:  0.4222978410395709\n",
      "Epoch:  472  Loss:  0.3878087289292704  Validation Loss:  0.4223800333386118\n",
      "Epoch:  473  Loss:  0.38785425566814163  Validation Loss:  0.4224624801088463\n",
      "Epoch:  474  Loss:  0.3879000896757299  Validation Loss:  0.422545168006962\n",
      "Epoch:  475  Loss:  0.3879462369350773  Validation Loss:  0.4226280980489471\n",
      "Epoch:  476  Loss:  0.3879926929984129  Validation Loss:  0.42271126888015054\n",
      "Epoch:  477  Loss:  0.3880394519278497  Validation Loss:  0.4227946847677231\n",
      "Epoch:  478  Loss:  0.3880865349801201  Validation Loss:  0.42287834388288587\n",
      "Epoch:  479  Loss:  0.3881338874273228  Validation Loss:  0.4229622611268\n",
      "Epoch:  480  Loss:  0.3881815538487651  Validation Loss:  0.42304640317505054\n",
      "Epoch:  481  Loss:  0.3882295211156209  Validation Loss:  0.42313080382618035\n",
      "Epoch:  482  Loss:  0.3882777975928603  Validation Loss:  0.4232154373418201\n",
      "Epoch:  483  Loss:  0.3883263900876045  Validation Loss:  0.42330031489784065\n",
      "Epoch:  484  Loss:  0.38837526983609705  Validation Loss:  0.42338545484976337\n",
      "Epoch:  485  Loss:  0.3884244286765655  Validation Loss:  0.42347081662579017\n",
      "Epoch:  486  Loss:  0.3884738977546945  Validation Loss:  0.42355642928318543\n",
      "Epoch:  487  Loss:  0.3885236656236829  Validation Loss:  0.4236422657289288\n",
      "Epoch:  488  Loss:  0.38857372161565407  Validation Loss:  0.4237283301624385\n",
      "Epoch:  489  Loss:  0.3886240536742138  Validation Loss:  0.4238146405328404\n",
      "Epoch:  490  Loss:  0.388674600998109  Validation Loss:  0.42390117997472937\n",
      "Epoch:  491  Loss:  0.38872539382992366  Validation Loss:  0.42398795634508135\n",
      "Epoch:  492  Loss:  0.38877639400236536  Validation Loss:  0.42407495298168874\n",
      "Epoch:  493  Loss:  0.38882768480389407  Validation Loss:  0.4241621673107147\n",
      "Epoch:  494  Loss:  0.38887924748388203  Validation Loss:  0.42424960603768175\n",
      "Epoch:  495  Loss:  0.38893106197091665  Validation Loss:  0.42433727444572883\n",
      "Epoch:  496  Loss:  0.3889831830606316  Validation Loss:  0.4244251591915434\n",
      "Epoch:  497  Loss:  0.3890355548398061  Validation Loss:  0.4245132809335535\n",
      "Epoch:  498  Loss:  0.3890881998746684  Validation Loss:  0.42460160133513536\n",
      "Epoch:  499  Loss:  0.3891411193053831  Validation Loss:  0.4246901585297151\n",
      "Epoch:  500  Loss:  0.3891943023737633  Validation Loss:  0.42477893477136436\n",
      "Epoch:  501  Loss:  0.38924774871856876  Validation Loss:  0.4248679354786873\n",
      "Epoch:  502  Loss:  0.38930144604634154  Validation Loss:  0.4249571368098259\n",
      "Epoch:  503  Loss:  0.3893553996402206  Validation Loss:  0.42504655840722\n",
      "Epoch:  504  Loss:  0.389409617300738  Validation Loss:  0.42513622296127407\n",
      "Epoch:  505  Loss:  0.38946407187842963  Validation Loss:  0.42522608204321427\n",
      "Epoch:  506  Loss:  0.3895187895632151  Validation Loss:  0.4253161729059436\n",
      "Epoch:  507  Loss:  0.3895737439506885  Validation Loss:  0.4254064236852256\n",
      "Epoch:  508  Loss:  0.3896289068302422  Validation Loss:  0.4254968118261207\n",
      "Epoch:  509  Loss:  0.38968427628278735  Validation Loss:  0.4255873775617643\n",
      "Epoch:  510  Loss:  0.3897398542838566  Validation Loss:  0.4256780986758796\n",
      "Epoch:  511  Loss:  0.38979561410167  Validation Loss:  0.42576890113678845\n",
      "Epoch:  512  Loss:  0.38985154364596714  Validation Loss:  0.4258598735386675\n",
      "Epoch:  513  Loss:  0.3899076794358817  Validation Loss:  0.4259510638361627\n",
      "Epoch:  514  Loss:  0.3899640092908433  Validation Loss:  0.4260424466295676\n",
      "Epoch:  515  Loss:  0.39002053039995105  Validation Loss:  0.42613400200551205\n",
      "Epoch:  516  Loss:  0.39007720738423596  Validation Loss:  0.42622572447765955\n",
      "Epoch:  517  Loss:  0.3901340444882711  Validation Loss:  0.426317605918104\n",
      "Epoch:  518  Loss:  0.3901910318682591  Validation Loss:  0.42640966393730856\n",
      "Epoch:  519  Loss:  0.3902480590072545  Validation Loss:  0.4265015195716511\n",
      "Epoch:  520  Loss:  0.39030510059586077  Validation Loss:  0.42659351778301324\n",
      "Epoch:  521  Loss:  0.3903621570291844  Validation Loss:  0.42668579877777535\n",
      "Epoch:  522  Loss:  0.39041928356569827  Validation Loss:  0.42677833519198677\n",
      "Epoch:  523  Loss:  0.39047648049890993  Validation Loss:  0.42687115357680755\n",
      "Epoch:  524  Loss:  0.39053373055701907  Validation Loss:  0.42696427790956065\n",
      "Epoch:  525  Loss:  0.39059102634588877  Validation Loss:  0.42705770615826955\n",
      "Epoch:  526  Loss:  0.39064832187511705  Validation Loss:  0.42715149210257963\n",
      "Epoch:  527  Loss:  0.3907055692013466  Validation Loss:  0.4272456293078986\n",
      "Epoch:  528  Loss:  0.3907627375852881  Validation Loss:  0.4273401855067773\n",
      "Epoch:  529  Loss:  0.39081972847608004  Validation Loss:  0.4274351966652003\n",
      "Epoch:  530  Loss:  0.39087651243264027  Validation Loss:  0.42753071121194147\n",
      "Epoch:  531  Loss:  0.3909329947197076  Validation Loss:  0.42762676098129965\n",
      "Epoch:  532  Loss:  0.39098914614455266  Validation Loss:  0.427723377333446\n",
      "Epoch:  533  Loss:  0.3910449407994747  Validation Loss:  0.4278205753050067\n",
      "Epoch:  534  Loss:  0.39110039311150707  Validation Loss:  0.42791833179918204\n",
      "Epoch:  535  Loss:  0.3911556044198347  Validation Loss:  0.42801657095551493\n",
      "Epoch:  536  Loss:  0.39121066503452534  Validation Loss:  0.42811523655598815\n",
      "Epoch:  537  Loss:  0.39126571099640745  Validation Loss:  0.4282142362134023\n",
      "Epoch:  538  Loss:  0.3913207337260246  Validation Loss:  0.42831352231177416\n",
      "Epoch:  539  Loss:  0.39137585973649314  Validation Loss:  0.42841300693425266\n",
      "Epoch:  540  Loss:  0.3914311741563407  Validation Loss:  0.42851268337531523\n",
      "Epoch:  541  Loss:  0.3914867325036815  Validation Loss:  0.4286125299605456\n",
      "Epoch:  542  Loss:  0.3915425821348573  Validation Loss:  0.42871251451698217\n",
      "Epoch:  543  Loss:  0.39159871755224285  Validation Loss:  0.428812652555379\n",
      "Epoch:  544  Loss:  0.391655145348473  Validation Loss:  0.42891290614550764\n",
      "Epoch:  545  Loss:  0.39171187357243265  Validation Loss:  0.4290132901207967\n",
      "Epoch:  546  Loss:  0.3917688939268842  Validation Loss:  0.4291138059713624\n",
      "Epoch:  547  Loss:  0.39182620244947347  Validation Loss:  0.42921442152424294\n",
      "Epoch:  548  Loss:  0.3918837971195127  Validation Loss:  0.42931517985734075\n",
      "Epoch:  549  Loss:  0.39194166627571436  Validation Loss:  0.42941604920408943\n",
      "Epoch:  550  Loss:  0.3919996794764743  Validation Loss:  0.4295170283453031\n",
      "Epoch:  551  Loss:  0.39205790673467245  Validation Loss:  0.4296181317080151\n",
      "Epoch:  552  Loss:  0.3921164088176958  Validation Loss:  0.4297193338247863\n",
      "Epoch:  553  Loss:  0.3921751746738499  Validation Loss:  0.429820666462183\n",
      "Epoch:  554  Loss:  0.39223420991364755  Validation Loss:  0.4299220901321281\n",
      "Epoch:  555  Loss:  0.39229349630574384  Validation Loss:  0.43002361750060863\n",
      "Epoch:  556  Loss:  0.3923530426666592  Validation Loss:  0.4301252533089031\n",
      "Epoch:  557  Loss:  0.3924127731698029  Validation Loss:  0.4302270064299757\n",
      "Epoch:  558  Loss:  0.39247264377772806  Validation Loss:  0.4303288367661563\n",
      "Epoch:  559  Loss:  0.39253271656731764  Validation Loss:  0.4304307714781978\n",
      "Epoch:  560  Loss:  0.3925930371225783  Validation Loss:  0.430532792346044\n",
      "Epoch:  561  Loss:  0.39265360097316176  Validation Loss:  0.43063491975719276\n",
      "Epoch:  562  Loss:  0.39271439214547477  Validation Loss:  0.43073712743141435\n",
      "Epoch:  563  Loss:  0.39277528741142964  Validation Loss:  0.4308394250544635\n",
      "Epoch:  564  Loss:  0.3928363452580842  Validation Loss:  0.43094181885773486\n",
      "Epoch:  565  Loss:  0.3928976079392614  Validation Loss:  0.4310442682694305\n",
      "Epoch:  566  Loss:  0.3929591040832527  Validation Loss:  0.43114679557355967\n",
      "Epoch:  567  Loss:  0.3930207786234942  Validation Loss:  0.43124937625093895\n",
      "Epoch:  568  Loss:  0.39308252240898034  Validation Loss:  0.43135203380476345\n",
      "Epoch:  569  Loss:  0.39314445895001743  Validation Loss:  0.4314547422934662\n",
      "Epoch:  570  Loss:  0.3932065813153079  Validation Loss:  0.4315574870868163\n",
      "Epoch:  571  Loss:  0.3932687832550569  Validation Loss:  0.43166026743975555\n",
      "Epoch:  572  Loss:  0.39333112388849256  Validation Loss:  0.43176310726187445\n",
      "Epoch:  573  Loss:  0.39339363643843117  Validation Loss:  0.4318659646944566\n",
      "Epoch:  574  Loss:  0.39345619197596204  Validation Loss:  0.43196882592006164\n",
      "Epoch:  575  Loss:  0.39351889559942665  Validation Loss:  0.43207167197357527\n",
      "Epoch:  576  Loss:  0.393581627185146  Validation Loss:  0.4321745319122618\n",
      "Epoch:  577  Loss:  0.3936444796734687  Validation Loss:  0.4322773806750774\n",
      "Epoch:  578  Loss:  0.3937073517929424  Validation Loss:  0.4323801709169691\n",
      "Epoch:  579  Loss:  0.39377032196657225  Validation Loss:  0.43248290866613387\n",
      "Epoch:  580  Loss:  0.3938332953462095  Validation Loss:  0.4325856042179194\n",
      "Epoch:  581  Loss:  0.39389624858670164  Validation Loss:  0.432688219235702\n",
      "Epoch:  582  Loss:  0.39395916520646124  Validation Loss:  0.4327907210046595\n",
      "Epoch:  583  Loss:  0.39402205482351055  Validation Loss:  0.4328931440006603\n",
      "Epoch:  584  Loss:  0.3940848884934729  Validation Loss:  0.4329954177818515\n",
      "Epoch:  585  Loss:  0.39414760991930964  Validation Loss:  0.4330975524403832\n",
      "Epoch:  586  Loss:  0.39421021675295903  Validation Loss:  0.43319950076666747\n",
      "Epoch:  587  Loss:  0.3942726217774731  Validation Loss:  0.43330122781070796\n",
      "Epoch:  588  Loss:  0.3943348097868941  Validation Loss:  0.43340274474837565\n",
      "Epoch:  589  Loss:  0.39439671076834204  Validation Loss:  0.4335039656609297\n",
      "Epoch:  590  Loss:  0.3944582378773978  Validation Loss:  0.4336048415100033\n",
      "Epoch:  591  Loss:  0.3945193100381981  Validation Loss:  0.43370537314225327\n",
      "Epoch:  592  Loss:  0.39457982718718776  Validation Loss:  0.4338055004789071\n",
      "Epoch:  593  Loss:  0.394639648666436  Validation Loss:  0.4339051473208449\n",
      "Epoch:  594  Loss:  0.39469864111055025  Validation Loss:  0.43400425392795694\n",
      "Epoch:  595  Loss:  0.39475663180152576  Validation Loss:  0.4341027310626073\n",
      "Epoch:  596  Loss:  0.3948134497598265  Validation Loss:  0.4342004784806208\n",
      "Epoch:  597  Loss:  0.39486889784986323  Validation Loss:  0.43429740437052466\n",
      "Epoch:  598  Loss:  0.3949228031504335  Validation Loss:  0.4343933523378589\n",
      "Epoch:  599  Loss:  0.3949750480665402  Validation Loss:  0.4344881876625798\n",
      "Epoch:  600  Loss:  0.39502563396412316  Validation Loss:  0.43458167111331764\n",
      "Epoch:  601  Loss:  0.39507459597379874  Validation Loss:  0.43467352556234057\n",
      "Epoch:  602  Loss:  0.3951221023432233  Validation Loss:  0.4347634243694219\n",
      "Epoch:  603  Loss:  0.3951682453241312  Validation Loss:  0.4348509380085902\n",
      "Epoch:  604  Loss:  0.3952131213902524  Validation Loss:  0.4349355318668214\n",
      "Epoch:  605  Loss:  0.39525676061483944  Validation Loss:  0.4350166198543527\n",
      "Epoch:  606  Loss:  0.3952989806167104  Validation Loss:  0.435093526576053\n",
      "Epoch:  607  Loss:  0.39533961734762696  Validation Loss:  0.435165477510203\n",
      "Epoch:  608  Loss:  0.3953784486448223  Validation Loss:  0.43523177653551104\n",
      "Epoch:  609  Loss:  0.39541522515091027  Validation Loss:  0.43529186296192085\n",
      "Epoch:  610  Loss:  0.39544982609875273  Validation Loss:  0.43534559177404103\n",
      "Epoch:  611  Loss:  0.3954822661750244  Validation Loss:  0.4353932803327387\n",
      "Epoch:  612  Loss:  0.39551283272378374  Validation Loss:  0.4354358499700373\n",
      "Epoch:  613  Loss:  0.3955418755836559  Validation Loss:  0.43547450906851076\n",
      "Epoch:  614  Loss:  0.39556995042119963  Validation Loss:  0.43551051250912926\n",
      "Epoch:  615  Loss:  0.39559752594566705  Validation Loss:  0.4355449581010775\n",
      "Epoch:  616  Loss:  0.39562491390741233  Validation Loss:  0.4355786973441189\n",
      "Epoch:  617  Loss:  0.39565245362393786  Validation Loss:  0.4356123019348491\n",
      "Epoch:  618  Loss:  0.3956802617645625  Validation Loss:  0.4356461205943064\n",
      "Epoch:  619  Loss:  0.39570849865223423  Validation Loss:  0.43568039248612794\n",
      "Epoch:  620  Loss:  0.39573715096621803  Validation Loss:  0.4357152276079763\n",
      "Epoch:  621  Loss:  0.39576627220394034  Validation Loss:  0.43575065776028415\n",
      "Epoch:  622  Loss:  0.39579591446302154  Validation Loss:  0.43578670289028776\n",
      "Epoch:  623  Loss:  0.3958259956854763  Validation Loss:  0.43582336977124214\n",
      "Epoch:  624  Loss:  0.39585657068951563  Validation Loss:  0.4358606025576591\n",
      "Epoch:  625  Loss:  0.3958876361788222  Validation Loss:  0.4358983691443096\n",
      "Epoch:  626  Loss:  0.39591911036634087  Validation Loss:  0.4359366754916581\n",
      "Epoch:  627  Loss:  0.3959510168681542  Validation Loss:  0.43597547513517465\n",
      "Epoch:  628  Loss:  0.395983387902379  Validation Loss:  0.43601468384943226\n",
      "Epoch:  629  Loss:  0.39601615155962383  Validation Loss:  0.4360543242571029\n",
      "Epoch:  630  Loss:  0.3960492571646517  Validation Loss:  0.43609431260688736\n",
      "Epoch:  631  Loss:  0.39608270981998156  Validation Loss:  0.43613461367785933\n",
      "Epoch:  632  Loss:  0.3961165302066189  Validation Loss:  0.43617520704865453\n",
      "Epoch:  633  Loss:  0.3961507385878852  Validation Loss:  0.43621605106375433\n",
      "Epoch:  634  Loss:  0.3961852330488689  Validation Loss:  0.4362570903517983\n",
      "Epoch:  635  Loss:  0.3962199940713066  Validation Loss:  0.43629826466468247\n",
      "Epoch:  636  Loss:  0.3962549990551038  Validation Loss:  0.4363395100628788\n",
      "Epoch:  637  Loss:  0.3962902554734187  Validation Loss:  0.43638073029843244\n",
      "Epoch:  638  Loss:  0.39632576235541794  Validation Loss:  0.4364218698983843\n",
      "Epoch:  639  Loss:  0.3963615254019246  Validation Loss:  0.4364628306505355\n",
      "Epoch:  640  Loss:  0.3963974228298122  Validation Loss:  0.436503485895016\n",
      "Epoch:  641  Loss:  0.39643343550463517  Validation Loss:  0.4365437155758793\n",
      "Epoch:  642  Loss:  0.39646950808889936  Validation Loss:  0.4365833920511332\n",
      "Epoch:  643  Loss:  0.39650563148386553  Validation Loss:  0.43662242438982835\n",
      "Epoch:  644  Loss:  0.3965417727715138  Validation Loss:  0.436660755222494\n",
      "Epoch:  645  Loss:  0.3965779421794595  Validation Loss:  0.4366983871906996\n",
      "Epoch:  646  Loss:  0.39661417085338724  Validation Loss:  0.4367354045537385\n",
      "Epoch:  647  Loss:  0.3966505429848577  Validation Loss:  0.4367720076983625\n",
      "Epoch:  648  Loss:  0.39668704748831013  Validation Loss:  0.4368083917281844\n",
      "Epoch:  649  Loss:  0.39672371476437107  Validation Loss:  0.43684471415525133\n",
      "Epoch:  650  Loss:  0.39676058375925727  Validation Loss:  0.43688111227344384\n",
      "Epoch:  651  Loss:  0.3967976882940892  Validation Loss:  0.43691771917722444\n",
      "Epoch:  652  Loss:  0.3968350598532142  Validation Loss:  0.43695458004420457\n",
      "Epoch:  653  Loss:  0.3968726785119736  Validation Loss:  0.43699167309836906\n",
      "Epoch:  654  Loss:  0.3969105831827178  Validation Loss:  0.43702909783883526\n",
      "Epoch:  655  Loss:  0.3969487510169997  Validation Loss:  0.4370668229731646\n",
      "Epoch:  656  Loss:  0.3969871973562421  Validation Loss:  0.43710483021356844\n",
      "Epoch:  657  Loss:  0.3970259396189993  Validation Loss:  0.43714309317821803\n",
      "Epoch:  658  Loss:  0.3970649797243602  Validation Loss:  0.43718166700141\n",
      "Epoch:  659  Loss:  0.3971043372018771  Validation Loss:  0.4372204526242885\n",
      "Epoch:  660  Loss:  0.3971439613876018  Validation Loss:  0.4372595092112368\n",
      "Epoch:  661  Loss:  0.3971838376738808  Validation Loss:  0.43729883747344667\n",
      "Epoch:  662  Loss:  0.397223969345743  Validation Loss:  0.4373383792286569\n",
      "Epoch:  663  Loss:  0.39726434049732756  Validation Loss:  0.43737813146276905\n",
      "Epoch:  664  Loss:  0.3973049586921027  Validation Loss:  0.43741809326139364\n",
      "Epoch:  665  Loss:  0.3973458079451864  Validation Loss:  0.43745824880898\n",
      "Epoch:  666  Loss:  0.39738689752464945  Validation Loss:  0.437498584931547\n",
      "Epoch:  667  Loss:  0.3974282111295245  Validation Loss:  0.4375391407446428\n",
      "Epoch:  668  Loss:  0.3974697518642202  Validation Loss:  0.4375798623331568\n",
      "Epoch:  669  Loss:  0.39751150301008514  Validation Loss:  0.43762075281278656\n",
      "Epoch:  670  Loss:  0.39755348227918147  Validation Loss:  0.4376618148928339\n",
      "Epoch:  671  Loss:  0.3975956617092544  Validation Loss:  0.4377030189403079\n",
      "Epoch:  672  Loss:  0.39763805007166936  Validation Loss:  0.4377443894066594\n",
      "Epoch:  673  Loss:  0.3976806520738385  Validation Loss:  0.4377858743071556\n",
      "Epoch:  674  Loss:  0.39772345091808925  Validation Loss:  0.4378274600275538\n",
      "Epoch:  675  Loss:  0.397766437754035  Validation Loss:  0.4378691786053506\n",
      "Epoch:  676  Loss:  0.397809652250373  Validation Loss:  0.43791097138415686\n",
      "Epoch:  677  Loss:  0.3978530806686842  Validation Loss:  0.43795284276658836\n",
      "Epoch:  678  Loss:  0.39789670902219687  Validation Loss:  0.437994766777212\n",
      "Epoch:  679  Loss:  0.3979405345225876  Validation Loss:  0.4380367097529498\n",
      "Epoch:  680  Loss:  0.3979845205829902  Validation Loss:  0.43807869241996245\n",
      "Epoch:  681  Loss:  0.3980286750603806  Validation Loss:  0.43812072422694076\n",
      "Epoch:  682  Loss:  0.3980729702860117  Validation Loss:  0.43816276521167974\n",
      "Epoch:  683  Loss:  0.3981174140378381  Validation Loss:  0.43820482096211477\n",
      "Epoch:  684  Loss:  0.39816200782855354  Validation Loss:  0.4382468482648784\n",
      "Epoch:  685  Loss:  0.39820672850491423  Validation Loss:  0.43828885937956247\n",
      "Epoch:  686  Loss:  0.3982515730528217  Validation Loss:  0.4383307749236172\n",
      "Epoch:  687  Loss:  0.39829651843192  Validation Loss:  0.43837262574921954\n",
      "Epoch:  688  Loss:  0.39834158401371855  Validation Loss:  0.4384143324738199\n",
      "Epoch:  689  Loss:  0.3983867259188132  Validation Loss:  0.4384558807719838\n",
      "Epoch:  690  Loss:  0.39843194317637065  Validation Loss:  0.43849722641435535\n",
      "Epoch:  691  Loss:  0.3984772180969065  Validation Loss:  0.43853836303407495\n",
      "Epoch:  692  Loss:  0.39852253805958865  Validation Loss:  0.43857927488332443\n",
      "Epoch:  693  Loss:  0.3985678838170839  Validation Loss:  0.43861986280164933\n",
      "Epoch:  694  Loss:  0.3986132340787938  Validation Loss:  0.43866013156419453\n",
      "Epoch:  695  Loss:  0.3986585745757276  Validation Loss:  0.43869997855614534\n",
      "Epoch:  696  Loss:  0.3987038577257684  Validation Loss:  0.4387393507429145\n",
      "Epoch:  697  Loss:  0.39874907051297753  Validation Loss:  0.4387781534005295\n",
      "Epoch:  698  Loss:  0.3987941603768956  Validation Loss:  0.4388163177465851\n",
      "Epoch:  699  Loss:  0.398839108363697  Validation Loss:  0.43885371370071713\n",
      "Epoch:  700  Loss:  0.39888384668438726  Validation Loss:  0.4388902418315411\n",
      "Epoch:  701  Loss:  0.3989283296533606  Validation Loss:  0.43892574611712587\n",
      "Epoch:  702  Loss:  0.39897249727086587  Validation Loss:  0.43896004964004864\n",
      "Epoch:  703  Loss:  0.3990162537517873  Validation Loss:  0.4389929360286756\n",
      "Epoch:  704  Loss:  0.39905951782835253  Validation Loss:  0.43902414041486654\n",
      "Epoch:  705  Loss:  0.3991021551191807  Validation Loss:  0.43905337612059986\n",
      "Epoch:  706  Loss:  0.39914405279313075  Validation Loss:  0.4390802512114698\n",
      "Epoch:  707  Loss:  0.39918501877197715  Validation Loss:  0.4391043046997352\n",
      "Epoch:  708  Loss:  0.3992248694666407  Validation Loss:  0.43912499472498895\n",
      "Epoch:  709  Loss:  0.3992633727689584  Validation Loss:  0.4391417010263963\n",
      "Epoch:  710  Loss:  0.39930024678734216  Validation Loss:  0.4391536870463328\n",
      "Epoch:  711  Loss:  0.3993352190337398  Validation Loss:  0.4391602525995536\n",
      "Epoch:  712  Loss:  0.3993680184876377  Validation Loss:  0.4391608253121376\n",
      "Epoch:  713  Loss:  0.3993984519306457  Validation Loss:  0.4391550552438606\n",
      "Epoch:  714  Loss:  0.3994264962095203  Validation Loss:  0.4391431691294367\n",
      "Epoch:  715  Loss:  0.39945233048814716  Validation Loss:  0.4391259592703798\n",
      "Epoch:  716  Loss:  0.3994763500875596  Validation Loss:  0.43910453617572787\n",
      "Epoch:  717  Loss:  0.3994990859519352  Validation Loss:  0.4390802337364717\n",
      "Epoch:  718  Loss:  0.39952108692942245  Validation Loss:  0.43905431265858086\n",
      "Epoch:  719  Loss:  0.39954280187234736  Validation Loss:  0.4390277152373032\n",
      "Epoch:  720  Loss:  0.3995645702788324  Validation Loss:  0.4390010970221324\n",
      "Epoch:  721  Loss:  0.39958662167191505  Validation Loss:  0.43897491483525797\n",
      "Epoch:  722  Loss:  0.3996090983802622  Validation Loss:  0.438949404284358\n",
      "Epoch:  723  Loss:  0.39963207346471874  Validation Loss:  0.4389247151261026\n",
      "Epoch:  724  Loss:  0.39965560020822466  Validation Loss:  0.43890094431963833\n",
      "Epoch:  725  Loss:  0.3996796942005555  Validation Loss:  0.43887809921394694\n",
      "Epoch:  726  Loss:  0.39970434981990943  Validation Loss:  0.4388561702248725\n",
      "Epoch:  727  Loss:  0.39972956542941657  Validation Loss:  0.4388351539319212\n",
      "Epoch:  728  Loss:  0.3997553273132353  Validation Loss:  0.4388150166381489\n",
      "Epoch:  729  Loss:  0.3997816239681208  Validation Loss:  0.43879573544995354\n",
      "Epoch:  730  Loss:  0.3998084372756156  Validation Loss:  0.43877727951515805\n",
      "Epoch:  731  Loss:  0.3998357604060209  Validation Loss:  0.4387596258724278\n",
      "Epoch:  732  Loss:  0.3998635786952394  Validation Loss:  0.4387427303262732\n",
      "Epoch:  733  Loss:  0.39989186616783795  Validation Loss:  0.4387265496971932\n",
      "Epoch:  734  Loss:  0.39992061118510636  Validation Loss:  0.43871105316687714\n",
      "Epoch:  735  Loss:  0.399949808452617  Validation Loss:  0.4386962695216591\n",
      "Epoch:  736  Loss:  0.39997944417550707  Validation Loss:  0.43868210972710087\n",
      "Epoch:  737  Loss:  0.4000095052249504  Validation Loss:  0.4386686019599438\n",
      "Epoch:  738  Loss:  0.40003999486339814  Validation Loss:  0.43865570642731405\n",
      "Epoch:  739  Loss:  0.4000708805905147  Validation Loss:  0.43864339949055153\n",
      "Epoch:  740  Loss:  0.4001021830873056  Validation Loss:  0.4386316768147729\n",
      "Epoch:  741  Loss:  0.40013388350154416  Validation Loss:  0.4386205379935828\n",
      "Epoch:  742  Loss:  0.4001659887306618  Validation Loss:  0.4386099518022754\n",
      "Epoch:  743  Loss:  0.4001984694351753  Validation Loss:  0.43859988762573765\n",
      "Epoch:  744  Loss:  0.40023133355108176  Validation Loss:  0.4385903487151319\n",
      "Epoch:  745  Loss:  0.4002645673625397  Validation Loss:  0.4385813352059234\n",
      "Epoch:  746  Loss:  0.4002981674716328  Validation Loss:  0.4385728461498564\n",
      "Epoch:  747  Loss:  0.4003321490165862  Validation Loss:  0.4385648350824009\n",
      "Epoch:  748  Loss:  0.4003664899730321  Validation Loss:  0.43855731913989243\n",
      "Epoch:  749  Loss:  0.40040119350182285  Validation Loss:  0.4385502761060541\n",
      "Epoch:  750  Loss:  0.40043623976860987  Validation Loss:  0.43854371241547846\n",
      "Epoch:  751  Loss:  0.4004716477949511  Validation Loss:  0.4385376343672926\n",
      "Epoch:  752  Loss:  0.4005074043052666  Validation Loss:  0.43853200409900056\n",
      "Epoch:  753  Loss:  0.4005435059242176  Validation Loss:  0.43852680095217444\n",
      "Epoch:  754  Loss:  0.40057994491900456  Validation Loss:  0.43852206427942625\n",
      "Epoch:  755  Loss:  0.4006167297110413  Validation Loss:  0.43851775276389987\n",
      "Epoch:  756  Loss:  0.40065385422697575  Validation Loss:  0.43851389634338295\n",
      "Epoch:  757  Loss:  0.40069131479796133  Validation Loss:  0.4385104699568315\n",
      "Epoch:  758  Loss:  0.4007291051813147  Validation Loss:  0.43850746574726973\n",
      "Epoch:  759  Loss:  0.4007672387993697  Validation Loss:  0.4385049066760323\n",
      "Epoch:  760  Loss:  0.40080569262305893  Validation Loss:  0.4385027628730644\n",
      "Epoch:  761  Loss:  0.40084448324685745  Validation Loss:  0.43850102417848325\n",
      "Epoch:  762  Loss:  0.40088360362657993  Validation Loss:  0.43849971795623954\n",
      "Epoch:  763  Loss:  0.400923044945706  Validation Loss:  0.43849881596185947\n",
      "Epoch:  764  Loss:  0.4009628079718713  Validation Loss:  0.43849833438342267\n",
      "Epoch:  765  Loss:  0.4010029105413141  Validation Loss:  0.4384982592002912\n",
      "Epoch:  766  Loss:  0.4010433175347068  Validation Loss:  0.4384985956278714\n",
      "Epoch:  767  Loss:  0.40108406201682306  Validation Loss:  0.43849932192401453\n",
      "Epoch:  768  Loss:  0.4011251146594683  Validation Loss:  0.43850042420354757\n",
      "Epoch:  769  Loss:  0.4011664468004848  Validation Loss:  0.4385019229217009\n",
      "Epoch:  770  Loss:  0.40120810523177636  Validation Loss:  0.4385038164528933\n",
      "Epoch:  771  Loss:  0.40125007531182333  Validation Loss:  0.438506077026779\n",
      "Epoch:  772  Loss:  0.40129235613752495  Validation Loss:  0.4385087226602164\n",
      "Epoch:  773  Loss:  0.4013349525066036  Validation Loss:  0.43851175687529825\n",
      "Epoch:  774  Loss:  0.40137785919236413  Validation Loss:  0.43851513727144764\n",
      "Epoch:  775  Loss:  0.401421073835456  Validation Loss:  0.43851893503557554\n",
      "Epoch:  776  Loss:  0.40146460360424086  Validation Loss:  0.4385231173173948\n",
      "Epoch:  777  Loss:  0.4015084480020133  Validation Loss:  0.4385276889259165\n",
      "Epoch:  778  Loss:  0.4015526191303224  Validation Loss:  0.43853262635794554\n",
      "Epoch:  779  Loss:  0.40159708115864884  Validation Loss:  0.43853796564719894\n",
      "Epoch:  780  Loss:  0.40164186891281245  Validation Loss:  0.43854366662827404\n",
      "Epoch:  781  Loss:  0.40168695163094637  Validation Loss:  0.43854975084012204\n",
      "Epoch:  782  Loss:  0.4017323456478841  Validation Loss:  0.4385562002658844\n",
      "Epoch:  783  Loss:  0.4017780477463296  Validation Loss:  0.4385630123994567\n",
      "Epoch:  784  Loss:  0.401824048613057  Validation Loss:  0.43857011822136965\n",
      "Epoch:  785  Loss:  0.40187030969695614  Validation Loss:  0.43857748129151086\n",
      "Epoch:  786  Loss:  0.401916810429909  Validation Loss:  0.43858512192964555\n",
      "Epoch:  787  Loss:  0.40196356277799966  Validation Loss:  0.43859292844479736\n",
      "Epoch:  788  Loss:  0.4020105654204434  Validation Loss:  0.43860102512619714\n",
      "Epoch:  789  Loss:  0.4020578336309303  Validation Loss:  0.4386094272136688\n",
      "Epoch:  790  Loss:  0.4021053550031149  Validation Loss:  0.4386180873621594\n",
      "Epoch:  791  Loss:  0.4021530514300773  Validation Loss:  0.4386267181824554\n",
      "Epoch:  792  Loss:  0.40220080397345803  Validation Loss:  0.43863546468994835\n",
      "Epoch:  793  Loss:  0.4022488364554716  Validation Loss:  0.4386445644226941\n",
      "Epoch:  794  Loss:  0.40229717608202586  Validation Loss:  0.43865404833446847\n",
      "Epoch:  795  Loss:  0.4023458080535585  Validation Loss:  0.4386638809334148\n",
      "Epoch:  796  Loss:  0.4023947584471016  Validation Loss:  0.43867409256371587\n",
      "Epoch:  797  Loss:  0.4024439983521447  Validation Loss:  0.43868464170531796\n",
      "Epoch:  798  Loss:  0.40249354368583723  Validation Loss:  0.43869554163380103\n",
      "Epoch:  799  Loss:  0.40254338804745315  Validation Loss:  0.43870681111108173\n",
      "Epoch:  800  Loss:  0.402593526594115  Validation Loss:  0.43871844214471906\n",
      "Epoch:  801  Loss:  0.4026439659410354  Validation Loss:  0.4387304255908186\n",
      "Epoch:  802  Loss:  0.4026946992923816  Validation Loss:  0.4387427560307763\n",
      "Epoch:  803  Loss:  0.40274573317305606  Validation Loss:  0.4387554606930776\n",
      "Epoch:  804  Loss:  0.4027970679668766  Validation Loss:  0.4387684717774391\n",
      "Epoch:  805  Loss:  0.4028486949927879  Validation Loss:  0.4387818787585605\n",
      "Epoch:  806  Loss:  0.40290061907108987  Validation Loss:  0.43879560713063587\n",
      "Epoch:  807  Loss:  0.40295282965808205  Validation Loss:  0.4388097030195323\n",
      "Epoch:  808  Loss:  0.4030053462042953  Validation Loss:  0.4388241650705988\n",
      "Epoch:  809  Loss:  0.4030581612478603  Validation Loss:  0.4388389678163962\n",
      "Epoch:  810  Loss:  0.4031112636241949  Validation Loss:  0.43885414823889735\n",
      "Epoch:  811  Loss:  0.4031646614837827  Validation Loss:  0.43886968351223254\n",
      "Epoch:  812  Loss:  0.40321836552836676  Validation Loss:  0.43888559944250366\n",
      "Epoch:  813  Loss:  0.4032723440929796  Validation Loss:  0.4389018657532605\n",
      "Epoch:  814  Loss:  0.4033266190665238  Validation Loss:  0.43891848569566555\n",
      "Epoch:  815  Loss:  0.40338117059207323  Validation Loss:  0.4389354686168107\n",
      "Epoch:  816  Loss:  0.4034360292508747  Validation Loss:  0.43895279135216364\n",
      "Epoch:  817  Loss:  0.40349116293769893  Validation Loss:  0.4389704791659659\n",
      "Epoch:  818  Loss:  0.403546587874492  Validation Loss:  0.4389885128899054\n",
      "Epoch:  819  Loss:  0.4036023080236081  Validation Loss:  0.4390069131824103\n",
      "Epoch:  820  Loss:  0.40365832208683994  Validation Loss:  0.439025657962669\n",
      "Epoch:  821  Loss:  0.403714621913704  Validation Loss:  0.43904473558068274\n",
      "Epoch:  822  Loss:  0.4037712059463515  Validation Loss:  0.43906417990272695\n",
      "Epoch:  823  Loss:  0.40382809221292987  Validation Loss:  0.4390839522535151\n",
      "Epoch:  824  Loss:  0.40388525652162954  Validation Loss:  0.43910410289059987\n",
      "Epoch:  825  Loss:  0.403942703015425  Validation Loss:  0.4391245921227065\n",
      "Epoch:  826  Loss:  0.40400044424741555  Validation Loss:  0.43914541561495174\n",
      "Epoch:  827  Loss:  0.4040584696174571  Validation Loss:  0.43916659368710087\n",
      "Epoch:  828  Loss:  0.4041167838781169  Validation Loss:  0.4391881293871186\n",
      "Epoch:  829  Loss:  0.40417539902934524  Validation Loss:  0.439209990745241\n",
      "Epoch:  830  Loss:  0.40423429191789845  Validation Loss:  0.43923222436146303\n",
      "Epoch:  831  Loss:  0.4042934750178547  Validation Loss:  0.43925480151718316\n",
      "Epoch:  832  Loss:  0.4043529623046969  Validation Loss:  0.4392777425998991\n",
      "Epoch:  833  Loss:  0.4044127410898606  Validation Loss:  0.43930105526338925\n",
      "Epoch:  834  Loss:  0.4044728165097309  Validation Loss:  0.43932471241463317\n",
      "Epoch:  835  Loss:  0.4045331745098035  Validation Loss:  0.4393487213687463\n",
      "Epoch:  836  Loss:  0.4045938351840684  Validation Loss:  0.4393730929629369\n",
      "Epoch:  837  Loss:  0.4046547805833997  Validation Loss:  0.43939782347191464\n",
      "Epoch:  838  Loss:  0.4047160279795979  Validation Loss:  0.43942290395498274\n",
      "Epoch:  839  Loss:  0.40477755730125037  Validation Loss:  0.4394483264874328\n",
      "Epoch:  840  Loss:  0.4048393789114374  Validation Loss:  0.4394741035320542\n",
      "Epoch:  841  Loss:  0.4049014833501794  Validation Loss:  0.4395002397623929\n",
      "Epoch:  842  Loss:  0.4049638871216413  Validation Loss:  0.4395267242057757\n",
      "Epoch:  843  Loss:  0.4050265780678301  Validation Loss:  0.43955355022441256\n",
      "Epoch:  844  Loss:  0.405089556561275  Validation Loss:  0.4395807182924314\n",
      "Epoch:  845  Loss:  0.40515282506292516  Validation Loss:  0.439608250151981\n",
      "Epoch:  846  Loss:  0.40521637296134777  Validation Loss:  0.4396361154588786\n",
      "Epoch:  847  Loss:  0.40528022207771286  Validation Loss:  0.43966433134945954\n",
      "Epoch:  848  Loss:  0.40534434665107366  Validation Loss:  0.43969290283593265\n",
      "Epoch:  849  Loss:  0.4054087657368544  Validation Loss:  0.4397218053313819\n",
      "Epoch:  850  Loss:  0.4054734678882541  Validation Loss:  0.43975106660615315\n",
      "Epoch:  851  Loss:  0.405538455893596  Validation Loss:  0.43978068659251385\n",
      "Epoch:  852  Loss:  0.4056037326428023  Validation Loss:  0.4398106560111046\n",
      "Epoch:  853  Loss:  0.4056692970860185  Validation Loss:  0.4398409479721026\n",
      "Epoch:  854  Loss:  0.4057351509504246  Validation Loss:  0.4398716203868389\n",
      "Epoch:  855  Loss:  0.4058012831278823  Validation Loss:  0.4399026355960152\n",
      "Epoch:  856  Loss:  0.40586769673408885  Validation Loss:  0.43993397856300526\n",
      "Epoch:  857  Loss:  0.4059343835056731  Validation Loss:  0.4399654737927697\n",
      "Epoch:  858  Loss:  0.40600122195301636  Validation Loss:  0.4399970954114741\n",
      "Epoch:  859  Loss:  0.4060682412462704  Validation Loss:  0.44002896764061666\n",
      "Epoch:  860  Loss:  0.4061354458557837  Validation Loss:  0.4400609616528858\n",
      "Epoch:  861  Loss:  0.4062026803917957  Validation Loss:  0.44009279601953244\n",
      "Epoch:  862  Loss:  0.40627006698738444  Validation Loss:  0.4401249402625994\n",
      "Epoch:  863  Loss:  0.40633772607102536  Validation Loss:  0.4401574307544665\n",
      "Epoch:  864  Loss:  0.40640568251185344  Validation Loss:  0.4401902714236216\n",
      "Epoch:  865  Loss:  0.40647390866369915  Validation Loss:  0.44022349071773614\n",
      "Epoch:  866  Loss:  0.4065424338321794  Validation Loss:  0.4402570428496057\n",
      "Epoch:  867  Loss:  0.4066112365460757  Validation Loss:  0.4402909465811469\n",
      "Epoch:  868  Loss:  0.4066803111384312  Validation Loss:  0.44032520523125473\n",
      "Epoch:  869  Loss:  0.4067496733570641  Validation Loss:  0.44035980728539553\n",
      "Epoch:  870  Loss:  0.4068193053205808  Validation Loss:  0.44039476723833515\n",
      "Epoch:  871  Loss:  0.40688922896303914  Validation Loss:  0.4404300803487951\n",
      "Epoch:  872  Loss:  0.40695942177465466  Validation Loss:  0.4404657563025301\n",
      "Epoch:  873  Loss:  0.4070298939604651  Validation Loss:  0.4405017557469281\n",
      "Epoch:  874  Loss:  0.40710064527211764  Validation Loss:  0.44053809426047585\n",
      "Epoch:  875  Loss:  0.4071716657416387  Validation Loss:  0.4405747885053808\n",
      "Epoch:  876  Loss:  0.4072429580783302  Validation Loss:  0.4406118182973428\n",
      "Epoch:  877  Loss:  0.40731453047783084  Validation Loss:  0.4406491932543841\n",
      "Epoch:  878  Loss:  0.4073863768667886  Validation Loss:  0.44068692367185247\n",
      "Epoch:  879  Loss:  0.4074584869272781  Validation Loss:  0.4407249879430641\n",
      "Epoch:  880  Loss:  0.4075308751201991  Validation Loss:  0.44076338694854217\n",
      "Epoch:  881  Loss:  0.4076035302358143  Validation Loss:  0.44080215753479435\n",
      "Epoch:  882  Loss:  0.40767645593168156  Validation Loss:  0.44084125994281337\n",
      "Epoch:  883  Loss:  0.4077496467214642  Validation Loss:  0.4408807233653285\n",
      "Epoch:  884  Loss:  0.4078231076963923  Validation Loss:  0.440920523960482\n",
      "Epoch:  885  Loss:  0.4078968331104878  Validation Loss:  0.4409606631506573\n",
      "Epoch:  886  Loss:  0.40797081018487613  Validation Loss:  0.4410011307082393\n",
      "Epoch:  887  Loss:  0.4080450334445094  Validation Loss:  0.44104190692305567\n",
      "Epoch:  888  Loss:  0.4081194641802347  Validation Loss:  0.4410827861590819\n",
      "Epoch:  889  Loss:  0.40819399526173417  Validation Loss:  0.4411237248642878\n",
      "Epoch:  890  Loss:  0.408268604009892  Validation Loss:  0.4411646089093252\n",
      "Epoch:  891  Loss:  0.4083431189597556  Validation Loss:  0.4412054729055275\n",
      "Epoch:  892  Loss:  0.40841786396322827  Validation Loss:  0.4412466745484959\n",
      "Epoch:  893  Loss:  0.40849285139278935  Validation Loss:  0.4412882234562527\n",
      "Epoch:  894  Loss:  0.40856811783530494  Validation Loss:  0.4413301573558287\n",
      "Epoch:  895  Loss:  0.4086436272006143  Validation Loss:  0.4413724354722283\n",
      "Epoch:  896  Loss:  0.4087193899533965  Validation Loss:  0.44141508693044834\n",
      "Epoch:  897  Loss:  0.4087954111961704  Validation Loss:  0.4414580974389206\n",
      "Epoch:  898  Loss:  0.4088716708123684  Validation Loss:  0.441501456905495\n",
      "Epoch:  899  Loss:  0.40894818443692094  Validation Loss:  0.44154519648714496\n",
      "Epoch:  900  Loss:  0.40902493395137063  Validation Loss:  0.4415892797437581\n",
      "Epoch:  901  Loss:  0.4091019214554267  Validation Loss:  0.44163371182300826\n",
      "Epoch:  902  Loss:  0.40917914789734466  Validation Loss:  0.4416785041716966\n",
      "Epoch:  903  Loss:  0.4092566098227645  Validation Loss:  0.44172365631569516\n",
      "Epoch:  904  Loss:  0.40933430662209336  Validation Loss:  0.4417691461064599\n",
      "Epoch:  905  Loss:  0.40941217696350635  Validation Loss:  0.4418146410448985\n",
      "Epoch:  906  Loss:  0.40949006121266973  Validation Loss:  0.4418601615862413\n",
      "Epoch:  907  Loss:  0.4095677959873821  Validation Loss:  0.4419053954834288\n",
      "Epoch:  908  Loss:  0.4096456096027837  Validation Loss:  0.44195096093145286\n",
      "Epoch:  909  Loss:  0.4097236294073589  Validation Loss:  0.44199689443815837\n",
      "Epoch:  910  Loss:  0.4098018520935015  Validation Loss:  0.4420431722294201\n",
      "Epoch:  911  Loss:  0.4098802671965325  Validation Loss:  0.44208980839360845\n",
      "Epoch:  912  Loss:  0.409958876150124  Validation Loss:  0.4421368050304326\n",
      "Epoch:  913  Loss:  0.4100376627661965  Validation Loss:  0.44218415225094015\n",
      "Epoch:  914  Loss:  0.41011663983491337  Validation Loss:  0.44223186576908285\n",
      "Epoch:  915  Loss:  0.41019577229339066  Validation Loss:  0.44227982339533894\n",
      "Epoch:  916  Loss:  0.41027496364532096  Validation Loss:  0.44232772954485633\n",
      "Epoch:  917  Loss:  0.41035406237298794  Validation Loss:  0.4423755599016493\n",
      "Epoch:  918  Loss:  0.4104329373687506  Validation Loss:  0.4424233693968166\n",
      "Epoch:  919  Loss:  0.41051192450704  Validation Loss:  0.4424715399064801\n",
      "Epoch:  920  Loss:  0.41059101586314767  Validation Loss:  0.4425200699405237\n",
      "Epoch:  921  Loss:  0.41067022213881665  Validation Loss:  0.44256897020069036\n",
      "Epoch:  922  Loss:  0.4107495085646709  Validation Loss:  0.4426182375712828\n",
      "Epoch:  923  Loss:  0.4108288406422644  Validation Loss:  0.4426675493066961\n",
      "Epoch:  924  Loss:  0.4109080000695857  Validation Loss:  0.44271669049154627\n",
      "Epoch:  925  Loss:  0.41098673134816416  Validation Loss:  0.4427657237784429\n",
      "Epoch:  926  Loss:  0.411065411940217  Validation Loss:  0.44281513995744964\n",
      "Epoch:  927  Loss:  0.41114406059637215  Validation Loss:  0.44286491803147576\n",
      "Epoch:  928  Loss:  0.41122264533557673  Validation Loss:  0.4429149773310531\n",
      "Epoch:  929  Loss:  0.4113009802206899  Validation Loss:  0.44296483173966406\n",
      "Epoch:  930  Loss:  0.41137864967864574  Validation Loss:  0.4430144571445205\n",
      "Epoch:  931  Loss:  0.41145600927146997  Validation Loss:  0.4430645054036921\n",
      "Epoch:  932  Loss:  0.4115330898964947  Validation Loss:  0.4431149694729935\n",
      "Epoch:  933  Loss:  0.4116097351141048  Validation Loss:  0.44316525479609314\n",
      "Epoch:  934  Loss:  0.4116854007045428  Validation Loss:  0.44321529147299854\n",
      "Epoch:  935  Loss:  0.411760340777762  Validation Loss:  0.4432658020745624\n",
      "Epoch:  936  Loss:  0.4118345280036782  Validation Loss:  0.4433164624327963\n",
      "Epoch:  937  Loss:  0.4119074972628644  Validation Loss:  0.4433669491925023\n",
      "Epoch:  938  Loss:  0.4119790079015674  Validation Loss:  0.44341780787164514\n",
      "Epoch:  939  Loss:  0.41204908070239155  Validation Loss:  0.4434685358269648\n",
      "Epoch:  940  Loss:  0.4121169396986564  Validation Loss:  0.4435194332491268\n",
      "Epoch:  941  Loss:  0.4121827515463034  Validation Loss:  0.44357059638608587\n",
      "Epoch:  942  Loss:  0.41224585791880436  Validation Loss:  0.44362185509367424\n",
      "Epoch:  943  Loss:  0.4123063024810769  Validation Loss:  0.4436732548204335\n",
      "Epoch:  944  Loss:  0.4123636873495398  Validation Loss:  0.44372504075819796\n",
      "Epoch:  945  Loss:  0.4124185784748106  Validation Loss:  0.4437768621200865\n",
      "Epoch:  946  Loss:  0.4124709774598931  Validation Loss:  0.4438282910395752\n",
      "Epoch:  947  Loss:  0.4125213863610318  Validation Loss:  0.4438793943686919\n",
      "Epoch:  948  Loss:  0.4125704026131919  Validation Loss:  0.4439298016781157\n",
      "Epoch:  949  Loss:  0.4126183810333411  Validation Loss:  0.4439792106097395\n",
      "Epoch:  950  Loss:  0.41266551872320245  Validation Loss:  0.44402734041213987\n",
      "Epoch:  951  Loss:  0.4127119763669643  Validation Loss:  0.44407437301494856\n",
      "Epoch:  952  Loss:  0.4127578859189243  Validation Loss:  0.44411956403743136\n",
      "Epoch:  953  Loss:  0.41280287113605124  Validation Loss:  0.4441628552295945\n",
      "Epoch:  954  Loss:  0.41284700148936476  Validation Loss:  0.44420373338189995\n",
      "Epoch:  955  Loss:  0.4128900241784074  Validation Loss:  0.4442417610098015\n",
      "Epoch:  956  Loss:  0.41293166074337384  Validation Loss:  0.44427654208107425\n",
      "Epoch:  957  Loss:  0.4129716074489283  Validation Loss:  0.44430749958211724\n",
      "Epoch:  958  Loss:  0.41300945615000795  Validation Loss:  0.4443337393755263\n",
      "Epoch:  959  Loss:  0.41304475201124496  Validation Loss:  0.44435478164391085\n",
      "Epoch:  960  Loss:  0.4130770902967814  Validation Loss:  0.4443693507801403\n",
      "Epoch:  961  Loss:  0.41310565538252847  Validation Loss:  0.44437623714858837\n",
      "Epoch:  962  Loss:  0.413129860817483  Validation Loss:  0.4443746234205636\n",
      "Epoch:  963  Loss:  0.41314913120233654  Validation Loss:  0.4443637652153319\n",
      "Epoch:  964  Loss:  0.4131631437914841  Validation Loss:  0.44434307129545647\n",
      "Epoch:  965  Loss:  0.41317168659333026  Validation Loss:  0.4443129240111871\n",
      "Epoch:  966  Loss:  0.413175191910881  Validation Loss:  0.44427472190423445\n",
      "Epoch:  967  Loss:  0.41317452037650526  Validation Loss:  0.44423041797497054\n",
      "Epoch:  968  Loss:  0.41317082939274385  Validation Loss:  0.4441821806810119\n",
      "Epoch:  969  Loss:  0.41316510495362857  Validation Loss:  0.4441316181285815\n",
      "Epoch:  970  Loss:  0.41315817711028185  Validation Loss:  0.4440801914442669\n",
      "Epoch:  971  Loss:  0.41315087630893244  Validation Loss:  0.4440292327241464\n",
      "Epoch:  972  Loss:  0.4131435118841402  Validation Loss:  0.44397903287952595\n",
      "Epoch:  973  Loss:  0.4131364624834422  Validation Loss:  0.44392999505454844\n",
      "Epoch:  974  Loss:  0.4131297812543132  Validation Loss:  0.44388220418583263\n",
      "Epoch:  975  Loss:  0.41312383740688813  Validation Loss:  0.4438357664780183\n",
      "Epoch:  976  Loss:  0.41311844420252425  Validation Loss:  0.44379049200903287\n",
      "Epoch:  977  Loss:  0.41311399471579174  Validation Loss:  0.4437465345317667\n",
      "Epoch:  978  Loss:  0.41311025484041736  Validation Loss:  0.44370360415090215\n",
      "Epoch:  979  Loss:  0.4131073541261933  Validation Loss:  0.4436618836765939\n",
      "Epoch:  980  Loss:  0.4131054057316347  Validation Loss:  0.4436211714690382\n",
      "Epoch:  981  Loss:  0.4131041126720833  Validation Loss:  0.44358139119365\n",
      "Epoch:  982  Loss:  0.4131037489934401  Validation Loss:  0.44354258931495927\n",
      "Epoch:  983  Loss:  0.4131040145276171  Validation Loss:  0.4435045063495636\n",
      "Epoch:  984  Loss:  0.41310503859863135  Validation Loss:  0.44346733912825587\n",
      "Epoch:  985  Loss:  0.41310682213216116  Validation Loss:  0.4434311418370767\n",
      "Epoch:  986  Loss:  0.4131092527824821  Validation Loss:  0.443395445631309\n",
      "Epoch:  987  Loss:  0.41311246479550995  Validation Loss:  0.4433607599952004\n",
      "Epoch:  988  Loss:  0.4131162635078936  Validation Loss:  0.44332672337239437\n",
      "Epoch:  989  Loss:  0.41312063521508013  Validation Loss:  0.44329320646145126\n",
      "Epoch:  990  Loss:  0.41312575909224425  Validation Loss:  0.4432606170800599\n",
      "Epoch:  991  Loss:  0.4131314417403756  Validation Loss:  0.4432287672026591\n",
      "Epoch:  992  Loss:  0.4131377067304019  Validation Loss:  0.4431972108781338\n",
      "Epoch:  993  Loss:  0.413144368136471  Validation Loss:  0.4431661762297153\n",
      "Epoch:  994  Loss:  0.41315177916125817  Validation Loss:  0.4431361058218913\n",
      "Epoch:  995  Loss:  0.4131597328366655  Validation Loss:  0.4431066907942295\n",
      "Epoch:  996  Loss:  0.41316823489738236  Validation Loss:  0.44307761503891513\n",
      "Epoch:  997  Loss:  0.41317711481542296  Validation Loss:  0.4430488085204905\n",
      "Epoch:  998  Loss:  0.4131863923461148  Validation Loss:  0.4430205846374685\n",
      "Epoch:  999  Loss:  0.41319639924349205  Validation Loss:  0.4429932788691737\n",
      "Epoch:  1000  Loss:  0.41320693944439746  Validation Loss:  0.4429666430435397\n",
      "Epoch:  1001  Loss:  0.41321799050677904  Validation Loss:  0.4429402782158418\n",
      "Epoch:  1002  Loss:  0.41322941685264764  Validation Loss:  0.44291422096165745\n",
      "Epoch:  1003  Loss:  0.4132412029712489  Validation Loss:  0.4428884541446512\n",
      "Epoch:  1004  Loss:  0.413253359564326  Validation Loss:  0.4428631463511424\n",
      "Epoch:  1005  Loss:  0.41326616460626775  Validation Loss:  0.442838653922081\n",
      "Epoch:  1006  Loss:  0.413279390289928  Validation Loss:  0.44281480434266\n",
      "Epoch:  1007  Loss:  0.41329310351248943  Validation Loss:  0.4427913463928483\n",
      "Epoch:  1008  Loss:  0.41330719592444826  Validation Loss:  0.44276813891800965\n",
      "Epoch:  1009  Loss:  0.4133215526288206  Validation Loss:  0.44274515414779836\n",
      "Epoch:  1010  Loss:  0.41333621297821854  Validation Loss:  0.44272242987697774\n",
      "Epoch:  1011  Loss:  0.41335120776837525  Validation Loss:  0.44269992682066833\n",
      "Epoch:  1012  Loss:  0.41336650254599977  Validation Loss:  0.44267765669660136\n",
      "Epoch:  1013  Loss:  0.4133820944889025  Validation Loss:  0.4426557737317952\n",
      "Epoch:  1014  Loss:  0.41339825362418636  Validation Loss:  0.44263462607156145\n",
      "Epoch:  1015  Loss:  0.4134148756437229  Validation Loss:  0.44261395490982314\n",
      "Epoch:  1016  Loss:  0.413431921623873  Validation Loss:  0.44259369319135494\n",
      "Epoch:  1017  Loss:  0.41344938612345494  Validation Loss:  0.44257361956618047\n",
      "Epoch:  1018  Loss:  0.4134671461627339  Validation Loss:  0.4425536807287823\n",
      "Epoch:  1019  Loss:  0.41348519849054743  Validation Loss:  0.44253386665474287\n",
      "Epoch:  1020  Loss:  0.4135035324051525  Validation Loss:  0.4425141541117972\n",
      "Epoch:  1021  Loss:  0.41352213634686036  Validation Loss:  0.4424944965676828\n",
      "Epoch:  1022  Loss:  0.41354099491780455  Validation Loss:  0.44247486198490316\n",
      "Epoch:  1023  Loss:  0.41356008913029324  Validation Loss:  0.44245517511259425\n",
      "Epoch:  1024  Loss:  0.41357940631833945  Validation Loss:  0.44243541590192104\n",
      "Epoch:  1025  Loss:  0.4135989006495837  Validation Loss:  0.44241546859795394\n",
      "Epoch:  1026  Loss:  0.41361855907422124  Validation Loss:  0.4423952907323837\n",
      "Epoch:  1027  Loss:  0.4136384097464157  Validation Loss:  0.4423750688406554\n",
      "Epoch:  1028  Loss:  0.41365860655452263  Validation Loss:  0.44235474805940284\n",
      "Epoch:  1029  Loss:  0.4136789172662027  Validation Loss:  0.44233399548313834\n",
      "Epoch:  1030  Loss:  0.41369929419774  Validation Loss:  0.44231254295869304\n",
      "Epoch:  1031  Loss:  0.41371964103344716  Validation Loss:  0.4422900210050019\n",
      "Epoch:  1032  Loss:  0.4137397838361336  Validation Loss:  0.4422661471095952\n",
      "Epoch:  1033  Loss:  0.4137596250257709  Validation Loss:  0.4422407258640636\n",
      "Epoch:  1034  Loss:  0.41377910759412884  Validation Loss:  0.4422136474062096\n",
      "Epoch:  1035  Loss:  0.4137982195525458  Validation Loss:  0.4421849545430053\n",
      "Epoch:  1036  Loss:  0.41381698487834495  Validation Loss:  0.44215484735640614\n",
      "Epoch:  1037  Loss:  0.4138354928656058  Validation Loss:  0.44212367981672285\n",
      "Epoch:  1038  Loss:  0.4138538921421224  Validation Loss:  0.4420918872410601\n",
      "Epoch:  1039  Loss:  0.41387233372890586  Validation Loss:  0.44205979664217343\n",
      "Epoch:  1040  Loss:  0.41389090010162555  Validation Loss:  0.44202774288979446\n",
      "Epoch:  1041  Loss:  0.41390970211588973  Validation Loss:  0.4419959005984393\n",
      "Epoch:  1042  Loss:  0.41392878975832104  Validation Loss:  0.4419644132256508\n",
      "Epoch:  1043  Loss:  0.4139482082516858  Validation Loss:  0.4419333284551447\n",
      "Epoch:  1044  Loss:  0.4139679721359051  Validation Loss:  0.44190273345871406\n",
      "Epoch:  1045  Loss:  0.413988082991405  Validation Loss:  0.4418726241046732\n",
      "Epoch:  1046  Loss:  0.4140085543421182  Validation Loss:  0.4418430028991266\n",
      "Epoch:  1047  Loss:  0.41402938302719233  Validation Loss:  0.44181388291445645\n",
      "Epoch:  1048  Loss:  0.414050563266783  Validation Loss:  0.4417852394282818\n",
      "Epoch:  1049  Loss:  0.4140721022631183  Validation Loss:  0.4417572586373849\n",
      "Epoch:  1050  Loss:  0.41409418314243807  Validation Loss:  0.44173009551384235\n",
      "Epoch:  1051  Loss:  0.41411674359079564  Validation Loss:  0.44170362095941196\n",
      "Epoch:  1052  Loss:  0.414139713121183  Validation Loss:  0.44167782616886225\n",
      "Epoch:  1053  Loss:  0.41416313095074714  Validation Loss:  0.44165264787999065\n",
      "Epoch:  1054  Loss:  0.41418693792639355  Validation Loss:  0.44162800217216663\n",
      "Epoch:  1055  Loss:  0.41421114870093084  Validation Loss:  0.4416038414971395\n",
      "Epoch:  1056  Loss:  0.4142356879557624  Validation Loss:  0.44158015332438727\n",
      "Epoch:  1057  Loss:  0.4142605546748999  Validation Loss:  0.4415568960661238\n",
      "Epoch:  1058  Loss:  0.41428575854409827  Validation Loss:  0.44153407243165105\n",
      "Epoch:  1059  Loss:  0.41431130480134126  Validation Loss:  0.44151169860904865\n",
      "Epoch:  1060  Loss:  0.4143371684758952  Validation Loss:  0.44148973754861137\n",
      "Epoch:  1061  Loss:  0.41436336320458034  Validation Loss:  0.44146820848638363\n",
      "Epoch:  1062  Loss:  0.41438989329970244  Validation Loss:  0.44144709943370386\n",
      "Epoch:  1063  Loss:  0.4144167432730848  Validation Loss:  0.44142641357400203\n",
      "Epoch:  1064  Loss:  0.41444393132220614  Validation Loss:  0.4414061340418729\n",
      "Epoch:  1065  Loss:  0.41447145168979965  Validation Loss:  0.4413862758739428\n",
      "Epoch:  1066  Loss:  0.4144992971736373  Validation Loss:  0.44136681008067996\n",
      "Epoch:  1067  Loss:  0.4145274795366056  Validation Loss:  0.4413477375426076\n",
      "Epoch:  1068  Loss:  0.41455598238742714  Validation Loss:  0.4413290705193173\n",
      "Epoch:  1069  Loss:  0.414584820491798  Validation Loss:  0.4413107993927869\n",
      "Epoch:  1070  Loss:  0.41461397901628955  Validation Loss:  0.44129295620051295\n",
      "Epoch:  1071  Loss:  0.41464346647262573  Validation Loss:  0.44127547483552587\n",
      "Epoch:  1072  Loss:  0.41467328076109744  Validation Loss:  0.44125841110944747\n",
      "Epoch:  1073  Loss:  0.41470342050447606  Validation Loss:  0.4412417237054218\n",
      "Epoch:  1074  Loss:  0.4147338636445277  Validation Loss:  0.4412254358557138\n",
      "Epoch:  1075  Loss:  0.41476463129123053  Validation Loss:  0.44120957160537894\n",
      "Epoch:  1076  Loss:  0.41479571703256984  Validation Loss:  0.4411940733140165\n",
      "Epoch:  1077  Loss:  0.41482713479887356  Validation Loss:  0.4411789697679606\n",
      "Epoch:  1078  Loss:  0.4148588490305525  Validation Loss:  0.4411642666567456\n",
      "Epoch:  1079  Loss:  0.41489089562585857  Validation Loss:  0.44114995856176725\n",
      "Epoch:  1080  Loss:  0.41492325148799203  Validation Loss:  0.44113602766936477\n",
      "Epoch:  1081  Loss:  0.4149559379527063  Validation Loss:  0.44112250554290683\n",
      "Epoch:  1082  Loss:  0.4149889649541089  Validation Loss:  0.4411093522201885\n",
      "Epoch:  1083  Loss:  0.4150222979034438  Validation Loss:  0.4410965853116729\n",
      "Epoch:  1084  Loss:  0.41505596497745223  Validation Loss:  0.44108420962637124\n",
      "Epoch:  1085  Loss:  0.4150899444791404  Validation Loss:  0.44107219461690295\n",
      "Epoch:  1086  Loss:  0.4151242225910678  Validation Loss:  0.4410605604675683\n",
      "Epoch:  1087  Loss:  0.4151587950912389  Validation Loss:  0.4410492760213939\n",
      "Epoch:  1088  Loss:  0.41519368437655046  Validation Loss:  0.44103840359232643\n",
      "Epoch:  1089  Loss:  0.4152288783680309  Validation Loss:  0.44102791141379966\n",
      "Epoch:  1090  Loss:  0.4152644004334103  Validation Loss:  0.4410178238695318\n",
      "Epoch:  1091  Loss:  0.4153002372067986  Validation Loss:  0.4410080953755162\n",
      "Epoch:  1092  Loss:  0.4153363960710439  Validation Loss:  0.4409987819465724\n",
      "Epoch:  1093  Loss:  0.41537290608341043  Validation Loss:  0.44098999405449085\n",
      "Epoch:  1094  Loss:  0.41540987171006927  Validation Loss:  0.44098182456059887\n",
      "Epoch:  1095  Loss:  0.41544729520877205  Validation Loss:  0.44097424312071365\n",
      "Epoch:  1096  Loss:  0.41548507021683634  Validation Loss:  0.44096709259531713\n",
      "Epoch:  1097  Loss:  0.4155231946345532  Validation Loss:  0.4409604590724815\n",
      "Epoch:  1098  Loss:  0.41556168031511886  Validation Loss:  0.4409543044865131\n",
      "Epoch:  1099  Loss:  0.4156005183855693  Validation Loss:  0.4409485810859637\n",
      "Epoch:  1100  Loss:  0.4156396993181922  Validation Loss:  0.44094332700425926\n",
      "Epoch:  1101  Loss:  0.41567923684011804  Validation Loss:  0.4409384742379189\n",
      "Epoch:  1102  Loss:  0.41571910295522574  Validation Loss:  0.4409340117465366\n",
      "Epoch:  1103  Loss:  0.4157593047528556  Validation Loss:  0.4409299091859297\n",
      "Epoch:  1104  Loss:  0.41579980649279824  Validation Loss:  0.440926170213656\n",
      "Epoch:  1105  Loss:  0.4158406223763119  Validation Loss:  0.44092283350500194\n",
      "Epoch:  1106  Loss:  0.4158817355605689  Validation Loss:  0.44091988144950434\n",
      "Epoch:  1107  Loss:  0.4159231669749274  Validation Loss:  0.44091728248379447\n",
      "Epoch:  1108  Loss:  0.415964872006214  Validation Loss:  0.4409150452099063\n",
      "Epoch:  1109  Loss:  0.4160068822403749  Validation Loss:  0.44091315045952795\n",
      "Epoch:  1110  Loss:  0.4160492048119054  Validation Loss:  0.440911635553295\n",
      "Epoch:  1111  Loss:  0.4160918313219692  Validation Loss:  0.4409105054356835\n",
      "Epoch:  1112  Loss:  0.4161347661280271  Validation Loss:  0.4409097796814008\n",
      "Epoch:  1113  Loss:  0.41617802424412786  Validation Loss:  0.44090942300178787\n",
      "Epoch:  1114  Loss:  0.4162215775838404  Validation Loss:  0.4409094293686477\n",
      "Epoch:  1115  Loss:  0.4162654547528787  Validation Loss:  0.44090980182994494\n",
      "Epoch:  1116  Loss:  0.41630962971936575  Validation Loss:  0.4409105452624234\n",
      "Epoch:  1117  Loss:  0.4163540884400859  Validation Loss:  0.440911632979458\n",
      "Epoch:  1118  Loss:  0.41639885900147033  Validation Loss:  0.4409131031144749\n",
      "Epoch:  1119  Loss:  0.4164439589236722  Validation Loss:  0.4409149723974141\n",
      "Epoch:  1120  Loss:  0.4164893569368305  Validation Loss:  0.44091724062507803\n",
      "Epoch:  1121  Loss:  0.4165350534473405  Validation Loss:  0.4409198712896217\n",
      "Epoch:  1122  Loss:  0.4165810549575271  Validation Loss:  0.44092287096110255\n",
      "Epoch:  1123  Loss:  0.4166273338550871  Validation Loss:  0.4409262036058036\n",
      "Epoch:  1124  Loss:  0.4166738777223862  Validation Loss:  0.44092989191412923\n",
      "Epoch:  1125  Loss:  0.41672071735515737  Validation Loss:  0.44093396074392577\n",
      "Epoch:  1126  Loss:  0.4167678472896417  Validation Loss:  0.4409384190358899\n",
      "Epoch:  1127  Loss:  0.4168152750441522  Validation Loss:  0.4409432790496133\n",
      "Epoch:  1128  Loss:  0.4168630123364203  Validation Loss:  0.44094852744178337\n",
      "Epoch:  1129  Loss:  0.41691104514580785  Validation Loss:  0.440954171798446\n",
      "Epoch:  1130  Loss:  0.4169593632221222  Validation Loss:  0.4409601500765844\n",
      "Epoch:  1131  Loss:  0.4170079571731163  Validation Loss:  0.44096652926369145\n",
      "Epoch:  1132  Loss:  0.4170568372264053  Validation Loss:  0.4409732797606425\n",
      "Epoch:  1133  Loss:  0.41710598254294107  Validation Loss:  0.44098036431453447\n",
      "Epoch:  1134  Loss:  0.4171553851302826  Validation Loss:  0.44098779911344704\n",
      "Epoch:  1135  Loss:  0.41720503211924526  Validation Loss:  0.44099552888761867\n",
      "Epoch:  1136  Loss:  0.41725489580721564  Validation Loss:  0.44100357592105865\n",
      "Epoch:  1137  Loss:  0.41730501572742607  Validation Loss:  0.44101197584108875\n",
      "Epoch:  1138  Loss:  0.4173553788978042  Validation Loss:  0.4410207136110826\n",
      "Epoch:  1139  Loss:  0.41740597423278925  Validation Loss:  0.44102976769208907\n",
      "Epoch:  1140  Loss:  0.4174567898791848  Validation Loss:  0.44103914458643306\n",
      "Epoch:  1141  Loss:  0.4175078335810791  Validation Loss:  0.4410488449037075\n",
      "Epoch:  1142  Loss:  0.4175590642473914  Validation Loss:  0.4410588244822892\n",
      "Epoch:  1143  Loss:  0.4176104602037054  Validation Loss:  0.44106907309456306\n",
      "Epoch:  1144  Loss:  0.41766202510757877  Validation Loss:  0.44107965779575437\n",
      "Epoch:  1145  Loss:  0.4177137706315879  Validation Loss:  0.44109055386348206\n",
      "Epoch:  1146  Loss:  0.4177656827325171  Validation Loss:  0.44110178818756884\n",
      "Epoch:  1147  Loss:  0.417817740864826  Validation Loss:  0.44111334518952805\n",
      "Epoch:  1148  Loss:  0.41786991831931203  Validation Loss:  0.44112518219785257\n",
      "Epoch:  1149  Loss:  0.41792218798037734  Validation Loss:  0.4411373300308531\n",
      "Epoch:  1150  Loss:  0.4179744926365939  Validation Loss:  0.4411497290161523\n",
      "Epoch:  1151  Loss:  0.4180268338909655  Validation Loss:  0.44116237285462295\n",
      "Epoch:  1152  Loss:  0.41807917293274044  Validation Loss:  0.44117526120760225\n",
      "Epoch:  1153  Loss:  0.4181314372655117  Validation Loss:  0.4411883734166622\n",
      "Epoch:  1154  Loss:  0.4181835828631213  Validation Loss:  0.4412016361951828\n",
      "Epoch:  1155  Loss:  0.41823546771298753  Validation Loss:  0.4412149968472394\n",
      "Epoch:  1156  Loss:  0.4182870478792624  Validation Loss:  0.441228486597538\n",
      "Epoch:  1157  Loss:  0.41833824736602376  Validation Loss:  0.44124206053939735\n",
      "Epoch:  1158  Loss:  0.41838891047871474  Validation Loss:  0.4412556467408484\n",
      "Epoch:  1159  Loss:  0.41843886267055164  Validation Loss:  0.44126911237835886\n",
      "Epoch:  1160  Loss:  0.41848788121432967  Validation Loss:  0.4412824087522247\n",
      "Epoch:  1161  Loss:  0.41853576325105896  Validation Loss:  0.4412954159758308\n",
      "Epoch:  1162  Loss:  0.418582294452371  Validation Loss:  0.4413080510768023\n",
      "Epoch:  1163  Loss:  0.4186272310713927  Validation Loss:  0.4413201962682334\n",
      "Epoch:  1164  Loss:  0.4186704650069728  Validation Loss:  0.44133185324343766\n",
      "Epoch:  1165  Loss:  0.4187120656623985  Validation Loss:  0.44134303426200694\n",
      "Epoch:  1166  Loss:  0.4187521522243818  Validation Loss:  0.441353791681203\n",
      "Epoch:  1167  Loss:  0.41879108934239906  Validation Loss:  0.441364243558862\n",
      "Epoch:  1168  Loss:  0.41882925925381254  Validation Loss:  0.44137453375892205\n",
      "Epoch:  1169  Loss:  0.41886699116139703  Validation Loss:  0.4413848043842749\n",
      "Epoch:  1170  Loss:  0.41890456279118854  Validation Loss:  0.4413951812142676\n",
      "Epoch:  1171  Loss:  0.41894215754035746  Validation Loss:  0.4414056155491959\n",
      "Epoch:  1172  Loss:  0.4189799102192575  Validation Loss:  0.4414162681184032\n",
      "Epoch:  1173  Loss:  0.4190178870703235  Validation Loss:  0.44142707484689625\n",
      "Epoch:  1174  Loss:  0.4190561100163243  Validation Loss:  0.4414381003515287\n",
      "Epoch:  1175  Loss:  0.4190946066469857  Validation Loss:  0.44144932363520967\n",
      "Epoch:  1176  Loss:  0.4191333886123065  Validation Loss:  0.4414607388729399\n",
      "Epoch:  1177  Loss:  0.41917245076461274  Validation Loss:  0.44147235398942775\n",
      "Epoch:  1178  Loss:  0.4192117882497383  Validation Loss:  0.4414841571314768\n",
      "Epoch:  1179  Loss:  0.41925139104326564  Validation Loss:  0.44149614863774994\n",
      "Epoch:  1180  Loss:  0.41929123866738693  Validation Loss:  0.4415083132684231\n",
      "Epoch:  1181  Loss:  0.4193313278257847  Validation Loss:  0.4415206210857088\n",
      "Epoch:  1182  Loss:  0.4193716305674929  Validation Loss:  0.4415330724960024\n",
      "Epoch:  1183  Loss:  0.41941214644096114  Validation Loss:  0.4415456884963946\n",
      "Epoch:  1184  Loss:  0.4194528092489098  Validation Loss:  0.44155836938457055\n",
      "Epoch:  1185  Loss:  0.41949349149610055  Validation Loss:  0.4415710598230362\n",
      "Epoch:  1186  Loss:  0.41953421237342287  Validation Loss:  0.44158380783417006\n",
      "Epoch:  1187  Loss:  0.41957497594482973  Validation Loss:  0.4415965701368722\n",
      "Epoch:  1188  Loss:  0.4196158463304693  Validation Loss:  0.4416093868965452\n",
      "Epoch:  1189  Loss:  0.41965681346076905  Validation Loss:  0.4416222199120305\n",
      "Epoch:  1190  Loss:  0.4196978718268149  Validation Loss:  0.4416350745341995\n",
      "Epoch:  1191  Loss:  0.4197389513479941  Validation Loss:  0.4416478723964908\n",
      "Epoch:  1192  Loss:  0.41978007304397497  Validation Loss:  0.44166062995791433\n",
      "Epoch:  1193  Loss:  0.4198211655923815  Validation Loss:  0.44167329648678955\n",
      "Epoch:  1194  Loss:  0.41986224208817335  Validation Loss:  0.4416858470575376\n",
      "Epoch:  1195  Loss:  0.4199032226069407  Validation Loss:  0.44169823215766385\n",
      "Epoch:  1196  Loss:  0.4199440638224284  Validation Loss:  0.4417103612287478\n",
      "Epoch:  1197  Loss:  0.4199847256369663  Validation Loss:  0.4417222531681711\n",
      "Epoch:  1198  Loss:  0.42002512340744336  Validation Loss:  0.4417337279428135\n",
      "Epoch:  1199  Loss:  0.42006518082185224  Validation Loss:  0.44174468036402353\n",
      "Epoch:  1200  Loss:  0.4201047560256539  Validation Loss:  0.44175496074286374\n",
      "Epoch:  1201  Loss:  0.4201437381406625  Validation Loss:  0.4417644338851625\n",
      "Epoch:  1202  Loss:  0.4201819866895676  Validation Loss:  0.44177291176535866\n",
      "Epoch:  1203  Loss:  0.42021936349796524  Validation Loss:  0.4417802462523634\n",
      "Epoch:  1204  Loss:  0.4202557249502702  Validation Loss:  0.4417863127860156\n",
      "Epoch:  1205  Loss:  0.4202909653837031  Validation Loss:  0.44179098599336364\n",
      "Epoch:  1206  Loss:  0.42032503842404395  Validation Loss:  0.44179426275871014\n",
      "Epoch:  1207  Loss:  0.42035795499881107  Validation Loss:  0.44179618961431766\n",
      "Epoch:  1208  Loss:  0.420389781689102  Validation Loss:  0.4417969314212149\n",
      "Epoch:  1209  Loss:  0.420420617384441  Validation Loss:  0.4417965589599176\n",
      "Epoch:  1210  Loss:  0.42045051642891135  Validation Loss:  0.4417952242222699\n",
      "Epoch:  1211  Loss:  0.42047955655690394  Validation Loss:  0.44179302379488944\n",
      "Epoch:  1212  Loss:  0.42050778222354973  Validation Loss:  0.44178994914347475\n",
      "Epoch:  1213  Loss:  0.42053529367302406  Validation Loss:  0.44178612408312884\n",
      "Epoch:  1214  Loss:  0.4205621923912655  Validation Loss:  0.4417816487225619\n",
      "Epoch:  1215  Loss:  0.42058860485752425  Validation Loss:  0.4417766444385052\n",
      "Epoch:  1216  Loss:  0.4206147818854361  Validation Loss:  0.4417713801291856\n",
      "Epoch:  1217  Loss:  0.42064088675560374  Validation Loss:  0.44176600887016815\n",
      "Epoch:  1218  Loss:  0.42066706157091893  Validation Loss:  0.441760665923357\n",
      "Epoch:  1219  Loss:  0.420693352683024  Validation Loss:  0.44175536754456435\n",
      "Epoch:  1220  Loss:  0.42071960360714883  Validation Loss:  0.441750056296587\n",
      "Epoch:  1221  Loss:  0.42074595725897584  Validation Loss:  0.4417448114265095\n",
      "Epoch:  1222  Loss:  0.42077253616668964  Validation Loss:  0.4417396546087482\n",
      "Epoch:  1223  Loss:  0.4207993321572289  Validation Loss:  0.44173457141626965\n",
      "Epoch:  1224  Loss:  0.42082636485045605  Validation Loss:  0.44172954213890164\n",
      "Epoch:  1225  Loss:  0.4208535944422086  Validation Loss:  0.44172453758391467\n",
      "Epoch:  1226  Loss:  0.4208810105919838  Validation Loss:  0.44171945466236634\n",
      "Epoch:  1227  Loss:  0.4209085459058935  Validation Loss:  0.4417142416265878\n",
      "Epoch:  1228  Loss:  0.4209361407792929  Validation Loss:  0.44170881394635547\n",
      "Epoch:  1229  Loss:  0.4209637786854397  Validation Loss:  0.44170309962196785\n",
      "Epoch:  1230  Loss:  0.4209914535509818  Validation Loss:  0.4416971057653427\n",
      "Epoch:  1231  Loss:  0.42101913715402284  Validation Loss:  0.4416907391764901\n",
      "Epoch:  1232  Loss:  0.4210467929867181  Validation Loss:  0.4416838652030988\n",
      "Epoch:  1233  Loss:  0.42107431376070686  Validation Loss:  0.4416764558716254\n",
      "Epoch:  1234  Loss:  0.4211015932487719  Validation Loss:  0.44166818979111583\n",
      "Epoch:  1235  Loss:  0.4211283357080185  Validation Loss:  0.4416589879176833\n",
      "Epoch:  1236  Loss:  0.4211546945300969  Validation Loss:  0.44164869040250776\n",
      "Epoch:  1237  Loss:  0.42118059983759215  Validation Loss:  0.4416370786049149\n",
      "Epoch:  1238  Loss:  0.4212059139979608  Validation Loss:  0.4416238621554591\n",
      "Epoch:  1239  Loss:  0.42123051850181636  Validation Loss:  0.44160873395475475\n",
      "Epoch:  1240  Loss:  0.42125424189549504  Validation Loss:  0.44159131253307515\n",
      "Epoch:  1241  Loss:  0.4212769172859914  Validation Loss:  0.4415711948140101\n",
      "Epoch:  1242  Loss:  0.4212983021681959  Validation Loss:  0.4415478105572137\n",
      "Epoch:  1243  Loss:  0.4213178630128051  Validation Loss:  0.44152059649879283\n",
      "Epoch:  1244  Loss:  0.4213357124138962  Validation Loss:  0.44148941961201754\n",
      "Epoch:  1245  Loss:  0.4213517765655662  Validation Loss:  0.44145405089313333\n",
      "Epoch:  1246  Loss:  0.42136605402285404  Validation Loss:  0.44141475341536784\n",
      "Epoch:  1247  Loss:  0.42137876003980634  Validation Loss:  0.4413721415129575\n",
      "Epoch:  1248  Loss:  0.42138995440168814  Validation Loss:  0.4413269855759361\n",
      "Epoch:  1249  Loss:  0.4214003002101725  Validation Loss:  0.441280318593437\n",
      "Epoch:  1250  Loss:  0.42141029500600063  Validation Loss:  0.44123292924328283\n",
      "Epoch:  1251  Loss:  0.42142025144262746  Validation Loss:  0.4411852895536206\n",
      "Epoch:  1252  Loss:  0.4214300642636689  Validation Loss:  0.4411377393386581\n",
      "Epoch:  1253  Loss:  0.4214401923345797  Validation Loss:  0.4410907382992181\n",
      "Epoch:  1254  Loss:  0.4214507642343189  Validation Loss:  0.4410443582318046\n",
      "Epoch:  1255  Loss:  0.42146153312289353  Validation Loss:  0.4409986453977498\n",
      "Epoch:  1256  Loss:  0.42147275096539294  Validation Loss:  0.44095358401536944\n",
      "Epoch:  1257  Loss:  0.42148420015970867  Validation Loss:  0.44090927717360584\n",
      "Epoch:  1258  Loss:  0.42149611790523384  Validation Loss:  0.44086571389978585\n",
      "Epoch:  1259  Loss:  0.421508250611298  Validation Loss:  0.44082283425060187\n",
      "Epoch:  1260  Loss:  0.42152057576811675  Validation Loss:  0.4407805436714129\n",
      "Epoch:  1261  Loss:  0.42153306038993776  Validation Loss:  0.4407388250258836\n",
      "Epoch:  1262  Loss:  0.42154563493800884  Validation Loss:  0.44069760990413753\n",
      "Epoch:  1263  Loss:  0.42155820564790203  Validation Loss:  0.4406568309122866\n",
      "Epoch:  1264  Loss:  0.4215706628606175  Validation Loss:  0.4406164188953963\n",
      "Epoch:  1265  Loss:  0.4215828794873122  Validation Loss:  0.4405763157389381\n",
      "Epoch:  1266  Loss:  0.42159468628691904  Validation Loss:  0.44053637940775264\n",
      "Epoch:  1267  Loss:  0.42160592995809787  Validation Loss:  0.44049655483527617\n",
      "Epoch:  1268  Loss:  0.4216164183661793  Validation Loss:  0.4404567607424476\n",
      "Epoch:  1269  Loss:  0.42162600552493873  Validation Loss:  0.44041692953218115\n",
      "Epoch:  1270  Loss:  0.42163447690281003  Validation Loss:  0.4403769166632132\n",
      "Epoch:  1271  Loss:  0.42164169628963327  Validation Loss:  0.4403366854245013\n",
      "Epoch:  1272  Loss:  0.4216476481972319  Validation Loss:  0.44029621671546587\n",
      "Epoch:  1273  Loss:  0.4216524767378966  Validation Loss:  0.4402555919506333\n",
      "Epoch:  1274  Loss:  0.42165636697953396  Validation Loss:  0.44021488306197254\n",
      "Epoch:  1275  Loss:  0.42165955158345625  Validation Loss:  0.44017421427098186\n",
      "Epoch:  1276  Loss:  0.42166251768216945  Validation Loss:  0.44013376547531646\n",
      "Epoch:  1277  Loss:  0.4216654309494929  Validation Loss:  0.440093580159274\n",
      "Epoch:  1278  Loss:  0.42166857678781855  Validation Loss:  0.4400537905367938\n",
      "Epoch:  1279  Loss:  0.42167203026739036  Validation Loss:  0.44001440405845643\n",
      "Epoch:  1280  Loss:  0.4216759139615478  Validation Loss:  0.43997548954053356\n",
      "Epoch:  1281  Loss:  0.4216802904325904  Validation Loss:  0.43993696570396423\n",
      "Epoch:  1282  Loss:  0.4216850211674517  Validation Loss:  0.4398988047784025\n",
      "Epoch:  1283  Loss:  0.42169022801699063  Validation Loss:  0.43986110172488474\n",
      "Epoch:  1284  Loss:  0.4216959449603702  Validation Loss:  0.4398237396370281\n",
      "Epoch:  1285  Loss:  0.42170205452676973  Validation Loss:  0.43978665173053744\n",
      "Epoch:  1286  Loss:  0.42170848261677857  Validation Loss:  0.439749821072275\n",
      "Epoch:  1287  Loss:  0.4217153622119716  Validation Loss:  0.439713314446536\n",
      "Epoch:  1288  Loss:  0.42172269146099234  Validation Loss:  0.43967698528008026\n",
      "Epoch:  1289  Loss:  0.4217302625829523  Validation Loss:  0.43964075283570725\n",
      "Epoch:  1290  Loss:  0.42173812493230356  Validation Loss:  0.43960465924306347\n",
      "Epoch:  1291  Loss:  0.4217464216279261  Validation Loss:  0.43956875503063203\n",
      "Epoch:  1292  Loss:  0.4217551523763122  Validation Loss:  0.43953285379843277\n",
      "Epoch:  1293  Loss:  0.421764069118283  Validation Loss:  0.4394968707453121\n",
      "Epoch:  1294  Loss:  0.4217731755113963  Validation Loss:  0.4394606836817481\n",
      "Epoch:  1295  Loss:  0.42178243344480343  Validation Loss:  0.439424183558334\n",
      "Epoch:  1296  Loss:  0.4217919573639378  Validation Loss:  0.4393874161622741\n",
      "Epoch:  1297  Loss:  0.42180180091297986  Validation Loss:  0.43935008645057677\n",
      "Epoch:  1298  Loss:  0.4218116544187069  Validation Loss:  0.43931195763024417\n",
      "Epoch:  1299  Loss:  0.42182143513451925  Validation Loss:  0.439272804422812\n",
      "Epoch:  1300  Loss:  0.42183106631943673  Validation Loss:  0.4392324145544659\n",
      "Epoch:  1301  Loss:  0.42184050877888996  Validation Loss:  0.4391906915740533\n",
      "Epoch:  1302  Loss:  0.42184967134486545  Validation Loss:  0.4391475027257746\n",
      "Epoch:  1303  Loss:  0.4218585898478826  Validation Loss:  0.43910300555554305\n",
      "Epoch:  1304  Loss:  0.42186743246786523  Validation Loss:  0.43905754590576346\n",
      "Epoch:  1305  Loss:  0.4218763616274704  Validation Loss:  0.4390114079822193\n",
      "Epoch:  1306  Loss:  0.42188534167679875  Validation Loss:  0.43896493017673494\n",
      "Epoch:  1307  Loss:  0.4218944306626464  Validation Loss:  0.4389184090224179\n",
      "Epoch:  1308  Loss:  0.4219037193692092  Validation Loss:  0.43887208198959177\n",
      "Epoch:  1309  Loss:  0.42191330097389945  Validation Loss:  0.4388261208480055\n",
      "Epoch:  1310  Loss:  0.4219232110137289  Validation Loss:  0.43878063424067065\n",
      "Epoch:  1311  Loss:  0.4219334845515815  Validation Loss:  0.43873568258502266\n",
      "Epoch:  1312  Loss:  0.4219441339825139  Validation Loss:  0.43869128105315297\n",
      "Epoch:  1313  Loss:  0.42195514180895055  Validation Loss:  0.43864743316715415\n",
      "Epoch:  1314  Loss:  0.4219665008286635  Validation Loss:  0.4386040829799392\n",
      "Epoch:  1315  Loss:  0.4219781997528943  Validation Loss:  0.4385612375356934\n",
      "Epoch:  1316  Loss:  0.42199026786468247  Validation Loss:  0.43851897581057114\n",
      "Epoch:  1317  Loss:  0.42200272968321134  Validation Loss:  0.4384772900830616\n",
      "Epoch:  1318  Loss:  0.4220157408353054  Validation Loss:  0.4384362879124555\n",
      "Epoch:  1319  Loss:  0.42202928285255575  Validation Loss:  0.4383959026499228\n",
      "Epoch:  1320  Loss:  0.42204331466645906  Validation Loss:  0.43835610015825793\n",
      "Epoch:  1321  Loss:  0.4220577268889456  Validation Loss:  0.4383168429136276\n",
      "Epoch:  1322  Loss:  0.42207251229521  Validation Loss:  0.4382781111381271\n",
      "Epoch:  1323  Loss:  0.422087653974692  Validation Loss:  0.43823989629745486\n",
      "Epoch:  1324  Loss:  0.4221031655190569  Validation Loss:  0.43820217807184564\n",
      "Epoch:  1325  Loss:  0.4221190258183263  Validation Loss:  0.4381649942560629\n",
      "Epoch:  1326  Loss:  0.4221352378527323  Validation Loss:  0.4381283158605749\n",
      "Epoch:  1327  Loss:  0.42215182203235047  Validation Loss:  0.4380921199917793\n",
      "Epoch:  1328  Loss:  0.42216876164981815  Validation Loss:  0.43805642520839516\n",
      "Epoch:  1329  Loss:  0.42218601979089504  Validation Loss:  0.4380211641842669\n",
      "Epoch:  1330  Loss:  0.42220358218659054  Validation Loss:  0.4379863187670708\n",
      "Epoch:  1331  Loss:  0.42222148376432334  Validation Loss:  0.43795195817947385\n",
      "Epoch:  1332  Loss:  0.42223974073475057  Validation Loss:  0.43791808648542924\n",
      "Epoch:  1333  Loss:  0.4222583489887642  Validation Loss:  0.43788470192389056\n",
      "Epoch:  1334  Loss:  0.4222773262948701  Validation Loss:  0.4378517843105576\n",
      "Epoch:  1335  Loss:  0.42229663598718065  Validation Loss:  0.4378193474628709\n",
      "Epoch:  1336  Loss:  0.4223163046845884  Validation Loss:  0.43778737661513417\n",
      "Epoch:  1337  Loss:  0.4223363137154868  Validation Loss:  0.43775585822083735\n",
      "Epoch:  1338  Loss:  0.42235666265090305  Validation Loss:  0.43772478686137634\n",
      "Epoch:  1339  Loss:  0.42237731340256607  Validation Loss:  0.43769404048269445\n",
      "Epoch:  1340  Loss:  0.42239820110526954  Validation Loss:  0.437663513015617\n",
      "Epoch:  1341  Loss:  0.42241936685009435  Validation Loss:  0.4376333712176843\n",
      "Epoch:  1342  Loss:  0.4224408287667867  Validation Loss:  0.4376035889441317\n",
      "Epoch:  1343  Loss:  0.42246261498693266  Validation Loss:  0.4375742553309961\n",
      "Epoch:  1344  Loss:  0.42248473305142287  Validation Loss:  0.43754535574804654\n",
      "Epoch:  1345  Loss:  0.4225071772255681  Validation Loss:  0.4375169031999328\n",
      "Epoch:  1346  Loss:  0.42252987652565493  Validation Loss:  0.43748873214830053\n",
      "Epoch:  1347  Loss:  0.4225528295292999  Validation Loss:  0.4374609343030236\n",
      "Epoch:  1348  Loss:  0.4225761175832965  Validation Loss:  0.43743355707688764\n",
      "Epoch:  1349  Loss:  0.4225998083976182  Validation Loss:  0.4374067013913935\n",
      "Epoch:  1350  Loss:  0.4226239188150926  Validation Loss:  0.4373803196982904\n",
      "Epoch:  1351  Loss:  0.42264840237118984  Validation Loss:  0.4373542838475921\n",
      "Epoch:  1352  Loss:  0.4226732550471118  Validation Loss:  0.43732861442999404\n",
      "Epoch:  1353  Loss:  0.4226984228600155  Validation Loss:  0.43730337809432634\n",
      "Epoch:  1354  Loss:  0.4227239111607725  Validation Loss:  0.437278586761518\n",
      "Epoch:  1355  Loss:  0.42274967285268233  Validation Loss:  0.43725410090251404\n",
      "Epoch:  1356  Loss:  0.4227757037137494  Validation Loss:  0.43722997375509953\n",
      "Epoch:  1357  Loss:  0.4228020284889322  Validation Loss:  0.4372062748128718\n",
      "Epoch:  1358  Loss:  0.4228286274906361  Validation Loss:  0.43718284937468443\n",
      "Epoch:  1359  Loss:  0.4228554627660549  Validation Loss:  0.43715976883064617\n",
      "Epoch:  1360  Loss:  0.42288259344570567  Validation Loss:  0.4371370609511029\n",
      "Epoch:  1361  Loss:  0.42290995014887867  Validation Loss:  0.43711463592269206\n",
      "Epoch:  1362  Loss:  0.4229375841716925  Validation Loss:  0.43709256892854514\n",
      "Epoch:  1363  Loss:  0.4229654449405092  Validation Loss:  0.437070765143091\n",
      "Epoch:  1364  Loss:  0.42299355643265174  Validation Loss:  0.43704930408434434\n",
      "Epoch:  1365  Loss:  0.4230218904262239  Validation Loss:  0.43702808726917614\n",
      "Epoch:  1366  Loss:  0.4230504557264574  Validation Loss:  0.4370071291923523\n",
      "Epoch:  1367  Loss:  0.42307923219420696  Validation Loss:  0.43698645423759114\n",
      "Epoch:  1368  Loss:  0.4231081942717234  Validation Loss:  0.4369659716432745\n",
      "Epoch:  1369  Loss:  0.4231373609692761  Validation Loss:  0.43694568520242516\n",
      "Epoch:  1370  Loss:  0.4231666977206866  Validation Loss:  0.43692558177492835\n",
      "Epoch:  1371  Loss:  0.4231962035099665  Validation Loss:  0.4369056681340391\n",
      "Epoch:  1372  Loss:  0.4232258460964217  Validation Loss:  0.4368858582594178\n",
      "Epoch:  1373  Loss:  0.4232555837793784  Validation Loss:  0.43686609119176867\n",
      "Epoch:  1374  Loss:  0.42328538005099153  Validation Loss:  0.4368462650613351\n",
      "Epoch:  1375  Loss:  0.4233152129659147  Validation Loss:  0.4368264080448584\n",
      "Epoch:  1376  Loss:  0.4233450399203734  Validation Loss:  0.43680630082433874\n",
      "Epoch:  1377  Loss:  0.42337478428627506  Validation Loss:  0.4367858413945545\n",
      "Epoch:  1378  Loss:  0.42340434541304905  Validation Loss:  0.43676498098806904\n",
      "Epoch:  1379  Loss:  0.42343371393102586  Validation Loss:  0.43674360012466257\n",
      "Epoch:  1380  Loss:  0.4234628050616293  Validation Loss:  0.43672154369679367\n",
      "Epoch:  1381  Loss:  0.42349151129072365  Validation Loss:  0.4366986389864575\n",
      "Epoch:  1382  Loss:  0.423519725713766  Validation Loss:  0.43667466884309597\n",
      "Epoch:  1383  Loss:  0.4235473206323205  Validation Loss:  0.43664941611615093\n",
      "Epoch:  1384  Loss:  0.4235741990985292  Validation Loss:  0.4366227339614521\n",
      "Epoch:  1385  Loss:  0.4236002865388538  Validation Loss:  0.43659450316971\n",
      "Epoch:  1386  Loss:  0.4236255749156981  Validation Loss:  0.4365647863258015\n",
      "Epoch:  1387  Loss:  0.4236501565711065  Validation Loss:  0.4365338165651668\n",
      "Epoch:  1388  Loss:  0.4236742015137817  Validation Loss:  0.4365019963546233\n",
      "Epoch:  1389  Loss:  0.4236978986498081  Validation Loss:  0.4364696311679753\n",
      "Epoch:  1390  Loss:  0.42372142792199596  Validation Loss:  0.4364371213045987\n",
      "Epoch:  1391  Loss:  0.4237449289497101  Validation Loss:  0.43640461916273293\n",
      "Epoch:  1392  Loss:  0.42376844801686026  Validation Loss:  0.4363722243092277\n",
      "Epoch:  1393  Loss:  0.42379202079592326  Validation Loss:  0.4363401482051069\n",
      "Epoch:  1394  Loss:  0.42381574486692747  Validation Loss:  0.436308520490473\n",
      "Epoch:  1395  Loss:  0.42383959620739475  Validation Loss:  0.43627739508043634\n",
      "Epoch:  1396  Loss:  0.42386359213428065  Validation Loss:  0.4362468284639445\n",
      "Epoch:  1397  Loss:  0.42388768936648513  Validation Loss:  0.43621680953285913\n",
      "Epoch:  1398  Loss:  0.42391184344887733  Validation Loss:  0.43618738597089596\n",
      "Epoch:  1399  Loss:  0.423936000172839  Validation Loss:  0.4361585122617808\n",
      "Epoch:  1400  Loss:  0.4239601019205469  Validation Loss:  0.4361299590630965\n",
      "Epoch:  1401  Loss:  0.42398402178377814  Validation Loss:  0.43610190803354437\n",
      "Epoch:  1402  Loss:  0.4240077377494538  Validation Loss:  0.43607434142719614\n",
      "Epoch:  1403  Loss:  0.4240311667323112  Validation Loss:  0.4360473856329918\n",
      "Epoch:  1404  Loss:  0.42405419952490114  Validation Loss:  0.4360209028829228\n",
      "Epoch:  1405  Loss:  0.424076683164546  Validation Loss:  0.4359949210828001\n",
      "Epoch:  1406  Loss:  0.4240984079738458  Validation Loss:  0.4359692791646177\n",
      "Epoch:  1407  Loss:  0.4241191719066013  Validation Loss:  0.4359441875056787\n",
      "Epoch:  1408  Loss:  0.42413884979305844  Validation Loss:  0.4359197460792281\n",
      "Epoch:  1409  Loss:  0.42415720987500566  Validation Loss:  0.43589582510969854\n",
      "Epoch:  1410  Loss:  0.4241739576964667  Validation Loss:  0.4358723224564032\n",
      "Epoch:  1411  Loss:  0.4241890232897166  Validation Loss:  0.43584954427047207\n",
      "Epoch:  1412  Loss:  0.4242024467524254  Validation Loss:  0.43582720485600557\n",
      "Epoch:  1413  Loss:  0.42421434582634404  Validation Loss:  0.43580545512112706\n",
      "Epoch:  1414  Loss:  0.42422517359708295  Validation Loss:  0.43578424941409716\n",
      "Epoch:  1415  Loss:  0.42423533494725374  Validation Loss:  0.4357635905796831\n",
      "Epoch:  1416  Loss:  0.4242452794855291  Validation Loss:  0.43574328097430143\n",
      "Epoch:  1417  Loss:  0.4242552303229318  Validation Loss:  0.4357233472845771\n",
      "Epoch:  1418  Loss:  0.42426538489984744  Validation Loss:  0.4357035944407636\n",
      "Epoch:  1419  Loss:  0.42427586495424763  Validation Loss:  0.43568407825448296\n",
      "Epoch:  1420  Loss:  0.42428673740589257  Validation Loss:  0.43566476770422674\n",
      "Epoch:  1421  Loss:  0.4242980151916995  Validation Loss:  0.4356455385684967\n",
      "Epoch:  1422  Loss:  0.4243096760728142  Validation Loss:  0.435626206072894\n",
      "Epoch:  1423  Loss:  0.424321642495466  Validation Loss:  0.4356067037040537\n",
      "Epoch:  1424  Loss:  0.42433390260645837  Validation Loss:  0.43558695302768186\n",
      "Epoch:  1425  Loss:  0.4243464427689711  Validation Loss:  0.4355669066309929\n",
      "Epoch:  1426  Loss:  0.42435922916188384  Validation Loss:  0.43554645573551004\n",
      "Epoch:  1427  Loss:  0.42437216578559445  Validation Loss:  0.435525392266837\n",
      "Epoch:  1428  Loss:  0.4243851851333271  Validation Loss:  0.4355035662651062\n",
      "Epoch:  1429  Loss:  0.4243982111640049  Validation Loss:  0.43548087680881675\n",
      "Epoch:  1430  Loss:  0.424411233062997  Validation Loss:  0.43545737943866036\n",
      "Epoch:  1431  Loss:  0.4244242563617952  Validation Loss:  0.43543315123428\n",
      "Epoch:  1432  Loss:  0.42443731937444573  Validation Loss:  0.4354084613648328\n",
      "Epoch:  1433  Loss:  0.4244505034928972  Validation Loss:  0.43538352061401714\n",
      "Epoch:  1434  Loss:  0.42446388934146273  Validation Loss:  0.43535864041610195\n",
      "Epoch:  1435  Loss:  0.42447756066015274  Validation Loss:  0.43533404036001727\n",
      "Epoch:  1436  Loss:  0.42449159353519933  Validation Loss:  0.43530975512482906\n",
      "Epoch:  1437  Loss:  0.42450593585769336  Validation Loss:  0.43528583252971825\n",
      "Epoch:  1438  Loss:  0.42452061571406596  Validation Loss:  0.435262412510135\n",
      "Epoch:  1439  Loss:  0.4245356442124555  Validation Loss:  0.4352393544533036\n",
      "Epoch:  1440  Loss:  0.4245509697180806  Validation Loss:  0.43521665172143414\n",
      "Epoch:  1441  Loss:  0.4245665966335571  Validation Loss:  0.4351944861086932\n",
      "Epoch:  1442  Loss:  0.4245825611957998  Validation Loss:  0.4351728515191512\n",
      "Epoch:  1443  Loss:  0.42459881621779816  Validation Loss:  0.43515158864584835\n",
      "Epoch:  1444  Loss:  0.4246152895869631  Validation Loss:  0.4351307653568008\n",
      "Epoch:  1445  Loss:  0.42463203700202884  Validation Loss:  0.43511049381711264\n",
      "Epoch:  1446  Loss:  0.42464887244683325  Validation Loss:  0.4350904951041395\n",
      "Epoch:  1447  Loss:  0.42466567346092426  Validation Loss:  0.4350708611986854\n",
      "Epoch:  1448  Loss:  0.42468250490950815  Validation Loss:  0.4350516840815544\n",
      "Epoch:  1449  Loss:  0.4246994598119548  Validation Loss:  0.4350331882184202\n",
      "Epoch:  1450  Loss:  0.4247164939389084  Validation Loss:  0.4350150647488507\n",
      "Epoch:  1451  Loss:  0.42473346945462803  Validation Loss:  0.4349973097443581\n",
      "Epoch:  1452  Loss:  0.42475033899148307  Validation Loss:  0.43497992862354623\n",
      "Epoch:  1453  Loss:  0.4247669921002605  Validation Loss:  0.4349628990346735\n",
      "Epoch:  1454  Loss:  0.4247833980755372  Validation Loss:  0.43494652008468454\n",
      "Epoch:  1455  Loss:  0.4247995275891188  Validation Loss:  0.4349305114962838\n",
      "Epoch:  1456  Loss:  0.4248153022970214  Validation Loss:  0.43491488735784184\n",
      "Epoch:  1457  Loss:  0.4248307334654259  Validation Loss:  0.4348996384577318\n",
      "Epoch:  1458  Loss:  0.42484591339122163  Validation Loss:  0.43488476222211664\n",
      "Epoch:  1459  Loss:  0.42486098634474206  Validation Loss:  0.43487026515332133\n",
      "Epoch:  1460  Loss:  0.42487607406395855  Validation Loss:  0.4348560243844986\n",
      "Epoch:  1461  Loss:  0.42489111317378103  Validation Loss:  0.434842080690644\n",
      "Epoch:  1462  Loss:  0.42490612898360597  Validation Loss:  0.43482852347872475\n",
      "Epoch:  1463  Loss:  0.4249213589637568  Validation Loss:  0.4348153184760701\n",
      "Epoch:  1464  Loss:  0.4249369051871878  Validation Loss:  0.4348024679855867\n",
      "Epoch:  1465  Loss:  0.4249528180469166  Validation Loss:  0.4347900142723864\n",
      "Epoch:  1466  Loss:  0.4249690876765685  Validation Loss:  0.43477794148705223\n",
      "Epoch:  1467  Loss:  0.42498571933670476  Validation Loss:  0.4347662115638906\n",
      "Epoch:  1468  Loss:  0.42500268439903405  Validation Loss:  0.43475481231104246\n",
      "Epoch:  1469  Loss:  0.4250198682826577  Validation Loss:  0.43474367301572453\n",
      "Epoch:  1470  Loss:  0.4250371293813893  Validation Loss:  0.4347328512506051\n",
      "Epoch:  1471  Loss:  0.42505475555857025  Validation Loss:  0.43472245037555696\n",
      "Epoch:  1472  Loss:  0.4250727698884227  Validation Loss:  0.43471249910918147\n",
      "Epoch:  1473  Loss:  0.42509118941697205  Validation Loss:  0.4347029060125351\n",
      "Epoch:  1474  Loss:  0.42510996307387494  Validation Loss:  0.4346935923803936\n",
      "Epoch:  1475  Loss:  0.4251286820480318  Validation Loss:  0.434684588692405\n",
      "Epoch:  1476  Loss:  0.4251476921366923  Validation Loss:  0.43467609882354735\n",
      "Epoch:  1477  Loss:  0.42516708644953644  Validation Loss:  0.434668002074415\n",
      "Epoch:  1478  Loss:  0.4251867590076996  Validation Loss:  0.43466016460548745\n",
      "Epoch:  1479  Loss:  0.425206455904426  Validation Loss:  0.43465259969234465\n",
      "Epoch:  1480  Loss:  0.4252264869935585  Validation Loss:  0.4346453459425406\n",
      "Epoch:  1481  Loss:  0.42524662952531467  Validation Loss:  0.4346383498473601\n",
      "Epoch:  1482  Loss:  0.42526691097653274  Validation Loss:  0.43463161465796557\n",
      "Epoch:  1483  Loss:  0.42528735760486486  Validation Loss:  0.4346251662481915\n",
      "Epoch:  1484  Loss:  0.42530788013880905  Validation Loss:  0.4346189256418835\n",
      "Epoch:  1485  Loss:  0.4253283960349632  Validation Loss:  0.43461287807334553\n",
      "Epoch:  1486  Loss:  0.4253490978118145  Validation Loss:  0.43460705266757443\n",
      "Epoch:  1487  Loss:  0.4253696878751119  Validation Loss:  0.43460137993097303\n",
      "Epoch:  1488  Loss:  0.42539014545353976  Validation Loss:  0.4345958024263382\n",
      "Epoch:  1489  Loss:  0.4254104464568875  Validation Loss:  0.4345902991565791\n",
      "Epoch:  1490  Loss:  0.42543033122113255  Validation Loss:  0.4345847628333352\n",
      "Epoch:  1491  Loss:  0.4254499627785249  Validation Loss:  0.4345792238007892\n",
      "Epoch:  1492  Loss:  0.42546914612705056  Validation Loss:  0.4345735574310476\n",
      "Epoch:  1493  Loss:  0.42548774735945644  Validation Loss:  0.4345677173950455\n",
      "Epoch:  1494  Loss:  0.42550563320065987  Validation Loss:  0.4345615480433811\n",
      "Epoch:  1495  Loss:  0.4255225336461356  Validation Loss:  0.43455490781502293\n",
      "Epoch:  1496  Loss:  0.42553819289261646  Validation Loss:  0.4345476879314943\n",
      "Epoch:  1497  Loss:  0.42555252760648726  Validation Loss:  0.43453984368931164\n",
      "Epoch:  1498  Loss:  0.42556540765094036  Validation Loss:  0.4345313395966183\n",
      "Epoch:  1499  Loss:  0.42557687079816153  Validation Loss:  0.4345222462307323\n",
      "Training session:  2\n",
      "2020_11_2_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_2_MV1_run\n",
      "Epoch:  0  Loss:  0.49007041628896836  Validation Loss:  0.5558722966483661\n",
      "Epoch:  1  Loss:  0.48993570472185427  Validation Loss:  0.5557070913325463\n",
      "Epoch:  2  Loss:  0.4897721499733671  Validation Loss:  0.5555075240720596\n",
      "Epoch:  3  Loss:  0.4895836192916131  Validation Loss:  0.5552753371053508\n",
      "Epoch:  4  Loss:  0.4893704285547578  Validation Loss:  0.5550114537722298\n",
      "Epoch:  5  Loss:  0.4891322575200944  Validation Loss:  0.5547128972996559\n",
      "Epoch:  6  Loss:  0.48886516478640085  Validation Loss:  0.5543728236641202\n",
      "Epoch:  7  Loss:  0.4885665068524124  Validation Loss:  0.5539922159431236\n",
      "Epoch:  8  Loss:  0.4882376291871776  Validation Loss:  0.5535738541345511\n",
      "Epoch:  9  Loss:  0.48788322195322553  Validation Loss:  0.553127265535295\n",
      "Epoch:  10  Loss:  0.48751147395584005  Validation Loss:  0.5526639316231012\n",
      "Epoch:  11  Loss:  0.4871300178078505  Validation Loss:  0.552191742695868\n",
      "Epoch:  12  Loss:  0.48674396033117756  Validation Loss:  0.5517165777938706\n",
      "Epoch:  13  Loss:  0.48635640899105187  Validation Loss:  0.5512403598321336\n",
      "Epoch:  14  Loss:  0.485968119558498  Validation Loss:  0.5507639081084302\n",
      "Epoch:  15  Loss:  0.485579688432654  Validation Loss:  0.5502876020701868\n",
      "Epoch:  16  Loss:  0.485191256513257  Validation Loss:  0.5498117623584611\n",
      "Epoch:  17  Loss:  0.48480341848008024  Validation Loss:  0.5493372186486211\n",
      "Epoch:  18  Loss:  0.48441626898635776  Validation Loss:  0.5488636110510144\n",
      "Epoch:  19  Loss:  0.4840304866080453  Validation Loss:  0.5483924173084753\n",
      "Epoch:  20  Loss:  0.4836466630270495  Validation Loss:  0.5479236442063536\n",
      "Epoch:  21  Loss:  0.48326492071504423  Validation Loss:  0.547457641123661\n",
      "Epoch:  22  Loss:  0.48288534361229846  Validation Loss:  0.5469937744949546\n",
      "Epoch:  23  Loss:  0.48250776538129386  Validation Loss:  0.5465330172862325\n",
      "Epoch:  24  Loss:  0.48213259170393974  Validation Loss:  0.546074414891856\n",
      "Epoch:  25  Loss:  0.4817591857098969  Validation Loss:  0.5456178677933556\n",
      "Epoch:  26  Loss:  0.4813875495153066  Validation Loss:  0.5451629534363747\n",
      "Epoch:  27  Loss:  0.48101708702963486  Validation Loss:  0.5447092019021511\n",
      "Epoch:  28  Loss:  0.48064764928535597  Validation Loss:  0.5442562578245997\n",
      "Epoch:  29  Loss:  0.480279138278679  Validation Loss:  0.5438038877078465\n",
      "Epoch:  30  Loss:  0.4799111460352085  Validation Loss:  0.5433517017268709\n",
      "Epoch:  31  Loss:  0.47954328697637694  Validation Loss:  0.542898807009416\n",
      "Epoch:  32  Loss:  0.4791752482659718  Validation Loss:  0.5424449334719351\n",
      "Epoch:  33  Loss:  0.478806781257398  Validation Loss:  0.5419899745445166\n",
      "Epoch:  34  Loss:  0.4784376591708533  Validation Loss:  0.5415328581418309\n",
      "Epoch:  35  Loss:  0.47806705217036977  Validation Loss:  0.5410731344350747\n",
      "Epoch:  36  Loss:  0.4776951567925645  Validation Loss:  0.5406110901385546\n",
      "Epoch:  37  Loss:  0.4773220619594557  Validation Loss:  0.5401470500177571\n",
      "Epoch:  38  Loss:  0.4769480802427382  Validation Loss:  0.5396813014522195\n",
      "Epoch:  39  Loss:  0.47657339429185236  Validation Loss:  0.5392142383913908\n",
      "Epoch:  40  Loss:  0.47619862938244667  Validation Loss:  0.5387477382485356\n",
      "Epoch:  41  Loss:  0.47582540167330284  Validation Loss:  0.538282321899065\n",
      "Epoch:  42  Loss:  0.47545283005611433  Validation Loss:  0.5378167748983417\n",
      "Epoch:  43  Loss:  0.47508030825641734  Validation Loss:  0.5373508009527411\n",
      "Epoch:  44  Loss:  0.4747078277655607  Validation Loss:  0.5368847445185695\n",
      "Epoch:  45  Loss:  0.4743356953799372  Validation Loss:  0.5364186935392874\n",
      "Epoch:  46  Loss:  0.4739639187264725  Validation Loss:  0.5359520820368614\n",
      "Epoch:  47  Loss:  0.4735917837838449  Validation Loss:  0.5354845840483904\n",
      "Epoch:  48  Loss:  0.4732194198571013  Validation Loss:  0.5350157685045686\n",
      "Epoch:  49  Loss:  0.472846488672248  Validation Loss:  0.5345457434388143\n",
      "Epoch:  50  Loss:  0.4724732301908837  Validation Loss:  0.5340742217376828\n",
      "Epoch:  51  Loss:  0.47209919645236087  Validation Loss:  0.5336001613842589\n",
      "Epoch:  52  Loss:  0.47172349325474905  Validation Loss:  0.5331223198611822\n",
      "Epoch:  53  Loss:  0.4713457529185086  Validation Loss:  0.5326403529782381\n",
      "Epoch:  54  Loss:  0.47096544671693497  Validation Loss:  0.5321528640176568\n",
      "Epoch:  55  Loss:  0.47058181098756  Validation Loss:  0.5316591763070652\n",
      "Epoch:  56  Loss:  0.4701946180688559  Validation Loss:  0.5311583739572338\n",
      "Epoch:  57  Loss:  0.4698034527562779  Validation Loss:  0.5306504789207663\n",
      "Epoch:  58  Loss:  0.46940828908300963  Validation Loss:  0.5301350359139698\n",
      "Epoch:  59  Loss:  0.4690090479582725  Validation Loss:  0.529612994353686\n",
      "Epoch:  60  Loss:  0.46860654934270846  Validation Loss:  0.5290858901238867\n",
      "Epoch:  61  Loss:  0.4682017976539375  Validation Loss:  0.5285550893417427\n",
      "Epoch:  62  Loss:  0.46779533731337836  Validation Loss:  0.5280218123059187\n",
      "Epoch:  63  Loss:  0.46738806746062445  Validation Loss:  0.5274876624877963\n",
      "Epoch:  64  Loss:  0.4669806683469101  Validation Loss:  0.5269530688279441\n",
      "Epoch:  65  Loss:  0.46657324904168146  Validation Loss:  0.5264184286019632\n",
      "Epoch:  66  Loss:  0.4661662174752478  Validation Loss:  0.5258846148582441\n",
      "Epoch:  67  Loss:  0.4657597940349015  Validation Loss:  0.5253511735105089\n",
      "Epoch:  68  Loss:  0.4653534553724633  Validation Loss:  0.5248176428888526\n",
      "Epoch:  69  Loss:  0.46494699000606876  Validation Loss:  0.5242840176714318\n",
      "Epoch:  70  Loss:  0.4645404140712947  Validation Loss:  0.5237502035285745\n",
      "Epoch:  71  Loss:  0.46413339775871243  Validation Loss:  0.5232155144746814\n",
      "Epoch:  72  Loss:  0.463725349783192  Validation Loss:  0.522679393578853\n",
      "Epoch:  73  Loss:  0.46331596727201924  Validation Loss:  0.5221415179382477\n",
      "Epoch:  74  Loss:  0.46290493112873043  Validation Loss:  0.5216014481016568\n",
      "Epoch:  75  Loss:  0.4624917390343  Validation Loss:  0.5210584602983934\n",
      "Epoch:  76  Loss:  0.4620759122117737  Validation Loss:  0.5205120436315026\n",
      "Epoch:  77  Loss:  0.46165719407902667  Validation Loss:  0.5199620496215565\n",
      "Epoch:  78  Loss:  0.4612358506085605  Validation Loss:  0.5194094469770789\n",
      "Epoch:  79  Loss:  0.46081277736898  Validation Loss:  0.518855067369129\n",
      "Epoch:  80  Loss:  0.46038871368712925  Validation Loss:  0.5182997729363186\n",
      "Epoch:  81  Loss:  0.4599643375217562  Validation Loss:  0.5177443384059838\n",
      "Epoch:  82  Loss:  0.4595403730340258  Validation Loss:  0.5171897145254272\n",
      "Epoch:  83  Loss:  0.45911744214902966  Validation Loss:  0.5166366016492248\n",
      "Epoch:  84  Loss:  0.4586961789155853  Validation Loss:  0.5160853538130011\n",
      "Epoch:  85  Loss:  0.45827647743845834  Validation Loss:  0.5155358710991484\n",
      "Epoch:  86  Loss:  0.4578585986643148  Validation Loss:  0.5149884525952595\n",
      "Epoch:  87  Loss:  0.457442466852933  Validation Loss:  0.5144428336726767\n",
      "Epoch:  88  Loss:  0.4570281309841653  Validation Loss:  0.5138992777626429\n",
      "Epoch:  89  Loss:  0.45661571842326215  Validation Loss:  0.513357969666166\n",
      "Epoch:  90  Loss:  0.4562053740377257  Validation Loss:  0.5128188762547714\n",
      "Epoch:  91  Loss:  0.45579715893113404  Validation Loss:  0.5122829249926976\n",
      "Epoch:  92  Loss:  0.4553920299520154  Validation Loss:  0.5117497075615185\n",
      "Epoch:  93  Loss:  0.4549887998128784  Validation Loss:  0.511218369805387\n",
      "Epoch:  94  Loss:  0.45458714553766705  Validation Loss:  0.5106884355523756\n",
      "Epoch:  95  Loss:  0.45418701986589377  Validation Loss:  0.5101603829701032\n",
      "Epoch:  96  Loss:  0.4537886301353133  Validation Loss:  0.5096339083143643\n",
      "Epoch:  97  Loss:  0.4533915967190054  Validation Loss:  0.509108501087342\n",
      "Epoch:  98  Loss:  0.45299575028158506  Validation Loss:  0.5085841893617596\n",
      "Epoch:  99  Loss:  0.45260107852298126  Validation Loss:  0.5080609501206449\n",
      "Epoch:  100  Loss:  0.4522074525349239  Validation Loss:  0.5075383601444108\n",
      "Epoch:  101  Loss:  0.45181463200312394  Validation Loss:  0.5070160225565944\n",
      "Epoch:  102  Loss:  0.45142256093801125  Validation Loss:  0.5064943815980639\n",
      "Epoch:  103  Loss:  0.4510314320847833  Validation Loss:  0.505973310608949\n",
      "Epoch:  104  Loss:  0.4506410775629021  Validation Loss:  0.5054523122629949\n",
      "Epoch:  105  Loss:  0.45025088616024106  Validation Loss:  0.5049303961651666\n",
      "Epoch:  106  Loss:  0.44986050359948854  Validation Loss:  0.5044074001322899\n",
      "Epoch:  107  Loss:  0.4494697810012913  Validation Loss:  0.5038832287703242\n",
      "Epoch:  108  Loss:  0.44907879053488287  Validation Loss:  0.5033582052482026\n",
      "Epoch:  109  Loss:  0.4486877902372349  Validation Loss:  0.5028324672686202\n",
      "Epoch:  110  Loss:  0.4482969336167595  Validation Loss:  0.5023065460845828\n",
      "Epoch:  111  Loss:  0.4479067281946628  Validation Loss:  0.5017810567681279\n",
      "Epoch:  112  Loss:  0.4475174909512672  Validation Loss:  0.501256679450827\n",
      "Epoch:  113  Loss:  0.44712979020275306  Validation Loss:  0.5007341548002192\n",
      "Epoch:  114  Loss:  0.4467438310825613  Validation Loss:  0.5002134277352265\n",
      "Epoch:  115  Loss:  0.4463595656689102  Validation Loss:  0.499694449827075\n",
      "Epoch:  116  Loss:  0.4459770336835342  Validation Loss:  0.4991773505296026\n",
      "Epoch:  117  Loss:  0.44559636906053895  Validation Loss:  0.4986623820981809\n",
      "Epoch:  118  Loss:  0.4452176480691814  Validation Loss:  0.49814947069223436\n",
      "Epoch:  119  Loss:  0.44484081379407964  Validation Loss:  0.49763859076691525\n",
      "Epoch:  120  Loss:  0.44446587293634754  Validation Loss:  0.4971299126212086\n",
      "Epoch:  121  Loss:  0.4440928931243321  Validation Loss:  0.49662341749561684\n",
      "Epoch:  122  Loss:  0.4437218703461822  Validation Loss:  0.49611897487193346\n",
      "Epoch:  123  Loss:  0.4433527205293701  Validation Loss:  0.4956166821398905\n",
      "Epoch:  124  Loss:  0.44298555538851836  Validation Loss:  0.4951164498925209\n",
      "Epoch:  125  Loss:  0.44262035724503046  Validation Loss:  0.49461855326912235\n",
      "Epoch:  126  Loss:  0.44225729508160133  Validation Loss:  0.4941228298204286\n",
      "Epoch:  127  Loss:  0.44189606827391675  Validation Loss:  0.4936289409441607\n",
      "Epoch:  128  Loss:  0.44153659671721374  Validation Loss:  0.49313706984477385\n",
      "Epoch:  129  Loss:  0.4411789665119888  Validation Loss:  0.49264718499034643\n",
      "Epoch:  130  Loss:  0.4408231280611817  Validation Loss:  0.49215921041156563\n",
      "Epoch:  131  Loss:  0.44046907488410997  Validation Loss:  0.4916731814986893\n",
      "Epoch:  132  Loss:  0.440116900752282  Validation Loss:  0.4911890854792936\n",
      "Epoch:  133  Loss:  0.4397664763165649  Validation Loss:  0.49070681831134216\n",
      "Epoch:  134  Loss:  0.4394177743316402  Validation Loss:  0.49022634739854504\n",
      "Epoch:  135  Loss:  0.43907078126302135  Validation Loss:  0.4897477730576481\n",
      "Epoch:  136  Loss:  0.4387256035349778  Validation Loss:  0.48927117764417616\n",
      "Epoch:  137  Loss:  0.43838223413779187  Validation Loss:  0.48879646097442936\n",
      "Epoch:  138  Loss:  0.4380407153942881  Validation Loss:  0.4883239202733551\n",
      "Epoch:  139  Loss:  0.43770122413451856  Validation Loss:  0.487853541970253\n",
      "Epoch:  140  Loss:  0.4373635468045635  Validation Loss:  0.4873850996206914\n",
      "Epoch:  141  Loss:  0.43702766964950507  Validation Loss:  0.48691851885191034\n",
      "Epoch:  142  Loss:  0.436693535092667  Validation Loss:  0.4864537465785231\n",
      "Epoch:  143  Loss:  0.43636109750475405  Validation Loss:  0.4859907101573689\n",
      "Epoch:  144  Loss:  0.436030341676001  Validation Loss:  0.48552940799189465\n",
      "Epoch:  145  Loss:  0.4357012803473416  Validation Loss:  0.4850698583094137\n",
      "Epoch:  146  Loss:  0.43537403391839485  Validation Loss:  0.4846123294638736\n",
      "Epoch:  147  Loss:  0.435048694529477  Validation Loss:  0.48415686442915884\n",
      "Epoch:  148  Loss:  0.4347252544654897  Validation Loss:  0.48370333295315504\n",
      "Epoch:  149  Loss:  0.43440362586248554  Validation Loss:  0.4832516558734434\n",
      "Epoch:  150  Loss:  0.43408372588235244  Validation Loss:  0.4828017693279045\n",
      "Epoch:  151  Loss:  0.43376552697116805  Validation Loss:  0.4823537551398788\n",
      "Epoch:  152  Loss:  0.4334490732592944  Validation Loss:  0.48190758896193336\n",
      "Epoch:  153  Loss:  0.43313432709705196  Validation Loss:  0.4814632036057966\n",
      "Epoch:  154  Loss:  0.43282127666931886  Validation Loss:  0.4810205733935748\n",
      "Epoch:  155  Loss:  0.43250992100619706  Validation Loss:  0.4805796804970929\n",
      "Epoch:  156  Loss:  0.43220026610342005  Validation Loss:  0.4801405741434012\n",
      "Epoch:  157  Loss:  0.43189234925797704  Validation Loss:  0.4797033465334347\n",
      "Epoch:  158  Loss:  0.4315862419778073  Validation Loss:  0.47926798316517044\n",
      "Epoch:  159  Loss:  0.43128192072083965  Validation Loss:  0.47883452674640076\n",
      "Epoch:  160  Loss:  0.43097940276889407  Validation Loss:  0.4784028728359512\n",
      "Epoch:  161  Loss:  0.43067860515159967  Validation Loss:  0.47797299615506617\n",
      "Epoch:  162  Loss:  0.43037952363667403  Validation Loss:  0.47754489963075947\n",
      "Epoch:  163  Loss:  0.43008215469721506  Validation Loss:  0.47711854946932625\n",
      "Epoch:  164  Loss:  0.42978648660627344  Validation Loss:  0.4766939672242318\n",
      "Epoch:  165  Loss:  0.42949252751981015  Validation Loss:  0.47627111218337503\n",
      "Epoch:  166  Loss:  0.42920029471964527  Validation Loss:  0.4758501784609897\n",
      "Epoch:  167  Loss:  0.4289098340995918  Validation Loss:  0.4754311838852508\n",
      "Epoch:  168  Loss:  0.4286211766082154  Validation Loss:  0.4750140591391495\n",
      "Epoch:  169  Loss:  0.4283342697828479  Validation Loss:  0.4745987600513867\n",
      "Epoch:  170  Loss:  0.4280490825867512  Validation Loss:  0.4741852198328291\n",
      "Epoch:  171  Loss:  0.4277656198253293  Validation Loss:  0.47377344353922773\n",
      "Epoch:  172  Loss:  0.42748386717054265  Validation Loss:  0.47336344607174397\n",
      "Epoch:  173  Loss:  0.42720386509359237  Validation Loss:  0.47295522689819336\n",
      "Epoch:  174  Loss:  0.42692561288909797  Validation Loss:  0.4725488756916353\n",
      "Epoch:  175  Loss:  0.4266491548196804  Validation Loss:  0.4721444209239313\n",
      "Epoch:  176  Loss:  0.426374567066424  Validation Loss:  0.4717419386974403\n",
      "Epoch:  177  Loss:  0.42610179593224495  Validation Loss:  0.47134132789713995\n",
      "Epoch:  178  Loss:  0.4258307993588363  Validation Loss:  0.47094256883221014\n",
      "Epoch:  179  Loss:  0.4255615946721043  Validation Loss:  0.47054563941700117\n",
      "Epoch:  180  Loss:  0.42529415943213467  Validation Loss:  0.47015054390898775\n",
      "Epoch:  181  Loss:  0.4250284631753109  Validation Loss:  0.4697572280253683\n",
      "Epoch:  182  Loss:  0.42476453041360224  Validation Loss:  0.4693657018776451\n",
      "Epoch:  183  Loss:  0.42450233570922763  Validation Loss:  0.4689759561525924\n",
      "Epoch:  184  Loss:  0.4242418847493166  Validation Loss:  0.468588099149721\n",
      "Epoch:  185  Loss:  0.42398317828333587  Validation Loss:  0.468202088826469\n",
      "Epoch:  186  Loss:  0.42372622583392106  Validation Loss:  0.46781789351786884\n",
      "Epoch:  187  Loss:  0.4234710309279741  Validation Loss:  0.4674355512751\n",
      "Epoch:  188  Loss:  0.42321761164086813  Validation Loss:  0.467055045068264\n",
      "Epoch:  189  Loss:  0.42296597070595215  Validation Loss:  0.46667639299162794\n",
      "Epoch:  190  Loss:  0.4227161133254068  Validation Loss:  0.4662996008992195\n",
      "Epoch:  191  Loss:  0.4224680525487697  Validation Loss:  0.4659246435122831\n",
      "Epoch:  192  Loss:  0.42222176553934987  Validation Loss:  0.4655515125819615\n",
      "Epoch:  193  Loss:  0.421977241980959  Validation Loss:  0.46518018575651304\n",
      "Epoch:  194  Loss:  0.42173448725212254  Validation Loss:  0.4648106563836336\n",
      "Epoch:  195  Loss:  0.4214935274519159  Validation Loss:  0.46444299737257616\n",
      "Epoch:  196  Loss:  0.4212543656663782  Validation Loss:  0.4640772193670273\n",
      "Epoch:  197  Loss:  0.4210170482742716  Validation Loss:  0.46371331810951233\n",
      "Epoch:  198  Loss:  0.4207815363033283  Validation Loss:  0.46335126512816976\n",
      "Epoch:  199  Loss:  0.4205477993340182  Validation Loss:  0.4629910258310182\n",
      "Epoch:  200  Loss:  0.4203158580868907  Validation Loss:  0.46263261378875803\n",
      "Epoch:  201  Loss:  0.420085692105914  Validation Loss:  0.4622760119714907\n",
      "Epoch:  202  Loss:  0.41985729759966833  Validation Loss:  0.4619213842919895\n",
      "Epoch:  203  Loss:  0.4196307168909784  Validation Loss:  0.461568736870374\n",
      "Epoch:  204  Loss:  0.4194059913327708  Validation Loss:  0.46121809099401745\n",
      "Epoch:  205  Loss:  0.41918313600255186  Validation Loss:  0.4608694040881736\n",
      "Epoch:  206  Loss:  0.4189621315023603  Validation Loss:  0.46052260643669535\n",
      "Epoch:  207  Loss:  0.4187429513804306  Validation Loss:  0.4601776490786246\n",
      "Epoch:  208  Loss:  0.4185255622193658  Validation Loss:  0.4598345288208553\n",
      "Epoch:  209  Loss:  0.4183099659589621  Validation Loss:  0.4594932334231479\n",
      "Epoch:  210  Loss:  0.4180961619820115  Validation Loss:  0.45915377885103226\n",
      "Epoch:  211  Loss:  0.4178841559315574  Validation Loss:  0.45881614461541176\n",
      "Epoch:  212  Loss:  0.41767395865282364  Validation Loss:  0.45848037036401884\n",
      "Epoch:  213  Loss:  0.41746557305550436  Validation Loss:  0.4581464539681162\n",
      "Epoch:  214  Loss:  0.4172590039009173  Validation Loss:  0.4578144034104688\n",
      "Epoch:  215  Loss:  0.41705424739764285  Validation Loss:  0.4574842186910765\n",
      "Epoch:  216  Loss:  0.4168513156253205  Validation Loss:  0.45715594477951527\n",
      "Epoch:  217  Loss:  0.4166502094656758  Validation Loss:  0.45682957901486326\n",
      "Epoch:  218  Loss:  0.4164509436435248  Validation Loss:  0.45650514321667807\n",
      "Epoch:  219  Loss:  0.41625348121456845  Validation Loss:  0.4561826730413096\n",
      "Epoch:  220  Loss:  0.41605780207546506  Validation Loss:  0.45586206843810423\n",
      "Epoch:  221  Loss:  0.4158639295919407  Validation Loss:  0.4555433525570801\n",
      "Epoch:  222  Loss:  0.41567187848881154  Validation Loss:  0.4552265357758318\n",
      "Epoch:  223  Loss:  0.41548166481348187  Validation Loss:  0.45491158350237776\n",
      "Epoch:  224  Loss:  0.4152932762217945  Validation Loss:  0.4545984928097044\n",
      "Epoch:  225  Loss:  0.4151067280557734  Validation Loss:  0.45428731478750706\n",
      "Epoch:  226  Loss:  0.4149220337176464  Validation Loss:  0.4539780340024403\n",
      "Epoch:  227  Loss:  0.4147392039644648  Validation Loss:  0.4536706515188728\n",
      "Epoch:  228  Loss:  0.4145582138433964  Validation Loss:  0.4533651684011732\n",
      "Epoch:  229  Loss:  0.4143790679394141  Validation Loss:  0.45306156761944294\n",
      "Epoch:  230  Loss:  0.4142017614030274  Validation Loss:  0.4527598877570459\n",
      "Epoch:  231  Loss:  0.41402630490311504  Validation Loss:  0.4524601250886917\n",
      "Epoch:  232  Loss:  0.41385270469992824  Validation Loss:  0.4521622889276062\n",
      "Epoch:  233  Loss:  0.4136809541805256  Validation Loss:  0.45186641599450794\n",
      "Epoch:  234  Loss:  0.41351099338757213  Validation Loss:  0.45157246717384886\n",
      "Epoch:  235  Loss:  0.4133428506244569  Validation Loss:  0.4512804142598595\n",
      "Epoch:  236  Loss:  0.41317654899238837  Validation Loss:  0.4509902678962265\n",
      "Epoch:  237  Loss:  0.41301212622921846  Validation Loss:  0.45070210764450686\n",
      "Epoch:  238  Loss:  0.41284974712944594  Validation Loss:  0.4504164531826973\n",
      "Epoch:  239  Loss:  0.41268968194194094  Validation Loss:  0.4501332566142082\n",
      "Epoch:  240  Loss:  0.4125319192924443  Validation Loss:  0.44985232076474596\n",
      "Epoch:  241  Loss:  0.4123761255360214  Validation Loss:  0.4495734524513994\n",
      "Epoch:  242  Loss:  0.41222225270680424  Validation Loss:  0.4492965319326946\n",
      "Epoch:  243  Loss:  0.41207022859147313  Validation Loss:  0.4490215283419405\n",
      "Epoch:  244  Loss:  0.4119200122779643  Validation Loss:  0.44874846270041807\n",
      "Epoch:  245  Loss:  0.4117716244868273  Validation Loss:  0.44847729802131653\n",
      "Epoch:  246  Loss:  0.4116249852455579  Validation Loss:  0.4482080505362579\n",
      "Epoch:  247  Loss:  0.4114801516899696  Validation Loss:  0.4479407694722925\n",
      "Epoch:  248  Loss:  0.41133716005898086  Validation Loss:  0.44767539761960506\n",
      "Epoch:  249  Loss:  0.4111960297505531  Validation Loss:  0.44741195333855494\n",
      "Epoch:  250  Loss:  0.4110567770766083  Validation Loss:  0.4471504408866167\n",
      "Epoch:  251  Loss:  0.4109194424201751  Validation Loss:  0.44689091188567026\n",
      "Epoch:  252  Loss:  0.41078401908013945  Validation Loss:  0.44663333653339315\n",
      "Epoch:  253  Loss:  0.4106504787531125  Validation Loss:  0.44637766161135267\n",
      "Epoch:  254  Loss:  0.41051878043885764  Validation Loss:  0.4461238839264427\n",
      "Epoch:  255  Loss:  0.4103888728209501  Validation Loss:  0.4458720324827092\n",
      "Epoch:  256  Loss:  0.4102607335917343  Validation Loss:  0.44562205698873314\n",
      "Epoch:  257  Loss:  0.4101344147730156  Validation Loss:  0.4453739888433899\n",
      "Epoch:  258  Loss:  0.4100099531327479  Validation Loss:  0.4451277961156198\n",
      "Epoch:  259  Loss:  0.4098873574881864  Validation Loss:  0.4448835208479847\n",
      "Epoch:  260  Loss:  0.4097666170822798  Validation Loss:  0.44464114787323133\n",
      "Epoch:  261  Loss:  0.40964775290009536  Validation Loss:  0.44440067027296337\n",
      "Epoch:  262  Loss:  0.4095307404296638  Validation Loss:  0.44416210560926367\n",
      "Epoch:  263  Loss:  0.40941550163827706  Validation Loss:  0.44392547516950537\n",
      "Epoch:  264  Loss:  0.4093020486055747  Validation Loss:  0.4436907906617437\n",
      "Epoch:  265  Loss:  0.40919045601370774  Validation Loss:  0.4434580701802458\n",
      "Epoch:  266  Loss:  0.40908073320896665  Validation Loss:  0.44322726636060644\n",
      "Epoch:  267  Loss:  0.40897288636343015  Validation Loss:  0.44299839516835554\n",
      "Epoch:  268  Loss:  0.4088669116856784  Validation Loss:  0.4427714464919908\n",
      "Epoch:  269  Loss:  0.40876276297329445  Validation Loss:  0.44254641075219425\n",
      "Epoch:  270  Loss:  0.40866034367733456  Validation Loss:  0.4423232807644776\n",
      "Epoch:  271  Loss:  0.4085597789146491  Validation Loss:  0.4421020700995411\n",
      "Epoch:  272  Loss:  0.40846107944228943  Validation Loss:  0.4418827484228781\n",
      "Epoch:  273  Loss:  0.4083642350322396  Validation Loss:  0.44166535458394457\n",
      "Epoch:  274  Loss:  0.40826923730810716  Validation Loss:  0.4414498955011368\n",
      "Epoch:  275  Loss:  0.40817599404140337  Validation Loss:  0.4412364310451916\n",
      "Epoch:  276  Loss:  0.4080846286737002  Validation Loss:  0.4410250075161457\n",
      "Epoch:  277  Loss:  0.40799517109549255  Validation Loss:  0.44081547457192627\n",
      "Epoch:  278  Loss:  0.40790753551488795  Validation Loss:  0.44060780773205416\n",
      "Epoch:  279  Loss:  0.40782161356782065  Validation Loss:  0.4404019843786955\n",
      "Epoch:  280  Loss:  0.40773741654037726  Validation Loss:  0.44019806305212633\n",
      "Epoch:  281  Loss:  0.40765505191489787  Validation Loss:  0.43999604721154484\n",
      "Epoch:  282  Loss:  0.40757448953637004  Validation Loss:  0.4397959054580757\n",
      "Epoch:  283  Loss:  0.40749559344271935  Validation Loss:  0.43959760825548855\n",
      "Epoch:  284  Loss:  0.4074184782582627  Validation Loss:  0.43940120270209654\n",
      "Epoch:  285  Loss:  0.4073432184888061  Validation Loss:  0.43920670582779814\n",
      "Epoch:  286  Loss:  0.40726966820877686  Validation Loss:  0.4390140753239393\n",
      "Epoch:  287  Loss:  0.40719788561205894  Validation Loss:  0.43882334950779167\n",
      "Epoch:  288  Loss:  0.40712790914188474  Validation Loss:  0.4386344961822033\n",
      "Epoch:  289  Loss:  0.4070595810575598  Validation Loss:  0.4384475076305015\n",
      "Epoch:  290  Loss:  0.40699307541170066  Validation Loss:  0.43826241977512836\n",
      "Epoch:  291  Loss:  0.4069283046489637  Validation Loss:  0.4380791700844254\n",
      "Epoch:  292  Loss:  0.40686524593265805  Validation Loss:  0.43789780272969175\n",
      "Epoch:  293  Loss:  0.4068039551641814  Validation Loss:  0.4377182692821537\n",
      "Epoch:  294  Loss:  0.4067443061686126  Validation Loss:  0.437540597149304\n",
      "Epoch:  295  Loss:  0.40668634603009424  Validation Loss:  0.4373647464173181\n",
      "Epoch:  296  Loss:  0.40663005041300193  Validation Loss:  0.43719073278563364\n",
      "Epoch:  297  Loss:  0.4065753814913112  Validation Loss:  0.4370185613100018\n",
      "Epoch:  298  Loss:  0.40652242549777734  Validation Loss:  0.43684819447142736\n",
      "Epoch:  299  Loss:  0.4064710558166165  Validation Loss:  0.4366796091198921\n",
      "Epoch:  300  Loss:  0.40642123585621986  Validation Loss:  0.43651282228529453\n",
      "Epoch:  301  Loss:  0.40637299048124687  Validation Loss:  0.4363478153411831\n",
      "Epoch:  302  Loss:  0.40632626793440985  Validation Loss:  0.4361845379961388\n",
      "Epoch:  303  Loss:  0.40628104890592  Validation Loss:  0.4360230333570923\n",
      "Epoch:  304  Loss:  0.4062373134687807  Validation Loss:  0.435863251930901\n",
      "Epoch:  305  Loss:  0.4061949943473353  Validation Loss:  0.43570516178650515\n",
      "Epoch:  306  Loss:  0.4061540747006264  Validation Loss:  0.4355487740997757\n",
      "Epoch:  307  Loss:  0.406114411424603  Validation Loss:  0.4353939936097179\n",
      "Epoch:  308  Loss:  0.40607607708527493  Validation Loss:  0.4352408799209765\n",
      "Epoch:  309  Loss:  0.40603888942997834  Validation Loss:  0.43508933165243696\n",
      "Epoch:  310  Loss:  0.4060027936153863  Validation Loss:  0.43493930489889215\n",
      "Epoch:  311  Loss:  0.4059677161937635  Validation Loss:  0.43479075548904283\n",
      "Epoch:  312  Loss:  0.4059334422004293  Validation Loss:  0.43464362780962673\n",
      "Epoch:  313  Loss:  0.405899825974329  Validation Loss:  0.43449780478009153\n",
      "Epoch:  314  Loss:  0.4058667564180476  Validation Loss:  0.4343532377055713\n",
      "Epoch:  315  Loss:  0.40583399722914726  Validation Loss:  0.4342097658663988\n",
      "Epoch:  316  Loss:  0.4058012743673381  Validation Loss:  0.43406725116074085\n",
      "Epoch:  317  Loss:  0.40576831599664404  Validation Loss:  0.43392551796776907\n",
      "Epoch:  318  Loss:  0.4057347295728661  Validation Loss:  0.4337843760315861\n",
      "Epoch:  319  Loss:  0.4057000153339826  Validation Loss:  0.43364354462495874\n",
      "Epoch:  320  Loss:  0.4056635902830835  Validation Loss:  0.43350269964763094\n",
      "Epoch:  321  Loss:  0.40562475997315356  Validation Loss:  0.43336145553205696\n",
      "Epoch:  322  Loss:  0.40558272750067287  Validation Loss:  0.43321940675377846\n",
      "Epoch:  323  Loss:  0.40553665981137543  Validation Loss:  0.43307612650096416\n",
      "Epoch:  324  Loss:  0.40548585417002614  Validation Loss:  0.4329312632658652\n",
      "Epoch:  325  Loss:  0.40542991856146143  Validation Loss:  0.4327847060880491\n",
      "Epoch:  326  Loss:  0.40536902571570943  Validation Loss:  0.4326366015842983\n",
      "Epoch:  327  Loss:  0.405303933652195  Validation Loss:  0.43248741302107063\n",
      "Epoch:  328  Loss:  0.405235842840206  Validation Loss:  0.43233767790453775\n",
      "Epoch:  329  Loss:  0.40516602525696954  Validation Loss:  0.43218801516507355\n",
      "Epoch:  330  Loss:  0.40509567634593807  Validation Loss:  0.43203883964036194\n",
      "Epoch:  331  Loss:  0.40502556885135244  Validation Loss:  0.431890532374382\n",
      "Epoch:  332  Loss:  0.4049564280806208  Validation Loss:  0.43174332699605394\n",
      "Epoch:  333  Loss:  0.4048884503058428  Validation Loss:  0.43159729215715614\n",
      "Epoch:  334  Loss:  0.40482189025751936  Validation Loss:  0.4314525460026094\n",
      "Epoch:  335  Loss:  0.404756849686775  Validation Loss:  0.43130913536463467\n",
      "Epoch:  336  Loss:  0.4046934344888439  Validation Loss:  0.43116709031164646\n",
      "Epoch:  337  Loss:  0.4046315869107049  Validation Loss:  0.43102635709302767\n",
      "Epoch:  338  Loss:  0.40457129381464785  Validation Loss:  0.43088699345077786\n",
      "Epoch:  339  Loss:  0.4045126202720157  Validation Loss:  0.430749010560768\n",
      "Epoch:  340  Loss:  0.40445549600928493  Validation Loss:  0.4306123395051275\n",
      "Epoch:  341  Loss:  0.4043998735896229  Validation Loss:  0.4304769914597273\n",
      "Epoch:  342  Loss:  0.4043457492216099  Validation Loss:  0.43034294274236473\n",
      "Epoch:  343  Loss:  0.404293104212665  Validation Loss:  0.4302102021340813\n",
      "Epoch:  344  Loss:  0.40424190593894416  Validation Loss:  0.4300787592572825\n",
      "Epoch:  345  Loss:  0.4041921329745174  Validation Loss:  0.4299486005412681\n",
      "Epoch:  346  Loss:  0.4041437402632109  Validation Loss:  0.4298196866043976\n",
      "Epoch:  347  Loss:  0.40409670338122805  Validation Loss:  0.4296920456524406\n",
      "Epoch:  348  Loss:  0.404051012629588  Validation Loss:  0.4295656843377011\n",
      "Epoch:  349  Loss:  0.4040066594555533  Validation Loss:  0.4294405185750553\n",
      "Epoch:  350  Loss:  0.40396359897929535  Validation Loss:  0.42931661009788513\n",
      "Epoch:  351  Loss:  0.40392179716620924  Validation Loss:  0.42919392697513103\n",
      "Epoch:  352  Loss:  0.40388126530238155  Validation Loss:  0.42907242716423105\n",
      "Epoch:  353  Loss:  0.403841834008341  Validation Loss:  0.4289521739951202\n",
      "Epoch:  354  Loss:  0.4038035959534391  Validation Loss:  0.4288330820522138\n",
      "Epoch:  355  Loss:  0.4037664356316335  Validation Loss:  0.4287151989660093\n",
      "Epoch:  356  Loss:  0.403730530975133  Validation Loss:  0.4285984893462488\n",
      "Epoch:  357  Loss:  0.4036956548514451  Validation Loss:  0.4284828563353845\n",
      "Epoch:  358  Loss:  0.4036619155364629  Validation Loss:  0.4283684814082725\n",
      "Epoch:  359  Loss:  0.4036293579981877  Validation Loss:  0.4282551713820015\n",
      "Epoch:  360  Loss:  0.4035977528116407  Validation Loss:  0.42814295100314276\n",
      "Epoch:  361  Loss:  0.40356723690879415  Validation Loss:  0.42803192138671875\n",
      "Epoch:  362  Loss:  0.403537764528094  Validation Loss:  0.4279218981308596\n",
      "Epoch:  363  Loss:  0.4035090715927485  Validation Loss:  0.42781283360506805\n",
      "Epoch:  364  Loss:  0.40348125086028197  Validation Loss:  0.42770485925887314\n",
      "Epoch:  365  Loss:  0.4034543779827434  Validation Loss:  0.42759786626057966\n",
      "Epoch:  366  Loss:  0.40342817812629  Validation Loss:  0.4274917761129992\n",
      "Epoch:  367  Loss:  0.4034025800475002  Validation Loss:  0.42738655103104456\n",
      "Epoch:  368  Loss:  0.40337762836168506  Validation Loss:  0.4272823216659682\n",
      "Epoch:  369  Loss:  0.40335330993113433  Validation Loss:  0.42717888419117245\n",
      "Epoch:  370  Loss:  0.4033292299191627  Validation Loss:  0.42707611301115583\n",
      "Epoch:  371  Loss:  0.4033052140968086  Validation Loss:  0.4269739107361862\n",
      "Epoch:  372  Loss:  0.4032811179492601  Validation Loss:  0.4268722337271486\n",
      "Epoch:  373  Loss:  0.40325683037910237  Validation Loss:  0.42677101865410805\n",
      "Epoch:  374  Loss:  0.4032319863519725  Validation Loss:  0.4266699621719973\n",
      "Epoch:  375  Loss:  0.40320607737676634  Validation Loss:  0.4265688822737762\n",
      "Epoch:  376  Loss:  0.40317872880831274  Validation Loss:  0.42646765017083715\n",
      "Epoch:  377  Loss:  0.4031497456089279  Validation Loss:  0.4263661429286003\n",
      "Epoch:  378  Loss:  0.40311923869968164  Validation Loss:  0.4262645510690553\n",
      "Epoch:  379  Loss:  0.4030875609471248  Validation Loss:  0.4261629560164043\n",
      "Epoch:  380  Loss:  0.40305487670489315  Validation Loss:  0.42606148070522715\n",
      "Epoch:  381  Loss:  0.4030216790338945  Validation Loss:  0.4259603981460844\n",
      "Epoch:  382  Loss:  0.40298849176725693  Validation Loss:  0.42585994356444906\n",
      "Epoch:  383  Loss:  0.40295575118276494  Validation Loss:  0.425760314400707\n",
      "Epoch:  384  Loss:  0.40292378351885894  Validation Loss:  0.42566163944346563\n",
      "Epoch:  385  Loss:  0.40289290707844955  Validation Loss:  0.42556413635611534\n",
      "Epoch:  386  Loss:  0.4028633823232538  Validation Loss:  0.42546780354210306\n",
      "Epoch:  387  Loss:  0.40283505565668704  Validation Loss:  0.42537255957722664\n",
      "Epoch:  388  Loss:  0.40280789789363475  Validation Loss:  0.42527841457298826\n",
      "Epoch:  389  Loss:  0.4027818592166054  Validation Loss:  0.4251853461776461\n",
      "Epoch:  390  Loss:  0.4027568844295818  Validation Loss:  0.42509337993604795\n",
      "Epoch:  391  Loss:  0.4027330207048789  Validation Loss:  0.42500252329877447\n",
      "Epoch:  392  Loss:  0.4027103573612913  Validation Loss:  0.424912765622139\n",
      "Epoch:  393  Loss:  0.4026889503883892  Validation Loss:  0.4248241681073393\n",
      "Epoch:  394  Loss:  0.40266886864893536  Validation Loss:  0.42473682495100157\n",
      "Epoch:  395  Loss:  0.4026501647819429  Validation Loss:  0.42465060523578096\n",
      "Epoch:  396  Loss:  0.40263259675375807  Validation Loss:  0.424565459468535\n",
      "Epoch:  397  Loss:  0.40261617108914977  Validation Loss:  0.42448138764926363\n",
      "Epoch:  398  Loss:  0.402600844936258  Validation Loss:  0.4243983966963632\n",
      "Epoch:  399  Loss:  0.40258659669280755  Validation Loss:  0.4243164913994925\n",
      "Epoch:  400  Loss:  0.40257337574775404  Validation Loss:  0.4242356669689928\n",
      "Epoch:  401  Loss:  0.4025612722134449  Validation Loss:  0.4241559175508363\n",
      "Epoch:  402  Loss:  0.40255030002114334  Validation Loss:  0.42407724048410145\n",
      "Epoch:  403  Loss:  0.40254043254273886  Validation Loss:  0.42399965492742403\n",
      "Epoch:  404  Loss:  0.4025316921740594  Validation Loss:  0.42392314757619587\n",
      "Epoch:  405  Loss:  0.4025241425756872  Validation Loss:  0.423847854669605\n",
      "Epoch:  406  Loss:  0.4025178085241092  Validation Loss:  0.42377375066280365\n",
      "Epoch:  407  Loss:  0.40251262997381787  Validation Loss:  0.42370069133383886\n",
      "Epoch:  408  Loss:  0.40250855014169007  Validation Loss:  0.42362871606435093\n",
      "Epoch:  409  Loss:  0.4025055467200703  Validation Loss:  0.42355779664857046\n",
      "Epoch:  410  Loss:  0.40250359096470667  Validation Loss:  0.4234879378761564\n",
      "Epoch:  411  Loss:  0.4025025558189528  Validation Loss:  0.42341912697468487\n",
      "Epoch:  412  Loss:  0.4025025889718321  Validation Loss:  0.42335137884531704\n",
      "Epoch:  413  Loss:  0.4025036890125839  Validation Loss:  0.4232846844409193\n",
      "Epoch:  414  Loss:  0.40250581714528555  Validation Loss:  0.4232190432293074\n",
      "Epoch:  415  Loss:  0.40250886297790256  Validation Loss:  0.423154457871403\n",
      "Epoch:  416  Loss:  0.4025129709370743  Validation Loss:  0.423090928367206\n",
      "Epoch:  417  Loss:  0.4025181074290586  Validation Loss:  0.42302844141210827\n",
      "Epoch:  418  Loss:  0.40252412644011026  Validation Loss:  0.42296700339232174\n",
      "Epoch:  419  Loss:  0.4025311635796135  Validation Loss:  0.4229066079216344\n",
      "Epoch:  420  Loss:  0.40253912141689885  Validation Loss:  0.42284730821847916\n",
      "Epoch:  421  Loss:  0.4025482423383103  Validation Loss:  0.4227892022047724\n",
      "Epoch:  422  Loss:  0.40255850915020036  Validation Loss:  0.4227322483701365\n",
      "Epoch:  423  Loss:  0.4025698635705124  Validation Loss:  0.422676361565079\n",
      "Epoch:  424  Loss:  0.4025820864904562  Validation Loss:  0.4226214752665588\n",
      "Epoch:  425  Loss:  0.4025951478431916  Validation Loss:  0.42256761182631764\n",
      "Epoch:  426  Loss:  0.40260910696884583  Validation Loss:  0.42251476805124966\n",
      "Epoch:  427  Loss:  0.4026238705808594  Validation Loss:  0.4224629295723779\n",
      "Epoch:  428  Loss:  0.40263948937844946  Validation Loss:  0.4224121474793979\n",
      "Epoch:  429  Loss:  0.4026559542798432  Validation Loss:  0.42236238984125\n",
      "Epoch:  430  Loss:  0.40267320409328977  Validation Loss:  0.4223136582544872\n",
      "Epoch:  431  Loss:  0.4026911810657682  Validation Loss:  0.4222659708133766\n",
      "Epoch:  432  Loss:  0.402709870119772  Validation Loss:  0.42221928920064655\n",
      "Epoch:  433  Loss:  0.40272917576442807  Validation Loss:  0.4221736059657165\n",
      "Epoch:  434  Loss:  0.4027490679328964  Validation Loss:  0.42212895463619915\n",
      "Epoch:  435  Loss:  0.40276947996672796  Validation Loss:  0.4220852963626385\n",
      "Epoch:  436  Loss:  0.40279031179007696  Validation Loss:  0.42204262582319124\n",
      "Epoch:  437  Loss:  0.4028114102472215  Validation Loss:  0.42200091427990366\n",
      "Epoch:  438  Loss:  0.40283268302150027  Validation Loss:  0.4219601867454393\n",
      "Epoch:  439  Loss:  0.40285395138715147  Validation Loss:  0.4219204144818442\n",
      "Epoch:  440  Loss:  0.4028749976461456  Validation Loss:  0.42188154852816034\n",
      "Epoch:  441  Loss:  0.4028956298468381  Validation Loss:  0.4218435713223049\n",
      "Epoch:  442  Loss:  0.40291566370859655  Validation Loss:  0.4218065084091255\n",
      "Epoch:  443  Loss:  0.4029350658140239  Validation Loss:  0.42177037575415205\n",
      "Epoch:  444  Loss:  0.402953872754729  Validation Loss:  0.4217351781470435\n",
      "Epoch:  445  Loss:  0.40297229561580006  Validation Loss:  0.4217009948832648\n",
      "Epoch:  446  Loss:  0.4029905890395655  Validation Loss:  0.4216677333627428\n",
      "Epoch:  447  Loss:  0.40300902054154664  Validation Loss:  0.42163544467517305\n",
      "Epoch:  448  Loss:  0.4030279266763721  Validation Loss:  0.4216041346745832\n",
      "Epoch:  449  Loss:  0.4030475410131308  Validation Loss:  0.42157379750694546\n",
      "Epoch:  450  Loss:  0.4030679914020222  Validation Loss:  0.42154443689755033\n",
      "Epoch:  451  Loss:  0.4030894260611054  Validation Loss:  0.42151608424527304\n",
      "Epoch:  452  Loss:  0.4031119412748066  Validation Loss:  0.4214887592409338\n",
      "Epoch:  453  Loss:  0.4031355960305626  Validation Loss:  0.42146243367876324\n",
      "Epoch:  454  Loss:  0.40316035911529025  Validation Loss:  0.42143712831395014\n",
      "Epoch:  455  Loss:  0.4031862475462919  Validation Loss:  0.4214128186660154\n",
      "Epoch:  456  Loss:  0.4032132346072846  Validation Loss:  0.42138949994529995\n",
      "Epoch:  457  Loss:  0.4032413479844494  Validation Loss:  0.4213671769414629\n",
      "Epoch:  458  Loss:  0.4032705666927191  Validation Loss:  0.421345841139555\n",
      "Epoch:  459  Loss:  0.4033008555512457  Validation Loss:  0.42132546859128134\n",
      "Epoch:  460  Loss:  0.40333216271456884  Validation Loss:  0.4213060678115913\n",
      "Epoch:  461  Loss:  0.4033645502561648  Validation Loss:  0.42128764199359076\n",
      "Epoch:  462  Loss:  0.4033980037157352  Validation Loss:  0.42127021508557455\n",
      "Epoch:  463  Loss:  0.4034325036953187  Validation Loss:  0.4212537652679852\n",
      "Epoch:  464  Loss:  0.40346796158150106  Validation Loss:  0.4212381547050817\n",
      "Epoch:  465  Loss:  0.4035042989007115  Validation Loss:  0.42122345737048555\n",
      "Epoch:  466  Loss:  0.4035416715420209  Validation Loss:  0.4212097355297634\n",
      "Epoch:  467  Loss:  0.40358010974861463  Validation Loss:  0.4211969849254404\n",
      "Epoch:  468  Loss:  0.40361945921852743  Validation Loss:  0.42118518852761816\n",
      "Epoch:  469  Loss:  0.40365984903637475  Validation Loss:  0.4211743623018265\n",
      "Epoch:  470  Loss:  0.40370129604311383  Validation Loss:  0.4211645227457796\n",
      "Epoch:  471  Loss:  0.40374368385097686  Validation Loss:  0.4211556299456528\n",
      "Epoch:  472  Loss:  0.40378697798449614  Validation Loss:  0.42114765303475515\n",
      "Epoch:  473  Loss:  0.4038312700549526  Validation Loss:  0.421140654278653\n",
      "Epoch:  474  Loss:  0.40387660361958677  Validation Loss:  0.42113460174628664\n",
      "Epoch:  475  Loss:  0.40392286617022294  Validation Loss:  0.4211295007594994\n",
      "Epoch:  476  Loss:  0.4039700222614954  Validation Loss:  0.4211252784090383\n",
      "Epoch:  477  Loss:  0.40401802286946564  Validation Loss:  0.42112196290067266\n",
      "Epoch:  478  Loss:  0.4040670497177621  Validation Loss:  0.4211196287402085\n",
      "Epoch:  479  Loss:  0.40411715253570374  Validation Loss:  0.4211182732667242\n",
      "Epoch:  480  Loss:  0.40416823371627625  Validation Loss:  0.42111798908029285\n",
      "Epoch:  481  Loss:  0.4042204507356565  Validation Loss:  0.4211187314774309\n",
      "Epoch:  482  Loss:  0.4042736010614937  Validation Loss:  0.4211203759270055\n",
      "Epoch:  483  Loss:  0.40432756733612196  Validation Loss:  0.42112292402556967\n",
      "Epoch:  484  Loss:  0.4043823976135818  Validation Loss:  0.421126375240939\n",
      "Epoch:  485  Loss:  0.4044381848277425  Validation Loss:  0.42113071999379564\n",
      "Epoch:  486  Loss:  0.4044948654061944  Validation Loss:  0.4211359848933561\n",
      "Epoch:  487  Loss:  0.40455241201544656  Validation Loss:  0.42114214120166643\n",
      "Epoch:  488  Loss:  0.4046107505905558  Validation Loss:  0.42114915060145514\n",
      "Epoch:  489  Loss:  0.404669796221355  Validation Loss:  0.42115691783172743\n",
      "Epoch:  490  Loss:  0.4047294214103349  Validation Loss:  0.42116534816367285\n",
      "Epoch:  491  Loss:  0.4047895753701058  Validation Loss:  0.42117452674678396\n",
      "Epoch:  492  Loss:  0.4048504452028218  Validation Loss:  0.42118451025869164\n",
      "Epoch:  493  Loss:  0.4049119566671947  Validation Loss:  0.4211952675666128\n",
      "Epoch:  494  Loss:  0.40497418435720295  Validation Loss:  0.4212067992027317\n",
      "Epoch:  495  Loss:  0.4050370785435276  Validation Loss:  0.42121908866933416\n",
      "Epoch:  496  Loss:  0.4051006350820587  Validation Loss:  0.4212320846106325\n",
      "Epoch:  497  Loss:  0.40516469455682314  Validation Loss:  0.4212457657392536\n",
      "Epoch:  498  Loss:  0.40522920741484714  Validation Loss:  0.42126007697411944\n",
      "Epoch:  499  Loss:  0.4052939726227134  Validation Loss:  0.4212747737765312\n",
      "Epoch:  500  Loss:  0.40535894459521277  Validation Loss:  0.42129000276327133\n",
      "Epoch:  501  Loss:  0.4054241181301647  Validation Loss:  0.42130570273314205\n",
      "Epoch:  502  Loss:  0.40548936008701664  Validation Loss:  0.421321784013084\n",
      "Epoch:  503  Loss:  0.40555447780874354  Validation Loss:  0.4213381071708032\n",
      "Epoch:  504  Loss:  0.40561927996090885  Validation Loss:  0.42135457455047537\n",
      "Epoch:  505  Loss:  0.40568353623680814  Validation Loss:  0.42137100813644274\n",
      "Epoch:  506  Loss:  0.4057469263055621  Validation Loss:  0.42138716525265146\n",
      "Epoch:  507  Loss:  0.4058090160936999  Validation Loss:  0.4214027638414076\n",
      "Epoch:  508  Loss:  0.4058695120747978  Validation Loss:  0.42141775068427834\n",
      "Epoch:  509  Loss:  0.4059282856932759  Validation Loss:  0.42143201801393715\n",
      "Epoch:  510  Loss:  0.40598520742365596  Validation Loss:  0.42144550462918623\n",
      "Epoch:  511  Loss:  0.40604031456292733  Validation Loss:  0.42145824299326967\n",
      "Epoch:  512  Loss:  0.4060938268370882  Validation Loss:  0.42147050159318106\n",
      "Epoch:  513  Loss:  0.40614618819493514  Validation Loss:  0.4214824701526335\n",
      "Epoch:  514  Loss:  0.40619771094364526  Validation Loss:  0.42149430327117443\n",
      "Epoch:  515  Loss:  0.40624896705855984  Validation Loss:  0.4215063729456493\n",
      "Epoch:  516  Loss:  0.40630036460224694  Validation Loss:  0.4215188811400107\n",
      "Epoch:  517  Loss:  0.40635213555668936  Validation Loss:  0.4215319167290415\n",
      "Epoch:  518  Loss:  0.40640441147533396  Validation Loss:  0.4215454900903361\n",
      "Epoch:  519  Loss:  0.40645721052172623  Validation Loss:  0.42155963288886206\n",
      "Epoch:  520  Loss:  0.40651057202082413  Validation Loss:  0.4215743217085089\n",
      "Epoch:  521  Loss:  0.40656444368630473  Validation Loss:  0.42158951237797737\n",
      "Epoch:  522  Loss:  0.406618588245832  Validation Loss:  0.421604954504541\n",
      "Epoch:  523  Loss:  0.40667303629528134  Validation Loss:  0.4216209003435714\n",
      "Epoch:  524  Loss:  0.4067278046756101  Validation Loss:  0.42163724585303236\n",
      "Epoch:  525  Loss:  0.40678280962289437  Validation Loss:  0.42165394579725607\n",
      "Epoch:  526  Loss:  0.4068380309456199  Validation Loss:  0.4216709267348051\n",
      "Epoch:  527  Loss:  0.4068931698270098  Validation Loss:  0.4216878485998937\n",
      "Epoch:  528  Loss:  0.4069481554645053  Validation Loss:  0.4217048252799681\n",
      "Epoch:  529  Loss:  0.4070029522363956  Validation Loss:  0.42172172026974813\n",
      "Epoch:  530  Loss:  0.40705738221047194  Validation Loss:  0.42173839041164946\n",
      "Epoch:  531  Loss:  0.4071110548705039  Validation Loss:  0.4217544746186052\n",
      "Epoch:  532  Loss:  0.4071638264070601  Validation Loss:  0.4217699140842472\n",
      "Epoch:  533  Loss:  0.40721536167627254  Validation Loss:  0.4217841579977955\n",
      "Epoch:  534  Loss:  0.4072648314152949  Validation Loss:  0.4217967920537506\n",
      "Epoch:  535  Loss:  0.4073122313036721  Validation Loss:  0.4218077579779284\n",
      "Epoch:  536  Loss:  0.407357063871869  Validation Loss:  0.4218165941004242\n",
      "Epoch:  537  Loss:  0.40739891753041535  Validation Loss:  0.4218229563640697\n",
      "Epoch:  538  Loss:  0.40743761760948677  Validation Loss:  0.4218269182103021\n",
      "Epoch:  539  Loss:  0.4074731000076384  Validation Loss:  0.4218284681971584\n",
      "Epoch:  540  Loss:  0.40750563550277574  Validation Loss:  0.42182799535138266\n",
      "Epoch:  541  Loss:  0.4075358360124058  Validation Loss:  0.4218260488872017\n",
      "Epoch:  542  Loss:  0.40756443116439167  Validation Loss:  0.4218231977096626\n",
      "Epoch:  543  Loss:  0.4075921132014348  Validation Loss:  0.4218199399432966\n",
      "Epoch:  544  Loss:  0.40761948830982636  Validation Loss:  0.4218166076711246\n",
      "Epoch:  545  Loss:  0.4076467594627798  Validation Loss:  0.4218132458627224\n",
      "Epoch:  546  Loss:  0.4076739125526868  Validation Loss:  0.4218098438744034\n",
      "Epoch:  547  Loss:  0.4077010238488045  Validation Loss:  0.4218064115515777\n",
      "Epoch:  548  Loss:  0.40772805067561785  Validation Loss:  0.4218029049890382\n",
      "Epoch:  549  Loss:  0.40775491332514047  Validation Loss:  0.42179921748382704\n",
      "Epoch:  550  Loss:  0.4077816133844782  Validation Loss:  0.4217953578169857\n",
      "Epoch:  551  Loss:  0.4078081004189316  Validation Loss:  0.421791337164385\n",
      "Epoch:  552  Loss:  0.4078345028077357  Validation Loss:  0.4217872675508261\n",
      "Epoch:  553  Loss:  0.40786095713017256  Validation Loss:  0.42178333391036305\n",
      "Epoch:  554  Loss:  0.4078877213791277  Validation Loss:  0.42177981484149185\n",
      "Epoch:  555  Loss:  0.4079149220822125  Validation Loss:  0.4217767074171986\n",
      "Epoch:  556  Loss:  0.4079426810938931  Validation Loss:  0.4217740786927087\n",
      "Epoch:  557  Loss:  0.40797069413069437  Validation Loss:  0.4217718483081886\n",
      "Epoch:  558  Loss:  0.4079993408636229  Validation Loss:  0.4217702496264662\n",
      "Epoch:  559  Loss:  0.4080285884043169  Validation Loss:  0.4217692235750811\n",
      "Epoch:  560  Loss:  0.40805840218913625  Validation Loss:  0.421768831089139\n",
      "Epoch:  561  Loss:  0.4080888810595112  Validation Loss:  0.42176917168710915\n",
      "Epoch:  562  Loss:  0.4081201337321976  Validation Loss:  0.42177028501672403\n",
      "Epoch:  563  Loss:  0.40815207988200103  Validation Loss:  0.42177205639226095\n",
      "Epoch:  564  Loss:  0.4081846569064101  Validation Loss:  0.42177447783095495\n",
      "Epoch:  565  Loss:  0.4082179792533965  Validation Loss:  0.42177771909960676\n",
      "Epoch:  566  Loss:  0.4082520955942086  Validation Loss:  0.42178164422512054\n",
      "Epoch:  567  Loss:  0.408286781353358  Validation Loss:  0.4217861683240959\n",
      "Epoch:  568  Loss:  0.4083220762084927  Validation Loss:  0.4217913289155279\n",
      "Epoch:  569  Loss:  0.40835801313614706  Validation Loss:  0.4217971180166517\n",
      "Epoch:  570  Loss:  0.4083942701301631  Validation Loss:  0.4218031732099397\n",
      "Epoch:  571  Loss:  0.40843085838845494  Validation Loss:  0.42180975739445004\n",
      "Epoch:  572  Loss:  0.4084679598109962  Validation Loss:  0.42181690755699364\n",
      "Epoch:  573  Loss:  0.40850560684528575  Validation Loss:  0.4218246534998928\n",
      "Epoch:  574  Loss:  0.4085437723341778  Validation Loss:  0.4218329880386591\n",
      "Epoch:  575  Loss:  0.4085825119145523  Validation Loss:  0.42184193272675785\n",
      "Epoch:  576  Loss:  0.4086217019684921  Validation Loss:  0.42185140480952604\n",
      "Epoch:  577  Loss:  0.4086613319152911  Validation Loss:  0.42186133643346174\n",
      "Epoch:  578  Loss:  0.4087013518492851  Validation Loss:  0.42187166107552393\n",
      "Epoch:  579  Loss:  0.40874138880058153  Validation Loss:  0.4218820809785809\n",
      "Epoch:  580  Loss:  0.40878167977699864  Validation Loss:  0.4218930186969893\n",
      "Epoch:  581  Loss:  0.40882236832345026  Validation Loss:  0.42190439493528437\n",
      "Epoch:  582  Loss:  0.40886341026548806  Validation Loss:  0.4219162879245622\n",
      "Epoch:  583  Loss:  0.40890495770076324  Validation Loss:  0.4219288051660572\n",
      "Epoch:  584  Loss:  0.4089469288051481  Validation Loss:  0.42194168269634247\n",
      "Epoch:  585  Loss:  0.4089887332634108  Validation Loss:  0.4219542558171919\n",
      "Epoch:  586  Loss:  0.40903022259297456  Validation Loss:  0.42196706336523804\n",
      "Epoch:  587  Loss:  0.4090718790976959  Validation Loss:  0.4219801995371069\n",
      "Epoch:  588  Loss:  0.40911372640781857  Validation Loss:  0.4219937595937933\n",
      "Epoch:  589  Loss:  0.4091558388528034  Validation Loss:  0.4220075663179159\n",
      "Epoch:  590  Loss:  0.4091977490299552  Validation Loss:  0.4220212743218456\n",
      "Epoch:  591  Loss:  0.4092395861120619  Validation Loss:  0.4220352289932115\n",
      "Epoch:  592  Loss:  0.40928145484811457  Validation Loss:  0.4220494127699307\n",
      "Epoch:  593  Loss:  0.40932324581597684  Validation Loss:  0.4220634887793234\n",
      "Epoch:  594  Loss:  0.4093646173470119  Validation Loss:  0.42207758501172066\n",
      "Epoch:  595  Loss:  0.4094059702736386  Validation Loss:  0.42209200880357195\n",
      "Epoch:  596  Loss:  0.4094471741886534  Validation Loss:  0.42210627160966396\n",
      "Epoch:  597  Loss:  0.4094877317106935  Validation Loss:  0.4221204021679504\n",
      "Epoch:  598  Loss:  0.4095278470473882  Validation Loss:  0.4221343459295375\n",
      "Epoch:  599  Loss:  0.4095670646993366  Validation Loss:  0.4221477870430265\n",
      "Epoch:  600  Loss:  0.40960539172034294  Validation Loss:  0.4221607401434864\n",
      "Epoch:  601  Loss:  0.40964248591273494  Validation Loss:  0.422173071918743\n",
      "Epoch:  602  Loss:  0.4096785474282045  Validation Loss:  0.42218491275395664\n",
      "Epoch:  603  Loss:  0.409713278948908  Validation Loss:  0.4221960833030088\n",
      "Epoch:  604  Loss:  0.40974640431841447  Validation Loss:  0.42220629059842657\n",
      "Epoch:  605  Loss:  0.40977769949027065  Validation Loss:  0.4222153771136488\n",
      "Epoch:  606  Loss:  0.4098067312727313  Validation Loss:  0.4222230701042073\n",
      "Epoch:  607  Loss:  0.4098330609191804  Validation Loss:  0.42222910720322815\n",
      "Epoch:  608  Loss:  0.409856162215831  Validation Loss:  0.42223308528108255\n",
      "Epoch:  609  Loss:  0.4098753669029157  Validation Loss:  0.4222343721027885\n",
      "Epoch:  610  Loss:  0.4098897099318589  Validation Loss:  0.42223251132028444\n",
      "Epoch:  611  Loss:  0.4098985235719286  Validation Loss:  0.42222697474062443\n",
      "Epoch:  612  Loss:  0.40990091199000206  Validation Loss:  0.4222172432179962\n",
      "Epoch:  613  Loss:  0.4098957342332637  Validation Loss:  0.42220244237354826\n",
      "Epoch:  614  Loss:  0.40988144569495727  Validation Loss:  0.4221815051777022\n",
      "Epoch:  615  Loss:  0.4098564919811734  Validation Loss:  0.4221535673631089\n",
      "Epoch:  616  Loss:  0.4098194974237645  Validation Loss:  0.4221175823892866\n",
      "Epoch:  617  Loss:  0.40976912038918784  Validation Loss:  0.4220729196178062\n",
      "Epoch:  618  Loss:  0.4097051856785836  Validation Loss:  0.4220196900091001\n",
      "Epoch:  619  Loss:  0.40962833148487926  Validation Loss:  0.4219582764697926\n",
      "Epoch:  620  Loss:  0.4095398035980541  Validation Loss:  0.4218893993113722\n",
      "Epoch:  621  Loss:  0.4094413955359769  Validation Loss:  0.42181413860193323\n",
      "Epoch:  622  Loss:  0.40933488194759077  Validation Loss:  0.42173338761287077\n",
      "Epoch:  623  Loss:  0.40922223393028306  Validation Loss:  0.42164853561137405\n",
      "Epoch:  624  Loss:  0.4091052808881511  Validation Loss:  0.4215608731444393\n",
      "Epoch:  625  Loss:  0.40898588123406177  Validation Loss:  0.4214717237544911\n",
      "Epoch:  626  Loss:  0.4088652830504807  Validation Loss:  0.42138186416455675\n",
      "Epoch:  627  Loss:  0.4087447382112932  Validation Loss:  0.42129238774733885\n",
      "Epoch:  628  Loss:  0.40862525884921735  Validation Loss:  0.4212040124194963\n",
      "Epoch:  629  Loss:  0.4085073776146364  Validation Loss:  0.42111677915922235\n",
      "Epoch:  630  Loss:  0.4083911100259194  Validation Loss:  0.4210309138787644\n",
      "Epoch:  631  Loss:  0.4082766722821625  Validation Loss:  0.4209464889551912\n",
      "Epoch:  632  Loss:  0.40816415431936814  Validation Loss:  0.4208635509546314\n",
      "Epoch:  633  Loss:  0.40805355975261104  Validation Loss:  0.42078231062207905\n",
      "Epoch:  634  Loss:  0.4079449113304093  Validation Loss:  0.4207022666398968\n",
      "Epoch:  635  Loss:  0.40783804901958215  Validation Loss:  0.42062388892684666\n",
      "Epoch:  636  Loss:  0.4077327818383832  Validation Loss:  0.42054664343595505\n",
      "Epoch:  637  Loss:  0.4076292532435536  Validation Loss:  0.4204707323972668\n",
      "Epoch:  638  Loss:  0.4075273615721415  Validation Loss:  0.4203964184437479\n",
      "Epoch:  639  Loss:  0.4074274264496459  Validation Loss:  0.4203233676297324\n",
      "Epoch:  640  Loss:  0.4073289660130732  Validation Loss:  0.42025155228163513\n",
      "Epoch:  641  Loss:  0.40723191854163737  Validation Loss:  0.42018063898597446\n",
      "Epoch:  642  Loss:  0.4071359276418855  Validation Loss:  0.4201107501451458\n",
      "Epoch:  643  Loss:  0.4070412744079116  Validation Loss:  0.42004180220620974\n",
      "Epoch:  644  Loss:  0.40694751912320154  Validation Loss:  0.41997348463961054\n",
      "Epoch:  645  Loss:  0.4068546588780612  Validation Loss:  0.4199061087731804\n",
      "Epoch:  646  Loss:  0.4067627366125231  Validation Loss:  0.41983918233641554\n",
      "Epoch:  647  Loss:  0.4066711538994806  Validation Loss:  0.4197725398199899\n",
      "Epoch:  648  Loss:  0.4065800291546703  Validation Loss:  0.4197064411959478\n",
      "Epoch:  649  Loss:  0.4064895478049679  Validation Loss:  0.41964066959917545\n",
      "Epoch:  650  Loss:  0.4063991602708602  Validation Loss:  0.4195747867758785\n",
      "Epoch:  651  Loss:  0.40630858060876296  Validation Loss:  0.41950863573168007\n",
      "Epoch:  652  Loss:  0.406217676736194  Validation Loss:  0.4194422848522663\n",
      "Epoch:  653  Loss:  0.4061265166341906  Validation Loss:  0.4193754656506436\n",
      "Epoch:  654  Loss:  0.4060344165246162  Validation Loss:  0.4193075586642538\n",
      "Epoch:  655  Loss:  0.40594086853357464  Validation Loss:  0.4192383342555591\n",
      "Epoch:  656  Loss:  0.40584574269472495  Validation Loss:  0.41916774825326036\n",
      "Epoch:  657  Loss:  0.4057490640490718  Validation Loss:  0.41909598213221344\n",
      "Epoch:  658  Loss:  0.40565146303035804  Validation Loss:  0.41902377935392515\n",
      "Epoch:  659  Loss:  0.40555321411973627  Validation Loss:  0.4189510957470962\n",
      "Epoch:  660  Loss:  0.40545455185619333  Validation Loss:  0.41887822933495045\n",
      "Epoch:  661  Loss:  0.40535591313472163  Validation Loss:  0.4188056912805353\n",
      "Epoch:  662  Loss:  0.4052576442971032  Validation Loss:  0.418733665187444\n",
      "Epoch:  663  Loss:  0.4051600513902642  Validation Loss:  0.41866238441850456\n",
      "Epoch:  664  Loss:  0.4050633470863986  Validation Loss:  0.4185920876583883\n",
      "Epoch:  665  Loss:  0.4049681986753757  Validation Loss:  0.4185235393898828\n",
      "Epoch:  666  Loss:  0.40487457176990055  Validation Loss:  0.41845601531011717\n",
      "Epoch:  667  Loss:  0.4047821457745761  Validation Loss:  0.41838965165827957\n",
      "Epoch:  668  Loss:  0.4046908009510774  Validation Loss:  0.4183242478008781\n",
      "Epoch:  669  Loss:  0.40460061418586935  Validation Loss:  0.41825996099838186\n",
      "Epoch:  670  Loss:  0.4045116131651331  Validation Loss:  0.4181968045553991\n",
      "Epoch:  671  Loss:  0.40442385925696445  Validation Loss:  0.41813470476440023\n",
      "Epoch:  672  Loss:  0.40433731525254674  Validation Loss:  0.41807376726397444\n",
      "Epoch:  673  Loss:  0.40425181926707543  Validation Loss:  0.41801370839987484\n",
      "Epoch:  674  Loss:  0.40416740110287297  Validation Loss:  0.4179547652602196\n",
      "Epoch:  675  Loss:  0.4040842557094506  Validation Loss:  0.41789713368884157\n",
      "Epoch:  676  Loss:  0.40400270571017405  Validation Loss:  0.41784091719559263\n",
      "Epoch:  677  Loss:  0.403922371786727  Validation Loss:  0.41778556018003393\n",
      "Epoch:  678  Loss:  0.4038428978983467  Validation Loss:  0.4177311485899346\n",
      "Epoch:  679  Loss:  0.4037646062275362  Validation Loss:  0.4176778072225196\n",
      "Epoch:  680  Loss:  0.4036873689240958  Validation Loss:  0.41762537801904337\n",
      "Epoch:  681  Loss:  0.4036111128929804  Validation Loss:  0.417573908077819\n",
      "Epoch:  682  Loss:  0.4035358600891553  Validation Loss:  0.4175233827637775\n",
      "Epoch:  683  Loss:  0.4034616213578444  Validation Loss:  0.4174737531159605\n",
      "Epoch:  684  Loss:  0.4033883410621677  Validation Loss:  0.4174249784222671\n",
      "Epoch:  685  Loss:  0.40331596532869624  Validation Loss:  0.4173771310597658\n",
      "Epoch:  686  Loss:  0.4032446864617647  Validation Loss:  0.41733021954340593\n",
      "Epoch:  687  Loss:  0.4031744487363206  Validation Loss:  0.4172842287059341\n",
      "Epoch:  688  Loss:  0.4031051281817566  Validation Loss:  0.4172390116644757\n",
      "Epoch:  689  Loss:  0.40303655224438956  Validation Loss:  0.4171946046075651\n",
      "Epoch:  690  Loss:  0.40296905536270705  Validation Loss:  0.4171512871980667\n",
      "Epoch:  691  Loss:  0.4029025922160177  Validation Loss:  0.4171089700290135\n",
      "Epoch:  692  Loss:  0.4028373130503491  Validation Loss:  0.41706783084997107\n",
      "Epoch:  693  Loss:  0.4027730765251013  Validation Loss:  0.4170274827629328\n",
      "Epoch:  694  Loss:  0.4027095600169086  Validation Loss:  0.4169879074075392\n",
      "Epoch:  695  Loss:  0.4026469408407719  Validation Loss:  0.4169491675815412\n",
      "Epoch:  696  Loss:  0.40258512932520646  Validation Loss:  0.41691132235739914\n",
      "Epoch:  697  Loss:  0.4025243441381398  Validation Loss:  0.41687436774373055\n",
      "Epoch:  698  Loss:  0.4024643126500429  Validation Loss:  0.4168381289179836\n",
      "Epoch:  699  Loss:  0.40240508723541124  Validation Loss:  0.41680269102965084\n",
      "Epoch:  700  Loss:  0.4023465955927527  Validation Loss:  0.41676799580454826\n",
      "Epoch:  701  Loss:  0.40228890358696323  Validation Loss:  0.41673404377486023\n",
      "Epoch:  702  Loss:  0.40223191669706765  Validation Loss:  0.4167008535670383\n",
      "Epoch:  703  Loss:  0.40217575430870056  Validation Loss:  0.4166684225201607\n",
      "Epoch:  704  Loss:  0.40212027940171713  Validation Loss:  0.4166367131152323\n",
      "Epoch:  705  Loss:  0.40206559795952407  Validation Loss:  0.4166058985782521\n",
      "Epoch:  706  Loss:  0.40201181155690074  Validation Loss:  0.41657582271311966\n",
      "Epoch:  707  Loss:  0.4019586823043033  Validation Loss:  0.41654640063643456\n",
      "Epoch:  708  Loss:  0.40190619433067254  Validation Loss:  0.41651767971260206\n",
      "Epoch:  709  Loss:  0.4018543490467692  Validation Loss:  0.4164895841053554\n",
      "Epoch:  710  Loss:  0.4018030855253603  Validation Loss:  0.41646212126527515\n",
      "Epoch:  711  Loss:  0.4017523308477458  Validation Loss:  0.4164351038634777\n",
      "Epoch:  712  Loss:  0.40170195689920846  Validation Loss:  0.41640861997646944\n",
      "Epoch:  713  Loss:  0.40165189613957375  Validation Loss:  0.4163826174501862\n",
      "Epoch:  714  Loss:  0.4016021965347098  Validation Loss:  0.4163570401391813\n",
      "Epoch:  715  Loss:  0.4015528883278017  Validation Loss:  0.4163319907550301\n",
      "Epoch:  716  Loss:  0.4015039927684344  Validation Loss:  0.41630739186491283\n",
      "Epoch:  717  Loss:  0.40145550941574504  Validation Loss:  0.41628332196601797\n",
      "Epoch:  718  Loss:  0.40140752732401064  Validation Loss:  0.4162598704653127\n",
      "Epoch:  719  Loss:  0.40136005636855693  Validation Loss:  0.416236904582807\n",
      "Epoch:  720  Loss:  0.4013128817610487  Validation Loss:  0.4162143615207502\n",
      "Epoch:  721  Loss:  0.40126618390252605  Validation Loss:  0.41619257921619074\n",
      "Epoch:  722  Loss:  0.4012200071437824  Validation Loss:  0.4161712120154074\n",
      "Epoch:  723  Loss:  0.40117394077707325  Validation Loss:  0.41615001750843866\n",
      "Epoch:  724  Loss:  0.4011278817286858  Validation Loss:  0.4161290129912751\n",
      "Epoch:  725  Loss:  0.40108174358951976  Validation Loss:  0.41610806302300524\n",
      "Epoch:  726  Loss:  0.40103537196943745  Validation Loss:  0.41608704573341776\n",
      "Epoch:  727  Loss:  0.40098859202226944  Validation Loss:  0.41606586665979456\n",
      "Epoch:  728  Loss:  0.4009412711364983  Validation Loss:  0.4160443858376571\n",
      "Epoch:  729  Loss:  0.4008932464574216  Validation Loss:  0.41602249656404766\n",
      "Epoch:  730  Loss:  0.4008442886482329  Validation Loss:  0.4159999934158155\n",
      "Epoch:  731  Loss:  0.4007941727807536  Validation Loss:  0.4159766895962613\n",
      "Epoch:  732  Loss:  0.4007426399803726  Validation Loss:  0.41595244833401274\n",
      "Epoch:  733  Loss:  0.40068942890364745  Validation Loss:  0.41592700673001154\n",
      "Epoch:  734  Loss:  0.4006342221293929  Validation Loss:  0.4159001926226275\n",
      "Epoch:  735  Loss:  0.40057669006861174  Validation Loss:  0.4158717000058719\n",
      "Epoch:  736  Loss:  0.4005163303141058  Validation Loss:  0.41584114517484394\n",
      "Epoch:  737  Loss:  0.40045255219795295  Validation Loss:  0.4158080763050488\n",
      "Epoch:  738  Loss:  0.40038460625346595  Validation Loss:  0.4157718638224261\n",
      "Epoch:  739  Loss:  0.400311542421403  Validation Loss:  0.4157318252005747\n",
      "Epoch:  740  Loss:  0.4002324085263811  Validation Loss:  0.41568724465157303\n",
      "Epoch:  741  Loss:  0.4001461464096103  Validation Loss:  0.41563731751271654\n",
      "Epoch:  742  Loss:  0.4000516492410524  Validation Loss:  0.4155813133610146\n",
      "Epoch:  743  Loss:  0.39994830122360814  Validation Loss:  0.4155190528503486\n",
      "Epoch:  744  Loss:  0.3998362041965744  Validation Loss:  0.4154508752482278\n",
      "Epoch:  745  Loss:  0.39971629631589856  Validation Loss:  0.415377762434738\n",
      "Epoch:  746  Loss:  0.3995902527718854  Validation Loss:  0.4153010613684143\n",
      "Epoch:  747  Loss:  0.39946000807031373  Validation Loss:  0.41522220415728434\n",
      "Epoch:  748  Loss:  0.3993274580973845  Validation Loss:  0.4151423876839025\n",
      "Epoch:  749  Loss:  0.39919400964615614  Validation Loss:  0.4150624836661986\n",
      "Epoch:  750  Loss:  0.39906062723616875  Validation Loss:  0.4149830846914223\n",
      "Epoch:  751  Loss:  0.39892800760692393  Validation Loss:  0.4149045702069998\n",
      "Epoch:  752  Loss:  0.3987965520317032  Validation Loss:  0.4148271448378052\n",
      "Epoch:  753  Loss:  0.39866643764916254  Validation Loss:  0.4147509131580591\n",
      "Epoch:  754  Loss:  0.39853780147944684  Validation Loss:  0.41467591534767834\n",
      "Epoch:  755  Loss:  0.3984107168821188  Validation Loss:  0.41460215034229414\n",
      "Epoch:  756  Loss:  0.39828511922669835  Validation Loss:  0.41452964554939953\n",
      "Epoch:  757  Loss:  0.39816099405288696  Validation Loss:  0.4144583586603403\n",
      "Epoch:  758  Loss:  0.3980383478854535  Validation Loss:  0.4143882864820106\n",
      "Epoch:  759  Loss:  0.3979171323176672  Validation Loss:  0.4143194234264748\n",
      "Epoch:  760  Loss:  0.39779730405680525  Validation Loss:  0.41425171228391783\n",
      "Epoch:  761  Loss:  0.3976788196337999  Validation Loss:  0.4141851168658052\n",
      "Epoch:  762  Loss:  0.39756164060541865  Validation Loss:  0.4141196063054459\n",
      "Epoch:  763  Loss:  0.3974457059562559  Validation Loss:  0.41405515958155903\n",
      "Epoch:  764  Loss:  0.3973309824452598  Validation Loss:  0.41399174236825537\n",
      "Epoch:  765  Loss:  0.39721746266593594  Validation Loss:  0.41392936797014307\n",
      "Epoch:  766  Loss:  0.3971051157578914  Validation Loss:  0.4138679711946419\n",
      "Epoch:  767  Loss:  0.3969939048649997  Validation Loss:  0.41380754938083036\n",
      "Epoch:  768  Loss:  0.3968838058279816  Validation Loss:  0.4137480562286718\n",
      "Epoch:  769  Loss:  0.39677476768310255  Validation Loss:  0.4136894763048206\n",
      "Epoch:  770  Loss:  0.3966667630086989  Validation Loss:  0.4136317952403\n",
      "Epoch:  771  Loss:  0.3965597686153897  Validation Loss:  0.4135750087776354\n",
      "Epoch:  772  Loss:  0.39645379790540275  Validation Loss:  0.41351911292544435\n",
      "Epoch:  773  Loss:  0.39634876649760636  Validation Loss:  0.4134640307830913\n",
      "Epoch:  774  Loss:  0.3962446610779452  Validation Loss:  0.4134097823074886\n",
      "Epoch:  775  Loss:  0.3961414755625132  Validation Loss:  0.4133563544601202\n",
      "Epoch:  776  Loss:  0.3960392175341499  Validation Loss:  0.41330379034791676\n",
      "Epoch:  777  Loss:  0.3959378735024548  Validation Loss:  0.41325201919036253\n",
      "Epoch:  778  Loss:  0.3958373925918658  Validation Loss:  0.41320100772593704\n",
      "Epoch:  779  Loss:  0.39573781483272125  Validation Loss:  0.4131508432328701\n",
      "Epoch:  780  Loss:  0.395639127263656  Validation Loss:  0.4131015004324062\n",
      "Epoch:  781  Loss:  0.39554141311955876  Validation Loss:  0.4130531254091433\n",
      "Epoch:  782  Loss:  0.39544488410272544  Validation Loss:  0.4130059275776148\n",
      "Epoch:  783  Loss:  0.39534941121671324  Validation Loss:  0.41295946495873587\n",
      "Epoch:  784  Loss:  0.39525481273789376  Validation Loss:  0.4129138854997499\n",
      "Epoch:  785  Loss:  0.39516113724934276  Validation Loss:  0.4128690931413855\n",
      "Epoch:  786  Loss:  0.3950683264690038  Validation Loss:  0.4128250873514584\n",
      "Epoch:  787  Loss:  0.3949762944286392  Validation Loss:  0.4127817465258496\n",
      "Epoch:  788  Loss:  0.39488502155394245  Validation Loss:  0.4127392005175352\n",
      "Epoch:  789  Loss:  0.3947945837614804  Validation Loss:  0.4126973423574652\n",
      "Epoch:  790  Loss:  0.3947048721581521  Validation Loss:  0.41265622792499407\n",
      "Epoch:  791  Loss:  0.394616012830706  Validation Loss:  0.41261583965803894\n",
      "Epoch:  792  Loss:  0.39452780871348975  Validation Loss:  0.4125760777720383\n",
      "Epoch:  793  Loss:  0.39444036032321184  Validation Loss:  0.41253711256597725\n",
      "Epoch:  794  Loss:  0.394353721004266  Validation Loss:  0.412498803543193\n",
      "Epoch:  795  Loss:  0.3942677193492122  Validation Loss:  0.41246111983699457\n",
      "Epoch:  796  Loss:  0.39418246239952787  Validation Loss:  0.41242423680211815\n",
      "Epoch:  797  Loss:  0.39409801496203833  Validation Loss:  0.4123879937188966\n",
      "Epoch:  798  Loss:  0.3940141977819465  Validation Loss:  0.4123523557292564\n",
      "Epoch:  799  Loss:  0.39393107998653276  Validation Loss:  0.412317482488496\n",
      "Epoch:  800  Loss:  0.39384874798489744  Validation Loss:  0.41228326835802626\n",
      "Epoch:  801  Loss:  0.3937670162619924  Validation Loss:  0.4122496673039028\n",
      "Epoch:  802  Loss:  0.39368588032101737  Validation Loss:  0.4122166737381901\n",
      "Epoch:  803  Loss:  0.3936054071731116  Validation Loss:  0.4121844305523804\n",
      "Epoch:  804  Loss:  0.39352567449829284  Validation Loss:  0.4121527887348618\n",
      "Epoch:  805  Loss:  0.3934464741211671  Validation Loss:  0.4121217043804271\n",
      "Epoch:  806  Loss:  0.39336779969331076  Validation Loss:  0.41209118414138046\n",
      "Epoch:  807  Loss:  0.3932897294237769  Validation Loss:  0.4120613461626427\n",
      "Epoch:  808  Loss:  0.3932123224763475  Validation Loss:  0.41203209332057406\n",
      "Epoch:  809  Loss:  0.3931353854886174  Validation Loss:  0.41200333514383863\n",
      "Epoch:  810  Loss:  0.3930588880410561  Validation Loss:  0.411975074293358\n",
      "Epoch:  811  Loss:  0.39298280923676915  Validation Loss:  0.4119472910783121\n",
      "Epoch:  812  Loss:  0.39290717676193754  Validation Loss:  0.4119200738412993\n",
      "Epoch:  813  Loss:  0.39283199035204375  Validation Loss:  0.4118932631931135\n",
      "Epoch:  814  Loss:  0.39275702596063444  Validation Loss:  0.41186677291989326\n",
      "Epoch:  815  Loss:  0.39268219973561325  Validation Loss:  0.41184056603482794\n",
      "Epoch:  816  Loss:  0.39260737659663136  Validation Loss:  0.41181459171431406\n",
      "Epoch:  817  Loss:  0.3925325069907149  Validation Loss:  0.41178887310837\n",
      "Epoch:  818  Loss:  0.39245757143172993  Validation Loss:  0.41176337083535536\n",
      "Epoch:  819  Loss:  0.3923823599808315  Validation Loss:  0.41173790927444187\n",
      "Epoch:  820  Loss:  0.39230672530168614  Validation Loss:  0.41171249960150036\n",
      "Epoch:  821  Loss:  0.39223065716627786  Validation Loss:  0.41168714926711153\n",
      "Epoch:  822  Loss:  0.39215422972772246  Validation Loss:  0.41166195140353273\n",
      "Epoch:  823  Loss:  0.3920776366129429  Validation Loss:  0.41163708083331585\n",
      "Epoch:  824  Loss:  0.3920011913635322  Validation Loss:  0.4116127930049385\n",
      "Epoch:  825  Loss:  0.3919252020543849  Validation Loss:  0.4115891328879765\n",
      "Epoch:  826  Loss:  0.3918497222944124  Validation Loss:  0.4115661717951298\n",
      "Epoch:  827  Loss:  0.3917749054156817  Validation Loss:  0.41154399061841623\n",
      "Epoch:  828  Loss:  0.3917008563435289  Validation Loss:  0.411522633263043\n",
      "Epoch:  829  Loss:  0.3916276432353364  Validation Loss:  0.4115021252738578\n",
      "Epoch:  830  Loss:  0.391555313880627  Validation Loss:  0.41148248155202183\n",
      "Epoch:  831  Loss:  0.3914839329980534  Validation Loss:  0.41146381571888924\n",
      "Epoch:  832  Loss:  0.3914136215603563  Validation Loss:  0.41144614001469954\n",
      "Epoch:  833  Loss:  0.39134430021223937  Validation Loss:  0.4114293421485594\n",
      "Epoch:  834  Loss:  0.39127589039195926  Validation Loss:  0.41141341759690214\n",
      "Epoch:  835  Loss:  0.391208385398402  Validation Loss:  0.4113983543855803\n",
      "Epoch:  836  Loss:  0.39114177914766163  Validation Loss:  0.41138415278068613\n",
      "Epoch:  837  Loss:  0.39107607040532244  Validation Loss:  0.4113708066620997\n",
      "Epoch:  838  Loss:  0.39101118792796274  Validation Loss:  0.41135821943836554\n",
      "Epoch:  839  Loss:  0.3909470425731332  Validation Loss:  0.4113463666290045\n",
      "Epoch:  840  Loss:  0.39088358240720084  Validation Loss:  0.4113352394529751\n",
      "Epoch:  841  Loss:  0.39082083361741354  Validation Loss:  0.4113249996943133\n",
      "Epoch:  842  Loss:  0.39075896514237984  Validation Loss:  0.41131546162068844\n",
      "Epoch:  843  Loss:  0.39069783193825264  Validation Loss:  0.4113067718488829\n",
      "Epoch:  844  Loss:  0.39063761969642524  Validation Loss:  0.41129895938294275\n",
      "Epoch:  845  Loss:  0.3905782777176806  Validation Loss:  0.41129196834351334\n",
      "Epoch:  846  Loss:  0.3905197751416257  Validation Loss:  0.4112857814346041\n",
      "Epoch:  847  Loss:  0.3904621039445584  Validation Loss:  0.4112804037119661\n",
      "Epoch:  848  Loss:  0.3904052667716551  Validation Loss:  0.41127583677215235\n",
      "Epoch:  849  Loss:  0.39034928161011645  Validation Loss:  0.4112720838082688\n",
      "Epoch:  850  Loss:  0.3902941836407904  Validation Loss:  0.4112691655755043\n",
      "Epoch:  851  Loss:  0.3902399198719736  Validation Loss:  0.41126699266689165\n",
      "Epoch:  852  Loss:  0.39018643828186056  Validation Loss:  0.41126553607838495\n",
      "Epoch:  853  Loss:  0.39013375632861663  Validation Loss:  0.4112648285393204\n",
      "Epoch:  854  Loss:  0.3900818695154416  Validation Loss:  0.41126491422099726\n",
      "Epoch:  855  Loss:  0.3900308122296305  Validation Loss:  0.4112658415521894\n",
      "Epoch:  856  Loss:  0.3899806308499455  Validation Loss:  0.41126759110816885\n",
      "Epoch:  857  Loss:  0.38993127458899685  Validation Loss:  0.41127014053719385\n",
      "Epoch:  858  Loss:  0.3898827245778586  Validation Loss:  0.41127348132431507\n",
      "Epoch:  859  Loss:  0.3898349761433855  Validation Loss:  0.41127759989883217\n",
      "Epoch:  860  Loss:  0.38978799930691016  Validation Loss:  0.41128248082739965\n",
      "Epoch:  861  Loss:  0.3897418190212645  Validation Loss:  0.41128815497670856\n",
      "Epoch:  862  Loss:  0.3896964665877043  Validation Loss:  0.41129465826920103\n",
      "Epoch:  863  Loss:  0.38965197216124225  Validation Loss:  0.41130198378648075\n",
      "Epoch:  864  Loss:  0.389608289010426  Validation Loss:  0.41131009214690756\n",
      "Epoch:  865  Loss:  0.38956538812648617  Validation Loss:  0.41131896312747684\n",
      "Epoch:  866  Loss:  0.3895232782385053  Validation Loss:  0.4113286015178476\n",
      "Epoch:  867  Loss:  0.38948193739151815  Validation Loss:  0.4113390174295221\n",
      "Epoch:  868  Loss:  0.3894413663790776  Validation Loss:  0.4113501975578921\n",
      "Epoch:  869  Loss:  0.38940157260767805  Validation Loss:  0.41136215520756586\n",
      "Epoch:  870  Loss:  0.38936258720223016  Validation Loss:  0.41137490049004555\n",
      "Epoch:  871  Loss:  0.3893244529264213  Validation Loss:  0.41138847544789314\n",
      "Epoch:  872  Loss:  0.38928711617134026  Validation Loss:  0.4114028039787497\n",
      "Epoch:  873  Loss:  0.38925054598842146  Validation Loss:  0.4114178791642189\n",
      "Epoch:  874  Loss:  0.38921472377325655  Validation Loss:  0.4114336743950844\n",
      "Epoch:  875  Loss:  0.389179561176949  Validation Loss:  0.41145000074590954\n",
      "Epoch:  876  Loss:  0.3891447793978911  Validation Loss:  0.4114667645522526\n",
      "Epoch:  877  Loss:  0.38911046184731657  Validation Loss:  0.4114841792200293\n",
      "Epoch:  878  Loss:  0.3890768772751622  Validation Loss:  0.4115023506539209\n",
      "Epoch:  879  Loss:  0.38904407144298214  Validation Loss:  0.4115213043987751\n",
      "Epoch:  880  Loss:  0.38901208852522473  Validation Loss:  0.41154106706380844\n",
      "Epoch:  881  Loss:  0.38898090868306584  Validation Loss:  0.41156159181679997\n",
      "Epoch:  882  Loss:  0.38895049893997125  Validation Loss:  0.41158286588532583\n",
      "Epoch:  883  Loss:  0.38892084950878775  Validation Loss:  0.4116048754325935\n",
      "Epoch:  884  Loss:  0.3888919517486053  Validation Loss:  0.41162763961723875\n",
      "Epoch:  885  Loss:  0.3888638302595658  Validation Loss:  0.4116511664220265\n",
      "Epoch:  886  Loss:  0.3888364791341082  Validation Loss:  0.4116754425423486\n",
      "Epoch:  887  Loss:  0.3888099010174091  Validation Loss:  0.41170045573796543\n",
      "Epoch:  888  Loss:  0.38878407457171105  Validation Loss:  0.4117262235709599\n",
      "Epoch:  889  Loss:  0.3887590144336576  Validation Loss:  0.411752742848226\n",
      "Epoch:  890  Loss:  0.3887347266871548  Validation Loss:  0.41178001889160704\n",
      "Epoch:  891  Loss:  0.38871124616036046  Validation Loss:  0.41180806340915815\n",
      "Epoch:  892  Loss:  0.3886885411111561  Validation Loss:  0.4118368444698198\n",
      "Epoch:  893  Loss:  0.3886665678059561  Validation Loss:  0.4118663567517485\n",
      "Epoch:  894  Loss:  0.38864531345974057  Validation Loss:  0.4118965608733041\n",
      "Epoch:  895  Loss:  0.3886247846854509  Validation Loss:  0.4119275041988918\n",
      "Epoch:  896  Loss:  0.3886049877433382  Validation Loss:  0.41195917608482496\n",
      "Epoch:  897  Loss:  0.38858590976020996  Validation Loss:  0.4119915249092238\n",
      "Epoch:  898  Loss:  0.38856754359408946  Validation Loss:  0.41202458260314806\n",
      "Epoch:  899  Loss:  0.38854984559956385  Validation Loss:  0.41205824964812826\n",
      "Epoch:  900  Loss:  0.38853273633316426  Validation Loss:  0.41209245792457033\n",
      "Epoch:  901  Loss:  0.3885160352175052  Validation Loss:  0.4121272015784468\n",
      "Epoch:  902  Loss:  0.38849985617152333  Validation Loss:  0.41216260141560007\n",
      "Epoch:  903  Loss:  0.3884844131900009  Validation Loss:  0.41219873087746756\n",
      "Epoch:  904  Loss:  0.38846969974816903  Validation Loss:  0.41223556069391115\n",
      "Epoch:  905  Loss:  0.3884557019147647  Validation Loss:  0.412273110555751\n",
      "Epoch:  906  Loss:  0.3884424316812549  Validation Loss:  0.41231137460895945\n",
      "Epoch:  907  Loss:  0.3884298873723611  Validation Loss:  0.4123503656259605\n",
      "Epoch:  908  Loss:  0.3884180685472206  Validation Loss:  0.41239007296306746\n",
      "Epoch:  909  Loss:  0.3884069824359826  Validation Loss:  0.41243050140993937\n",
      "Epoch:  910  Loss:  0.38839662542357245  Validation Loss:  0.4124716483056545\n",
      "Epoch:  911  Loss:  0.38838699539384897  Validation Loss:  0.4125135211007936\n",
      "Epoch:  912  Loss:  0.38837809014249836  Validation Loss:  0.41255612085972515\n",
      "Epoch:  913  Loss:  0.3883698884199357  Validation Loss:  0.4125993885099888\n",
      "Epoch:  914  Loss:  0.38836239375306303  Validation Loss:  0.41264332458376884\n",
      "Epoch:  915  Loss:  0.38835558700843675  Validation Loss:  0.4126879381281989\n",
      "Epoch:  916  Loss:  0.38834950116259104  Validation Loss:  0.412733256816864\n",
      "Epoch:  917  Loss:  0.3883441732479976  Validation Loss:  0.41277935089809553\n",
      "Epoch:  918  Loss:  0.38833962045830384  Validation Loss:  0.4128261554454054\n",
      "Epoch:  919  Loss:  0.38833576158658994  Validation Loss:  0.41287362948060036\n",
      "Epoch:  920  Loss:  0.3883325706219532  Validation Loss:  0.41292172563927515\n",
      "Epoch:  921  Loss:  0.3883300512676408  Validation Loss:  0.4129704859639917\n",
      "Epoch:  922  Loss:  0.38832822591948085  Validation Loss:  0.4130199301455702\n",
      "Epoch:  923  Loss:  0.3883270938720929  Validation Loss:  0.4130700262529509\n",
      "Epoch:  924  Loss:  0.3883266396952804  Validation Loss:  0.4131207460803645\n",
      "Epoch:  925  Loss:  0.38832682803185026  Validation Loss:  0.41317207845194\n",
      "Epoch:  926  Loss:  0.3883276804840776  Validation Loss:  0.41322408616542816\n",
      "Epoch:  927  Loss:  0.3883292267661123  Validation Loss:  0.4132767990231514\n",
      "Epoch:  928  Loss:  0.3883314642327777  Validation Loss:  0.4133301717894418\n",
      "Epoch:  929  Loss:  0.38833437092910855  Validation Loss:  0.41338417891945156\n",
      "Epoch:  930  Loss:  0.3883379249001396  Validation Loss:  0.41343881615570616\n",
      "Epoch:  931  Loss:  0.3883421507460126  Validation Loss:  0.4134941462959562\n",
      "Epoch:  932  Loss:  0.38834709070137974  Validation Loss:  0.4135501672114645\n",
      "Epoch:  933  Loss:  0.388352635079587  Validation Loss:  0.41360665432044436\n",
      "Epoch:  934  Loss:  0.3883585159242506  Validation Loss:  0.4136636092194489\n",
      "Epoch:  935  Loss:  0.3883647943389486  Validation Loss:  0.41372112025107655\n",
      "Epoch:  936  Loss:  0.3883717177358605  Validation Loss:  0.4137793023671423\n",
      "Epoch:  937  Loss:  0.38837930674736315  Validation Loss:  0.4138380933020796\n",
      "Epoch:  938  Loss:  0.38838751763987117  Validation Loss:  0.4138974957168102\n",
      "Epoch:  939  Loss:  0.38839638682864824  Validation Loss:  0.4139575638941356\n",
      "Epoch:  940  Loss:  0.388405930713789  Validation Loss:  0.41401826962828636\n",
      "Epoch:  941  Loss:  0.38841613051453994  Validation Loss:  0.414079555443355\n",
      "Epoch:  942  Loss:  0.3884269486693941  Validation Loss:  0.4141414043094431\n",
      "Epoch:  943  Loss:  0.38843841215915226  Validation Loss:  0.4142038875392505\n",
      "Epoch:  944  Loss:  0.3884504880954528  Validation Loss:  0.41426687740853857\n",
      "Epoch:  945  Loss:  0.38846287307654614  Validation Loss:  0.41433001841817585\n",
      "Epoch:  946  Loss:  0.3884754430436524  Validation Loss:  0.41439368283110006\n",
      "Epoch:  947  Loss:  0.3884886362143522  Validation Loss:  0.4144579507410526\n",
      "Epoch:  948  Loss:  0.388502427547641  Validation Loss:  0.41452277691236566\n",
      "Epoch:  949  Loss:  0.38851684869746483  Validation Loss:  0.41458825474338873\n",
      "Epoch:  950  Loss:  0.38853192250051444  Validation Loss:  0.414654337401901\n",
      "Epoch:  951  Loss:  0.388547591909149  Validation Loss:  0.4147209964160408\n",
      "Epoch:  952  Loss:  0.38856394536043765  Validation Loss:  0.414788318797946\n",
      "Epoch:  953  Loss:  0.38858093559389284  Validation Loss:  0.4148561991751194\n",
      "Epoch:  954  Loss:  0.38859843202596583  Validation Loss:  0.4149244515491383\n",
      "Epoch:  955  Loss:  0.38861618556919886  Validation Loss:  0.4149931073188782\n",
      "Epoch:  956  Loss:  0.3886343008844105  Validation Loss:  0.41506220240678104\n",
      "Epoch:  957  Loss:  0.3886529738028374  Validation Loss:  0.4151318993951593\n",
      "Epoch:  958  Loss:  0.3886722707184109  Validation Loss:  0.4152021650224924\n",
      "Epoch:  959  Loss:  0.38869214816206304  Validation Loss:  0.41527299263647627\n",
      "Epoch:  960  Loss:  0.3887126327619045  Validation Loss:  0.4153444011296545\n",
      "Epoch:  961  Loss:  0.3887337071479425  Validation Loss:  0.41541633888014723\n",
      "Epoch:  962  Loss:  0.3887553808428127  Validation Loss:  0.4154888622994934\n",
      "Epoch:  963  Loss:  0.38877763453672626  Validation Loss:  0.4155619269503014\n",
      "Epoch:  964  Loss:  0.3888004815437385  Validation Loss:  0.4156355589096035\n",
      "Epoch:  965  Loss:  0.3888239036121312  Validation Loss:  0.4157096818089485\n",
      "Epoch:  966  Loss:  0.38884787058689185  Validation Loss:  0.415784286867295\n",
      "Epoch:  967  Loss:  0.38887237894111837  Validation Loss:  0.41585932060011793\n",
      "Epoch:  968  Loss:  0.38889740601446504  Validation Loss:  0.4159347236688648\n",
      "Epoch:  969  Loss:  0.38892278101669964  Validation Loss:  0.41601033854697433\n",
      "Epoch:  970  Loss:  0.38894813582742005  Validation Loss:  0.41608624745692524\n",
      "Epoch:  971  Loss:  0.38897396139139256  Validation Loss:  0.41616265129830154\n",
      "Epoch:  972  Loss:  0.38900032498427395  Validation Loss:  0.41623954607972075\n",
      "Epoch:  973  Loss:  0.38902725173524144  Validation Loss:  0.4163169405822243\n",
      "Epoch:  974  Loss:  0.38905453496783443  Validation Loss:  0.41639443540147375\n",
      "Epoch:  975  Loss:  0.3890817713808026  Validation Loss:  0.416472195780703\n",
      "Epoch:  976  Loss:  0.389109488951384  Validation Loss:  0.4165504103792565\n",
      "Epoch:  977  Loss:  0.38913770531408887  Validation Loss:  0.4166290736091988\n",
      "Epoch:  978  Loss:  0.38916641835277604  Validation Loss:  0.4167081423635994\n",
      "Epoch:  979  Loss:  0.38919553292926246  Validation Loss:  0.41678741494459765\n",
      "Epoch:  980  Loss:  0.38922469899851897  Validation Loss:  0.4168668423912355\n",
      "Epoch:  981  Loss:  0.3892541504823245  Validation Loss:  0.4169466740318707\n",
      "Epoch:  982  Loss:  0.38928409476251996  Validation Loss:  0.4170269127935171\n",
      "Epoch:  983  Loss:  0.3893145031830263  Validation Loss:  0.4171075451054743\n",
      "Epoch:  984  Loss:  0.38934538315033773  Validation Loss:  0.4171885653798069\n",
      "Epoch:  985  Loss:  0.3893766924298021  Validation Loss:  0.4172698711710317\n",
      "Epoch:  986  Loss:  0.3894083916964616  Validation Loss:  0.4173515146332128\n",
      "Epoch:  987  Loss:  0.3894404568792095  Validation Loss:  0.4174333017851625\n",
      "Epoch:  988  Loss:  0.3894725657955429  Validation Loss:  0.41751515226704733\n",
      "Epoch:  989  Loss:  0.38950480370831914  Validation Loss:  0.41759722945945604\n",
      "Epoch:  990  Loss:  0.3895373326786876  Validation Loss:  0.4176793409777539\n",
      "Epoch:  991  Loss:  0.38956967093182737  Validation Loss:  0.4177613726684025\n",
      "Epoch:  992  Loss:  0.3896022364056322  Validation Loss:  0.4178436579448836\n",
      "Epoch:  993  Loss:  0.3896351483975642  Validation Loss:  0.41792616434395313\n",
      "Epoch:  994  Loss:  0.38966825921859966  Validation Loss:  0.4180085515337331\n",
      "Epoch:  995  Loss:  0.3897010986445218  Validation Loss:  0.4180909280798265\n",
      "Epoch:  996  Loss:  0.38973417119867  Validation Loss:  0.41817345150879454\n",
      "Epoch:  997  Loss:  0.38976753048995544  Validation Loss:  0.4182560930826834\n",
      "Epoch:  998  Loss:  0.3898011458343303  Validation Loss:  0.4183388091623783\n",
      "Epoch:  999  Loss:  0.38983486407607265  Validation Loss:  0.41842126393956797\n",
      "Epoch:  1000  Loss:  0.38986815970677596  Validation Loss:  0.4185034983924457\n",
      "Epoch:  1001  Loss:  0.3899011950521074  Validation Loss:  0.41858514212071896\n",
      "Epoch:  1002  Loss:  0.3899339605012589  Validation Loss:  0.41866667275982244\n",
      "Epoch:  1003  Loss:  0.3899667315934537  Validation Loss:  0.41874779521354605\n",
      "Epoch:  1004  Loss:  0.38999899463540705  Validation Loss:  0.4188285171985626\n",
      "Epoch:  1005  Loss:  0.3900312326363558  Validation Loss:  0.4189089677695717\n",
      "Epoch:  1006  Loss:  0.39006343192955445  Validation Loss:  0.4189890529960394\n",
      "Epoch:  1007  Loss:  0.3900953994171154  Validation Loss:  0.419068413653544\n",
      "Epoch:  1008  Loss:  0.39012631562334543  Validation Loss:  0.4191465135663748\n",
      "Epoch:  1009  Loss:  0.39015646243589164  Validation Loss:  0.41922389449817793\n",
      "Epoch:  1010  Loss:  0.39018614942858204  Validation Loss:  0.41930019004004343\n",
      "Epoch:  1011  Loss:  0.3902148168820601  Validation Loss:  0.4193753530936582\n",
      "Epoch:  1012  Loss:  0.39024288908264343  Validation Loss:  0.41944930808884756\n",
      "Epoch:  1013  Loss:  0.3902696871016858  Validation Loss:  0.4195212205605848\n",
      "Epoch:  1014  Loss:  0.3902948392037104  Validation Loss:  0.41959129699638914\n",
      "Epoch:  1015  Loss:  0.3903187610341247  Validation Loss:  0.41965912761432783\n",
      "Epoch:  1016  Loss:  0.39034102398615617  Validation Loss:  0.4197247821305479\n",
      "Epoch:  1017  Loss:  0.39036165433522513  Validation Loss:  0.4197873837713684\n",
      "Epoch:  1018  Loss:  0.39037949719725273  Validation Loss:  0.4198466124279158\n",
      "Epoch:  1019  Loss:  0.3903948151500973  Validation Loss:  0.4199018401226827\n",
      "Epoch:  1020  Loss:  0.3904070379818685  Validation Loss:  0.41995224143777576\n",
      "Epoch:  1021  Loss:  0.3904150531313123  Validation Loss:  0.419997043375458\n",
      "Epoch:  1022  Loss:  0.3904188665941622  Validation Loss:  0.42003526645047323\n",
      "Epoch:  1023  Loss:  0.39041738370819207  Validation Loss:  0.42006530133741243\n",
      "Epoch:  1024  Loss:  0.39040926989366315  Validation Loss:  0.42008585881974014\n",
      "Epoch:  1025  Loss:  0.3903936789585994  Validation Loss:  0.4200949328286307\n",
      "Epoch:  1026  Loss:  0.3903688926844907  Validation Loss:  0.4200907251132386\n",
      "Epoch:  1027  Loss:  0.3903338391576293  Validation Loss:  0.4200712455702679\n",
      "Epoch:  1028  Loss:  0.39028733078191974  Validation Loss:  0.4200355929455587\n",
      "Epoch:  1029  Loss:  0.3902286202949885  Validation Loss:  0.4199832073811974\n",
      "Epoch:  1030  Loss:  0.3901579393261283  Validation Loss:  0.4199154201362814\n",
      "Epoch:  1031  Loss:  0.3900766021753909  Validation Loss:  0.41983488627842497\n",
      "Epoch:  1032  Loss:  0.38998646381691365  Validation Loss:  0.41974462675196783\n",
      "Epoch:  1033  Loss:  0.38988939827010477  Validation Loss:  0.41964754169540747\n",
      "Epoch:  1034  Loss:  0.38978704219386423  Validation Loss:  0.4195457531937531\n",
      "Epoch:  1035  Loss:  0.38968045268891127  Validation Loss:  0.41944083225514206\n",
      "Epoch:  1036  Loss:  0.38957035841321097  Validation Loss:  0.41933372457112583\n",
      "Epoch:  1037  Loss:  0.3894570163015783  Validation Loss:  0.4192248149109738\n",
      "Epoch:  1038  Loss:  0.38934025944337336  Validation Loss:  0.4191140995493957\n",
      "Epoch:  1039  Loss:  0.3892194520263277  Validation Loss:  0.41900104177849634\n",
      "Epoch:  1040  Loss:  0.3890938058760039  Validation Loss:  0.41888505779206753\n",
      "Epoch:  1041  Loss:  0.3889624643960648  Validation Loss:  0.41876563536269323\n",
      "Epoch:  1042  Loss:  0.3888243049735854  Validation Loss:  0.4186419469437429\n",
      "Epoch:  1043  Loss:  0.3886778350236148  Validation Loss:  0.4185129909643105\n",
      "Epoch:  1044  Loss:  0.38852138376447576  Validation Loss:  0.4183775471257312\n",
      "Epoch:  1045  Loss:  0.38835312055765525  Validation Loss:  0.4182343663913863\n",
      "Epoch:  1046  Loss:  0.3881711143361041  Validation Loss:  0.41808229205863817\n",
      "Epoch:  1047  Loss:  0.38797385629112197  Validation Loss:  0.41792060860565733\n",
      "Epoch:  1048  Loss:  0.38776052915132964  Validation Loss:  0.4177491960248777\n",
      "Epoch:  1049  Loss:  0.3875316836424833  Validation Loss:  0.41756907664239407\n",
      "Epoch:  1050  Loss:  0.3872893024125748  Validation Loss:  0.41738197659807547\n",
      "Epoch:  1051  Loss:  0.38703646347720244  Validation Loss:  0.41719026544264387\n",
      "Epoch:  1052  Loss:  0.3867767611904257  Validation Loss:  0.4169962387531996\n",
      "Epoch:  1053  Loss:  0.38651359619120873  Validation Loss:  0.41680209817630903\n",
      "Epoch:  1054  Loss:  0.38624967493601803  Validation Loss:  0.41660926969988005\n",
      "Epoch:  1055  Loss:  0.385986915089675  Validation Loss:  0.4164185393601656\n",
      "Epoch:  1056  Loss:  0.3857262218315926  Validation Loss:  0.4162303555224623\n",
      "Epoch:  1057  Loss:  0.3854681567327511  Validation Loss:  0.4160448083920138\n",
      "Epoch:  1058  Loss:  0.3852133042889939  Validation Loss:  0.4158622920513153\n",
      "Epoch:  1059  Loss:  0.3849617151113657  Validation Loss:  0.415682956044163\n",
      "Epoch:  1060  Loss:  0.3847136122764215  Validation Loss:  0.4155066039945398\n",
      "Epoch:  1061  Loss:  0.3844690329048055  Validation Loss:  0.41533344904226915\n",
      "Epoch:  1062  Loss:  0.3842276961669414  Validation Loss:  0.41516321684632984\n",
      "Epoch:  1063  Loss:  0.38398973970018196  Validation Loss:  0.4149958597762244\n",
      "Epoch:  1064  Loss:  0.3837548562231854  Validation Loss:  0.41483135601239546\n",
      "Epoch:  1065  Loss:  0.3835230784479683  Validation Loss:  0.41466937879366533\n",
      "Epoch:  1066  Loss:  0.3832941372719037  Validation Loss:  0.41451016600642887\n",
      "Epoch:  1067  Loss:  0.38306816742265015  Validation Loss:  0.4143532884440252\n",
      "Epoch:  1068  Loss:  0.38284467213605283  Validation Loss:  0.41419865377247334\n",
      "Epoch:  1069  Loss:  0.382623996343133  Validation Loss:  0.414046494822417\n",
      "Epoch:  1070  Loss:  0.38240580287205395  Validation Loss:  0.4138965726430927\n",
      "Epoch:  1071  Loss:  0.3821901065358043  Validation Loss:  0.41374919111175196\n",
      "Epoch:  1072  Loss:  0.3819771008731345  Validation Loss:  0.4136040434241295\n",
      "Epoch:  1073  Loss:  0.38176637200208813  Validation Loss:  0.41346096832837376\n",
      "Epoch:  1074  Loss:  0.38155778545952407  Validation Loss:  0.4133201377200229\n",
      "Epoch:  1075  Loss:  0.3813517168605116  Validation Loss:  0.41318112798035145\n",
      "Epoch:  1076  Loss:  0.3811477684586711  Validation Loss:  0.4130442304802792\n",
      "Epoch:  1077  Loss:  0.38094581839953656  Validation Loss:  0.4129092137196234\n",
      "Epoch:  1078  Loss:  0.38074599982366053  Validation Loss:  0.4127763845026493\n",
      "Epoch:  1079  Loss:  0.38054855564642237  Validation Loss:  0.4126456292080028\n",
      "Epoch:  1080  Loss:  0.380353087416062  Validation Loss:  0.41251653007098604\n",
      "Epoch:  1081  Loss:  0.3801595633904609  Validation Loss:  0.4123892533992018\n",
      "Epoch:  1082  Loss:  0.37996782485902664  Validation Loss:  0.41226376353629995\n",
      "Epoch:  1083  Loss:  0.37977806456695645  Validation Loss:  0.41214026963072165\n",
      "Epoch:  1084  Loss:  0.3795903741255314  Validation Loss:  0.41201849920409067\n",
      "Epoch:  1085  Loss:  0.3794046165146066  Validation Loss:  0.4118985246334757\n",
      "Epoch:  1086  Loss:  0.3792208231236102  Validation Loss:  0.4117803903562682\n",
      "Epoch:  1087  Loss:  0.37903877537278735  Validation Loss:  0.4116636458784342\n",
      "Epoch:  1088  Loss:  0.37885818670134574  Validation Loss:  0.41154846735298634\n",
      "Epoch:  1089  Loss:  0.3786794682578928  Validation Loss:  0.4114351397646325\n",
      "Epoch:  1090  Loss:  0.3785025251687631  Validation Loss:  0.4113231836152928\n",
      "Epoch:  1091  Loss:  0.37832728716043323  Validation Loss:  0.4112131108662912\n",
      "Epoch:  1092  Loss:  0.3781539474189634  Validation Loss:  0.41110447315233095\n",
      "Epoch:  1093  Loss:  0.3779823871759268  Validation Loss:  0.4109976424702576\n",
      "Epoch:  1094  Loss:  0.37781253915566665  Validation Loss:  0.4108920767903328\n",
      "Epoch:  1095  Loss:  0.37764416348475677  Validation Loss:  0.41078800708055496\n",
      "Epoch:  1096  Loss:  0.3774772711847661  Validation Loss:  0.4106853473931551\n",
      "Epoch:  1097  Loss:  0.377311861197624  Validation Loss:  0.4105840168361153\n",
      "Epoch:  1098  Loss:  0.3771481350416968  Validation Loss:  0.41048408299684525\n",
      "Epoch:  1099  Loss:  0.37698592488053284  Validation Loss:  0.4103852968130793\n",
      "Epoch:  1100  Loss:  0.376825003008518  Validation Loss:  0.41028767531471594\n",
      "Epoch:  1101  Loss:  0.37666555494070053  Validation Loss:  0.41019129992595743\n",
      "Epoch:  1102  Loss:  0.37650766056141205  Validation Loss:  0.4100959777299847\n",
      "Epoch:  1103  Loss:  0.3763510925618149  Validation Loss:  0.41000165125089033\n",
      "Epoch:  1104  Loss:  0.376195969886681  Validation Loss:  0.4099082284207855\n",
      "Epoch:  1105  Loss:  0.3760420585260589  Validation Loss:  0.40981553787631647\n",
      "Epoch:  1106  Loss:  0.37588917922515136  Validation Loss:  0.4097233973443508\n",
      "Epoch:  1107  Loss:  0.3757373003740988  Validation Loss:  0.40963167351271423\n",
      "Epoch:  1108  Loss:  0.3755862642762929  Validation Loss:  0.4095400518604687\n",
      "Epoch:  1109  Loss:  0.37543590446195657  Validation Loss:  0.40944827161729336\n",
      "Epoch:  1110  Loss:  0.375286238389255  Validation Loss:  0.4093561936169863\n",
      "Epoch:  1111  Loss:  0.3751372291579754  Validation Loss:  0.4092634019574949\n",
      "Epoch:  1112  Loss:  0.3749885130563431  Validation Loss:  0.40916952916554045\n",
      "Epoch:  1113  Loss:  0.37483985819054777  Validation Loss:  0.4090742202741759\n",
      "Epoch:  1114  Loss:  0.37469109668005146  Validation Loss:  0.4089773150959185\n",
      "Epoch:  1115  Loss:  0.37454220934732424  Validation Loss:  0.4088789083595787\n",
      "Epoch:  1116  Loss:  0.3743934350958943  Validation Loss:  0.40877959611160414\n",
      "Epoch:  1117  Loss:  0.37424520434007136  Validation Loss:  0.40867981660578934\n",
      "Epoch:  1118  Loss:  0.37409763509881566  Validation Loss:  0.4085801746696234\n",
      "Epoch:  1119  Loss:  0.3739510907312117  Validation Loss:  0.4084811532603843\n",
      "Epoch:  1120  Loss:  0.373805799824599  Validation Loss:  0.40838323161005974\n",
      "Epoch:  1121  Loss:  0.37366193793052754  Validation Loss:  0.4082866233906576\n",
      "Epoch:  1122  Loss:  0.37351951439528774  Validation Loss:  0.40819158165582586\n",
      "Epoch:  1123  Loss:  0.3733786340119571  Validation Loss:  0.40809813381305765\n",
      "Epoch:  1124  Loss:  0.3732393749895886  Validation Loss:  0.40800649566309793\n",
      "Epoch:  1125  Loss:  0.3731017357410764  Validation Loss:  0.4079164761517729\n",
      "Epoch:  1126  Loss:  0.37296569193079626  Validation Loss:  0.4078282993286848\n",
      "Epoch:  1127  Loss:  0.372831325074272  Validation Loss:  0.40774176376206533\n",
      "Epoch:  1128  Loss:  0.372698502824504  Validation Loss:  0.40765696710773874\n",
      "Epoch:  1129  Loss:  0.37256737529526096  Validation Loss:  0.4075738452374935\n",
      "Epoch:  1130  Loss:  0.3724379606941748  Validation Loss:  0.40749238883810385\n",
      "Epoch:  1131  Loss:  0.37231019628647516  Validation Loss:  0.40741255985839026\n",
      "Epoch:  1132  Loss:  0.3721840067287169  Validation Loss:  0.4073343218437263\n",
      "Epoch:  1133  Loss:  0.372059352387338  Validation Loss:  0.4072576614895037\n",
      "Epoch:  1134  Loss:  0.3719362078686438  Validation Loss:  0.4071825391479901\n",
      "Epoch:  1135  Loss:  0.3718145609166495  Validation Loss:  0.40710886009037495\n",
      "Epoch:  1136  Loss:  0.37169432133083513  Validation Loss:  0.40703663629080566\n",
      "Epoch:  1137  Loss:  0.3715755492007944  Validation Loss:  0.4069658366164991\n",
      "Epoch:  1138  Loss:  0.37145817513472934  Validation Loss:  0.4068963410598891\n",
      "Epoch:  1139  Loss:  0.3713421640399645  Validation Loss:  0.4068282400923116\n",
      "Epoch:  1140  Loss:  0.3712276488366212  Validation Loss:  0.4067615307867527\n",
      "Epoch:  1141  Loss:  0.3711145972094592  Validation Loss:  0.4066959965441908\n",
      "Epoch:  1142  Loss:  0.37100291878161346  Validation Loss:  0.4066315197518894\n",
      "Epoch:  1143  Loss:  0.3708925197374891  Validation Loss:  0.4065681972673961\n",
      "Epoch:  1144  Loss:  0.3707834787270021  Validation Loss:  0.4065058348434312\n",
      "Epoch:  1145  Loss:  0.3706756101910179  Validation Loss:  0.4064442270568439\n",
      "Epoch:  1146  Loss:  0.3705687489823477  Validation Loss:  0.40638315624424387\n",
      "Epoch:  1147  Loss:  0.37046276667767025  Validation Loss:  0.40632250000323566\n",
      "Epoch:  1148  Loss:  0.37035763603166716  Validation Loss:  0.4062623315091644\n",
      "Epoch:  1149  Loss:  0.37025335364969525  Validation Loss:  0.40620244214577333\n",
      "Epoch:  1150  Loss:  0.3701497654502208  Validation Loss:  0.40614262755428043\n",
      "Epoch:  1151  Loss:  0.3700468404846784  Validation Loss:  0.4060829688927957\n",
      "Epoch:  1152  Loss:  0.369944678388051  Validation Loss:  0.4060236771724054\n",
      "Epoch:  1153  Loss:  0.36984340701053836  Validation Loss:  0.40596500651112627\n",
      "Epoch:  1154  Loss:  0.36974319414450574  Validation Loss:  0.40590743055301054\n",
      "Epoch:  1155  Loss:  0.36964426992031246  Validation Loss:  0.40585110442978994\n",
      "Epoch:  1156  Loss:  0.36954672356858054  Validation Loss:  0.40579624979623724\n",
      "Epoch:  1157  Loss:  0.3694505804830049  Validation Loss:  0.4057427636746849\n",
      "Epoch:  1158  Loss:  0.3693558356818363  Validation Loss:  0.40569075888821055\n",
      "Epoch:  1159  Loss:  0.3692625169394284  Validation Loss:  0.4056401957890817\n",
      "Epoch:  1160  Loss:  0.36917070233257565  Validation Loss:  0.40559120955211775\n",
      "Epoch:  1161  Loss:  0.3690804580788641  Validation Loss:  0.40554373897612095\n",
      "Epoch:  1162  Loss:  0.36899172937905295  Validation Loss:  0.40549780933984686\n",
      "Epoch:  1163  Loss:  0.368904521303064  Validation Loss:  0.4054535864187138\n",
      "Epoch:  1164  Loss:  0.3688188978641696  Validation Loss:  0.4054111186414957\n",
      "Epoch:  1165  Loss:  0.3687348353880397  Validation Loss:  0.4053703040948936\n",
      "Epoch:  1166  Loss:  0.36865228679053175  Validation Loss:  0.4053310938179493\n",
      "Epoch:  1167  Loss:  0.3685711971401463  Validation Loss:  0.4052933749875852\n",
      "Epoch:  1168  Loss:  0.3684915861875348  Validation Loss:  0.40525726574872223\n",
      "Epoch:  1169  Loss:  0.3684134541972149  Validation Loss:  0.40522265886621817\n",
      "Epoch:  1170  Loss:  0.3683367999347709  Validation Loss:  0.40518965146371294\n",
      "Epoch:  1171  Loss:  0.3682615973011276  Validation Loss:  0.4051580838859081\n",
      "Epoch:  1172  Loss:  0.36818782425314717  Validation Loss:  0.4051280631018536\n",
      "Epoch:  1173  Loss:  0.3681155149576932  Validation Loss:  0.40509958166096893\n",
      "Epoch:  1174  Loss:  0.3680446548222085  Validation Loss:  0.40507260390690397\n",
      "Epoch:  1175  Loss:  0.3679752453015401  Validation Loss:  0.4050471412816218\n",
      "Epoch:  1176  Loss:  0.3679072784601584  Validation Loss:  0.4050231932529381\n",
      "Epoch:  1177  Loss:  0.3678407528873026  Validation Loss:  0.4050008039921522\n",
      "Epoch:  1178  Loss:  0.36777570442511487  Validation Loss:  0.40497999052916256\n",
      "Epoch:  1179  Loss:  0.36771220202453037  Validation Loss:  0.40496089096580234\n",
      "Epoch:  1180  Loss:  0.36765016289152336  Validation Loss:  0.4049431064299175\n",
      "Epoch:  1181  Loss:  0.36758945631028633  Validation Loss:  0.40492644160985947\n",
      "Epoch:  1182  Loss:  0.36753007967972895  Validation Loss:  0.40491093774991377\n",
      "Epoch:  1183  Loss:  0.3674720871377979  Validation Loss:  0.40489686706236433\n",
      "Epoch:  1184  Loss:  0.3674155313235063  Validation Loss:  0.4048843128340585\n",
      "Epoch:  1185  Loss:  0.36736038900338686  Validation Loss:  0.40487320721149445\n",
      "Epoch:  1186  Loss:  0.3673066342547095  Validation Loss:  0.40486350895038675\n",
      "Epoch:  1187  Loss:  0.36725425680537194  Validation Loss:  0.4048552294926984\n",
      "Epoch:  1188  Loss:  0.3672032613726057  Validation Loss:  0.4048483603234802\n",
      "Epoch:  1189  Loss:  0.367153637111187  Validation Loss:  0.4048429397600038\n",
      "Epoch:  1190  Loss:  0.3671054327364504  Validation Loss:  0.4048389989350523\n",
      "Epoch:  1191  Loss:  0.3670586222815796  Validation Loss:  0.4048365309302296\n",
      "Epoch:  1192  Loss:  0.3670132090971315  Validation Loss:  0.40483548146273407\n",
      "Epoch:  1193  Loss:  0.36696916351304254  Validation Loss:  0.4048358252538102\n",
      "Epoch:  1194  Loss:  0.3669264875131951  Validation Loss:  0.4048375780028956\n",
      "Epoch:  1195  Loss:  0.36688517391152636  Validation Loss:  0.4048407410404512\n",
      "Epoch:  1196  Loss:  0.36684522632311084  Validation Loss:  0.40484530106186867\n",
      "Epoch:  1197  Loss:  0.3668066450565524  Validation Loss:  0.40485125673668726\n",
      "Epoch:  1198  Loss:  0.3667694227053569  Validation Loss:  0.40485857480338644\n",
      "Epoch:  1199  Loss:  0.3667334924347302  Validation Loss:  0.4048671757004091\n",
      "Epoch:  1200  Loss:  0.3666988422972916  Validation Loss:  0.4048771999244179\n",
      "Epoch:  1201  Loss:  0.36666559507331903  Validation Loss:  0.4048887648220573\n",
      "Epoch:  1202  Loss:  0.366633787618939  Validation Loss:  0.4049018562904426\n",
      "Epoch:  1203  Loss:  0.3666034192728573  Validation Loss:  0.40491632159267155\n",
      "Epoch:  1204  Loss:  0.36657440494856186  Validation Loss:  0.4049321176218135\n",
      "Epoch:  1205  Loss:  0.3665467506858724  Validation Loss:  0.404949228944523\n",
      "Epoch:  1206  Loss:  0.3665204346620825  Validation Loss:  0.4049677380493709\n",
      "Epoch:  1207  Loss:  0.3664954681191924  Validation Loss:  0.40498761859323296\n",
      "Epoch:  1208  Loss:  0.36647182376779747  Validation Loss:  0.4050088737692152\n",
      "Epoch:  1209  Loss:  0.36644951972735706  Validation Loss:  0.4050314732428108\n",
      "Epoch:  1210  Loss:  0.3664284723221198  Validation Loss:  0.40505518870694296\n",
      "Epoch:  1211  Loss:  0.36640857556867884  Validation Loss:  0.40508017635771204\n",
      "Epoch:  1212  Loss:  0.3663900132186314  Validation Loss:  0.40510657855442594\n",
      "Epoch:  1213  Loss:  0.36637280281831525  Validation Loss:  0.40513440115111216\n",
      "Epoch:  1214  Loss:  0.3663569434419186  Validation Loss:  0.40516361807073864\n",
      "Epoch:  1215  Loss:  0.3663424201001077  Validation Loss:  0.4051941790218864\n",
      "Epoch:  1216  Loss:  0.3663292132626624  Validation Loss:  0.4052261066223894\n",
      "Epoch:  1217  Loss:  0.3663173097477862  Validation Loss:  0.40525928379169535\n",
      "Epoch:  1218  Loss:  0.3663065528728553  Validation Loss:  0.40529352080609116\n",
      "Epoch:  1219  Loss:  0.366297030325472  Validation Loss:  0.40532911968018326\n",
      "Epoch:  1220  Loss:  0.36628882595773277  Validation Loss:  0.4053660798817873\n",
      "Epoch:  1221  Loss:  0.36628193549326893  Validation Loss:  0.40540436149707865\n",
      "Epoch:  1222  Loss:  0.3662763602987549  Validation Loss:  0.4054440068347113\n",
      "Epoch:  1223  Loss:  0.3662720479996952  Validation Loss:  0.4054847399571112\n",
      "Epoch:  1224  Loss:  0.3662688359177324  Validation Loss:  0.40552655208323685\n",
      "Epoch:  1225  Loss:  0.36626685044821905  Validation Loss:  0.4055695382079908\n",
      "Epoch:  1226  Loss:  0.3662660959997826  Validation Loss:  0.40561370870896746\n",
      "Epoch:  1227  Loss:  0.3662665683401407  Validation Loss:  0.40565899333783556\n",
      "Epoch:  1228  Loss:  0.36626815015571357  Validation Loss:  0.4057053934250559\n",
      "Epoch:  1229  Loss:  0.3662709735730696  Validation Loss:  0.40575312450528145\n",
      "Epoch:  1230  Loss:  0.36627509021723764  Validation Loss:  0.40580214586641106\n",
      "Epoch:  1231  Loss:  0.3662803410690212  Validation Loss:  0.40585214724498136\n",
      "Epoch:  1232  Loss:  0.3662867642189624  Validation Loss:  0.4059034660458565\n",
      "Epoch:  1233  Loss:  0.3662944527331894  Validation Loss:  0.40595596842467785\n",
      "Epoch:  1234  Loss:  0.3663032630667884  Validation Loss:  0.4060096088796854\n",
      "Epoch:  1235  Loss:  0.36631331209247636  Validation Loss:  0.4060644879937172\n",
      "Epoch:  1236  Loss:  0.36632447063746537  Validation Loss:  0.40612024201878477\n",
      "Epoch:  1237  Loss:  0.3663367235360766  Validation Loss:  0.40617706520216806\n",
      "Epoch:  1238  Loss:  0.3663500570333921  Validation Loss:  0.4062349011323282\n",
      "Epoch:  1239  Loss:  0.366364512261907  Validation Loss:  0.406293768967901\n",
      "Epoch:  1240  Loss:  0.36638004557620846  Validation Loss:  0.40635374268250807\n",
      "Epoch:  1241  Loss:  0.366396647806351  Validation Loss:  0.4064146855047771\n",
      "Epoch:  1242  Loss:  0.36641427614456096  Validation Loss:  0.4064765184053353\n",
      "Epoch:  1243  Loss:  0.3664328835507822  Validation Loss:  0.4065390621711101\n",
      "Epoch:  1244  Loss:  0.36645233190271276  Validation Loss:  0.4066022051764386\n",
      "Epoch:  1245  Loss:  0.3664726503854673  Validation Loss:  0.4066660502659423\n",
      "Epoch:  1246  Loss:  0.36649382740435515  Validation Loss:  0.40673061327210497\n",
      "Epoch:  1247  Loss:  0.3665158478377839  Validation Loss:  0.40679586745266405\n",
      "Epoch:  1248  Loss:  0.366538693874898  Validation Loss:  0.4068617218040994\n",
      "Epoch:  1249  Loss:  0.36656225014191407  Validation Loss:  0.40692802678261486\n",
      "Epoch:  1250  Loss:  0.36658637155089857  Validation Loss:  0.4069944678672722\n",
      "Epoch:  1251  Loss:  0.3666109600098881  Validation Loss:  0.40706098319164347\n",
      "Epoch:  1252  Loss:  0.3666359630562145  Validation Loss:  0.4071274647223098\n",
      "Epoch:  1253  Loss:  0.3666611987899041  Validation Loss:  0.4071936784312129\n",
      "Epoch:  1254  Loss:  0.36668656250605214  Validation Loss:  0.40725941783083336\n",
      "Epoch:  1255  Loss:  0.3667117896870043  Validation Loss:  0.40732425384755644\n",
      "Epoch:  1256  Loss:  0.36673666735196253  Validation Loss:  0.4073879492602178\n",
      "Epoch:  1257  Loss:  0.36676099539332135  Validation Loss:  0.4074501936723079\n",
      "Epoch:  1258  Loss:  0.36678458022824406  Validation Loss:  0.40751062985509634\n",
      "Epoch:  1259  Loss:  0.3668072877021936  Validation Loss:  0.4075692280062607\n",
      "Epoch:  1260  Loss:  0.3668293220227992  Validation Loss:  0.407626555301249\n",
      "Epoch:  1261  Loss:  0.3668511036849586  Validation Loss:  0.40768328761415823\n",
      "Epoch:  1262  Loss:  0.3668730276576161  Validation Loss:  0.4077399651120816\n",
      "Epoch:  1263  Loss:  0.36689550231194357  Validation Loss:  0.40779712290636133\n",
      "Epoch:  1264  Loss:  0.3669188994715905  Validation Loss:  0.4078552881255746\n",
      "Epoch:  1265  Loss:  0.3669434428744062  Validation Loss:  0.40791462135634254\n",
      "Epoch:  1266  Loss:  0.36696926857063755  Validation Loss:  0.4079753729913916\n",
      "Epoch:  1267  Loss:  0.36699649149320535  Validation Loss:  0.4080375794853483\n",
      "Epoch:  1268  Loss:  0.3670251415766908  Validation Loss:  0.4081013861245343\n",
      "Epoch:  1269  Loss:  0.36705531091732385  Validation Loss:  0.4081667616431202\n",
      "Epoch:  1270  Loss:  0.36708688841768977  Validation Loss:  0.4082335636817983\n",
      "Epoch:  1271  Loss:  0.3671198384119914  Validation Loss:  0.40830164761947735\n",
      "Epoch:  1272  Loss:  0.36715414313345973  Validation Loss:  0.40837124455720186\n",
      "Epoch:  1273  Loss:  0.3671898956482227  Validation Loss:  0.40844246545540436\n",
      "Epoch:  1274  Loss:  0.36722715291574864  Validation Loss:  0.4085152472502419\n",
      "Epoch:  1275  Loss:  0.36726582786564294  Validation Loss:  0.40858957464141504\n",
      "Epoch:  1276  Loss:  0.36730597684016597  Validation Loss:  0.4086654291355184\n",
      "Epoch:  1277  Loss:  0.3673475138269938  Validation Loss:  0.4087428117969206\n",
      "Epoch:  1278  Loss:  0.36739052012121887  Validation Loss:  0.40882168976323946\n",
      "Epoch:  1279  Loss:  0.3674348748382732  Validation Loss:  0.4089019534045032\n",
      "Epoch:  1280  Loss:  0.36748056012321506  Validation Loss:  0.408983353259308\n",
      "Epoch:  1281  Loss:  0.36752728932707973  Validation Loss:  0.4090655270431723\n",
      "Epoch:  1282  Loss:  0.3675750727660557  Validation Loss:  0.40914890449494123\n",
      "Epoch:  1283  Loss:  0.3676242184709515  Validation Loss:  0.4092338074530874\n",
      "Epoch:  1284  Loss:  0.3676747195202218  Validation Loss:  0.40932004393211435\n",
      "Epoch:  1285  Loss:  0.3677265085941236  Validation Loss:  0.4094076247087547\n",
      "Epoch:  1286  Loss:  0.36777961104226536  Validation Loss:  0.4094967015885881\n",
      "Epoch:  1287  Loss:  0.3678341056027356  Validation Loss:  0.4095869653725198\n",
      "Epoch:  1288  Loss:  0.3678895724419306  Validation Loss:  0.40967795212886166\n",
      "Epoch:  1289  Loss:  0.36794613010784577  Validation Loss:  0.4097701734197991\n",
      "Epoch:  1290  Loss:  0.3680039516831996  Validation Loss:  0.40986377998654333\n",
      "Epoch:  1291  Loss:  0.3680631420051558  Validation Loss:  0.4099588692188263\n",
      "Epoch:  1292  Loss:  0.3681236478174932  Validation Loss:  0.41005528731537716\n",
      "Epoch:  1293  Loss:  0.3681854056359748  Validation Loss:  0.4101528988352844\n",
      "Epoch:  1294  Loss:  0.3682481904442494  Validation Loss:  0.410251208048846\n",
      "Epoch:  1295  Loss:  0.3683119651216727  Validation Loss:  0.41035063391817467\n",
      "Epoch:  1296  Loss:  0.3683769580792393  Validation Loss:  0.41045146635068314\n",
      "Epoch:  1297  Loss:  0.3684433201801847  Validation Loss:  0.4105537263676524\n",
      "Epoch:  1298  Loss:  0.36851094566153353  Validation Loss:  0.41065720482064144\n",
      "Epoch:  1299  Loss:  0.3685795955315849  Validation Loss:  0.41076137670981033\n",
      "Epoch:  1300  Loss:  0.3686492139330277  Validation Loss:  0.4108666389116219\n",
      "Epoch:  1301  Loss:  0.3687200130971931  Validation Loss:  0.41097314975091387\n",
      "Epoch:  1302  Loss:  0.36879202807267036  Validation Loss:  0.4110809069659029\n",
      "Epoch:  1303  Loss:  0.3688651435297622  Validation Loss:  0.41118940351797\n",
      "Epoch:  1304  Loss:  0.3689391437984077  Validation Loss:  0.41129897055881365\n",
      "Epoch:  1305  Loss:  0.36901440317108786  Validation Loss:  0.4114099061116576\n",
      "Epoch:  1306  Loss:  0.3690908787959426  Validation Loss:  0.41152195246624096\n",
      "Epoch:  1307  Loss:  0.3691682426269943  Validation Loss:  0.41163454444280695\n",
      "Epoch:  1308  Loss:  0.36924655925063693  Validation Loss:  0.4117481374580945\n",
      "Epoch:  1309  Loss:  0.3693257951613009  Validation Loss:  0.411862415793751\n",
      "Epoch:  1310  Loss:  0.3694057577901338  Validation Loss:  0.41197711269238163\n",
      "Epoch:  1311  Loss:  0.36948664429096073  Validation Loss:  0.41209298957671436\n",
      "Epoch:  1312  Loss:  0.3695686266443433  Validation Loss:  0.41220969932952095\n",
      "Epoch:  1313  Loss:  0.3696514373347604  Validation Loss:  0.41232723902378765\n",
      "Epoch:  1314  Loss:  0.3697353217023364  Validation Loss:  0.4124458844640425\n",
      "Epoch:  1315  Loss:  0.3698200329080136  Validation Loss:  0.41256493808967726\n",
      "Epoch:  1316  Loss:  0.3699056527318334  Validation Loss:  0.4126850740451898\n",
      "Epoch:  1317  Loss:  0.36999207501404385  Validation Loss:  0.41280557827225756\n",
      "Epoch:  1318  Loss:  0.3700793561850779  Validation Loss:  0.41292699998510735\n",
      "Epoch:  1319  Loss:  0.3701673854120384  Validation Loss:  0.41304898262023926\n",
      "Epoch:  1320  Loss:  0.3702562833149758  Validation Loss:  0.41317159802253756\n",
      "Epoch:  1321  Loss:  0.37034589836936027  Validation Loss:  0.413294887835426\n",
      "Epoch:  1322  Loss:  0.3704361888254888  Validation Loss:  0.4134185290230172\n",
      "Epoch:  1323  Loss:  0.37052712770256063  Validation Loss:  0.41354247328958343\n",
      "Epoch:  1324  Loss:  0.37061860363864335  Validation Loss:  0.41366675961762667\n",
      "Epoch:  1325  Loss:  0.3707105464924722  Validation Loss:  0.4137909400409886\n",
      "Epoch:  1326  Loss:  0.37080263540413255  Validation Loss:  0.413914941384324\n",
      "Epoch:  1327  Loss:  0.37089507643287706  Validation Loss:  0.41403904357658966\n",
      "Epoch:  1328  Loss:  0.3709878916218436  Validation Loss:  0.4141631633309381\n",
      "Epoch:  1329  Loss:  0.37108097172524096  Validation Loss:  0.4142871335414903\n",
      "Epoch:  1330  Loss:  0.37117423522754533  Validation Loss:  0.41441083792597055\n",
      "Epoch:  1331  Loss:  0.371267561773224  Validation Loss:  0.41453407598393305\n",
      "Epoch:  1332  Loss:  0.3713608709929963  Validation Loss:  0.41465667116322685\n",
      "Epoch:  1333  Loss:  0.3714539366801815  Validation Loss:  0.4147783661527293\n",
      "Epoch:  1334  Loss:  0.37154664187389014  Validation Loss:  0.41489892679133583\n",
      "Epoch:  1335  Loss:  0.3716387027907654  Validation Loss:  0.4150178472378424\n",
      "Epoch:  1336  Loss:  0.3717298017451044  Validation Loss:  0.41513446292706896\n",
      "Epoch:  1337  Loss:  0.3718194523330271  Validation Loss:  0.4152485343760678\n",
      "Epoch:  1338  Loss:  0.3719075890423278  Validation Loss:  0.4153596108247127\n",
      "Epoch:  1339  Loss:  0.37199379402328525  Validation Loss:  0.4154671908223203\n",
      "Epoch:  1340  Loss:  0.3720776373024523  Validation Loss:  0.4155704590624997\n",
      "Epoch:  1341  Loss:  0.3721584975719452  Validation Loss:  0.41566839814186096\n",
      "Epoch:  1342  Loss:  0.37223554583343527  Validation Loss:  0.41575964101191076\n",
      "Epoch:  1343  Loss:  0.37230783718577504  Validation Loss:  0.4158428008002894\n",
      "Epoch:  1344  Loss:  0.3723742289126977  Validation Loss:  0.4159156939546977\n",
      "Epoch:  1345  Loss:  0.37243305217232225  Validation Loss:  0.4159762452223471\n",
      "Epoch:  1346  Loss:  0.37248328023937327  Validation Loss:  0.41602311682488236\n",
      "Epoch:  1347  Loss:  0.37252378961920035  Validation Loss:  0.4160546510081206\n",
      "Epoch:  1348  Loss:  0.3725537382639371  Validation Loss:  0.4160702284425497\n",
      "Epoch:  1349  Loss:  0.372573154521059  Validation Loss:  0.416070716854717\n",
      "Epoch:  1350  Loss:  0.37258296530451296  Validation Loss:  0.41605782229453325\n",
      "Epoch:  1351  Loss:  0.37258482856687003  Validation Loss:  0.416035163482385\n",
      "Epoch:  1352  Loss:  0.3725813499833705  Validation Loss:  0.41600625137133257\n",
      "Epoch:  1353  Loss:  0.3725746845793442  Validation Loss:  0.4159738816586988\n",
      "Epoch:  1354  Loss:  0.37256654457756755  Validation Loss:  0.4159400706578578\n",
      "Epoch:  1355  Loss:  0.3725576701866099  Validation Loss:  0.41590545286557506\n",
      "Epoch:  1356  Loss:  0.37254893149320895  Validation Loss:  0.41587171743490864\n",
      "Epoch:  1357  Loss:  0.372541114908351  Validation Loss:  0.41583934386393856\n",
      "Epoch:  1358  Loss:  0.37253430282928535  Validation Loss:  0.4158081223389932\n",
      "Epoch:  1359  Loss:  0.3725281815821602  Validation Loss:  0.4157778230894889\n",
      "Epoch:  1360  Loss:  0.3725232062255137  Validation Loss:  0.4157495280461652\n",
      "Epoch:  1361  Loss:  0.37251952343438505  Validation Loss:  0.4157224889578564\n",
      "Epoch:  1362  Loss:  0.37251652984400474  Validation Loss:  0.4156962681029524\n",
      "Epoch:  1363  Loss:  0.37251450469684316  Validation Loss:  0.4156715837972505\n",
      "Epoch:  1364  Loss:  0.37251349401897227  Validation Loss:  0.41564788496387856\n",
      "Epoch:  1365  Loss:  0.3725132586423462  Validation Loss:  0.4156255144625902\n",
      "Epoch:  1366  Loss:  0.37251388748898306  Validation Loss:  0.41560367148901733\n",
      "Epoch:  1367  Loss:  0.3725150504408503  Validation Loss:  0.41558278910815716\n",
      "Epoch:  1368  Loss:  0.3725167197676805  Validation Loss:  0.41556224546262194\n",
      "Epoch:  1369  Loss:  0.37251893382453355  Validation Loss:  0.41554246190935373\n",
      "Epoch:  1370  Loss:  0.37252167466829517  Validation Loss:  0.41552338296813623\n",
      "Epoch:  1371  Loss:  0.37252487996097144  Validation Loss:  0.4155043045591031\n",
      "Epoch:  1372  Loss:  0.37252818793058395  Validation Loss:  0.41548555211297106\n",
      "Epoch:  1373  Loss:  0.372531767648  Validation Loss:  0.41546694974281956\n",
      "Epoch:  1374  Loss:  0.37253557035379864  Validation Loss:  0.41544817414666924\n",
      "Epoch:  1375  Loss:  0.37253921875763224  Validation Loss:  0.4154293573062335\n",
      "Epoch:  1376  Loss:  0.37254293218872253  Validation Loss:  0.41541000295962605\n",
      "Epoch:  1377  Loss:  0.37254617420526653  Validation Loss:  0.4153901015275291\n",
      "Epoch:  1378  Loss:  0.3725491900151298  Validation Loss:  0.4153693120128342\n",
      "Epoch:  1379  Loss:  0.372551478136926  Validation Loss:  0.41534746571310927\n",
      "Epoch:  1380  Loss:  0.3725530758676444  Validation Loss:  0.4153240865894726\n",
      "Epoch:  1381  Loss:  0.37255340073941023  Validation Loss:  0.4152983921979155\n",
      "Epoch:  1382  Loss:  0.3725521730688902  Validation Loss:  0.41527045677815166\n",
      "Epoch:  1383  Loss:  0.37254934387623206  Validation Loss:  0.41523945624274866\n",
      "Epoch:  1384  Loss:  0.37254398871632016  Validation Loss:  0.41520415326314314\n",
      "Epoch:  1385  Loss:  0.3725356868297391  Validation Loss:  0.41516455662037643\n",
      "Epoch:  1386  Loss:  0.3725242919382259  Validation Loss:  0.41511965077370405\n",
      "Epoch:  1387  Loss:  0.37250889454191255  Validation Loss:  0.41506852355918716\n",
      "Epoch:  1388  Loss:  0.3724893038794839  Validation Loss:  0.4150115517633302\n",
      "Epoch:  1389  Loss:  0.37246596359113265  Validation Loss:  0.41494915674307514\n",
      "Epoch:  1390  Loss:  0.3724390857318449  Validation Loss:  0.41488201690039467\n",
      "Epoch:  1391  Loss:  0.3724094220167081  Validation Loss:  0.4148113790101239\n",
      "Epoch:  1392  Loss:  0.3723779614772317  Validation Loss:  0.41473905249897924\n",
      "Epoch:  1393  Loss:  0.3723459249064767  Validation Loss:  0.4146660917571613\n",
      "Epoch:  1394  Loss:  0.37231352616696667  Validation Loss:  0.41459266668451683\n",
      "Epoch:  1395  Loss:  0.37228122745921627  Validation Loss:  0.4145195609224694\n",
      "Epoch:  1396  Loss:  0.3722492728889341  Validation Loss:  0.41444681451788973\n",
      "Epoch:  1397  Loss:  0.37221796105246574  Validation Loss:  0.41437561876539675\n",
      "Epoch:  1398  Loss:  0.37218785052292447  Validation Loss:  0.4143055004200765\n",
      "Epoch:  1399  Loss:  0.37215851577957704  Validation Loss:  0.41423640919051\n",
      "Epoch:  1400  Loss:  0.3721298428594008  Validation Loss:  0.414168121027095\n",
      "Epoch:  1401  Loss:  0.3721019314414651  Validation Loss:  0.41410052457026075\n",
      "Epoch:  1402  Loss:  0.3720746915897674  Validation Loss:  0.4140341615836535\n",
      "Epoch:  1403  Loss:  0.37204833584424307  Validation Loss:  0.41396895942411255\n",
      "Epoch:  1404  Loss:  0.3720230752899802  Validation Loss:  0.41390501907361404\n",
      "Epoch:  1405  Loss:  0.37199842660913807  Validation Loss:  0.4138416730399643\n",
      "Epoch:  1406  Loss:  0.371974471405413  Validation Loss:  0.41377920218344244\n",
      "Epoch:  1407  Loss:  0.3719510097475447  Validation Loss:  0.4137172279879451\n",
      "Epoch:  1408  Loss:  0.371928225343044  Validation Loss:  0.4136563390493393\n",
      "Epoch:  1409  Loss:  0.37190604769795604  Validation Loss:  0.41359590286655085\n",
      "Epoch:  1410  Loss:  0.3718844596627196  Validation Loss:  0.4135368752426335\n",
      "Epoch:  1411  Loss:  0.37186405283106855  Validation Loss:  0.41347892209887505\n",
      "Epoch:  1412  Loss:  0.37184411856020694  Validation Loss:  0.4134213160723448\n",
      "Epoch:  1413  Loss:  0.371824588119631  Validation Loss:  0.4133644358121923\n",
      "Epoch:  1414  Loss:  0.3718057686584236  Validation Loss:  0.41330837790987324\n",
      "Epoch:  1415  Loss:  0.3717873991858324  Validation Loss:  0.4132526449060866\n",
      "Epoch:  1416  Loss:  0.3717693552463012  Validation Loss:  0.41319723347468035\n",
      "Epoch:  1417  Loss:  0.3717517200747185  Validation Loss:  0.41314260807952713\n",
      "Epoch:  1418  Loss:  0.3717348121062538  Validation Loss:  0.41308863926678896\n",
      "Epoch:  1419  Loss:  0.37171838983628874  Validation Loss:  0.4130355174254094\n",
      "Epoch:  1420  Loss:  0.3717027343589173  Validation Loss:  0.4129830991317119\n",
      "Epoch:  1421  Loss:  0.37168748659142375  Validation Loss:  0.41293105323399815\n",
      "Epoch:  1422  Loss:  0.371672665226389  Validation Loss:  0.4128797889820167\n",
      "Epoch:  1423  Loss:  0.3716585681988643  Validation Loss:  0.41282917372882366\n",
      "Epoch:  1424  Loss:  0.3716448401293811  Validation Loss:  0.4127788422629237\n",
      "Epoch:  1425  Loss:  0.37163137463775614  Validation Loss:  0.4127285638824105\n",
      "Epoch:  1426  Loss:  0.37161810272896784  Validation Loss:  0.4126784037798643\n",
      "Epoch:  1427  Loss:  0.3716051139422422  Validation Loss:  0.41262850325022427\n",
      "Epoch:  1428  Loss:  0.37159242040130513  Validation Loss:  0.41257890513432877\n",
      "Epoch:  1429  Loss:  0.3715802416998959  Validation Loss:  0.41253029674823793\n",
      "Epoch:  1430  Loss:  0.37156870753983773  Validation Loss:  0.41248214271451744\n",
      "Epoch:  1431  Loss:  0.37155760952530525  Validation Loss:  0.4124346189200878\n",
      "Epoch:  1432  Loss:  0.37154709909265565  Validation Loss:  0.4123878723808697\n",
      "Epoch:  1433  Loss:  0.37153716702785716  Validation Loss:  0.4123416669400675\n",
      "Epoch:  1434  Loss:  0.3715275932081352  Validation Loss:  0.4122957680374384\n",
      "Epoch:  1435  Loss:  0.37151833032891596  Validation Loss:  0.41225018950977493\n",
      "Epoch:  1436  Loss:  0.3715093976999881  Validation Loss:  0.41220494226685594\n",
      "Epoch:  1437  Loss:  0.371500788179375  Validation Loss:  0.4121600268408656\n",
      "Epoch:  1438  Loss:  0.37149256410507053  Validation Loss:  0.4121157898168479\n",
      "Epoch:  1439  Loss:  0.3714850216927613  Validation Loss:  0.4120722769626549\n",
      "Epoch:  1440  Loss:  0.3714778766300551  Validation Loss:  0.4120290566767965\n",
      "Epoch:  1441  Loss:  0.3714710608918286  Validation Loss:  0.4119861349463463\n",
      "Epoch:  1442  Loss:  0.3714645495693359  Validation Loss:  0.41194350578423056\n",
      "Epoch:  1443  Loss:  0.3714583375485691  Validation Loss:  0.4119011601433158\n",
      "Epoch:  1444  Loss:  0.37145242209617907  Validation Loss:  0.4118590953626803\n",
      "Epoch:  1445  Loss:  0.37144682657789196  Validation Loss:  0.4118173266095774\n",
      "Epoch:  1446  Loss:  0.3714415296559503  Validation Loss:  0.4117758299357125\n",
      "Epoch:  1447  Loss:  0.3714365374583464  Validation Loss:  0.4117346101307443\n",
      "Epoch:  1448  Loss:  0.3714318771422262  Validation Loss:  0.4116937659148659\n",
      "Epoch:  1449  Loss:  0.3714276110014972  Validation Loss:  0.41165357136300634\n",
      "Epoch:  1450  Loss:  0.37142397375149133  Validation Loss:  0.4116139567590186\n",
      "Epoch:  1451  Loss:  0.37142077789327804  Validation Loss:  0.4115747732243368\n",
      "Epoch:  1452  Loss:  0.3714179435425256  Validation Loss:  0.41153599561325144\n",
      "Epoch:  1453  Loss:  0.37141562341409323  Validation Loss:  0.41149797649788006\n",
      "Epoch:  1454  Loss:  0.37141383950703244  Validation Loss:  0.4114603344351053\n",
      "Epoch:  1455  Loss:  0.37141236592326643  Validation Loss:  0.4114229322544166\n",
      "Epoch:  1456  Loss:  0.37141116673248054  Validation Loss:  0.41138576130781856\n",
      "Epoch:  1457  Loss:  0.3714102372174432  Validation Loss:  0.41134881174990107\n",
      "Epoch:  1458  Loss:  0.37140954841347135  Validation Loss:  0.41131203688148943\n",
      "Epoch:  1459  Loss:  0.3714091014668081  Validation Loss:  0.4112754079646298\n",
      "Epoch:  1460  Loss:  0.37140887803756273  Validation Loss:  0.4112388930682625\n",
      "Epoch:  1461  Loss:  0.37140886816223695  Validation Loss:  0.4112024601282818\n",
      "Epoch:  1462  Loss:  0.3714090497095204  Validation Loss:  0.411166070827416\n",
      "Epoch:  1463  Loss:  0.3714094291600955  Validation Loss:  0.4111297034791538\n",
      "Epoch:  1464  Loss:  0.37141000554406434  Validation Loss:  0.41109336433666094\n",
      "Epoch:  1465  Loss:  0.3714107862238348  Validation Loss:  0.41105712085430113\n",
      "Epoch:  1466  Loss:  0.3714118013103333  Validation Loss:  0.4110209945855396\n",
      "Epoch:  1467  Loss:  0.3714130554326187  Validation Loss:  0.4109850249120167\n",
      "Epoch:  1468  Loss:  0.3714145733671781  Validation Loss:  0.4109492751636675\n",
      "Epoch:  1469  Loss:  0.3714163723517452  Validation Loss:  0.4109137812629342\n",
      "Epoch:  1470  Loss:  0.37141845913152016  Validation Loss:  0.410878566359835\n",
      "Epoch:  1471  Loss:  0.3714208607313901  Validation Loss:  0.4108436643811209\n",
      "Epoch:  1472  Loss:  0.37142357697500983  Validation Loss:  0.4108090882322618\n",
      "Epoch:  1473  Loss:  0.37142662633452894  Validation Loss:  0.41077484576297657\n",
      "Epoch:  1474  Loss:  0.37142999686256667  Validation Loss:  0.4107409224712423\n",
      "Epoch:  1475  Loss:  0.3714336884268642  Validation Loss:  0.4107074588537216\n",
      "Epoch:  1476  Loss:  0.37143777694398833  Validation Loss:  0.41067463039819685\n",
      "Epoch:  1477  Loss:  0.3714424914421415  Validation Loss:  0.41064251214265823\n",
      "Epoch:  1478  Loss:  0.37144779171464004  Validation Loss:  0.4106112868924226\n",
      "Epoch:  1479  Loss:  0.3714537549124667  Validation Loss:  0.410580719688109\n",
      "Epoch:  1480  Loss:  0.37146015072891697  Validation Loss:  0.4105505103777562\n",
      "Epoch:  1481  Loss:  0.37146688922798843  Validation Loss:  0.41052064751940115\n",
      "Epoch:  1482  Loss:  0.3714739399460646  Validation Loss:  0.4104910966541086\n",
      "Epoch:  1483  Loss:  0.371481310025122  Validation Loss:  0.41046186603073564\n",
      "Epoch:  1484  Loss:  0.37148899175006256  Validation Loss:  0.41043295711278915\n",
      "Epoch:  1485  Loss:  0.37149698445959206  Validation Loss:  0.4104043697672231\n",
      "Epoch:  1486  Loss:  0.3715052936204086  Validation Loss:  0.41037611038024935\n",
      "Epoch:  1487  Loss:  0.37151392196586147  Validation Loss:  0.4103481784196837\n",
      "Epoch:  1488  Loss:  0.37152286945186425  Validation Loss:  0.4103205549929823\n",
      "Epoch:  1489  Loss:  0.3715321278342834  Validation Loss:  0.410293241164514\n",
      "Epoch:  1490  Loss:  0.3715417079142565  Validation Loss:  0.4102662474449192\n",
      "Epoch:  1491  Loss:  0.3715516112348032  Validation Loss:  0.41023957250373705\n",
      "Epoch:  1492  Loss:  0.3715618028355068  Validation Loss:  0.41021308449230026\n",
      "Epoch:  1493  Loss:  0.3715721602446934  Validation Loss:  0.4101868263844933\n",
      "Epoch:  1494  Loss:  0.37158282308359825  Validation Loss:  0.41016090993902515\n",
      "Epoch:  1495  Loss:  0.3715937988909744  Validation Loss:  0.4101353044222508\n",
      "Epoch:  1496  Loss:  0.3716050923840534  Validation Loss:  0.41011001488992144\n",
      "Epoch:  1497  Loss:  0.37161670210798814  Validation Loss:  0.41008503176271915\n",
      "Epoch:  1498  Loss:  0.3716286176584176  Validation Loss:  0.41006036036248716\n",
      "Epoch:  1499  Loss:  0.37164084983647927  Validation Loss:  0.410035996564797\n",
      "Training session:  3\n",
      "2020_11_9_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_9_MV1_run\n",
      "Epoch:  0  Loss:  1.1277765142066138  Validation Loss:  0.9263613243986454\n",
      "Epoch:  1  Loss:  1.1279217396818457  Validation Loss:  0.9264994574976819\n",
      "Epoch:  2  Loss:  1.1280557052010582  Validation Loss:  0.9266289676140461\n",
      "Epoch:  3  Loss:  1.12818027580423  Validation Loss:  0.9267510202314172\n",
      "Epoch:  4  Loss:  1.128297833282323  Validation Loss:  0.9268679694671716\n",
      "Epoch:  5  Loss:  1.1284101480352027  Validation Loss:  0.9269807654033814\n",
      "Epoch:  6  Loss:  1.1285181536028783  Validation Loss:  0.9270896296948195\n",
      "Epoch:  7  Loss:  1.128622935020498  Validation Loss:  0.9271955913198846\n",
      "Epoch:  8  Loss:  1.1287255428199257  Validation Loss:  0.927299606746861\n",
      "Epoch:  9  Loss:  1.1288261883670376  Validation Loss:  0.9274013474849718\n",
      "Epoch:  10  Loss:  1.1289244850299187  Validation Loss:  0.927500582965357\n",
      "Epoch:  11  Loss:  1.1290213573014451  Validation Loss:  0.9275990925463182\n",
      "Epoch:  12  Loss:  1.1291180857945056  Validation Loss:  0.9276969978319747\n",
      "Epoch:  13  Loss:  1.1292141680383967  Validation Loss:  0.9277936472956624\n",
      "Epoch:  14  Loss:  1.1293090243069899  Validation Loss:  0.9278886875669871\n",
      "Epoch:  15  Loss:  1.1294035836167278  Validation Loss:  0.927983535187585\n",
      "Epoch:  16  Loss:  1.1294985076501256  Validation Loss:  0.9280782643971699\n",
      "Epoch:  17  Loss:  1.1295935460144566  Validation Loss:  0.9281730075765934\n",
      "Epoch:  18  Loss:  1.1296884391811632  Validation Loss:  0.9282671423362834\n",
      "Epoch:  19  Loss:  1.1297833013037841  Validation Loss:  0.9283607084570187\n",
      "Epoch:  20  Loss:  1.1298777431781803  Validation Loss:  0.928453835525683\n",
      "Epoch:  21  Loss:  1.1299718297308399  Validation Loss:  0.9285459364099162\n",
      "Epoch:  22  Loss:  1.1300660140280212  Validation Loss:  0.9286379139604313\n",
      "Epoch:  23  Loss:  1.1301598451322032  Validation Loss:  0.9287294415490968\n",
      "Epoch:  24  Loss:  1.130253766885116  Validation Loss:  0.9288206970585244\n",
      "Epoch:  25  Loss:  1.1303475626877375  Validation Loss:  0.9289118718089802\n",
      "Epoch:  26  Loss:  1.1304408303861107  Validation Loss:  0.9290016797770347\n",
      "Epoch:  27  Loss:  1.130533163746198  Validation Loss:  0.9290908465960196\n",
      "Epoch:  28  Loss:  1.130624908953905  Validation Loss:  0.9291783965059689\n",
      "Epoch:  29  Loss:  1.130715590857324  Validation Loss:  0.9292650289301362\n",
      "Epoch:  30  Loss:  1.1308061123958655  Validation Loss:  0.9293517632676023\n",
      "Epoch:  31  Loss:  1.1308965933110033  Validation Loss:  0.9294376760455114\n",
      "Epoch:  32  Loss:  1.1309863766211838  Validation Loss:  0.9295229025717292\n",
      "Epoch:  33  Loss:  1.1310757239837022  Validation Loss:  0.9296069975410189\n",
      "Epoch:  34  Loss:  1.1311643477529287  Validation Loss:  0.9296904400523219\n",
      "Epoch:  35  Loss:  1.1312524368543  Validation Loss:  0.9297730125752943\n",
      "Epoch:  36  Loss:  1.1313401245999903  Validation Loss:  0.9298552555431213\n",
      "Epoch:  37  Loss:  1.131427101790905  Validation Loss:  0.9299357377790979\n",
      "Epoch:  38  Loss:  1.1315125824794883  Validation Loss:  0.9300145188878689\n",
      "Epoch:  39  Loss:  1.131596645251626  Validation Loss:  0.9300918914377689\n",
      "Epoch:  40  Loss:  1.131680076764453  Validation Loss:  0.930168168353183\n",
      "Epoch:  41  Loss:  1.1317617683893157  Validation Loss:  0.9302415513832655\n",
      "Epoch:  42  Loss:  1.1318407549212377  Validation Loss:  0.9303127657622099\n",
      "Epoch:  43  Loss:  1.1319179242210728  Validation Loss:  0.9303816568904689\n",
      "Epoch:  44  Loss:  1.1319934369197913  Validation Loss:  0.9304486340177911\n",
      "Epoch:  45  Loss:  1.1320673250371502  Validation Loss:  0.9305134234683854\n",
      "Epoch:  46  Loss:  1.132139232896623  Validation Loss:  0.9305755041007485\n",
      "Epoch:  47  Loss:  1.132208017366273  Validation Loss:  0.9306338413485459\n",
      "Epoch:  48  Loss:  1.1322742532051744  Validation Loss:  0.9306895594511714\n",
      "Epoch:  49  Loss:  1.1323381148810898  Validation Loss:  0.9307422511545675\n",
      "Epoch:  50  Loss:  1.1323994689044499  Validation Loss:  0.9307914264500141\n",
      "Epoch:  51  Loss:  1.1324575903515022  Validation Loss:  0.9308369093175445\n",
      "Epoch:  52  Loss:  1.1325120529425996  Validation Loss:  0.9308781844696828\n",
      "Epoch:  53  Loss:  1.132562573644377  Validation Loss:  0.9309151848512036\n",
      "Epoch:  54  Loss:  1.132609607030948  Validation Loss:  0.9309482498626623\n",
      "Epoch:  55  Loss:  1.1326536196505739  Validation Loss:  0.9309778538133416\n",
      "Epoch:  56  Loss:  1.1326947273420436  Validation Loss:  0.9310038154944777\n",
      "Epoch:  57  Loss:  1.132732912099787  Validation Loss:  0.9310263682688985\n",
      "Epoch:  58  Loss:  1.1327675580091419  Validation Loss:  0.9310444863513112\n",
      "Epoch:  59  Loss:  1.13279864564538  Validation Loss:  0.931059423035809\n",
      "Epoch:  60  Loss:  1.132826909777664  Validation Loss:  0.9310709647834301\n",
      "Epoch:  61  Loss:  1.1328528796633084  Validation Loss:  0.9310800568865878\n",
      "Epoch:  62  Loss:  1.1328766916301989  Validation Loss:  0.9310861953667232\n",
      "Epoch:  63  Loss:  1.1328980026855355  Validation Loss:  0.9310899485966989\n",
      "Epoch:  64  Loss:  1.1329180741948741  Validation Loss:  0.9310920497934733\n",
      "Epoch:  65  Loss:  1.132936227179709  Validation Loss:  0.931091657174485\n",
      "Epoch:  66  Loss:  1.132952071903717  Validation Loss:  0.9310879200430853\n",
      "Epoch:  67  Loss:  1.1329652907415515  Validation Loss:  0.9310816377401352\n",
      "Epoch:  68  Loss:  1.1329765071471531  Validation Loss:  0.9310727420129946\n",
      "Epoch:  69  Loss:  1.1329850550031377  Validation Loss:  0.931060568828668\n",
      "Epoch:  70  Loss:  1.1329913179257087  Validation Loss:  0.9310461884098393\n",
      "Epoch:  71  Loss:  1.132995159054796  Validation Loss:  0.931028388440609\n",
      "Epoch:  72  Loss:  1.1329966851820548  Validation Loss:  0.9310083846960749\n",
      "Epoch:  73  Loss:  1.132995991479783  Validation Loss:  0.9309862926602364\n",
      "Epoch:  74  Loss:  1.1329943140347798  Validation Loss:  0.9309620126815779\n",
      "Epoch:  75  Loss:  1.132990117140469  Validation Loss:  0.9309353575642619\n",
      "Epoch:  76  Loss:  1.1329832022033988  Validation Loss:  0.9309057987162045\n",
      "Epoch:  77  Loss:  1.1329737552219914  Validation Loss:  0.9308735180113997\n",
      "Epoch:  78  Loss:  1.1329618640953587  Validation Loss:  0.930839085153171\n",
      "Epoch:  79  Loss:  1.1329470362869047  Validation Loss:  0.9308010596515877\n",
      "Epoch:  80  Loss:  1.1329294903469938  Validation Loss:  0.9307608943698662\n",
      "Epoch:  81  Loss:  1.1329095162273872  Validation Loss:  0.9307184708969933\n",
      "Epoch:  82  Loss:  1.132886469985048  Validation Loss:  0.930672401429287\n",
      "Epoch:  83  Loss:  1.1328603876311154  Validation Loss:  0.9306237777428967\n",
      "Epoch:  84  Loss:  1.132831147650168  Validation Loss:  0.9305720317310521\n",
      "Epoch:  85  Loss:  1.1327984916667144  Validation Loss:  0.9305169986827033\n",
      "Epoch:  86  Loss:  1.13276243307406  Validation Loss:  0.9304593060431736\n",
      "Epoch:  87  Loss:  1.132724330272703  Validation Loss:  0.9303999310359359\n",
      "Epoch:  88  Loss:  1.1326840189950806  Validation Loss:  0.9303377845457622\n",
      "Epoch:  89  Loss:  1.1326411833897942  Validation Loss:  0.9302735582792333\n",
      "Epoch:  90  Loss:  1.1325957168425833  Validation Loss:  0.9302060886153153\n",
      "Epoch:  91  Loss:  1.132547294454915  Validation Loss:  0.930136167976473\n",
      "Epoch:  92  Loss:  1.1324965309883868  Validation Loss:  0.9300638658127615\n",
      "Epoch:  93  Loss:  1.1324437194104706  Validation Loss:  0.9299893702513405\n",
      "Epoch:  94  Loss:  1.1323881089864742  Validation Loss:  0.9299121793093426\n",
      "Epoch:  95  Loss:  1.1323305326735689  Validation Loss:  0.9298334784273591\n",
      "Epoch:  96  Loss:  1.1322716607579164  Validation Loss:  0.9297533091157675\n",
      "Epoch:  97  Loss:  1.1322114043647336  Validation Loss:  0.9296718646905252\n",
      "Epoch:  98  Loss:  1.1321498250500077  Validation Loss:  0.929589170829526\n",
      "Epoch:  99  Loss:  1.1320873683407193  Validation Loss:  0.9295057963047709\n",
      "Epoch:  100  Loss:  1.1320245583497344  Validation Loss:  0.9294224236426609\n",
      "Epoch:  101  Loss:  1.1319615823172389  Validation Loss:  0.9293388769562755\n",
      "Epoch:  102  Loss:  1.1318980571592139  Validation Loss:  0.9292546607820051\n",
      "Epoch:  103  Loss:  1.1318348384506645  Validation Loss:  0.929171109572053\n",
      "Epoch:  104  Loss:  1.131771249164428  Validation Loss:  0.9290861556572574\n",
      "Epoch:  105  Loss:  1.1317060882491725  Validation Loss:  0.9290007708062019\n",
      "Epoch:  106  Loss:  1.1316405082387584  Validation Loss:  0.9289148621527212\n",
      "Epoch:  107  Loss:  1.1315753822702737  Validation Loss:  0.9288296184635588\n",
      "Epoch:  108  Loss:  1.131510952487588  Validation Loss:  0.9287452584664736\n",
      "Epoch:  109  Loss:  1.131446882461508  Validation Loss:  0.9286611203902534\n",
      "Epoch:  110  Loss:  1.1313826824050575  Validation Loss:  0.9285765331504601\n",
      "Epoch:  111  Loss:  1.131318265040006  Validation Loss:  0.9284919991290995\n",
      "Epoch:  112  Loss:  1.1312539001838082  Validation Loss:  0.9284075938963464\n",
      "Epoch:  113  Loss:  1.131189620211011  Validation Loss:  0.9283229678070971\n",
      "Epoch:  114  Loss:  1.131124893735562  Validation Loss:  0.9282379747767534\n",
      "Epoch:  115  Loss:  1.1310601441987924  Validation Loss:  0.9281530469389898\n",
      "Epoch:  116  Loss:  1.1309951724750655  Validation Loss:  0.92806780418115\n",
      "Epoch:  117  Loss:  1.1309304095449901  Validation Loss:  0.9279823406998601\n",
      "Epoch:  118  Loss:  1.1308656968176365  Validation Loss:  0.9278976039162704\n",
      "Epoch:  119  Loss:  1.1308017499035312  Validation Loss:  0.9278135913025055\n",
      "Epoch:  120  Loss:  1.1307375524193048  Validation Loss:  0.9277289838397077\n",
      "Epoch:  121  Loss:  1.13067311784696  Validation Loss:  0.9276442084727543\n",
      "Epoch:  122  Loss:  1.1306083854287863  Validation Loss:  0.9275591265676277\n",
      "Epoch:  123  Loss:  1.1305429970934278  Validation Loss:  0.9274733138403722\n",
      "Epoch:  124  Loss:  1.130476797265666  Validation Loss:  0.9273863727492946\n",
      "Epoch:  125  Loss:  1.1304095917869181  Validation Loss:  0.9272984898250017\n",
      "Epoch:  126  Loss:  1.1303420279707228  Validation Loss:  0.9272105784288475\n",
      "Epoch:  127  Loss:  1.1302741581485385  Validation Loss:  0.9271219319530896\n",
      "Epoch:  128  Loss:  1.1302052577514023  Validation Loss:  0.9270323307386467\n",
      "Epoch:  129  Loss:  1.130135497433089  Validation Loss:  0.9269418587375965\n",
      "Epoch:  130  Loss:  1.1300649309442157  Validation Loss:  0.9268506757382836\n",
      "Epoch:  131  Loss:  1.1299934931808995  Validation Loss:  0.926758060364851\n",
      "Epoch:  132  Loss:  1.1299205791382563  Validation Loss:  0.9266640103555152\n",
      "Epoch:  133  Loss:  1.1298466433017027  Validation Loss:  0.9265691870823503\n",
      "Epoch:  134  Loss:  1.129772320921932  Validation Loss:  0.9264745584556034\n",
      "Epoch:  135  Loss:  1.1296978445634955  Validation Loss:  0.9263793360441923\n",
      "Epoch:  136  Loss:  1.1296230108432828  Validation Loss:  0.926284145829933\n",
      "Epoch:  137  Loss:  1.1295476866265137  Validation Loss:  0.9261873130287442\n",
      "Epoch:  138  Loss:  1.1294714545032807  Validation Loss:  0.9260900269395539\n",
      "Epoch:  139  Loss:  1.1293945583914007  Validation Loss:  0.9259912263868111\n",
      "Epoch:  140  Loss:  1.1293148307041043  Validation Loss:  0.9258890507210579\n",
      "Epoch:  141  Loss:  1.1292323575665553  Validation Loss:  0.9257855789203729\n",
      "Epoch:  142  Loss:  1.1291488142950195  Validation Loss:  0.9256810140130776\n",
      "Epoch:  143  Loss:  1.1290640863811685  Validation Loss:  0.9255748689174652\n",
      "Epoch:  144  Loss:  1.1289779064910752  Validation Loss:  0.9254673264388528\n",
      "Epoch:  145  Loss:  1.128890353831507  Validation Loss:  0.9253580804382052\n",
      "Epoch:  146  Loss:  1.1288010721050559  Validation Loss:  0.925247060268053\n",
      "Epoch:  147  Loss:  1.128709982282349  Validation Loss:  0.925133625577603\n",
      "Epoch:  148  Loss:  1.1286168993406354  Validation Loss:  0.9250183666923216\n",
      "Epoch:  149  Loss:  1.1285219681227492  Validation Loss:  0.9249009733487453\n",
      "Epoch:  150  Loss:  1.128425390770038  Validation Loss:  0.92478197067976\n",
      "Epoch:  151  Loss:  1.1283267220216138  Validation Loss:  0.9246603792001095\n",
      "Epoch:  152  Loss:  1.1282258173894315  Validation Loss:  0.9245362748791065\n",
      "Epoch:  153  Loss:  1.1281225192582323  Validation Loss:  0.9244094469717571\n",
      "Epoch:  154  Loss:  1.1280163012090183  Validation Loss:  0.9242791462955731\n",
      "Epoch:  155  Loss:  1.1279068990122705  Validation Loss:  0.9241455595142075\n",
      "Epoch:  156  Loss:  1.127794451035914  Validation Loss:  0.9240084349044732\n",
      "Epoch:  157  Loss:  1.1276784449638355  Validation Loss:  0.9238671786817056\n",
      "Epoch:  158  Loss:  1.1275584251575528  Validation Loss:  0.9237215694572244\n",
      "Epoch:  159  Loss:  1.12743434052737  Validation Loss:  0.9235715266051037\n",
      "Epoch:  160  Loss:  1.1273058973075378  Validation Loss:  0.9234165135504944\n",
      "Epoch:  161  Loss:  1.1271727640359175  Validation Loss:  0.9232562849564212\n",
      "Epoch:  162  Loss:  1.1270346058798688  Validation Loss:  0.9230905809838857\n",
      "Epoch:  163  Loss:  1.1268910234350533  Validation Loss:  0.9229187741875648\n",
      "Epoch:  164  Loss:  1.1267414718334163  Validation Loss:  0.9227402952632734\n",
      "Epoch:  165  Loss:  1.1265849638730288  Validation Loss:  0.9225536966696382\n",
      "Epoch:  166  Loss:  1.1264209799645912  Validation Loss:  0.9223590859078935\n",
      "Epoch:  167  Loss:  1.1262489454377265  Validation Loss:  0.9221552213920015\n",
      "Epoch:  168  Loss:  1.1260681308451153  Validation Loss:  0.921941882930696\n",
      "Epoch:  169  Loss:  1.1258774868079595  Validation Loss:  0.9217168361480746\n",
      "Epoch:  170  Loss:  1.1256752493126052  Validation Loss:  0.921480744944087\n",
      "Epoch:  171  Loss:  1.1254627176870902  Validation Loss:  0.9212334810623101\n",
      "Epoch:  172  Loss:  1.1252399887889624  Validation Loss:  0.9209753711308751\n",
      "Epoch:  173  Loss:  1.12500652715209  Validation Loss:  0.9207054640033415\n",
      "Epoch:  174  Loss:  1.124762435488048  Validation Loss:  0.9204244975532804\n",
      "Epoch:  175  Loss:  1.124508072843864  Validation Loss:  0.9201326458049672\n",
      "Epoch:  176  Loss:  1.1242435652585256  Validation Loss:  0.9198303098923394\n",
      "Epoch:  177  Loss:  1.1239696090065299  Validation Loss:  0.9195182417918529\n",
      "Epoch:  178  Loss:  1.1236873031372117  Validation Loss:  0.919197895697185\n",
      "Epoch:  179  Loss:  1.1233974872600465  Validation Loss:  0.9188700066879392\n",
      "Epoch:  180  Loss:  1.1231011821932735  Validation Loss:  0.9185358200754438\n",
      "Epoch:  181  Loss:  1.1227994591352486  Validation Loss:  0.9181963367653745\n",
      "Epoch:  182  Loss:  1.1224932849761986  Validation Loss:  0.9178525462214436\n",
      "Epoch:  183  Loss:  1.1221835447386617  Validation Loss:  0.9175052875652909\n",
      "Epoch:  184  Loss:  1.1218709078218256  Validation Loss:  0.9171552111261657\n",
      "Epoch:  185  Loss:  1.1215561837667511  Validation Loss:  0.9168031935447029\n",
      "Epoch:  186  Loss:  1.1212398259057885  Validation Loss:  0.9164494800248316\n",
      "Epoch:  187  Loss:  1.120922234264158  Validation Loss:  0.9160945283781204\n",
      "Epoch:  188  Loss:  1.1206042658360231  Validation Loss:  0.9157392968024526\n",
      "Epoch:  189  Loss:  1.120286175271585  Validation Loss:  0.915383491798171\n",
      "Epoch:  190  Loss:  1.1199677497858094  Validation Loss:  0.9150268242561391\n",
      "Epoch:  191  Loss:  1.1196480874149572  Validation Loss:  0.9146683196138058\n",
      "Epoch:  192  Loss:  1.1193266397430783  Validation Loss:  0.9143090789605465\n",
      "Epoch:  193  Loss:  1.1190049184397572  Validation Loss:  0.9139494774863124\n",
      "Epoch:  194  Loss:  1.1186834021161  Validation Loss:  0.9135899156598108\n",
      "Epoch:  195  Loss:  1.1183620672672987  Validation Loss:  0.9132299105237637\n",
      "Epoch:  196  Loss:  1.1180405246005172  Validation Loss:  0.9128693504525083\n",
      "Epoch:  197  Loss:  1.1177186665258236  Validation Loss:  0.9125079529892121\n",
      "Epoch:  198  Loss:  1.1173969823867083  Validation Loss:  0.9121467769145966\n",
      "Epoch:  199  Loss:  1.1170754519601662  Validation Loss:  0.911784320271441\n",
      "Epoch:  200  Loss:  1.1167529785029946  Validation Loss:  0.9114203719156129\n",
      "Epoch:  201  Loss:  1.1164295379782008  Validation Loss:  0.9110548779634493\n",
      "Epoch:  202  Loss:  1.1161043667012738  Validation Loss:  0.9106861351590071\n",
      "Epoch:  203  Loss:  1.1157760407243456  Validation Loss:  0.9103147595056466\n",
      "Epoch:  204  Loss:  1.1154460415598892  Validation Loss:  0.9099410705800567\n",
      "Epoch:  205  Loss:  1.1151143566128754  Validation Loss:  0.9095645743821349\n",
      "Epoch:  206  Loss:  1.1147804829691137  Validation Loss:  0.909184852748045\n",
      "Epoch:  207  Loss:  1.1144442329449313  Validation Loss:  0.908801794052124\n",
      "Epoch:  208  Loss:  1.1141055911956799  Validation Loss:  0.9084151896781155\n",
      "Epoch:  209  Loss:  1.1137631365231104  Validation Loss:  0.9080228512840611\n",
      "Epoch:  210  Loss:  1.1134162319912797  Validation Loss:  0.907626214836325\n",
      "Epoch:  211  Loss:  1.1130661619383664  Validation Loss:  0.9072251941210457\n",
      "Epoch:  212  Loss:  1.1127130833587475  Validation Loss:  0.9068199582397938\n",
      "Epoch:  213  Loss:  1.112356698140502  Validation Loss:  0.9064097586753113\n",
      "Epoch:  214  Loss:  1.1119954680048285  Validation Loss:  0.9059938924121005\n",
      "Epoch:  215  Loss:  1.1116304687623466  Validation Loss:  0.9055740947702101\n",
      "Epoch:  216  Loss:  1.1112628854988587  Validation Loss:  0.9051509438348668\n",
      "Epoch:  217  Loss:  1.1108924758931  Validation Loss:  0.9047234134216394\n",
      "Epoch:  218  Loss:  1.110518373903774  Validation Loss:  0.9042928439698049\n",
      "Epoch:  219  Loss:  1.110142525640272  Validation Loss:  0.9038600199190634\n",
      "Epoch:  220  Loss:  1.1097642699522632  Validation Loss:  0.9034240718132683\n",
      "Epoch:  221  Loss:  1.109384155965277  Validation Loss:  0.902987423219851\n",
      "Epoch:  222  Loss:  1.1090032608203946  Validation Loss:  0.9025491587817669\n",
      "Epoch:  223  Loss:  1.1086209109496503  Validation Loss:  0.9021106021744865\n",
      "Epoch:  224  Loss:  1.1082378926553897  Validation Loss:  0.9016709317054067\n",
      "Epoch:  225  Loss:  1.1078538154917104  Validation Loss:  0.9012307857296297\n",
      "Epoch:  226  Loss:  1.1074686990607352  Validation Loss:  0.9007906474705253\n",
      "Epoch:  227  Loss:  1.1070829743430728  Validation Loss:  0.9003496990938272\n",
      "Epoch:  228  Loss:  1.106696305796504  Validation Loss:  0.8999084463076932\n",
      "Epoch:  229  Loss:  1.1063084895057338  Validation Loss:  0.8994667508772441\n",
      "Epoch:  230  Loss:  1.1059192268266564  Validation Loss:  0.8990243061312607\n",
      "Epoch:  231  Loss:  1.1055285491581475  Validation Loss:  0.8985810500702688\n",
      "Epoch:  232  Loss:  1.1051364179168428  Validation Loss:  0.8981372344174555\n",
      "Epoch:  233  Loss:  1.1047428300870317  Validation Loss:  0.8976927358391029\n",
      "Epoch:  234  Loss:  1.1043477780407382  Validation Loss:  0.8972477207758597\n",
      "Epoch:  235  Loss:  1.1039515640586615  Validation Loss:  0.8968027756948557\n",
      "Epoch:  236  Loss:  1.1035543153328555  Validation Loss:  0.8963572778073805\n",
      "Epoch:  237  Loss:  1.1031558541137547  Validation Loss:  0.8959114623389074\n",
      "Epoch:  238  Loss:  1.1027564446308784  Validation Loss:  0.8954650139702218\n",
      "Epoch:  239  Loss:  1.1023560359719253  Validation Loss:  0.895018529679094\n",
      "Epoch:  240  Loss:  1.1019547873487074  Validation Loss:  0.8945722933858633\n",
      "Epoch:  241  Loss:  1.1015536718602692  Validation Loss:  0.8941259059522834\n",
      "Epoch:  242  Loss:  1.1011515279256163  Validation Loss:  0.8936797607956188\n",
      "Epoch:  243  Loss:  1.1007500397307532  Validation Loss:  0.8932345935276577\n",
      "Epoch:  244  Loss:  1.1003491910440582  Validation Loss:  0.8927901252838117\n",
      "Epoch:  245  Loss:  1.0999483861738728  Validation Loss:  0.8923452394083142\n",
      "Epoch:  246  Loss:  1.0995470435314236  Validation Loss:  0.8919011929205486\n",
      "Epoch:  247  Loss:  1.0991465310078292  Validation Loss:  0.8914578611563359\n",
      "Epoch:  248  Loss:  1.0987466691682737  Validation Loss:  0.891015456058085\n",
      "Epoch:  249  Loss:  1.098347710179431  Validation Loss:  0.8905740696936846\n",
      "Epoch:  250  Loss:  1.097949583260786  Validation Loss:  0.8901335362877164\n",
      "Epoch:  251  Loss:  1.0975523293905316  Validation Loss:  0.8896940826837506\n",
      "Epoch:  252  Loss:  1.0971557128110103  Validation Loss:  0.8892552043710437\n",
      "Epoch:  253  Loss:  1.0967598728658188  Validation Loss:  0.8888173867017031\n",
      "Epoch:  254  Loss:  1.0963657870001735  Validation Loss:  0.8883814652051244\n",
      "Epoch:  255  Loss:  1.0959735462175948  Validation Loss:  0.8879467542948467\n",
      "Epoch:  256  Loss:  1.0955822860733384  Validation Loss:  0.8875127586403063\n",
      "Epoch:  257  Loss:  1.0951915701762551  Validation Loss:  0.8870794874216829\n",
      "Epoch:  258  Loss:  1.0948015236783595  Validation Loss:  0.8866469648533634\n",
      "Epoch:  259  Loss:  1.0944124495699292  Validation Loss:  0.8862154364053693\n",
      "Epoch:  260  Loss:  1.0940239648556425  Validation Loss:  0.8857843720221094\n",
      "Epoch:  261  Loss:  1.0936361310914868  Validation Loss:  0.88535419665277\n",
      "Epoch:  262  Loss:  1.0932489862399442  Validation Loss:  0.8849245417597038\n",
      "Epoch:  263  Loss:  1.0928622885119348  Validation Loss:  0.8844954590978367\n",
      "Epoch:  264  Loss:  1.0924761563184715  Validation Loss:  0.8840669994907719\n",
      "Epoch:  265  Loss:  1.092090730777099  Validation Loss:  0.8836393348340478\n",
      "Epoch:  266  Loss:  1.0917058823009331  Validation Loss:  0.8832121691001313\n",
      "Epoch:  267  Loss:  1.0913215887156271  Validation Loss:  0.8827861466311983\n",
      "Epoch:  268  Loss:  1.0909396912015619  Validation Loss:  0.8823619611295206\n",
      "Epoch:  269  Loss:  1.0905589157981532  Validation Loss:  0.8819382551259228\n",
      "Epoch:  270  Loss:  1.090178470349028  Validation Loss:  0.8815149432048202\n",
      "Epoch:  271  Loss:  1.0897985117598659  Validation Loss:  0.8810921935364604\n",
      "Epoch:  272  Loss:  1.089419092007336  Validation Loss:  0.8806699823055949\n",
      "Epoch:  273  Loss:  1.0890403488384826  Validation Loss:  0.880248649045825\n",
      "Epoch:  274  Loss:  1.0886621124865044  Validation Loss:  0.8798276627702373\n",
      "Epoch:  275  Loss:  1.088284216643799  Validation Loss:  0.8794069711917213\n",
      "Epoch:  276  Loss:  1.0879069008820115  Validation Loss:  0.8789872850424477\n",
      "Epoch:  277  Loss:  1.0875307070534854  Validation Loss:  0.8785688206553459\n",
      "Epoch:  278  Loss:  1.087155363389424  Validation Loss:  0.8781508605128953\n",
      "Epoch:  279  Loss:  1.086780489555427  Validation Loss:  0.8777334694085377\n",
      "Epoch:  280  Loss:  1.0864061048875253  Validation Loss:  0.8773163916277034\n",
      "Epoch:  281  Loss:  1.0860320237420855  Validation Loss:  0.8768997426543917\n",
      "Epoch:  282  Loss:  1.085658478417567  Validation Loss:  0.8764838209109647\n",
      "Epoch:  283  Loss:  1.0852856644917102  Validation Loss:  0.8760685411148837\n",
      "Epoch:  284  Loss:  1.0849131804314398  Validation Loss:  0.8756535381876996\n",
      "Epoch:  285  Loss:  1.0845409843715883  Validation Loss:  0.8752388056101543\n",
      "Epoch:  286  Loss:  1.0841692348143883  Validation Loss:  0.8748246902333838\n",
      "Epoch:  287  Loss:  1.0837979346868538  Validation Loss:  0.8744109433942607\n",
      "Epoch:  288  Loss:  1.0834270760062195  Validation Loss:  0.873997690023056\n",
      "Epoch:  289  Loss:  1.083057367198524  Validation Loss:  0.8735864368666496\n",
      "Epoch:  290  Loss:  1.082689910772301  Validation Loss:  0.873176081638251\n",
      "Epoch:  291  Loss:  1.082322996553211  Validation Loss:  0.8727660219052008\n",
      "Epoch:  292  Loss:  1.0819564097161805  Validation Loss:  0.872356366366148\n",
      "Epoch:  293  Loss:  1.0815902519971132  Validation Loss:  0.8719472034967372\n",
      "Epoch:  294  Loss:  1.081224542909435  Validation Loss:  0.8715384079675589\n",
      "Epoch:  295  Loss:  1.0808591987228109  Validation Loss:  0.871130069850811\n",
      "Epoch:  296  Loss:  1.0804943970094125  Validation Loss:  0.8707223341667226\n",
      "Epoch:  297  Loss:  1.0801300131494092  Validation Loss:  0.8703150763841612\n",
      "Epoch:  298  Loss:  1.0797660314433633  Validation Loss:  0.8699081148952246\n",
      "Epoch:  299  Loss:  1.0794023585816224  Validation Loss:  0.8695014747125762\n",
      "Epoch:  300  Loss:  1.0790390061835449  Validation Loss:  0.8690951229738337\n",
      "Epoch:  301  Loss:  1.0786763839423656  Validation Loss:  0.8686898584876742\n",
      "Epoch:  302  Loss:  1.0783148243845928  Validation Loss:  0.8682850671133825\n",
      "Epoch:  303  Loss:  1.0779536763827007  Validation Loss:  0.8678807960823178\n",
      "Epoch:  304  Loss:  1.0775929958160435  Validation Loss:  0.8674769143440894\n",
      "Epoch:  305  Loss:  1.077232790844781  Validation Loss:  0.8670736325106451\n",
      "Epoch:  306  Loss:  1.0768731758885441  Validation Loss:  0.8666710763105324\n",
      "Epoch:  307  Loss:  1.0765143828910022  Validation Loss:  0.8662692867219448\n",
      "Epoch:  308  Loss:  1.076156094936388  Validation Loss:  0.8658678176413689\n",
      "Epoch:  309  Loss:  1.0757980901925337  Validation Loss:  0.865466615850372\n",
      "Epoch:  310  Loss:  1.0754404157577526  Validation Loss:  0.8650657300438199\n",
      "Epoch:  311  Loss:  1.0750831660060656  Validation Loss:  0.8646654026316745\n",
      "Epoch:  312  Loss:  1.0747263468801975  Validation Loss:  0.8642654110278402\n",
      "Epoch:  313  Loss:  1.0743698180608807  Validation Loss:  0.8638656378856727\n",
      "Epoch:  314  Loss:  1.0740135761776142  Validation Loss:  0.8634663115122488\n",
      "Epoch:  315  Loss:  1.0736579438227982  Validation Loss:  0.8630676038031068\n",
      "Epoch:  316  Loss:  1.0733027393441825  Validation Loss:  0.8626694806984493\n",
      "Epoch:  317  Loss:  1.0729480050504208  Validation Loss:  0.8622716758400202\n",
      "Epoch:  318  Loss:  1.0725937349987882  Validation Loss:  0.8618744614401034\n",
      "Epoch:  319  Loss:  1.072240043342823  Validation Loss:  0.8614779597680483\n",
      "Epoch:  320  Loss:  1.071886888128661  Validation Loss:  0.8610817804666502\n",
      "Epoch:  321  Loss:  1.0715340532007671  Validation Loss:  0.8606859218063099\n",
      "Epoch:  322  Loss:  1.0711816366584528  Validation Loss:  0.8602906238021595\n",
      "Epoch:  323  Loss:  1.070829677173779  Validation Loss:  0.8598956016025373\n",
      "Epoch:  324  Loss:  1.0704780008998656  Validation Loss:  0.8595008992456964\n",
      "Epoch:  325  Loss:  1.0701266380825214  Validation Loss:  0.859106484667531\n",
      "Epoch:  326  Loss:  1.069775655333485  Validation Loss:  0.8587125531796899\n",
      "Epoch:  327  Loss:  1.0694250534510328  Validation Loss:  0.8583189761266112\n",
      "Epoch:  328  Loss:  1.0690751010108561  Validation Loss:  0.8579263033877526\n",
      "Epoch:  329  Loss:  1.0687256450099605  Validation Loss:  0.8575339353244219\n",
      "Epoch:  330  Loss:  1.0683764741711674  Validation Loss:  0.8571418071431773\n",
      "Epoch:  331  Loss:  1.0680276076531126  Validation Loss:  0.8567499761868801\n",
      "Epoch:  332  Loss:  1.0676789623463439  Validation Loss:  0.8563583430701068\n",
      "Epoch:  333  Loss:  1.0673305555468513  Validation Loss:  0.8559669685949173\n",
      "Epoch:  334  Loss:  1.0669824810077746  Validation Loss:  0.8555759224774582\n",
      "Epoch:  335  Loss:  1.0666348482703878  Validation Loss:  0.8551854394110185\n",
      "Epoch:  336  Loss:  1.0662876207026697  Validation Loss:  0.8547952453206692\n",
      "Epoch:  337  Loss:  1.065940689472925  Validation Loss:  0.8544053497857281\n",
      "Epoch:  338  Loss:  1.0655941179997863  Validation Loss:  0.8540158446079918\n",
      "Epoch:  339  Loss:  1.0652478912046977  Validation Loss:  0.8536266747063824\n",
      "Epoch:  340  Loss:  1.0649020970754681  Validation Loss:  0.8532379932169404\n",
      "Epoch:  341  Loss:  1.064556626070823  Validation Loss:  0.8528496287763119\n",
      "Epoch:  342  Loss:  1.0642116350964421  Validation Loss:  0.8524619838488954\n",
      "Epoch:  343  Loss:  1.0638672018512374  Validation Loss:  0.8520747665315866\n",
      "Epoch:  344  Loss:  1.0635232542242323  Validation Loss:  0.8516880887161408\n",
      "Epoch:  345  Loss:  1.0631796817871786  Validation Loss:  0.851301754558725\n",
      "Epoch:  346  Loss:  1.0628363691447746  Validation Loss:  0.8509156848969204\n",
      "Epoch:  347  Loss:  1.0624933286259572  Validation Loss:  0.8505297843366861\n",
      "Epoch:  348  Loss:  1.0621504919337375  Validation Loss:  0.8501442104045834\n",
      "Epoch:  349  Loss:  1.0618089701802957  Validation Loss:  0.8497603036729353\n",
      "Epoch:  350  Loss:  1.0614691111480905  Validation Loss:  0.8493771180510521\n",
      "Epoch:  351  Loss:  1.0611297634563275  Validation Loss:  0.8489942764863372\n",
      "Epoch:  352  Loss:  1.0607907245201724  Validation Loss:  0.8486116983528648\n",
      "Epoch:  353  Loss:  1.0604519868890445  Validation Loss:  0.8482293992170266\n",
      "Epoch:  354  Loss:  1.0601135205832266  Validation Loss:  0.8478473926495228\n",
      "Epoch:  355  Loss:  1.0597753913274832  Validation Loss:  0.847465666277068\n",
      "Epoch:  356  Loss:  1.059437601250552  Validation Loss:  0.8470843684460435\n",
      "Epoch:  357  Loss:  1.0591003427370673  Validation Loss:  0.8467035026156476\n",
      "Epoch:  358  Loss:  1.058763518840784  Validation Loss:  0.8463231049744147\n",
      "Epoch:  359  Loss:  1.058427148897733  Validation Loss:  0.8459431176472988\n",
      "Epoch:  360  Loss:  1.0580910579966647  Validation Loss:  0.8455633108637163\n",
      "Epoch:  361  Loss:  1.0577552029419512  Validation Loss:  0.8451837462240032\n",
      "Epoch:  362  Loss:  1.0574196170838106  Validation Loss:  0.8448044529982975\n",
      "Epoch:  363  Loss:  1.0570844001181068  Validation Loss:  0.8444256046786904\n",
      "Epoch:  364  Loss:  1.0567495384741397  Validation Loss:  0.8440471339438643\n",
      "Epoch:  365  Loss:  1.056415157836108  Validation Loss:  0.8436691355226296\n",
      "Epoch:  366  Loss:  1.056081135979011  Validation Loss:  0.8432915459520051\n",
      "Epoch:  367  Loss:  1.0557474555181605  Validation Loss:  0.8429143126787884\n",
      "Epoch:  368  Loss:  1.0554142047961552  Validation Loss:  0.8425375442685825\n",
      "Epoch:  369  Loss:  1.0550813528576068  Validation Loss:  0.8421611044821995\n",
      "Epoch:  370  Loss:  1.0547488180122204  Validation Loss:  0.8417849607233491\n",
      "Epoch:  371  Loss:  1.0544165724977141  Validation Loss:  0.8414090537865248\n",
      "Epoch:  372  Loss:  1.054084535510767  Validation Loss:  0.8410333257966808\n",
      "Epoch:  373  Loss:  1.05375273827286  Validation Loss:  0.8406578984909824\n",
      "Epoch:  374  Loss:  1.053421267263946  Validation Loss:  0.8402827384748629\n",
      "Epoch:  375  Loss:  1.0530900790223054  Validation Loss:  0.8399078822029489\n",
      "Epoch:  376  Loss:  1.052759200778036  Validation Loss:  0.8395333095852818\n",
      "Epoch:  377  Loss:  1.0524286035270918  Validation Loss:  0.8391590159652489\n",
      "Epoch:  378  Loss:  1.0520983899810485  Validation Loss:  0.8387852251263601\n",
      "Epoch:  379  Loss:  1.0517686569087563  Validation Loss:  0.838411767434861\n",
      "Epoch:  380  Loss:  1.0514392088211717  Validation Loss:  0.838038648744779\n",
      "Epoch:  381  Loss:  1.0511100516610203  Validation Loss:  0.8376656899760876\n",
      "Epoch:  382  Loss:  1.0507810913203728  Validation Loss:  0.837292996368238\n",
      "Epoch:  383  Loss:  1.0504523925483227  Validation Loss:  0.8369205379858613\n",
      "Epoch:  384  Loss:  1.0501240046606177  Validation Loss:  0.8365484127508742\n",
      "Epoch:  385  Loss:  1.0497958971453565  Validation Loss:  0.8361765407025814\n",
      "Epoch:  386  Loss:  1.049468093152557  Validation Loss:  0.835804988630116\n",
      "Epoch:  387  Loss:  1.0491406100669078  Validation Loss:  0.8354337118299944\n",
      "Epoch:  388  Loss:  1.0488134183521782  Validation Loss:  0.8350627025855439\n",
      "Epoch:  389  Loss:  1.0484865132187093  Validation Loss:  0.8346920218318701\n",
      "Epoch:  390  Loss:  1.0481599924997205  Validation Loss:  0.834321749263576\n",
      "Epoch:  391  Loss:  1.0478338103386617  Validation Loss:  0.8339517772463816\n",
      "Epoch:  392  Loss:  1.0475079975135269  Validation Loss:  0.8335822867229581\n",
      "Epoch:  393  Loss:  1.0471826796198176  Validation Loss:  0.833213331710015\n",
      "Epoch:  394  Loss:  1.0468580297948349  Validation Loss:  0.832845169252583\n",
      "Epoch:  395  Loss:  1.0465340382818664  Validation Loss:  0.8324777517201645\n",
      "Epoch:  396  Loss:  1.04621055030397  Validation Loss:  0.8321106294170022\n",
      "Epoch:  397  Loss:  1.0458873434967937  Validation Loss:  0.8317436933783549\n",
      "Epoch:  398  Loss:  1.045564337677899  Validation Loss:  0.8313770193074431\n",
      "Epoch:  399  Loss:  1.0452415991929316  Validation Loss:  0.8310106355430824\n",
      "Epoch:  400  Loss:  1.0449191717697042  Validation Loss:  0.8306444859398263\n",
      "Epoch:  401  Loss:  1.0445970474254518  Validation Loss:  0.830278684651213\n",
      "Epoch:  402  Loss:  1.0442752458509945  Validation Loss:  0.8299131793901324\n",
      "Epoch:  403  Loss:  1.043953841729533  Validation Loss:  0.8295482019228595\n",
      "Epoch:  404  Loss:  1.0436328100484042  Validation Loss:  0.8291833934241107\n",
      "Epoch:  405  Loss:  1.0433119708406073  Validation Loss:  0.8288188649873648\n",
      "Epoch:  406  Loss:  1.042991476399558  Validation Loss:  0.8284545850807002\n",
      "Epoch:  407  Loss:  1.0426712320851428  Validation Loss:  0.8280906188966972\n",
      "Epoch:  408  Loss:  1.0423513107179176  Validation Loss:  0.8277269136160612\n",
      "Epoch:  409  Loss:  1.0420316725614525  Validation Loss:  0.8273635183327964\n",
      "Epoch:  410  Loss:  1.0417122892325832  Validation Loss:  0.8270002849666136\n",
      "Epoch:  411  Loss:  1.0413931241879861  Validation Loss:  0.8266373131690281\n",
      "Epoch:  412  Loss:  1.0410742335731076  Validation Loss:  0.8262746057340077\n",
      "Epoch:  413  Loss:  1.0407556588096278  Validation Loss:  0.8259122221331511\n",
      "Epoch:  414  Loss:  1.040437349162641  Validation Loss:  0.825550100233938\n",
      "Epoch:  415  Loss:  1.0401193618419624  Validation Loss:  0.8251882203455482\n",
      "Epoch:  416  Loss:  1.0398015557300477  Validation Loss:  0.8248265414897885\n",
      "Epoch:  417  Loss:  1.0394841439667202  Validation Loss:  0.8244653825781175\n",
      "Epoch:  418  Loss:  1.039167153072499  Validation Loss:  0.8241045548181448\n",
      "Epoch:  419  Loss:  1.0388504819323618  Validation Loss:  0.8237440261457648\n",
      "Epoch:  420  Loss:  1.038533951643677  Validation Loss:  0.8233835707817759\n",
      "Epoch:  421  Loss:  1.0382173513727528  Validation Loss:  0.8230232020307865\n",
      "Epoch:  422  Loss:  1.037900701786081  Validation Loss:  0.8226631178653666\n",
      "Epoch:  423  Loss:  1.0375843420624733  Validation Loss:  0.8223032961998668\n",
      "Epoch:  424  Loss:  1.0372682584538346  Validation Loss:  0.8219437588538442\n",
      "Epoch:  425  Loss:  1.03695238151011  Validation Loss:  0.8215843944677285\n",
      "Epoch:  426  Loss:  1.0366367814796311  Validation Loss:  0.8212252895214728\n",
      "Epoch:  427  Loss:  1.0363214834637584  Validation Loss:  0.8208665106711643\n",
      "Epoch:  428  Loss:  1.0360064672394877  Validation Loss:  0.8205079550721815\n",
      "Epoch:  429  Loss:  1.0356916904094673  Validation Loss:  0.8201495995745063\n",
      "Epoch:  430  Loss:  1.03537714303959  Validation Loss:  0.8197915174865297\n",
      "Epoch:  431  Loss:  1.0350628795900516  Validation Loss:  0.8194337379453438\n",
      "Epoch:  432  Loss:  1.0347489188646986  Validation Loss:  0.8190761793937001\n",
      "Epoch:  433  Loss:  1.0344352890693007  Validation Loss:  0.8187190782544869\n",
      "Epoch:  434  Loss:  1.0341220767725081  Validation Loss:  0.8183624889435512\n",
      "Epoch:  435  Loss:  1.0338093396276236  Validation Loss:  0.8180062877280372\n",
      "Epoch:  436  Loss:  1.0334969390893267  Validation Loss:  0.8176504241834793\n",
      "Epoch:  437  Loss:  1.0331848047318912  Validation Loss:  0.8172948280615466\n",
      "Epoch:  438  Loss:  1.0328729707925093  Validation Loss:  0.8169395722714918\n",
      "Epoch:  439  Loss:  1.0325614153629257  Validation Loss:  0.8165844521884408\n",
      "Epoch:  440  Loss:  1.032250064203427  Validation Loss:  0.8162296165579132\n",
      "Epoch:  441  Loss:  1.0319389940372534  Validation Loss:  0.8158750286591905\n",
      "Epoch:  442  Loss:  1.0316281415344704  Validation Loss:  0.8155205763344254\n",
      "Epoch:  443  Loss:  1.0313174681117137  Validation Loss:  0.8151663644239306\n",
      "Epoch:  444  Loss:  1.0310070161663352  Validation Loss:  0.8148123236106974\n",
      "Epoch:  445  Loss:  1.030696782860018  Validation Loss:  0.8144584600148457\n",
      "Epoch:  446  Loss:  1.0303867713858683  Validation Loss:  0.8141048497387341\n",
      "Epoch:  447  Loss:  1.0300769767768325  Validation Loss:  0.8137514074998242\n",
      "Epoch:  448  Loss:  1.0297673633765607  Validation Loss:  0.8133981991559267\n",
      "Epoch:  449  Loss:  1.0294580745200317  Validation Loss:  0.8130452445309077\n",
      "Epoch:  450  Loss:  1.0291490051008405  Validation Loss:  0.8126925094319242\n",
      "Epoch:  451  Loss:  1.028840210998342  Validation Loss:  0.8123400692961046\n",
      "Epoch:  452  Loss:  1.0285317782490027  Validation Loss:  0.8119880175217986\n",
      "Epoch:  453  Loss:  1.0282236812192769  Validation Loss:  0.8116362975644213\n",
      "Epoch:  454  Loss:  1.027915864828087  Validation Loss:  0.8112847125157714\n",
      "Epoch:  455  Loss:  1.0276082651246161  Validation Loss:  0.8109334274860365\n",
      "Epoch:  456  Loss:  1.0273009071215278  Validation Loss:  0.8105822884078536\n",
      "Epoch:  457  Loss:  1.026993791351006  Validation Loss:  0.8102314393701298\n",
      "Epoch:  458  Loss:  1.0266869112494446  Validation Loss:  0.809880741073617\n",
      "Epoch:  459  Loss:  1.0263802614063025  Validation Loss:  0.8095302854531577\n",
      "Epoch:  460  Loss:  1.0260738138819026  Validation Loss:  0.8091800698478308\n",
      "Epoch:  461  Loss:  1.0257676348444962  Validation Loss:  0.8088300089750972\n",
      "Epoch:  462  Loss:  1.025461652892686  Validation Loss:  0.8084801982289979\n",
      "Epoch:  463  Loss:  1.0251558806215013  Validation Loss:  0.8081305527261325\n",
      "Epoch:  464  Loss:  1.024850351824647  Validation Loss:  0.8077811251527497\n",
      "Epoch:  465  Loss:  1.0245451034889335  Validation Loss:  0.80743200105748\n",
      "Epoch:  466  Loss:  1.024240241430345  Validation Loss:  0.807083184032568\n",
      "Epoch:  467  Loss:  1.0239356176129408  Validation Loss:  0.8067345286586455\n",
      "Epoch:  468  Loss:  1.023631255541529  Validation Loss:  0.806386095205588\n",
      "Epoch:  469  Loss:  1.023327043368703  Validation Loss:  0.8060378136911562\n",
      "Epoch:  470  Loss:  1.0230230173716943  Validation Loss:  0.8056897982688886\n",
      "Epoch:  471  Loss:  1.0227192920588313  Validation Loss:  0.8053419777591314\n",
      "Epoch:  472  Loss:  1.0224157977139665  Validation Loss:  0.8049943561532668\n",
      "Epoch:  473  Loss:  1.0221124596538997  Validation Loss:  0.8046469073742628\n",
      "Epoch:  474  Loss:  1.0218093257752203  Validation Loss:  0.8042995823281152\n",
      "Epoch:  475  Loss:  1.0215063326592957  Validation Loss:  0.803952421726925\n",
      "Epoch:  476  Loss:  1.0212035358306908  Validation Loss:  0.8036053868542824\n",
      "Epoch:  477  Loss:  1.020900877281314  Validation Loss:  0.8032585057829108\n",
      "Epoch:  478  Loss:  1.0205983660582985  Validation Loss:  0.802911747646119\n",
      "Epoch:  479  Loss:  1.020296038527574  Validation Loss:  0.8025652011856437\n",
      "Epoch:  480  Loss:  1.0199939170408816  Validation Loss:  0.8022188029385039\n",
      "Epoch:  481  Loss:  1.0196919425257616  Validation Loss:  0.801872483986829\n",
      "Epoch:  482  Loss:  1.0193900958235775  Validation Loss:  0.8015262597639646\n",
      "Epoch:  483  Loss:  1.019088353252127  Validation Loss:  0.8011801377204912\n",
      "Epoch:  484  Loss:  1.0187864457922322  Validation Loss:  0.8008338320734245\n",
      "Epoch:  485  Loss:  1.0184841164875598  Validation Loss:  0.8004875732585788\n",
      "Epoch:  486  Loss:  1.018181900005965  Validation Loss:  0.800141340254673\n",
      "Epoch:  487  Loss:  1.017879754127491  Validation Loss:  0.7997951441045318\n",
      "Epoch:  488  Loss:  1.0175776336164701  Validation Loss:  0.7994489770914827\n",
      "Epoch:  489  Loss:  1.0172755707587515  Validation Loss:  0.7991027971729636\n",
      "Epoch:  490  Loss:  1.0169735339780648  Validation Loss:  0.7987566117995551\n",
      "Epoch:  491  Loss:  1.0166715268223059  Validation Loss:  0.7984104562284691\n",
      "Epoch:  492  Loss:  1.0163695439696312  Validation Loss:  0.7980642918763416\n",
      "Epoch:  493  Loss:  1.0160675770824863  Validation Loss:  0.7977180736405509\n",
      "Epoch:  494  Loss:  1.015765564338792  Validation Loss:  0.7973717441782355\n",
      "Epoch:  495  Loss:  1.0154634797502131  Validation Loss:  0.7970253014937043\n",
      "Epoch:  496  Loss:  1.0151612800324248  Validation Loss:  0.7966786799952388\n",
      "Epoch:  497  Loss:  1.014859003236606  Validation Loss:  0.7963320260335293\n",
      "Epoch:  498  Loss:  1.0145566256805545  Validation Loss:  0.7959851468248027\n",
      "Epoch:  499  Loss:  1.0142540771159387  Validation Loss:  0.7956380661843079\n",
      "Epoch:  500  Loss:  1.0139513540835607  Validation Loss:  0.7952907544427684\n",
      "Epoch:  501  Loss:  1.0136484225236235  Validation Loss:  0.7949432288961751\n",
      "Epoch:  502  Loss:  1.0133451979075159  Validation Loss:  0.7945952946320176\n",
      "Epoch:  503  Loss:  1.0130417927035265  Validation Loss:  0.79424722080252\n",
      "Epoch:  504  Loss:  1.0127382462045975  Validation Loss:  0.7938987308048776\n",
      "Epoch:  505  Loss:  1.0124342359957241  Validation Loss:  0.7935496648507459\n",
      "Epoch:  506  Loss:  1.0121292332630782  Validation Loss:  0.7932001055617418\n",
      "Epoch:  507  Loss:  1.0118235990050293  Validation Loss:  0.7928497161982315\n",
      "Epoch:  508  Loss:  1.0115171817264386  Validation Loss:  0.7924984851852059\n",
      "Epoch:  509  Loss:  1.011209925814044  Validation Loss:  0.7921462057690535\n",
      "Epoch:  510  Loss:  1.010901731838073  Validation Loss:  0.791792854799756\n",
      "Epoch:  511  Loss:  1.0105924630271537  Validation Loss:  0.7914382212662271\n",
      "Epoch:  512  Loss:  1.0102819589277108  Validation Loss:  0.7910822003281542\n",
      "Epoch:  513  Loss:  1.0099701786502486  Validation Loss:  0.7907246904713767\n",
      "Epoch:  514  Loss:  1.0096570004132532  Validation Loss:  0.7903656499194247\n",
      "Epoch:  515  Loss:  1.0093424006232194  Validation Loss:  0.7900049750294004\n",
      "Epoch:  516  Loss:  1.0090260801925546  Validation Loss:  0.7896423734990614\n",
      "Epoch:  517  Loss:  1.0087077175045298  Validation Loss:  0.7892780023227844\n",
      "Epoch:  518  Loss:  1.0083877155113787  Validation Loss:  0.7889119127233114\n",
      "Epoch:  519  Loss:  1.0080662342231899  Validation Loss:  0.7885441980989916\n",
      "Epoch:  520  Loss:  1.0077432747930288  Validation Loss:  0.7881748813337514\n",
      "Epoch:  521  Loss:  1.0074189174033346  Validation Loss:  0.7878040643408895\n",
      "Epoch:  522  Loss:  1.007093298204598  Validation Loss:  0.7874319276639393\n",
      "Epoch:  523  Loss:  1.0067663197183894  Validation Loss:  0.7870583832263947\n",
      "Epoch:  524  Loss:  1.0064379502797411  Validation Loss:  0.7866838903033307\n",
      "Epoch:  525  Loss:  1.0061088100607907  Validation Loss:  0.7863086764035481\n",
      "Epoch:  526  Loss:  1.005779152115186  Validation Loss:  0.7859329159504601\n",
      "Epoch:  527  Loss:  1.0054491337920939  Validation Loss:  0.7855568256761346\n",
      "Epoch:  528  Loss:  1.0051185464752572  Validation Loss:  0.7851802521784391\n",
      "Epoch:  529  Loss:  1.0047875172680332  Validation Loss:  0.7848037031612226\n",
      "Epoch:  530  Loss:  1.0044565819026459  Validation Loss:  0.7844272432848811\n",
      "Epoch:  531  Loss:  1.004125581522073  Validation Loss:  0.7840507041130748\n",
      "Epoch:  532  Loss:  1.003794296777674  Validation Loss:  0.7836743716948799\n",
      "Epoch:  533  Loss:  1.0034633378187816  Validation Loss:  0.7832984244450927\n",
      "Epoch:  534  Loss:  1.0031324409480606  Validation Loss:  0.7829226070482816\n",
      "Epoch:  535  Loss:  1.0028015191533737  Validation Loss:  0.7825472317636013\n",
      "Epoch:  536  Loss:  1.0024708271736191  Validation Loss:  0.7821720400825143\n",
      "Epoch:  537  Loss:  1.0021400607767559  Validation Loss:  0.7817973107365626\n",
      "Epoch:  538  Loss:  1.0018094051629305  Validation Loss:  0.7814227156341076\n",
      "Epoch:  539  Loss:  1.0014787010316337  Validation Loss:  0.7810484966529267\n",
      "Epoch:  540  Loss:  1.0011478988010258  Validation Loss:  0.7806745379098824\n",
      "Epoch:  541  Loss:  1.0008170125739915  Validation Loss:  0.7803007034318787\n",
      "Epoch:  542  Loss:  1.0004858355082216  Validation Loss:  0.7799270492313164\n",
      "Epoch:  543  Loss:  1.00015439838171  Validation Loss:  0.7795536153550658\n",
      "Epoch:  544  Loss:  0.999822775345473  Validation Loss:  0.7791804462405187\n",
      "Epoch:  545  Loss:  0.9994909062626816  Validation Loss:  0.7788075328405414\n",
      "Epoch:  546  Loss:  0.9991587978743371  Validation Loss:  0.778434797589268\n",
      "Epoch:  547  Loss:  0.99882637274762  Validation Loss:  0.778062263902809\n",
      "Epoch:  548  Loss:  0.9984935977984042  Validation Loss:  0.7776899112920675\n",
      "Epoch:  549  Loss:  0.9981605161336207  Validation Loss:  0.7773178129323891\n",
      "Epoch:  550  Loss:  0.997827165449659  Validation Loss:  0.7769459391544972\n",
      "Epoch:  551  Loss:  0.9974935665017083  Validation Loss:  0.7765744349786213\n",
      "Epoch:  552  Loss:  0.9971598786789746  Validation Loss:  0.7762030865997076\n",
      "Epoch:  553  Loss:  0.9968258940747806  Validation Loss:  0.7758319479014192\n",
      "Epoch:  554  Loss:  0.9964917554919209  Validation Loss:  0.7754612265686903\n",
      "Epoch:  555  Loss:  0.9961577360296533  Validation Loss:  0.7750907244959048\n",
      "Epoch:  556  Loss:  0.995823542454413  Validation Loss:  0.7747205776561584\n",
      "Epoch:  557  Loss:  0.9954895262739488  Validation Loss:  0.7743506313168577\n",
      "Epoch:  558  Loss:  0.995155671079244  Validation Loss:  0.7739810411419187\n",
      "Epoch:  559  Loss:  0.9948218359301487  Validation Loss:  0.7736116291156837\n",
      "Epoch:  560  Loss:  0.9944878456493219  Validation Loss:  0.7732425783095616\n",
      "Epoch:  561  Loss:  0.9941541488681521  Validation Loss:  0.7728739618988973\n",
      "Epoch:  562  Loss:  0.99382072722628  Validation Loss:  0.7725057096353599\n",
      "Epoch:  563  Loss:  0.9934875589928457  Validation Loss:  0.7721378875098058\n",
      "Epoch:  564  Loss:  0.9931546802676859  Validation Loss:  0.7717704069135445\n",
      "Epoch:  565  Loss:  0.9928220192946139  Validation Loss:  0.7714033600475106\n",
      "Epoch:  566  Loss:  0.9924896270746276  Validation Loss:  0.7710366905001658\n",
      "Epoch:  567  Loss:  0.9921574486153466  Validation Loss:  0.7706703020791922\n",
      "Epoch:  568  Loss:  0.9918256801153932  Validation Loss:  0.7703043525772435\n",
      "Epoch:  569  Loss:  0.9914944772386834  Validation Loss:  0.7699389424441117\n",
      "Epoch:  570  Loss:  0.991163798740932  Validation Loss:  0.7695739705647741\n",
      "Epoch:  571  Loss:  0.990833383230936  Validation Loss:  0.7692093293049506\n",
      "Epoch:  572  Loss:  0.990503306012778  Validation Loss:  0.7688451276293823\n",
      "Epoch:  573  Loss:  0.9901735785284212  Validation Loss:  0.768481303804687\n",
      "Epoch:  574  Loss:  0.989844202463116  Validation Loss:  0.7681177918400083\n",
      "Epoch:  575  Loss:  0.9895149955437297  Validation Loss:  0.7677544932812452\n",
      "Epoch:  576  Loss:  0.9891861212395486  Validation Loss:  0.7673915765647378\n",
      "Epoch:  577  Loss:  0.9888576192870027  Validation Loss:  0.7670290395617485\n",
      "Epoch:  578  Loss:  0.9885295676510959  Validation Loss:  0.7666669493275029\n",
      "Epoch:  579  Loss:  0.988201890406864  Validation Loss:  0.7663051597774029\n",
      "Epoch:  580  Loss:  0.987874505686618  Validation Loss:  0.7659436403108495\n",
      "Epoch:  581  Loss:  0.9875474659105142  Validation Loss:  0.7655825183859893\n",
      "Epoch:  582  Loss:  0.987221345571535  Validation Loss:  0.7652219643018076\n",
      "Epoch:  583  Loss:  0.9868958722800016  Validation Loss:  0.7648618279823235\n",
      "Epoch:  584  Loss:  0.9865706669432777  Validation Loss:  0.7645018260393824\n",
      "Epoch:  585  Loss:  0.9862457485426039  Validation Loss:  0.7641422165823835\n",
      "Epoch:  586  Loss:  0.9859212822325173  Validation Loss:  0.7637829631567001\n",
      "Epoch:  587  Loss:  0.9855971913784742  Validation Loss:  0.7634240750755582\n",
      "Epoch:  588  Loss:  0.9852734131827241  Validation Loss:  0.7630654089152813\n",
      "Epoch:  589  Loss:  0.9849500155874661  Validation Loss:  0.7627072134720427\n",
      "Epoch:  590  Loss:  0.9846269879490137  Validation Loss:  0.7623492261128766\n",
      "Epoch:  591  Loss:  0.9843042920387927  Validation Loss:  0.7619915958493948\n",
      "Epoch:  592  Loss:  0.9839819589895862  Validation Loss:  0.7616342697292566\n",
      "Epoch:  593  Loss:  0.98365985548922  Validation Loss:  0.7612770806465831\n",
      "Epoch:  594  Loss:  0.9833380974651802  Validation Loss:  0.7609203425901276\n",
      "Epoch:  595  Loss:  0.983016621144045  Validation Loss:  0.7605636942067316\n",
      "Epoch:  596  Loss:  0.9826953291360822  Validation Loss:  0.760207200422883\n",
      "Epoch:  597  Loss:  0.9823742745710271  Validation Loss:  0.7598510565502303\n",
      "Epoch:  598  Loss:  0.9820535488958869  Validation Loss:  0.7594950941524335\n",
      "Epoch:  599  Loss:  0.9817330051390898  Validation Loss:  0.759139229410461\n",
      "Epoch:  600  Loss:  0.9814126370918184  Validation Loss:  0.7587835775422198\n",
      "Epoch:  601  Loss:  0.9810925212999185  Validation Loss:  0.7584282061351197\n",
      "Epoch:  602  Loss:  0.980772640556097  Validation Loss:  0.7580729464867285\n",
      "Epoch:  603  Loss:  0.9804529199997584  Validation Loss:  0.7577178164252213\n",
      "Epoch:  604  Loss:  0.9801337251528388  Validation Loss:  0.7573628566626992\n",
      "Epoch:  605  Loss:  0.9798147848674229  Validation Loss:  0.7570080948727471\n",
      "Epoch:  606  Loss:  0.9794959753219571  Validation Loss:  0.7566533902926105\n",
      "Epoch:  607  Loss:  0.9791772115443435  Validation Loss:  0.756298650588308\n",
      "Epoch:  608  Loss:  0.9788584804960659  Validation Loss:  0.7559440481875624\n",
      "Epoch:  609  Loss:  0.9785397172506366  Validation Loss:  0.7555890535669667\n",
      "Epoch:  610  Loss:  0.9782195574648324  Validation Loss:  0.7552331316151789\n",
      "Epoch:  611  Loss:  0.9778988019873699  Validation Loss:  0.7548770803425994\n",
      "Epoch:  612  Loss:  0.9775779252605779  Validation Loss:  0.7545209689331906\n",
      "Epoch:  613  Loss:  0.9772569231156792  Validation Loss:  0.7541646896196263\n",
      "Epoch:  614  Loss:  0.9769357946656999  Validation Loss:  0.7538083573537213\n",
      "Epoch:  615  Loss:  0.9766145591579732  Validation Loss:  0.7534518683595317\n",
      "Epoch:  616  Loss:  0.9762931635514611  Validation Loss:  0.7530952569629464\n",
      "Epoch:  617  Loss:  0.9759717574786573  Validation Loss:  0.7527386037898915\n",
      "Epoch:  618  Loss:  0.9756502750374022  Validation Loss:  0.7523818625403302\n",
      "Epoch:  619  Loss:  0.9753287798237233  Validation Loss:  0.7520251431103263\n",
      "Epoch:  620  Loss:  0.9750074221796933  Validation Loss:  0.7516685985028744\n",
      "Epoch:  621  Loss:  0.9746862005974565  Validation Loss:  0.7513121784265552\n",
      "Epoch:  622  Loss:  0.9743650943218243  Validation Loss:  0.7509558421692678\n",
      "Epoch:  623  Loss:  0.9740441783907867  Validation Loss:  0.7505996967000621\n",
      "Epoch:  624  Loss:  0.9737235081515142  Validation Loss:  0.7502437571861914\n",
      "Epoch:  625  Loss:  0.9734031380642028  Validation Loss:  0.7498881678496089\n",
      "Epoch:  626  Loss:  0.9730831531896478  Validation Loss:  0.7495329414627382\n",
      "Epoch:  627  Loss:  0.9727635662115756  Validation Loss:  0.7491780716393676\n",
      "Epoch:  628  Loss:  0.9724443315395287  Validation Loss:  0.748823503564511\n",
      "Epoch:  629  Loss:  0.9721254772905793  Validation Loss:  0.7484692971089056\n",
      "Epoch:  630  Loss:  0.9718070161484537  Validation Loss:  0.748115493782929\n",
      "Epoch:  631  Loss:  0.9714889688683408  Validation Loss:  0.7477620616555214\n",
      "Epoch:  632  Loss:  0.9711713633012204  Validation Loss:  0.7474090196192265\n",
      "Epoch:  633  Loss:  0.9708542414009571  Validation Loss:  0.7470564544200897\n",
      "Epoch:  634  Loss:  0.9705374912314472  Validation Loss:  0.7467042236988034\n",
      "Epoch:  635  Loss:  0.9702211371844723  Validation Loss:  0.7463522917990174\n",
      "Epoch:  636  Loss:  0.9699051735833997  Validation Loss:  0.7460007949599198\n",
      "Epoch:  637  Loss:  0.9695896537353595  Validation Loss:  0.7456497028470039\n",
      "Epoch:  638  Loss:  0.9692746111679644  Validation Loss:  0.7452990159924541\n",
      "Epoch:  639  Loss:  0.9689600214894328  Validation Loss:  0.7449487365250077\n",
      "Epoch:  640  Loss:  0.9686457567094338  Validation Loss:  0.744598686961191\n",
      "Epoch:  641  Loss:  0.9683316589466163  Validation Loss:  0.744248896038958\n",
      "Epoch:  642  Loss:  0.9680179101193235  Validation Loss:  0.7438994201698473\n",
      "Epoch:  643  Loss:  0.9677045749766486  Validation Loss:  0.7435504405626229\n",
      "Epoch:  644  Loss:  0.9673917282017923  Validation Loss:  0.7432018569005387\n",
      "Epoch:  645  Loss:  0.9670794204409633  Validation Loss:  0.7428538796624967\n",
      "Epoch:  646  Loss:  0.9667677017194884  Validation Loss:  0.7425063819225345\n",
      "Epoch:  647  Loss:  0.9664564328711658  Validation Loss:  0.7421593434576478\n",
      "Epoch:  648  Loss:  0.9661456165569169  Validation Loss:  0.7418127514954124\n",
      "Epoch:  649  Loss:  0.9658353455542099  Validation Loss:  0.7414669112435409\n",
      "Epoch:  650  Loss:  0.9655256836364666  Validation Loss:  0.7411214858293533\n",
      "Epoch:  651  Loss:  0.9652164513688712  Validation Loss:  0.7407764686005456\n",
      "Epoch:  652  Loss:  0.9649076949627626  Validation Loss:  0.7404318824410439\n",
      "Epoch:  653  Loss:  0.9645994112250351  Validation Loss:  0.740087764603751\n",
      "Epoch:  654  Loss:  0.9642915662732863  Validation Loss:  0.7397439961454698\n",
      "Epoch:  655  Loss:  0.9639840840051571  Validation Loss:  0.739400550989168\n",
      "Epoch:  656  Loss:  0.9636769875706661  Validation Loss:  0.7390574509544032\n",
      "Epoch:  657  Loss:  0.9633702450387535  Validation Loss:  0.7387147210538387\n",
      "Epoch:  658  Loss:  0.963063878317674  Validation Loss:  0.7383723139230695\n",
      "Epoch:  659  Loss:  0.9627579602279833  Validation Loss:  0.7380303516983986\n",
      "Epoch:  660  Loss:  0.9624524191908893  Validation Loss:  0.7376887029302972\n",
      "Epoch:  661  Loss:  0.962147276937252  Validation Loss:  0.7373475703809943\n",
      "Epoch:  662  Loss:  0.9618431955930733  Validation Loss:  0.7370073925703764\n",
      "Epoch:  663  Loss:  0.961540002109749  Validation Loss:  0.736667690266456\n",
      "Epoch:  664  Loss:  0.9612375239708594  Validation Loss:  0.7363285230738776\n",
      "Epoch:  665  Loss:  0.9609356794861101  Validation Loss:  0.7359897592770202\n",
      "Epoch:  666  Loss:  0.9606343803129026  Validation Loss:  0.7356513919574874\n",
      "Epoch:  667  Loss:  0.9603335425435078  Validation Loss:  0.735313440273915\n",
      "Epoch:  668  Loss:  0.9600331409878674  Validation Loss:  0.7349758784153632\n",
      "Epoch:  669  Loss:  0.9597331074376901  Validation Loss:  0.7346386297472886\n",
      "Epoch:  670  Loss:  0.9594334546653998  Validation Loss:  0.7343017134283271\n",
      "Epoch:  671  Loss:  0.959134140539737  Validation Loss:  0.7339651387717042\n",
      "Epoch:  672  Loss:  0.9588352311402559  Validation Loss:  0.7336289060435125\n",
      "Epoch:  673  Loss:  0.958536689302751  Validation Loss:  0.7332930830972535\n",
      "Epoch:  674  Loss:  0.9582385607950744  Validation Loss:  0.7329575728092875\n",
      "Epoch:  675  Loss:  0.957940808985205  Validation Loss:  0.7326224448957613\n",
      "Epoch:  676  Loss:  0.9576431723045451  Validation Loss:  0.732286932479058\n",
      "Epoch:  677  Loss:  0.9573444888173115  Validation Loss:  0.7319512186305863\n",
      "Epoch:  678  Loss:  0.957045974298602  Validation Loss:  0.7316159414393562\n",
      "Epoch:  679  Loss:  0.9567479524938833  Validation Loss:  0.7312810671116624\n",
      "Epoch:  680  Loss:  0.95645039980965  Validation Loss:  0.730946713260242\n",
      "Epoch:  681  Loss:  0.9561532854679085  Validation Loss:  0.7306126875004598\n",
      "Epoch:  682  Loss:  0.9558565310601678  Validation Loss:  0.7302790473082236\n",
      "Epoch:  683  Loss:  0.9555601919335979  Validation Loss:  0.7299457402633769\n",
      "Epoch:  684  Loss:  0.9552641967754989  Validation Loss:  0.7296127687607493\n",
      "Epoch:  685  Loss:  0.9549685856770902  Validation Loss:  0.7292801580790963\n",
      "Epoch:  686  Loss:  0.9546733450676713  Validation Loss:  0.7289479201925653\n",
      "Epoch:  687  Loss:  0.9543785235534111  Validation Loss:  0.7286160779850823\n",
      "Epoch:  688  Loss:  0.9540840813978797  Validation Loss:  0.7282845590795789\n",
      "Epoch:  689  Loss:  0.9537899976684934  Validation Loss:  0.727953376514571\n",
      "Epoch:  690  Loss:  0.9534963194635653  Validation Loss:  0.7276225513113397\n",
      "Epoch:  691  Loss:  0.9532030233669848  Validation Loss:  0.7272920768175807\n",
      "Epoch:  692  Loss:  0.9529100568698985  Validation Loss:  0.7269619522350175\n",
      "Epoch:  693  Loss:  0.952617481173504  Validation Loss:  0.7266321834176779\n",
      "Epoch:  694  Loss:  0.9523253179199639  Validation Loss:  0.7263027834040778\n",
      "Epoch:  695  Loss:  0.9520336404620182  Validation Loss:  0.7259738761931658\n",
      "Epoch:  696  Loss:  0.9517424579354978  Validation Loss:  0.7256455240505082\n",
      "Epoch:  697  Loss:  0.9514516703784466  Validation Loss:  0.7253175042569637\n",
      "Epoch:  698  Loss:  0.9511608492050853  Validation Loss:  0.7249889576009342\n",
      "Epoch:  699  Loss:  0.9508688464051201  Validation Loss:  0.7246601464492934\n",
      "Epoch:  700  Loss:  0.9505769577586934  Validation Loss:  0.7243316476898534\n",
      "Epoch:  701  Loss:  0.9502854725079877  Validation Loss:  0.7240035254508257\n",
      "Epoch:  702  Loss:  0.9499943512713626  Validation Loss:  0.7236757757408279\n",
      "Epoch:  703  Loss:  0.9497036517908176  Validation Loss:  0.7233483799334083\n",
      "Epoch:  704  Loss:  0.949413319694854  Validation Loss:  0.7230213521314519\n",
      "Epoch:  705  Loss:  0.949123400751324  Validation Loss:  0.7226946989872626\n",
      "Epoch:  706  Loss:  0.9488339035638741  Validation Loss:  0.7223684819681304\n",
      "Epoch:  707  Loss:  0.9485448423240866  Validation Loss:  0.7220426204481295\n",
      "Epoch:  708  Loss:  0.9482562158788953  Validation Loss:  0.7217171564698219\n",
      "Epoch:  709  Loss:  0.9479679007615361  Validation Loss:  0.7213915676942894\n",
      "Epoch:  710  Loss:  0.9476785830975998  Validation Loss:  0.7210656002696071\n",
      "Epoch:  711  Loss:  0.947389249113344  Validation Loss:  0.7207399949963603\n",
      "Epoch:  712  Loss:  0.9471003064619643  Validation Loss:  0.7204147348446506\n",
      "Epoch:  713  Loss:  0.9468117381135622  Validation Loss:  0.7200898820800441\n",
      "Epoch:  714  Loss:  0.9465235556874957  Validation Loss:  0.7197653587375369\n",
      "Epoch:  715  Loss:  0.9462357308006003  Validation Loss:  0.719441173065986\n",
      "Epoch:  716  Loss:  0.9459480923556146  Validation Loss:  0.719116677663156\n",
      "Epoch:  717  Loss:  0.9456593829783655  Validation Loss:  0.7187919244170189\n",
      "Epoch:  718  Loss:  0.9453707888190236  Validation Loss:  0.7184675466269255\n",
      "Epoch:  719  Loss:  0.9450825869682289  Validation Loss:  0.7181434894778899\n",
      "Epoch:  720  Loss:  0.9447947701527959  Validation Loss:  0.7178197942141976\n",
      "Epoch:  721  Loss:  0.9445067791356927  Validation Loss:  0.7174954057804176\n",
      "Epoch:  722  Loss:  0.9442178469506048  Validation Loss:  0.7171711360237428\n",
      "Epoch:  723  Loss:  0.9439292976721412  Validation Loss:  0.7168472438518491\n",
      "Epoch:  724  Loss:  0.9436410489004283  Validation Loss:  0.7165232918092183\n",
      "Epoch:  725  Loss:  0.9433518454787277  Validation Loss:  0.7161988411098719\n",
      "Epoch:  726  Loss:  0.9430625241781984  Validation Loss:  0.71587474138609\n",
      "Epoch:  727  Loss:  0.9427733684756926  Validation Loss:  0.7155502614166055\n",
      "Epoch:  728  Loss:  0.942483158427335  Validation Loss:  0.7152255861354726\n",
      "Epoch:  729  Loss:  0.942192981463103  Validation Loss:  0.7149006346506732\n",
      "Epoch:  730  Loss:  0.9419015339087873  Validation Loss:  0.7145750488021544\n",
      "Epoch:  731  Loss:  0.9416097173733371  Validation Loss:  0.7142491375229189\n",
      "Epoch:  732  Loss:  0.9413168899537552  Validation Loss:  0.7139229436538049\n",
      "Epoch:  733  Loss:  0.9410235473797435  Validation Loss:  0.7135960731123175\n",
      "Epoch:  734  Loss:  0.9407292223047643  Validation Loss:  0.7132688201963902\n",
      "Epoch:  735  Loss:  0.940433862042569  Validation Loss:  0.712941010083471\n",
      "Epoch:  736  Loss:  0.9401374077867894  Validation Loss:  0.7126125075987407\n",
      "Epoch:  737  Loss:  0.9398398512885684  Validation Loss:  0.7122831216880253\n",
      "Epoch:  738  Loss:  0.9395409616686049  Validation Loss:  0.7119530082813331\n",
      "Epoch:  739  Loss:  0.9392406687672649  Validation Loss:  0.7116220287446465\n",
      "Epoch:  740  Loss:  0.9389389524502414  Validation Loss:  0.7112901857388871\n",
      "Epoch:  741  Loss:  0.9386357433561768  Validation Loss:  0.7109574369554009\n",
      "Epoch:  742  Loss:  0.9383310953243857  Validation Loss:  0.7106237919735057\n",
      "Epoch:  743  Loss:  0.9380250278682936  Validation Loss:  0.7102893343461412\n",
      "Epoch:  744  Loss:  0.9377176595763081  Validation Loss:  0.7099541659866061\n",
      "Epoch:  745  Loss:  0.9374091113429694  Validation Loss:  0.7096183731087616\n",
      "Epoch:  746  Loss:  0.9370994281378531  Validation Loss:  0.7092822563967535\n",
      "Epoch:  747  Loss:  0.9367890957565534  Validation Loss:  0.7089453347559486\n",
      "Epoch:  748  Loss:  0.9364780702938637  Validation Loss:  0.7086087875068188\n",
      "Epoch:  749  Loss:  0.9361670631028357  Validation Loss:  0.7082718310079404\n",
      "Epoch:  750  Loss:  0.9358555882104805  Validation Loss:  0.7079349828085729\n",
      "Epoch:  751  Loss:  0.9355441127859411  Validation Loss:  0.7075981654758964\n",
      "Epoch:  752  Loss:  0.9352327121332997  Validation Loss:  0.7072613473449435\n",
      "Epoch:  753  Loss:  0.9349204696537483  Validation Loss:  0.7069239895790815\n",
      "Epoch:  754  Loss:  0.9346080665432271  Validation Loss:  0.7065870277583599\n",
      "Epoch:  755  Loss:  0.9342960927280641  Validation Loss:  0.7062504214367696\n",
      "Epoch:  756  Loss:  0.9339845489178386  Validation Loss:  0.7059142264936652\n",
      "Epoch:  757  Loss:  0.9336734121399266  Validation Loss:  0.7055784099336181\n",
      "Epoch:  758  Loss:  0.9333626992468324  Validation Loss:  0.7052429674991539\n",
      "Epoch:  759  Loss:  0.9330524216805186  Validation Loss:  0.7049079388380051\n",
      "Epoch:  760  Loss:  0.9327425815697227  Validation Loss:  0.7045732914869275\n",
      "Epoch:  761  Loss:  0.9324335544591859  Validation Loss:  0.7042399290949106\n",
      "Epoch:  762  Loss:  0.932126285951762  Validation Loss:  0.703907296327608\n",
      "Epoch:  763  Loss:  0.931819574197843  Validation Loss:  0.7035750674882105\n",
      "Epoch:  764  Loss:  0.9315131906242597  Validation Loss:  0.7032429424247572\n",
      "Epoch:  765  Loss:  0.9312068570760035  Validation Loss:  0.7029110823890993\n",
      "Epoch:  766  Loss:  0.9309009333096799  Validation Loss:  0.7025795855692455\n",
      "Epoch:  767  Loss:  0.9305954315655288  Validation Loss:  0.7022484945399421\n",
      "Epoch:  768  Loss:  0.9302903485617467  Validation Loss:  0.7019178178161383\n",
      "Epoch:  769  Loss:  0.9299857408872673  Validation Loss:  0.7015875458185162\n",
      "Epoch:  770  Loss:  0.9296815895608493  Validation Loss:  0.7012576774827072\n",
      "Epoch:  771  Loss:  0.9293778670863027  Validation Loss:  0.7009282428771257\n",
      "Epoch:  772  Loss:  0.9290746483242228  Validation Loss:  0.7005991893155235\n",
      "Epoch:  773  Loss:  0.928771846262472  Validation Loss:  0.7002705827887569\n",
      "Epoch:  774  Loss:  0.9284694962913081  Validation Loss:  0.6999423509197575\n",
      "Epoch:  775  Loss:  0.9281681977389824  Validation Loss:  0.6996154247650078\n",
      "Epoch:  776  Loss:  0.9278681423692476  Validation Loss:  0.6992888833795275\n",
      "Epoch:  777  Loss:  0.9275685077799218  Validation Loss:  0.698962719312736\n",
      "Epoch:  778  Loss:  0.9272692865204244  Validation Loss:  0.6986369479979787\n",
      "Epoch:  779  Loss:  0.9269704798325187  Validation Loss:  0.6983115494783435\n",
      "Epoch:  780  Loss:  0.9266720806204137  Validation Loss:  0.6979865328009639\n",
      "Epoch:  781  Loss:  0.9263740926093998  Validation Loss:  0.6976619086095265\n",
      "Epoch:  782  Loss:  0.9260764891015631  Validation Loss:  0.6973374954291752\n",
      "Epoch:  783  Loss:  0.9257789586803743  Validation Loss:  0.6970132240759475\n",
      "Epoch:  784  Loss:  0.92548176530926  Validation Loss:  0.6966893233891044\n",
      "Epoch:  785  Loss:  0.9251849497890189  Validation Loss:  0.6963658064071622\n",
      "Epoch:  786  Loss:  0.9248885837871403  Validation Loss:  0.6960426670100007\n",
      "Epoch:  787  Loss:  0.9245926194957325  Validation Loss:  0.6957198988114085\n",
      "Epoch:  788  Loss:  0.924297082282248  Validation Loss:  0.6953974805240121\n",
      "Epoch:  789  Loss:  0.9240016957656259  Validation Loss:  0.695075122905629\n",
      "Epoch:  790  Loss:  0.923706501988428  Validation Loss:  0.6947531064174005\n",
      "Epoch:  791  Loss:  0.9234117308542842  Validation Loss:  0.6944314544754369\n",
      "Epoch:  792  Loss:  0.9231173666637569  Validation Loss:  0.6941102101866689\n",
      "Epoch:  793  Loss:  0.9228234584665015  Validation Loss:  0.693789363439594\n",
      "Epoch:  794  Loss:  0.9225298546786819  Validation Loss:  0.6934686359018087\n",
      "Epoch:  795  Loss:  0.922236318478272  Validation Loss:  0.6931481595550265\n",
      "Epoch:  796  Loss:  0.921943530085541  Validation Loss:  0.6928288957902363\n",
      "Epoch:  797  Loss:  0.9216525026907524  Validation Loss:  0.6925103989030633\n",
      "Epoch:  798  Loss:  0.9213619714691526  Validation Loss:  0.6921919821096318\n",
      "Epoch:  799  Loss:  0.9210715075688702  Validation Loss:  0.6918738428503275\n",
      "Epoch:  800  Loss:  0.9207814088357347  Validation Loss:  0.6915560684033802\n",
      "Epoch:  801  Loss:  0.9204917338987192  Validation Loss:  0.6912386718073061\n",
      "Epoch:  802  Loss:  0.9202022113438163  Validation Loss:  0.6909213106014899\n",
      "Epoch:  803  Loss:  0.9199128944781565  Validation Loss:  0.6906042947833028\n",
      "Epoch:  804  Loss:  0.919623978613388  Validation Loss:  0.6902876895453248\n",
      "Epoch:  805  Loss:  0.919335378511321  Validation Loss:  0.6899712013878992\n",
      "Epoch:  806  Loss:  0.9190468483914932  Validation Loss:  0.6896549907646009\n",
      "Epoch:  807  Loss:  0.9187586892928395  Validation Loss:  0.6893390475639275\n",
      "Epoch:  808  Loss:  0.9184706396467629  Validation Loss:  0.6890231796673366\n",
      "Epoch:  809  Loss:  0.9181828577781007  Validation Loss:  0.6887077085141625\n",
      "Epoch:  810  Loss:  0.9178953734004781  Validation Loss:  0.6883923387421029\n",
      "Epoch:  811  Loss:  0.9176079391368798  Validation Loss:  0.6880772430449724\n",
      "Epoch:  812  Loss:  0.9173208121210337  Validation Loss:  0.6877622351582561\n",
      "Epoch:  813  Loss:  0.9170337581031379  Validation Loss:  0.6874475316809756\n",
      "Epoch:  814  Loss:  0.9167469836594093  Validation Loss:  0.6871329157480172\n",
      "Epoch:  815  Loss:  0.9164602917042517  Validation Loss:  0.6868184884744031\n",
      "Epoch:  816  Loss:  0.9161736942118123  Validation Loss:  0.6865041822727237\n",
      "Epoch:  817  Loss:  0.9158872718080169  Validation Loss:  0.6861899660101959\n",
      "Epoch:  818  Loss:  0.9156008720220554  Validation Loss:  0.685875885986856\n",
      "Epoch:  819  Loss:  0.915314531663344  Validation Loss:  0.6855618440146957\n",
      "Epoch:  820  Loss:  0.9150282203086785  Validation Loss:  0.6852478725569588\n",
      "Epoch:  821  Loss:  0.9147419179124492  Validation Loss:  0.6849338739578213\n",
      "Epoch:  822  Loss:  0.9144556678476787  Validation Loss:  0.6846199432121856\n",
      "Epoch:  823  Loss:  0.9141693691767397  Validation Loss:  0.6843060135309186\n",
      "Epoch:  824  Loss:  0.9138828829995224  Validation Loss:  0.6839918991816896\n",
      "Epoch:  825  Loss:  0.9135962709607113  Validation Loss:  0.6836777329444885\n",
      "Epoch:  826  Loss:  0.9133094907516525  Validation Loss:  0.6833634496267352\n",
      "Epoch:  827  Loss:  0.913022577585209  Validation Loss:  0.683049102979047\n",
      "Epoch:  828  Loss:  0.9127353301183099  Validation Loss:  0.6827345091317382\n",
      "Epoch:  829  Loss:  0.9124477538501933  Validation Loss:  0.6824196260422468\n",
      "Epoch:  830  Loss:  0.9121598041660729  Validation Loss:  0.6821044313588313\n",
      "Epoch:  831  Loss:  0.911871357687882  Validation Loss:  0.681788854567068\n",
      "Epoch:  832  Loss:  0.911582368559071  Validation Loss:  0.6814728477703673\n",
      "Epoch:  833  Loss:  0.911292686881054  Validation Loss:  0.6811562678111451\n",
      "Epoch:  834  Loss:  0.9110023108798833  Validation Loss:  0.6808391043118068\n",
      "Epoch:  835  Loss:  0.9107110658217044  Validation Loss:  0.6805212646722794\n",
      "Epoch:  836  Loss:  0.91041891596147  Validation Loss:  0.6802026480436325\n",
      "Epoch:  837  Loss:  0.9101257553058011  Validation Loss:  0.6798832017396178\n",
      "Epoch:  838  Loss:  0.9098314541791167  Validation Loss:  0.6795628124049732\n",
      "Epoch:  839  Loss:  0.9095358510634729  Validation Loss:  0.679241344332695\n",
      "Epoch:  840  Loss:  0.9092389012553862  Validation Loss:  0.6789187520210233\n",
      "Epoch:  841  Loss:  0.9089405627122947  Validation Loss:  0.6785950203027044\n",
      "Epoch:  842  Loss:  0.9086407489542451  Validation Loss:  0.6782700656247991\n",
      "Epoch:  843  Loss:  0.9083394621099744  Validation Loss:  0.6779439499867814\n",
      "Epoch:  844  Loss:  0.9080367789914211  Validation Loss:  0.677616739113416\n",
      "Epoch:  845  Loss:  0.9077327544135707  Validation Loss:  0.6772884777081865\n",
      "Epoch:  846  Loss:  0.9074274737920079  Validation Loss:  0.6769592900361333\n",
      "Epoch:  847  Loss:  0.9071211440577394  Validation Loss:  0.6766293322933572\n",
      "Epoch:  848  Loss:  0.9068139131580081  Validation Loss:  0.6762987207621336\n",
      "Epoch:  849  Loss:  0.9065060069163641  Validation Loss:  0.6759676680501018\n",
      "Epoch:  850  Loss:  0.9061975618380875  Validation Loss:  0.6756363146539245\n",
      "Epoch:  851  Loss:  0.9058888939519724  Validation Loss:  0.675304842580642\n",
      "Epoch:  852  Loss:  0.9055799708834716  Validation Loss:  0.6749732635383096\n",
      "Epoch:  853  Loss:  0.9052710075463567  Validation Loss:  0.6746417454310826\n",
      "Epoch:  854  Loss:  0.9049621823110751  Validation Loss:  0.67431043194873\n",
      "Epoch:  855  Loss:  0.9046543014368841  Validation Loss:  0.6739804409444332\n",
      "Epoch:  856  Loss:  0.904347677670774  Validation Loss:  0.6736508211387056\n",
      "Epoch:  857  Loss:  0.9040414677666766  Validation Loss:  0.673321606857436\n",
      "Epoch:  858  Loss:  0.9037356674671173  Validation Loss:  0.6729927847960165\n",
      "Epoch:  859  Loss:  0.903430309678827  Validation Loss:  0.6726643663964101\n",
      "Epoch:  860  Loss:  0.9031253422477415  Validation Loss:  0.6723362931183406\n",
      "Epoch:  861  Loss:  0.9028209767171315  Validation Loss:  0.67200895372246\n",
      "Epoch:  862  Loss:  0.9025173145568087  Validation Loss:  0.6716820563056639\n",
      "Epoch:  863  Loss:  0.9022140430197829  Validation Loss:  0.6713555484477963\n",
      "Epoch:  864  Loss:  0.9019112324430829  Validation Loss:  0.6710295344569853\n",
      "Epoch:  865  Loss:  0.9016091560146638  Validation Loss:  0.6707041814391103\n",
      "Epoch:  866  Loss:  0.901307625696063  Validation Loss:  0.6703792323491403\n",
      "Epoch:  867  Loss:  0.9010065023210787  Validation Loss:  0.6700546494019883\n",
      "Epoch:  868  Loss:  0.9007060173011961  Validation Loss:  0.6697308349290064\n",
      "Epoch:  869  Loss:  0.9004061815461942  Validation Loss:  0.669407411611506\n",
      "Epoch:  870  Loss:  0.900106761959337  Validation Loss:  0.669084319844842\n",
      "Epoch:  871  Loss:  0.8998079429424944  Validation Loss:  0.6687620183719056\n",
      "Epoch:  872  Loss:  0.8995098068955398  Validation Loss:  0.6684400886297226\n",
      "Epoch:  873  Loss:  0.8992120714946872  Validation Loss:  0.6681185425924403\n",
      "Epoch:  874  Loss:  0.8989147571403355  Validation Loss:  0.6677975063877446\n",
      "Epoch:  875  Loss:  0.8986182154289314  Validation Loss:  0.6674771284950631\n",
      "Epoch:  876  Loss:  0.8983222063453424  Validation Loss:  0.6671571601182222\n",
      "Epoch:  877  Loss:  0.8980266816381898  Validation Loss:  0.6668376140296459\n",
      "Epoch:  878  Loss:  0.8977316762542441  Validation Loss:  0.6665186674467155\n",
      "Epoch:  879  Loss:  0.8974374423601797  Validation Loss:  0.6662003368671451\n",
      "Epoch:  880  Loss:  0.8971437527132886  Validation Loss:  0.6658824115459409\n",
      "Epoch:  881  Loss:  0.8968504863303333  Validation Loss:  0.6655648755175727\n",
      "Epoch:  882  Loss:  0.8965576175777685  Validation Loss:  0.6652477322412389\n",
      "Epoch:  883  Loss:  0.8962653933891228  Validation Loss:  0.6649313481258494\n",
      "Epoch:  884  Loss:  0.8959738474694037  Validation Loss:  0.6646153602216925\n",
      "Epoch:  885  Loss:  0.8956827278293314  Validation Loss:  0.6642997850264821\n",
      "Epoch:  886  Loss:  0.8953920112301906  Validation Loss:  0.6639845546867166\n",
      "Epoch:  887  Loss:  0.8951016778037661  Validation Loss:  0.6636697115110499\n",
      "Epoch:  888  Loss:  0.8948119406011843  Validation Loss:  0.6633555383554527\n",
      "Epoch:  889  Loss:  0.894522867298552  Validation Loss:  0.6630418505519629\n",
      "Epoch:  890  Loss:  0.8942342599232992  Validation Loss:  0.662728527294738\n",
      "Epoch:  891  Loss:  0.893946047428818  Validation Loss:  0.6624155866780451\n",
      "Epoch:  892  Loss:  0.8936582263559103  Validation Loss:  0.6621030414743083\n",
      "Epoch:  893  Loss:  0.8933708416741519  Validation Loss:  0.6617908523018871\n",
      "Epoch:  894  Loss:  0.8930838659760498  Validation Loss:  0.6614791357091495\n",
      "Epoch:  895  Loss:  0.8927976400369689  Validation Loss:  0.6611681176083428\n",
      "Epoch:  896  Loss:  0.8925119550632579  Validation Loss:  0.6608574736331191\n",
      "Epoch:  897  Loss:  0.892226686346389  Validation Loss:  0.6605472428990262\n",
      "Epoch:  898  Loss:  0.8919418641321716  Validation Loss:  0.660237390814083\n",
      "Epoch:  899  Loss:  0.8916574301464217  Validation Loss:  0.6599279107259852\n",
      "Epoch:  900  Loss:  0.8913733874048505  Validation Loss:  0.659618787999664\n",
      "Epoch:  901  Loss:  0.8910897783048096  Validation Loss:  0.6593100875616074\n",
      "Epoch:  902  Loss:  0.8908066260850146  Validation Loss:  0.6590019044067178\n",
      "Epoch:  903  Loss:  0.8905241678335837  Validation Loss:  0.6586943119764328\n",
      "Epoch:  904  Loss:  0.8902422515231938  Validation Loss:  0.658387091010809\n",
      "Epoch:  905  Loss:  0.8899607394068014  Validation Loss:  0.6580802864794221\n",
      "Epoch:  906  Loss:  0.8896796440794354  Validation Loss:  0.6577738395759037\n",
      "Epoch:  907  Loss:  0.8893989391092744  Validation Loss:  0.6574677665318761\n",
      "Epoch:  908  Loss:  0.8891186707963546  Validation Loss:  0.6571621426514217\n",
      "Epoch:  909  Loss:  0.8888388101366305  Validation Loss:  0.6568568689482552\n",
      "Epoch:  910  Loss:  0.8885593941169125  Validation Loss:  0.656552005559206\n",
      "Epoch:  911  Loss:  0.8882803626003719  Validation Loss:  0.6562475077807903\n",
      "Epoch:  912  Loss:  0.8880017521303325  Validation Loss:  0.6559434296297175\n",
      "Epoch:  913  Loss:  0.8877238390878552  Validation Loss:  0.6556400811033589\n",
      "Epoch:  914  Loss:  0.8874465052393221  Validation Loss:  0.6553371176123619\n",
      "Epoch:  915  Loss:  0.8871695948321194  Validation Loss:  0.6550345162728003\n",
      "Epoch:  916  Loss:  0.8868930927876916  Validation Loss:  0.6547323098140103\n",
      "Epoch:  917  Loss:  0.8866169958242348  Validation Loss:  0.6544304886566741\n",
      "Epoch:  918  Loss:  0.8863412953381028  Validation Loss:  0.6541290730237961\n",
      "Epoch:  919  Loss:  0.8860660269856453  Validation Loss:  0.6538280905889613\n",
      "Epoch:  920  Loss:  0.8857913101535468  Validation Loss:  0.6535277217626572\n",
      "Epoch:  921  Loss:  0.8855170790283453  Validation Loss:  0.6532277196113553\n",
      "Epoch:  922  Loss:  0.8852432206095684  Validation Loss:  0.6529281136712858\n",
      "Epoch:  923  Loss:  0.8849697882043464  Validation Loss:  0.6526289028780801\n",
      "Epoch:  924  Loss:  0.8846967579530818  Validation Loss:  0.6523300579616002\n",
      "Epoch:  925  Loss:  0.8844241494578975  Validation Loss:  0.6520316105868135\n",
      "Epoch:  926  Loss:  0.8841520429012322  Validation Loss:  0.6517337310527053\n",
      "Epoch:  927  Loss:  0.8838806249910877  Validation Loss:  0.6514364347926208\n",
      "Epoch:  928  Loss:  0.8836096962470383  Validation Loss:  0.6511395169155938\n",
      "Epoch:  929  Loss:  0.8833391721404734  Validation Loss:  0.65084297688944\n",
      "Epoch:  930  Loss:  0.8830690772405693  Validation Loss:  0.6505468407911914\n",
      "Epoch:  931  Loss:  0.882799390082558  Validation Loss:  0.6502510354455028\n",
      "Epoch:  932  Loss:  0.8825300862746579  Validation Loss:  0.6499556579760143\n",
      "Epoch:  933  Loss:  0.8822612100768656  Validation Loss:  0.6496606509068182\n",
      "Epoch:  934  Loss:  0.8819927397583213  Validation Loss:  0.6493660347270114\n",
      "Epoch:  935  Loss:  0.8817247120397431  Validation Loss:  0.6490717889474971\n",
      "Epoch:  936  Loss:  0.8814570967640195  Validation Loss:  0.6487779896706343\n",
      "Epoch:  937  Loss:  0.8811899000512702  Validation Loss:  0.6484845200819629\n",
      "Epoch:  938  Loss:  0.8809231038072279  Validation Loss:  0.6481914525585515\n",
      "Epoch:  939  Loss:  0.8806567077658006  Validation Loss:  0.6478987402681794\n",
      "Epoch:  940  Loss:  0.8803907206193322  Validation Loss:  0.6476064255195004\n",
      "Epoch:  941  Loss:  0.8801251434321914  Validation Loss:  0.6473144580210958\n",
      "Epoch:  942  Loss:  0.8798599890654996  Validation Loss:  0.647022919729352\n",
      "Epoch:  943  Loss:  0.8795952134366546  Validation Loss:  0.6467317419924906\n",
      "Epoch:  944  Loss:  0.8793308691432079  Validation Loss:  0.6464409319950002\n",
      "Epoch:  945  Loss:  0.8790669468719334  Validation Loss:  0.6461505011788437\n",
      "Epoch:  946  Loss:  0.8788036096486307  Validation Loss:  0.6458607997213092\n",
      "Epoch:  947  Loss:  0.8785409420019105  Validation Loss:  0.6455715224146843\n",
      "Epoch:  948  Loss:  0.8782786914990062  Validation Loss:  0.6452826210962874\n",
      "Epoch:  949  Loss:  0.8780168438596385  Validation Loss:  0.6449940955000264\n",
      "Epoch:  950  Loss:  0.8777554170006797  Validation Loss:  0.6447059325873852\n",
      "Epoch:  951  Loss:  0.8774943974401269  Validation Loss:  0.6444182081946305\n",
      "Epoch:  952  Loss:  0.8772337858875593  Validation Loss:  0.6441308299877814\n",
      "Epoch:  953  Loss:  0.8769736112583251  Validation Loss:  0.6438438290996211\n",
      "Epoch:  954  Loss:  0.8767138527972358  Validation Loss:  0.6435572736497436\n",
      "Epoch:  955  Loss:  0.8764545043841714  Validation Loss:  0.643271124788693\n",
      "Epoch:  956  Loss:  0.8761955994580474  Validation Loss:  0.6429853460618428\n",
      "Epoch:  957  Loss:  0.8759370927831956  Validation Loss:  0.6426999507738012\n",
      "Epoch:  958  Loss:  0.8756790069774503  Validation Loss:  0.6424149045986789\n",
      "Epoch:  959  Loss:  0.8754213162298713  Validation Loss:  0.6421302596905402\n",
      "Epoch:  960  Loss:  0.8751640394330025  Validation Loss:  0.6418460059378829\n",
      "Epoch:  961  Loss:  0.8749071737485272  Validation Loss:  0.6415621311004672\n",
      "Epoch:  962  Loss:  0.8746507095084304  Validation Loss:  0.64127861016563\n",
      "Epoch:  963  Loss:  0.8743946601947149  Validation Loss:  0.6409954891673156\n",
      "Epoch:  964  Loss:  0.874138999819046  Validation Loss:  0.6407127324491739\n",
      "Epoch:  965  Loss:  0.8738837689161301  Validation Loss:  0.640430365822145\n",
      "Epoch:  966  Loss:  0.873628943448975  Validation Loss:  0.6401483743850674\n",
      "Epoch:  967  Loss:  0.8733745274089632  Validation Loss:  0.6398667823523283\n",
      "Epoch:  968  Loss:  0.8731205315284786  Validation Loss:  0.639585575887135\n",
      "Epoch:  969  Loss:  0.872866955984916  Validation Loss:  0.6393047446118933\n",
      "Epoch:  970  Loss:  0.8726137756769147  Validation Loss:  0.639024281874299\n",
      "Epoch:  971  Loss:  0.8723610071021886  Validation Loss:  0.6387442110904625\n",
      "Epoch:  972  Loss:  0.8721086433423417  Validation Loss:  0.6384645152304854\n",
      "Epoch:  973  Loss:  0.8718566899853093  Validation Loss:  0.6381852075989757\n",
      "Epoch:  974  Loss:  0.8716051534173035  Validation Loss:  0.6379062738269567\n",
      "Epoch:  975  Loss:  0.8713540375410092  Validation Loss:  0.6376277370644468\n",
      "Epoch:  976  Loss:  0.8711034496802659  Validation Loss:  0.6373499528105769\n",
      "Epoch:  977  Loss:  0.870853509399153  Validation Loss:  0.6370726610933032\n",
      "Epoch:  978  Loss:  0.8706039577899944  Validation Loss:  0.6367958108229297\n",
      "Epoch:  979  Loss:  0.8703547509475833  Validation Loss:  0.6365194081195763\n",
      "Epoch:  980  Loss:  0.8701059176098733  Validation Loss:  0.6362433561256954\n",
      "Epoch:  981  Loss:  0.8698574867809102  Validation Loss:  0.6359677325401988\n",
      "Epoch:  982  Loss:  0.8696094292792536  Validation Loss:  0.6356924593980823\n",
      "Epoch:  983  Loss:  0.8693617712706327  Validation Loss:  0.6354176234453917\n",
      "Epoch:  984  Loss:  0.8691145304945254  Validation Loss:  0.6351431435240167\n",
      "Epoch:  985  Loss:  0.8688676963959422  Validation Loss:  0.6348690438483443\n",
      "Epoch:  986  Loss:  0.8686212549606959  Validation Loss:  0.6345953427787338\n",
      "Epoch:  987  Loss:  0.8683752351041351  Validation Loss:  0.6343220102467707\n",
      "Epoch:  988  Loss:  0.8681296090639773  Validation Loss:  0.6340490377375058\n",
      "Epoch:  989  Loss:  0.8678843968858322  Validation Loss:  0.6337764563837222\n",
      "Epoch:  990  Loss:  0.8676395798545509  Validation Loss:  0.6335042747003692\n",
      "Epoch:  991  Loss:  0.8673951983274448  Validation Loss:  0.6332324336149863\n",
      "Epoch:  992  Loss:  0.8671512139872426  Validation Loss:  0.6329610174787896\n",
      "Epoch:  993  Loss:  0.8669076557492926  Validation Loss:  0.6326899642923048\n",
      "Epoch:  994  Loss:  0.8666644956739176  Validation Loss:  0.6324192972055503\n",
      "Epoch:  995  Loss:  0.8664217333176306  Validation Loss:  0.632148999986904\n",
      "Epoch:  996  Loss:  0.8661793849120537  Validation Loss:  0.6318791072283473\n",
      "Epoch:  997  Loss:  0.8659374426518168  Validation Loss:  0.6316095798143319\n",
      "Epoch:  998  Loss:  0.8656959082221701  Validation Loss:  0.6313404086977243\n",
      "Epoch:  999  Loss:  0.8654547783413103  Validation Loss:  0.6310716524188008\n",
      "Epoch:  1000  Loss:  0.8652140631207398  Validation Loss:  0.6308032032102346\n",
      "Epoch:  1001  Loss:  0.8649736758144129  Validation Loss:  0.6305350916726249\n",
      "Epoch:  1002  Loss:  0.8647336681329069  Validation Loss:  0.6302673055657319\n",
      "Epoch:  1003  Loss:  0.8644939694731009  Validation Loss:  0.6299998097653899\n",
      "Epoch:  1004  Loss:  0.864254597929262  Validation Loss:  0.6297326183744839\n",
      "Epoch:  1005  Loss:  0.864015635723869  Validation Loss:  0.6294658309114831\n",
      "Epoch:  1006  Loss:  0.8637770870256991  Validation Loss:  0.629199406132102\n",
      "Epoch:  1007  Loss:  0.8635389209680614  Validation Loss:  0.628933373572571\n",
      "Epoch:  1008  Loss:  0.8633011591044211  Validation Loss:  0.6286677162029913\n",
      "Epoch:  1009  Loss:  0.8630638271570206  Validation Loss:  0.6284024388130222\n",
      "Epoch:  1010  Loss:  0.8628268944365638  Validation Loss:  0.6281375190509217\n",
      "Epoch:  1011  Loss:  0.8625903607656559  Validation Loss:  0.6278729949678693\n",
      "Epoch:  1012  Loss:  0.8623542273860603  Validation Loss:  0.6276088686926025\n",
      "Epoch:  1013  Loss:  0.8621185193991378  Validation Loss:  0.6273450933929\n",
      "Epoch:  1014  Loss:  0.8618832105504615  Validation Loss:  0.6270817071199417\n",
      "Epoch:  1015  Loss:  0.8616483091775861  Validation Loss:  0.6268186875219856\n",
      "Epoch:  1016  Loss:  0.861413827786843  Validation Loss:  0.6265560548220362\n",
      "Epoch:  1017  Loss:  0.8611797418090559  Validation Loss:  0.6262938420155219\n",
      "Epoch:  1018  Loss:  0.8609460793612969  Validation Loss:  0.6260320850248847\n",
      "Epoch:  1019  Loss:  0.8607128569412799  Validation Loss:  0.6257707644253969\n",
      "Epoch:  1020  Loss:  0.8604800527294477  Validation Loss:  0.6255098589296851\n",
      "Epoch:  1021  Loss:  0.8602476536872841  Validation Loss:  0.6252493477825608\n",
      "Epoch:  1022  Loss:  0.86001565910521  Validation Loss:  0.6249892014477935\n",
      "Epoch:  1023  Loss:  0.85978407936082  Validation Loss:  0.6247294127408948\n",
      "Epoch:  1024  Loss:  0.8595528875788053  Validation Loss:  0.6244700375412192\n",
      "Epoch:  1025  Loss:  0.8593221305026895  Validation Loss:  0.6242110095918179\n",
      "Epoch:  1026  Loss:  0.8590917628968046  Validation Loss:  0.623952381046755\n",
      "Epoch:  1027  Loss:  0.8588618072015899  Validation Loss:  0.6236941255629063\n",
      "Epoch:  1028  Loss:  0.8586322983638162  Validation Loss:  0.6234362875776631\n",
      "Epoch:  1029  Loss:  0.8584033529318514  Validation Loss:  0.6231791244021484\n",
      "Epoch:  1030  Loss:  0.8581750612883341  Validation Loss:  0.6229223646223545\n",
      "Epoch:  1031  Loss:  0.8579471691378525  Validation Loss:  0.6226659901440144\n",
      "Epoch:  1032  Loss:  0.8577196877449751  Validation Loss:  0.6224100097481694\n",
      "Epoch:  1033  Loss:  0.8574926079738707  Validation Loss:  0.6221543678215572\n",
      "Epoch:  1034  Loss:  0.857265949337965  Validation Loss:  0.6218991449901036\n",
      "Epoch:  1035  Loss:  0.8570396817688432  Validation Loss:  0.62164426887674\n",
      "Epoch:  1036  Loss:  0.8568138304565635  Validation Loss:  0.6213897767343691\n",
      "Epoch:  1037  Loss:  0.8565883690580016  Validation Loss:  0.6211356991635901\n",
      "Epoch:  1038  Loss:  0.8563633067976861  Validation Loss:  0.6208819832120623\n",
      "Epoch:  1039  Loss:  0.8561388511388075  Validation Loss:  0.6206288045006139\n",
      "Epoch:  1040  Loss:  0.855914943629787  Validation Loss:  0.6203759440353939\n",
      "Epoch:  1041  Loss:  0.8556914514019376  Validation Loss:  0.6201235016009637\n",
      "Epoch:  1042  Loss:  0.8554683526357015  Validation Loss:  0.6198714431375265\n",
      "Epoch:  1043  Loss:  0.8552456696828207  Validation Loss:  0.6196197412375893\n",
      "Epoch:  1044  Loss:  0.8550233862229756  Validation Loss:  0.6193684182528939\n",
      "Epoch:  1045  Loss:  0.8548014939186119  Validation Loss:  0.6191175015909332\n",
      "Epoch:  1046  Loss:  0.8545800066065221  Validation Loss:  0.6188669571919101\n",
      "Epoch:  1047  Loss:  0.8543589464610531  Validation Loss:  0.6186167645667281\n",
      "Epoch:  1048  Loss:  0.8541382769388812  Validation Loss:  0.6183669761355434\n",
      "Epoch:  1049  Loss:  0.8539180237622488  Validation Loss:  0.6181175666196006\n",
      "Epoch:  1050  Loss:  0.8536981759326798  Validation Loss:  0.6178685463964939\n",
      "Epoch:  1051  Loss:  0.8534787354015169  Validation Loss:  0.6176199026937995\n",
      "Epoch:  1052  Loss:  0.8532597009269964  Validation Loss:  0.6173716304557664\n",
      "Epoch:  1053  Loss:  0.8530410655907222  Validation Loss:  0.6171237376651594\n",
      "Epoch:  1054  Loss:  0.8528228391494069  Validation Loss:  0.6168762291116374\n",
      "Epoch:  1055  Loss:  0.8526050107819694  Validation Loss:  0.616629084572196\n",
      "Epoch:  1056  Loss:  0.8523875762309346  Validation Loss:  0.6163823277290378\n",
      "Epoch:  1057  Loss:  0.8521705573158604  Validation Loss:  0.6161359543246883\n",
      "Epoch:  1058  Loss:  0.8519539393129802  Validation Loss:  0.6158899465309722\n",
      "Epoch:  1059  Loss:  0.8517377365912709  Validation Loss:  0.6156443293605532\n",
      "Epoch:  1060  Loss:  0.8515219237832796  Validation Loss:  0.6153990605047771\n",
      "Epoch:  1061  Loss:  0.8513065266112486  Validation Loss:  0.6151542019631181\n",
      "Epoch:  1062  Loss:  0.8510915055161431  Validation Loss:  0.6149097119591066\n",
      "Epoch:  1063  Loss:  0.8508769188608442  Validation Loss:  0.6146655944841248\n",
      "Epoch:  1064  Loss:  0.8506627426970572  Validation Loss:  0.6144218633749655\n",
      "Epoch:  1065  Loss:  0.8504489628332002  Validation Loss:  0.6141785151724305\n",
      "Epoch:  1066  Loss:  0.850235581575405  Validation Loss:  0.6139355466834137\n",
      "Epoch:  1067  Loss:  0.8500226439819449  Validation Loss:  0.6136929725429842\n",
      "Epoch:  1068  Loss:  0.8498101037527833  Validation Loss:  0.6134507794465337\n",
      "Epoch:  1069  Loss:  0.8495979743699232  Validation Loss:  0.6132090065096106\n",
      "Epoch:  1070  Loss:  0.8493862831521601  Validation Loss:  0.6129675922649247\n",
      "Epoch:  1071  Loss:  0.8491749806063515  Validation Loss:  0.6127265880682639\n",
      "Epoch:  1072  Loss:  0.8489641414156982  Validation Loss:  0.6124859625207526\n",
      "Epoch:  1073  Loss:  0.8487536580789656  Validation Loss:  0.612245700987322\n",
      "Epoch:  1074  Loss:  0.8485436212448847  Validation Loss:  0.6120058481714555\n",
      "Epoch:  1075  Loss:  0.848333992950973  Validation Loss:  0.6117663803909507\n",
      "Epoch:  1076  Loss:  0.8481248051282906  Validation Loss:  0.61152729551707\n",
      "Epoch:  1077  Loss:  0.8479160155568805  Validation Loss:  0.6112886268113341\n",
      "Epoch:  1078  Loss:  0.8477076384283248  Validation Loss:  0.6110503412783146\n",
      "Epoch:  1079  Loss:  0.8474996866924422  Validation Loss:  0.6108124399823802\n",
      "Epoch:  1080  Loss:  0.8472921706381298  Validation Loss:  0.6105749325028488\n",
      "Epoch:  1081  Loss:  0.8470850670266719  Validation Loss:  0.6103378284190383\n",
      "Epoch:  1082  Loss:  0.8468783728423572  Validation Loss:  0.6101011117654187\n",
      "Epoch:  1083  Loss:  0.8466721294181687  Validation Loss:  0.6098648277776582\n",
      "Epoch:  1084  Loss:  0.8464662929375967  Validation Loss:  0.6096288934350014\n",
      "Epoch:  1085  Loss:  0.8462608632232461  Validation Loss:  0.6093933545053005\n",
      "Epoch:  1086  Loss:  0.8460558067475047  Validation Loss:  0.6091581955552101\n",
      "Epoch:  1087  Loss:  0.8458512036928109  Validation Loss:  0.6089233963617257\n",
      "Epoch:  1088  Loss:  0.8456469799081484  Validation Loss:  0.6086890037570681\n",
      "Epoch:  1089  Loss:  0.8454431389414129  Validation Loss:  0.6084549581365926\n",
      "Epoch:  1090  Loss:  0.84523973560759  Validation Loss:  0.6082212967532021\n",
      "Epoch:  1091  Loss:  0.8450367133177462  Validation Loss:  0.6079880185425282\n",
      "Epoch:  1092  Loss:  0.8448340912305173  Validation Loss:  0.6077551091355937\n",
      "Epoch:  1093  Loss:  0.844631896664699  Validation Loss:  0.6075225701289517\n",
      "Epoch:  1094  Loss:  0.8444300730313573  Validation Loss:  0.6072904185525009\n",
      "Epoch:  1095  Loss:  0.8442286763872419  Validation Loss:  0.6070586480200291\n",
      "Epoch:  1096  Loss:  0.8440276574166048  Validation Loss:  0.6068272351154259\n",
      "Epoch:  1097  Loss:  0.8438270689830893  Validation Loss:  0.6065962186881474\n",
      "Epoch:  1098  Loss:  0.8436268557395253  Validation Loss:  0.606365583304848\n",
      "Epoch:  1099  Loss:  0.8434270673564502  Validation Loss:  0.6061353156609195\n",
      "Epoch:  1100  Loss:  0.8432276428100609  Validation Loss:  0.6059054248034954\n",
      "Epoch:  1101  Loss:  0.8430286805544581  Validation Loss:  0.6056759112647602\n",
      "Epoch:  1102  Loss:  0.8428300837320941  Validation Loss:  0.6054467894136906\n",
      "Epoch:  1103  Loss:  0.8426318959820838  Validation Loss:  0.6052180512675217\n",
      "Epoch:  1104  Loss:  0.8424341313186146  Validation Loss:  0.6049896797963551\n",
      "Epoch:  1105  Loss:  0.8422367326205685  Validation Loss:  0.6047617133174624\n",
      "Epoch:  1106  Loss:  0.8420397555899053  Validation Loss:  0.6045341018055167\n",
      "Epoch:  1107  Loss:  0.8418431775200934  Validation Loss:  0.6043068857065269\n",
      "Epoch:  1108  Loss:  0.8416470110061622  Validation Loss:  0.6040800660848618\n",
      "Epoch:  1109  Loss:  0.8414512340511594  Validation Loss:  0.603853563112872\n",
      "Epoch:  1110  Loss:  0.8412558587179297  Validation Loss:  0.6036274236227784\n",
      "Epoch:  1111  Loss:  0.8410608878447896  Validation Loss:  0.6034016763525349\n",
      "Epoch:  1112  Loss:  0.8408663061757883  Validation Loss:  0.603176297886031\n",
      "Epoch:  1113  Loss:  0.8406721241772175  Validation Loss:  0.6029512956738472\n",
      "Epoch:  1114  Loss:  0.8404783617172923  Validation Loss:  0.6027266840849604\n",
      "Epoch:  1115  Loss:  0.840285001766114  Validation Loss:  0.6025024514113154\n",
      "Epoch:  1116  Loss:  0.8400920205527828  Validation Loss:  0.6022785657218525\n",
      "Epoch:  1117  Loss:  0.8398994395420665  Validation Loss:  0.6020550706556865\n",
      "Epoch:  1118  Loss:  0.8397072998895532  Validation Loss:  0.6018319576978683\n",
      "Epoch:  1119  Loss:  0.8395155270894369  Validation Loss:  0.6016092060932091\n",
      "Epoch:  1120  Loss:  0.8393241512988295  Validation Loss:  0.6013868514980588\n",
      "Epoch:  1121  Loss:  0.8391331945146833  Validation Loss:  0.6011648598526206\n",
      "Epoch:  1122  Loss:  0.8389426185971215  Validation Loss:  0.6009432449936867\n",
      "Epoch:  1123  Loss:  0.838752439334279  Validation Loss:  0.6007219946810177\n",
      "Epoch:  1124  Loss:  0.8385626890120053  Validation Loss:  0.6005011413778577\n",
      "Epoch:  1125  Loss:  0.8383733154762358  Validation Loss:  0.6002806488956723\n",
      "Epoch:  1126  Loss:  0.8381843652044024  Validation Loss:  0.6000605002045631\n",
      "Epoch:  1127  Loss:  0.8379957959765479  Validation Loss:  0.5998407852436815\n",
      "Epoch:  1128  Loss:  0.8378076585275787  Validation Loss:  0.5996215034808431\n",
      "Epoch:  1129  Loss:  0.8376198249558607  Validation Loss:  0.5994025756205831\n",
      "Epoch:  1130  Loss:  0.8374323598330929  Validation Loss:  0.5991840633962836\n",
      "Epoch:  1131  Loss:  0.8372452977512564  Validation Loss:  0.5989659386021751\n",
      "Epoch:  1132  Loss:  0.8370586193743206  Validation Loss:  0.5987482517957687\n",
      "Epoch:  1133  Loss:  0.8368723701153483  Validation Loss:  0.5985309822218758\n",
      "Epoch:  1134  Loss:  0.8366865343635991  Validation Loss:  0.5983140814517226\n",
      "Epoch:  1135  Loss:  0.8365011692401909  Validation Loss:  0.598097637295723\n",
      "Epoch:  1136  Loss:  0.8363163352367424  Validation Loss:  0.5978816694446972\n",
      "Epoch:  1137  Loss:  0.8361319809087685  Validation Loss:  0.5976660794445446\n",
      "Epoch:  1138  Loss:  0.8359480544569946  Validation Loss:  0.5974508625056062\n",
      "Epoch:  1139  Loss:  0.8357644975185394  Validation Loss:  0.5972360159669604\n",
      "Epoch:  1140  Loss:  0.8355813459271476  Validation Loss:  0.5970215329102108\n",
      "Epoch:  1141  Loss:  0.8353985892165274  Validation Loss:  0.596807445266417\n",
      "Epoch:  1142  Loss:  0.8352162233065992  Validation Loss:  0.5965937062033585\n",
      "Epoch:  1143  Loss:  0.8350342269099894  Validation Loss:  0.5963802311037268\n",
      "Epoch:  1144  Loss:  0.8348525375837371  Validation Loss:  0.5961670300790242\n",
      "Epoch:  1145  Loss:  0.8346712037566162  Validation Loss:  0.5959543048271111\n",
      "Epoch:  1146  Loss:  0.834490450897387  Validation Loss:  0.5957421250641346\n",
      "Epoch:  1147  Loss:  0.8343102570090976  Validation Loss:  0.5955303561474595\n",
      "Epoch:  1148  Loss:  0.834130426780099  Validation Loss:  0.5953189336827823\n",
      "Epoch:  1149  Loss:  0.8339510148479825  Validation Loss:  0.595107880554029\n",
      "Epoch:  1150  Loss:  0.8337719850242138  Validation Loss:  0.5948972159198352\n",
      "Epoch:  1151  Loss:  0.8335933679980891  Validation Loss:  0.5946869094456945\n",
      "Epoch:  1152  Loss:  0.8334151352090495  Validation Loss:  0.5944769818867955\n",
      "Epoch:  1153  Loss:  0.8332372893180165  Validation Loss:  0.5942674401615348\n",
      "Epoch:  1154  Loss:  0.8330598672231039  Validation Loss:  0.5940582454204559\n",
      "Epoch:  1155  Loss:  0.8328828254625911  Validation Loss:  0.5938494487532547\n",
      "Epoch:  1156  Loss:  0.8327061996928283  Validation Loss:  0.5936410145035812\n",
      "Epoch:  1157  Loss:  0.8325299405980677  Validation Loss:  0.5934329490576472\n",
      "Epoch:  1158  Loss:  0.832354082592896  Validation Loss:  0.5932252614625863\n",
      "Epoch:  1159  Loss:  0.8321786618658474  Validation Loss:  0.5930179698126656\n",
      "Epoch:  1160  Loss:  0.8320036209410145  Validation Loss:  0.5928110549492496\n",
      "Epoch:  1161  Loss:  0.8318290164073309  Validation Loss:  0.5926045594470841\n",
      "Epoch:  1162  Loss:  0.8316548362019516  Validation Loss:  0.5923985088510173\n",
      "Epoch:  1163  Loss:  0.831481104805356  Validation Loss:  0.5921928573931966\n",
      "Epoch:  1164  Loss:  0.8313077791106134  Validation Loss:  0.5919875805931432\n",
      "Epoch:  1165  Loss:  0.8311348520219326  Validation Loss:  0.5917826944163868\n",
      "Epoch:  1166  Loss:  0.8309623377308959  Validation Loss:  0.5915782158928258\n",
      "Epoch:  1167  Loss:  0.8307898725782122  Validation Loss:  0.5913734978863171\n",
      "Epoch:  1168  Loss:  0.830617124126071  Validation Loss:  0.5911691359111241\n",
      "Epoch:  1169  Loss:  0.830444784391494  Validation Loss:  0.5909651730741773\n",
      "Epoch:  1170  Loss:  0.8302728853055409  Validation Loss:  0.5907616072467395\n",
      "Epoch:  1171  Loss:  0.8301013773750692  Validation Loss:  0.5905584086264882\n",
      "Epoch:  1172  Loss:  0.8299302701793966  Validation Loss:  0.5903555548616818\n",
      "Epoch:  1173  Loss:  0.829759537818886  Validation Loss:  0.5901531295052597\n",
      "Epoch:  1174  Loss:  0.8295892070801485  Validation Loss:  0.5899510415537017\n",
      "Epoch:  1175  Loss:  0.8294192855911595  Validation Loss:  0.5897493208093303\n",
      "Epoch:  1176  Loss:  0.8292497387599378  Validation Loss:  0.5895479858985969\n",
      "Epoch:  1177  Loss:  0.8290805939052787  Validation Loss:  0.5893470240490777\n",
      "Epoch:  1178  Loss:  0.828911844818365  Validation Loss:  0.5891464246170861\n",
      "Epoch:  1179  Loss:  0.8287435019654887  Validation Loss:  0.588946175894567\n",
      "Epoch:  1180  Loss:  0.8285754935017654  Validation Loss:  0.5887463087482112\n",
      "Epoch:  1181  Loss:  0.8284078806283928  Validation Loss:  0.588546810405595\n",
      "Epoch:  1182  Loss:  0.8282406376231284  Validation Loss:  0.5883476829954556\n",
      "Epoch:  1183  Loss:  0.8280738157530626  Validation Loss:  0.5881489057626043\n",
      "Epoch:  1184  Loss:  0.8279073639284997  Validation Loss:  0.5879505260714463\n",
      "Epoch:  1185  Loss:  0.8277413302234241  Validation Loss:  0.5877525125231061\n",
      "Epoch:  1186  Loss:  0.8275756665638515  Validation Loss:  0.5875548704394272\n",
      "Epoch:  1187  Loss:  0.8274104050582364  Validation Loss:  0.5873575694859028\n",
      "Epoch:  1188  Loss:  0.8272455465935525  Validation Loss:  0.5871607001338687\n",
      "Epoch:  1189  Loss:  0.8270810681084791  Validation Loss:  0.5869641437062195\n",
      "Epoch:  1190  Loss:  0.8269169868103096  Validation Loss:  0.5867679645972592\n",
      "Epoch:  1191  Loss:  0.8267533011024907  Validation Loss:  0.5865721904805729\n",
      "Epoch:  1192  Loss:  0.8265900095658643  Validation Loss:  0.586376755897488\n",
      "Epoch:  1193  Loss:  0.8264270985410327  Validation Loss:  0.5861817369503635\n",
      "Epoch:  1194  Loss:  0.8262644592849981  Validation Loss:  0.5859870915966374\n",
      "Epoch:  1195  Loss:  0.8261021858169919  Validation Loss:  0.5857928310121808\n",
      "Epoch:  1196  Loss:  0.8259402717508021  Validation Loss:  0.5855989344418049\n",
      "Epoch:  1197  Loss:  0.8257787782876265  Validation Loss:  0.5854054135935647\n",
      "Epoch:  1198  Loss:  0.825617644403662  Validation Loss:  0.5852122599525111\n",
      "Epoch:  1199  Loss:  0.8254569437177408  Validation Loss:  0.5850194809692246\n",
      "Epoch:  1200  Loss:  0.8252966027884256  Validation Loss:  0.5848270745149681\n",
      "Epoch:  1201  Loss:  0.8251366844134671  Validation Loss:  0.5846350560230869\n",
      "Epoch:  1202  Loss:  0.824977113554875  Validation Loss:  0.5844433312969548\n",
      "Epoch:  1203  Loss:  0.8248178964214665  Validation Loss:  0.5842518183801856\n",
      "Epoch:  1204  Loss:  0.8246588799215498  Validation Loss:  0.5840606034866401\n",
      "Epoch:  1205  Loss:  0.8245002324027675  Validation Loss:  0.5838697510106223\n",
      "Epoch:  1206  Loss:  0.8243419545746985  Validation Loss:  0.5836792604199478\n",
      "Epoch:  1207  Loss:  0.8241840705630326  Validation Loss:  0.5834891396973815\n",
      "Epoch:  1208  Loss:  0.8240266041386695  Validation Loss:  0.583299381924527\n",
      "Epoch:  1209  Loss:  0.8238695168069431  Validation Loss:  0.583110007324389\n",
      "Epoch:  1210  Loss:  0.823712811938354  Validation Loss:  0.5829209765153271\n",
      "Epoch:  1211  Loss:  0.8235565136585917  Validation Loss:  0.5827323416514056\n",
      "Epoch:  1212  Loss:  0.8234005765545935  Validation Loss:  0.5825440532394818\n",
      "Epoch:  1213  Loss:  0.8232450657302425  Validation Loss:  0.582356158643961\n",
      "Epoch:  1214  Loss:  0.8230899222904727  Validation Loss:  0.5821686094360692\n",
      "Epoch:  1215  Loss:  0.8229351469448635  Validation Loss:  0.5819814897009304\n",
      "Epoch:  1216  Loss:  0.822780618887572  Validation Loss:  0.5817947483488491\n",
      "Epoch:  1217  Loss:  0.8226264768413135  Validation Loss:  0.5816083539809499\n",
      "Epoch:  1218  Loss:  0.8224727259505362  Validation Loss:  0.5814223353351865\n",
      "Epoch:  1219  Loss:  0.8223193626673448  Validation Loss:  0.5812366833644254\n",
      "Epoch:  1220  Loss:  0.8221663914266086  Validation Loss:  0.5810514065836158\n",
      "Epoch:  1221  Loss:  0.8220138090352217  Validation Loss:  0.5808664964778083\n",
      "Epoch:  1222  Loss:  0.8218616177993161  Validation Loss:  0.580681925373418\n",
      "Epoch:  1223  Loss:  0.821709815235365  Validation Loss:  0.5804977720337254\n",
      "Epoch:  1224  Loss:  0.8215583906996817  Validation Loss:  0.5803139630172934\n",
      "Epoch:  1225  Loss:  0.8214073770103001  Validation Loss:  0.5801305371735778\n",
      "Epoch:  1226  Loss:  0.8212566906142802  Validation Loss:  0.579947506742818\n",
      "Epoch:  1227  Loss:  0.8211062967422462  Validation Loss:  0.579764837133033\n",
      "Epoch:  1228  Loss:  0.8209562596111071  Validation Loss:  0.5795825357948031\n",
      "Epoch:  1229  Loss:  0.8208066109745276  Validation Loss:  0.5794006341270038\n",
      "Epoch:  1230  Loss:  0.8206573611214047  Validation Loss:  0.5792190890227046\n",
      "Epoch:  1231  Loss:  0.8205084930218401  Validation Loss:  0.5790378807910851\n",
      "Epoch:  1232  Loss:  0.8203600265440487  Validation Loss:  0.5788570881954261\n",
      "Epoch:  1233  Loss:  0.8202118776029065  Validation Loss:  0.5786766803690365\n",
      "Epoch:  1234  Loss:  0.8200640030914829  Validation Loss:  0.5784965593899999\n",
      "Epoch:  1235  Loss:  0.8199158557468936  Validation Loss:  0.5783161457095828\n",
      "Epoch:  1236  Loss:  0.8197675930956999  Validation Loss:  0.5781359007315976\n",
      "Epoch:  1237  Loss:  0.8196195527201607  Validation Loss:  0.5779559947550297\n",
      "Epoch:  1238  Loss:  0.8194717791463647  Validation Loss:  0.577776489513261\n",
      "Epoch:  1239  Loss:  0.8193243537985143  Validation Loss:  0.5775973493499416\n",
      "Epoch:  1240  Loss:  0.8191773137521177  Validation Loss:  0.577418573732887\n",
      "Epoch:  1241  Loss:  0.8190306198029291  Validation Loss:  0.577240202575922\n",
      "Epoch:  1242  Loss:  0.8188841963807741  Validation Loss:  0.5770622076732772\n",
      "Epoch:  1243  Loss:  0.8187381316508565  Validation Loss:  0.5768846273422241\n",
      "Epoch:  1244  Loss:  0.8185923796679292  Validation Loss:  0.5767074264585972\n",
      "Epoch:  1245  Loss:  0.8184469322718325  Validation Loss:  0.5765306172626359\n",
      "Epoch:  1246  Loss:  0.8183018228127843  Validation Loss:  0.5763541800635201\n",
      "Epoch:  1247  Loss:  0.8181569865416913  Validation Loss:  0.5761781398739133\n",
      "Epoch:  1248  Loss:  0.8180124346344244  Validation Loss:  0.5760025179811886\n",
      "Epoch:  1249  Loss:  0.817868196893306  Validation Loss:  0.5758273111922401\n",
      "Epoch:  1250  Loss:  0.817724187814054  Validation Loss:  0.5756524838507175\n",
      "Epoch:  1251  Loss:  0.8175804545836789  Validation Loss:  0.5754780593727317\n",
      "Epoch:  1252  Loss:  0.8174370241661867  Validation Loss:  0.5753040436123099\n",
      "Epoch:  1253  Loss:  0.8172937911890802  Validation Loss:  0.5751304562602725\n",
      "Epoch:  1254  Loss:  0.8171508078064237  Validation Loss:  0.5749572781579835\n",
      "Epoch:  1255  Loss:  0.8170080287825494  Validation Loss:  0.5747845199491296\n",
      "Epoch:  1256  Loss:  0.8168654596166951  Validation Loss:  0.5746121135141168\n",
      "Epoch:  1257  Loss:  0.81672255836782  Validation Loss:  0.5744393004902771\n",
      "Epoch:  1258  Loss:  0.8165791279503277  Validation Loss:  0.5742668280644077\n",
      "Epoch:  1259  Loss:  0.8164359244207541  Validation Loss:  0.5740947462618351\n",
      "Epoch:  1260  Loss:  0.8162929229438305  Validation Loss:  0.5739230981894902\n",
      "Epoch:  1261  Loss:  0.8161501533218792  Validation Loss:  0.5737518721393177\n",
      "Epoch:  1262  Loss:  0.8160076386162213  Validation Loss:  0.5735810148928847\n",
      "Epoch:  1263  Loss:  0.8158654233529454  Validation Loss:  0.5734105807329927\n",
      "Epoch:  1264  Loss:  0.8157234406542211  Validation Loss:  0.573240550501006\n",
      "Epoch:  1265  Loss:  0.8155818148737862  Validation Loss:  0.5730708837509155\n",
      "Epoch:  1266  Loss:  0.8154404193517708  Validation Loss:  0.5729016363620758\n",
      "Epoch:  1267  Loss:  0.8152994130338941  Validation Loss:  0.5727327189275196\n",
      "Epoch:  1268  Loss:  0.8151586025598503  Validation Loss:  0.5725637802055904\n",
      "Epoch:  1269  Loss:  0.8150173280210722  Validation Loss:  0.5723949441952365\n",
      "Epoch:  1270  Loss:  0.8148762938522157  Validation Loss:  0.5722265009369168\n",
      "Epoch:  1271  Loss:  0.8147355954916704  Validation Loss:  0.5720582125442368\n",
      "Epoch:  1272  Loss:  0.8145950209526789  Validation Loss:  0.5718902078058038\n",
      "Epoch:  1273  Loss:  0.8144548352630365  Validation Loss:  0.5717225495193686\n",
      "Epoch:  1274  Loss:  0.8143150279564517  Validation Loss:  0.5715552605688572\n",
      "Epoch:  1275  Loss:  0.814175296574831  Validation Loss:  0.5713878039802823\n",
      "Epoch:  1276  Loss:  0.8140352708952767  Validation Loss:  0.5712205416389874\n",
      "Epoch:  1277  Loss:  0.8138956126003039  Validation Loss:  0.5710536539554596\n",
      "Epoch:  1278  Loss:  0.8137563717152391  Validation Loss:  0.5708870786641326\n",
      "Epoch:  1279  Loss:  0.8136176383566289  Validation Loss:  0.5707208854811532\n",
      "Epoch:  1280  Loss:  0.8134787990933373  Validation Loss:  0.5705543788416045\n",
      "Epoch:  1281  Loss:  0.8133398086896965  Validation Loss:  0.5703881217965058\n",
      "Epoch:  1282  Loss:  0.8132010373686042  Validation Loss:  0.5702220291963646\n",
      "Epoch:  1283  Loss:  0.813062478211664  Validation Loss:  0.5700560105698449\n",
      "Epoch:  1284  Loss:  0.8129235482996419  Validation Loss:  0.5698899690593991\n",
      "Epoch:  1285  Loss:  0.8127848358736152  Validation Loss:  0.569724301142352\n",
      "Epoch:  1286  Loss:  0.8126462499300638  Validation Loss:  0.5695584911320891\n",
      "Epoch:  1287  Loss:  0.8125073480464163  Validation Loss:  0.5693928844162396\n",
      "Epoch:  1288  Loss:  0.8123687032077994  Validation Loss:  0.5692273165498462\n",
      "Epoch:  1289  Loss:  0.8122296858401525  Validation Loss:  0.5690616864178862\n",
      "Epoch:  1290  Loss:  0.8120905730341162  Validation Loss:  0.5688958008374486\n",
      "Epoch:  1291  Loss:  0.8119510383833022  Validation Loss:  0.5687300035996097\n",
      "Epoch:  1292  Loss:  0.8118113728151435  Validation Loss:  0.5685638822615147\n",
      "Epoch:  1293  Loss:  0.811671527191287  Validation Loss:  0.5683977502797332\n",
      "Epoch:  1294  Loss:  0.8115312916537126  Validation Loss:  0.568231534745012\n",
      "Epoch:  1295  Loss:  0.8113906465116001  Validation Loss:  0.5680651089974812\n",
      "Epoch:  1296  Loss:  0.811249456767525  Validation Loss:  0.5678982245070594\n",
      "Epoch:  1297  Loss:  0.8111076087114357  Validation Loss:  0.5677310116589069\n",
      "Epoch:  1298  Loss:  0.8109651413701829  Validation Loss:  0.5675635140921388\n",
      "Epoch:  1299  Loss:  0.8108221404254436  Validation Loss:  0.5673957509653909\n",
      "Epoch:  1300  Loss:  0.8106785317262014  Validation Loss:  0.567227688218866\n",
      "Epoch:  1301  Loss:  0.8105342790839218  Validation Loss:  0.5670591795018741\n",
      "Epoch:  1302  Loss:  0.8103892861732415  Validation Loss:  0.5668903126248291\n",
      "Epoch:  1303  Loss:  0.8102437591268903  Validation Loss:  0.5667211817843574\n",
      "Epoch:  1304  Loss:  0.8100978370223727  Validation Loss:  0.5665520094335079\n",
      "Epoch:  1305  Loss:  0.8099514998140789  Validation Loss:  0.5663827391607421\n",
      "Epoch:  1306  Loss:  0.8098047664832502  Validation Loss:  0.5662129909864494\n",
      "Epoch:  1307  Loss:  0.8096578447591691  Validation Loss:  0.566043564251491\n",
      "Epoch:  1308  Loss:  0.8095107633797896  Validation Loss:  0.5658739294324603\n",
      "Epoch:  1309  Loss:  0.80936361068771  Validation Loss:  0.5657044909894466\n",
      "Epoch:  1310  Loss:  0.8092166832869961  Validation Loss:  0.5655353202351502\n",
      "Epoch:  1311  Loss:  0.8090701096114659  Validation Loss:  0.5653664145086493\n",
      "Epoch:  1312  Loss:  0.8089232932598818  Validation Loss:  0.5651971857462611\n",
      "Epoch:  1313  Loss:  0.8087763750836963  Validation Loss:  0.5650282039174012\n",
      "Epoch:  1314  Loss:  0.8086299348090377  Validation Loss:  0.5648596175014973\n",
      "Epoch:  1315  Loss:  0.808483880368017  Validation Loss:  0.5646912279937949\n",
      "Epoch:  1316  Loss:  0.80833806079768  Validation Loss:  0.5645231631185327\n",
      "Epoch:  1317  Loss:  0.8081925729555743  Validation Loss:  0.5643553153744766\n",
      "Epoch:  1318  Loss:  0.8080473233546529  Validation Loss:  0.5641877438340869\n",
      "Epoch:  1319  Loss:  0.8079024010470935  Validation Loss:  0.5640204341283866\n",
      "Epoch:  1320  Loss:  0.8077581319070998  Validation Loss:  0.5638539487762111\n",
      "Epoch:  1321  Loss:  0.8076147140846366  Validation Loss:  0.5636877327093056\n",
      "Epoch:  1322  Loss:  0.8074715164090905  Validation Loss:  0.5635217390954494\n",
      "Epoch:  1323  Loss:  0.8073286172889528  Validation Loss:  0.5633559338748455\n",
      "Epoch:  1324  Loss:  0.8071859023045926  Validation Loss:  0.5631904176303318\n",
      "Epoch:  1325  Loss:  0.807043439575604  Validation Loss:  0.5630250115479741\n",
      "Epoch:  1326  Loss:  0.8069011788992655  Validation Loss:  0.5628597576703344\n",
      "Epoch:  1327  Loss:  0.8067590947307292  Validation Loss:  0.5626946277916431\n",
      "Epoch:  1328  Loss:  0.8066171347385361  Validation Loss:  0.5625296421349049\n",
      "Epoch:  1329  Loss:  0.806475353915067  Validation Loss:  0.5623647501426083\n",
      "Epoch:  1330  Loss:  0.8063337048959165  Validation Loss:  0.562199957136597\n",
      "Epoch:  1331  Loss:  0.8061921582335517  Validation Loss:  0.562035226396152\n",
      "Epoch:  1332  Loss:  0.8060507286517393  Validation Loss:  0.5618705871914115\n",
      "Epoch:  1333  Loss:  0.805909461386147  Validation Loss:  0.5617062550570283\n",
      "Epoch:  1334  Loss:  0.8057689680939629  Validation Loss:  0.5615422917263848\n",
      "Epoch:  1335  Loss:  0.8056286523739496  Validation Loss:  0.5613782959324973\n",
      "Epoch:  1336  Loss:  0.8054883182048798  Validation Loss:  0.5612141458051545\n",
      "Epoch:  1337  Loss:  0.8053478964027905  Validation Loss:  0.5610499626823834\n",
      "Epoch:  1338  Loss:  0.8052073965469996  Validation Loss:  0.5608856028744152\n",
      "Epoch:  1339  Loss:  0.8050667663060483  Validation Loss:  0.5607210291283471\n",
      "Epoch:  1340  Loss:  0.8049259086449941  Validation Loss:  0.5605561552303178\n",
      "Epoch:  1341  Loss:  0.8047847958902518  Validation Loss:  0.5603909934205669\n",
      "Epoch:  1342  Loss:  0.8046433781938893  Validation Loss:  0.5602254101208278\n",
      "Epoch:  1343  Loss:  0.8045015920485769  Validation Loss:  0.5600593978805202\n",
      "Epoch:  1344  Loss:  0.8043593510630584  Validation Loss:  0.5598929029490266\n",
      "Epoch:  1345  Loss:  0.8042166523990177  Validation Loss:  0.5597258183572974\n",
      "Epoch:  1346  Loss:  0.8040734032789866  Validation Loss:  0.5595581052558762\n",
      "Epoch:  1347  Loss:  0.803929500104416  Validation Loss:  0.5593897019113813\n",
      "Epoch:  1348  Loss:  0.8037849309898558  Validation Loss:  0.5592205551053796\n",
      "Epoch:  1349  Loss:  0.8036396709226427  Validation Loss:  0.5590506589838437\n",
      "Epoch:  1350  Loss:  0.8034936636686325  Validation Loss:  0.5588800098214831\n",
      "Epoch:  1351  Loss:  0.8033469161462217  Validation Loss:  0.5587086406137262\n",
      "Epoch:  1352  Loss:  0.8031994753650257  Validation Loss:  0.5585365614720753\n",
      "Epoch:  1353  Loss:  0.8030513913503715  Validation Loss:  0.5583638798977647\n",
      "Epoch:  1354  Loss:  0.8029027162563234  Validation Loss:  0.5581906517701489\n",
      "Epoch:  1355  Loss:  0.8027540324699312  Validation Loss:  0.5580176157610757\n",
      "Epoch:  1356  Loss:  0.8026055658147448  Validation Loss:  0.5578443450587136\n",
      "Epoch:  1357  Loss:  0.8024568770612989  Validation Loss:  0.5576708620148045\n",
      "Epoch:  1358  Loss:  0.8023081129150731  Validation Loss:  0.5574973497007575\n",
      "Epoch:  1359  Loss:  0.8021593485914525  Validation Loss:  0.5573238070522036\n",
      "Epoch:  1360  Loss:  0.8020106518552417  Validation Loss:  0.5571503889347825\n",
      "Epoch:  1361  Loss:  0.8018621243536472  Validation Loss:  0.5569772028497287\n",
      "Epoch:  1362  Loss:  0.8017139147434916  Validation Loss:  0.5568042679556778\n",
      "Epoch:  1363  Loss:  0.8015659103790919  Validation Loss:  0.5566315672227314\n",
      "Epoch:  1364  Loss:  0.8014182854621184  Validation Loss:  0.5564592640314784\n",
      "Epoch:  1365  Loss:  0.8012710646504447  Validation Loss:  0.5562873285795961\n",
      "Epoch:  1366  Loss:  0.8011242475892816  Validation Loss:  0.5561158284544945\n",
      "Epoch:  1367  Loss:  0.8009778553886073  Validation Loss:  0.5559447216136115\n",
      "Epoch:  1368  Loss:  0.8008319098679793  Validation Loss:  0.5557740761765412\n",
      "Epoch:  1369  Loss:  0.8006865201251847  Validation Loss:  0.5556039788893291\n",
      "Epoch:  1370  Loss:  0.800541629748685  Validation Loss:  0.5554343020277364\n",
      "Epoch:  1371  Loss:  0.8003971864070211  Validation Loss:  0.5552650493170533\n",
      "Epoch:  1372  Loss:  0.8002532990205855  Validation Loss:  0.5550963846700532\n",
      "Epoch:  1373  Loss:  0.800109937787056  Validation Loss:  0.5549281207578523\n",
      "Epoch:  1374  Loss:  0.7999669636289278  Validation Loss:  0.554760175624064\n",
      "Epoch:  1375  Loss:  0.7998245436520803  Validation Loss:  0.5545927658677101\n",
      "Epoch:  1376  Loss:  0.7996827064170724  Validation Loss:  0.5544258856347629\n",
      "Epoch:  1377  Loss:  0.7995413281023502  Validation Loss:  0.5542593768664769\n",
      "Epoch:  1378  Loss:  0.7994003583277974  Validation Loss:  0.5540933630296162\n",
      "Epoch:  1379  Loss:  0.7992599987912745  Validation Loss:  0.5539279154368809\n",
      "Epoch:  1380  Loss:  0.7991200855800084  Validation Loss:  0.5537628733686039\n",
      "Epoch:  1381  Loss:  0.7989806005997317  Validation Loss:  0.553598267691476\n",
      "Epoch:  1382  Loss:  0.7988416364505178  Validation Loss:  0.5534343293734959\n",
      "Epoch:  1383  Loss:  0.7987030375571478  Validation Loss:  0.5532708290432181\n",
      "Epoch:  1384  Loss:  0.7985646951766241  Validation Loss:  0.5531077470098223\n",
      "Epoch:  1385  Loss:  0.7984267322435266  Validation Loss:  0.5529451237193176\n",
      "Epoch:  1386  Loss:  0.7982893105418909  Validation Loss:  0.5527830932821546\n",
      "Epoch:  1387  Loss:  0.7981523921092352  Validation Loss:  0.5526214699660029\n",
      "Epoch:  1388  Loss:  0.7980158721052465  Validation Loss:  0.552460217582328\n",
      "Epoch:  1389  Loss:  0.7978797473368191  Validation Loss:  0.5522993286805493\n",
      "Epoch:  1390  Loss:  0.7977440614430678  Validation Loss:  0.5521389368389334\n",
      "Epoch:  1391  Loss:  0.7976089799333186  Validation Loss:  0.551979119756392\n",
      "Epoch:  1392  Loss:  0.7974743541507494  Validation Loss:  0.5518196794603553\n",
      "Epoch:  1393  Loss:  0.7973401542930376  Validation Loss:  0.5516606553324631\n",
      "Epoch:  1394  Loss:  0.7972063913586593  Validation Loss:  0.5515020729175636\n",
      "Epoch:  1395  Loss:  0.7970731496101334  Validation Loss:  0.5513440125754901\n",
      "Epoch:  1396  Loss:  0.7969405115360305  Validation Loss:  0.551186526460307\n",
      "Epoch:  1397  Loss:  0.7968083513634545  Validation Loss:  0.551029405423573\n",
      "Epoch:  1398  Loss:  0.796676599731048  Validation Loss:  0.5508726622377124\n",
      "Epoch:  1399  Loss:  0.7965452440437817  Validation Loss:  0.5507163123360702\n",
      "Epoch:  1400  Loss:  0.7964142841242609  Validation Loss:  0.5505603370921952\n",
      "Epoch:  1401  Loss:  0.7962837533227035  Validation Loss:  0.5504048227199486\n",
      "Epoch:  1402  Loss:  0.7961537774120059  Validation Loss:  0.5502498990723065\n",
      "Epoch:  1403  Loss:  0.7960242978518918  Validation Loss:  0.5500953160226345\n",
      "Epoch:  1404  Loss:  0.7958951995131516  Validation Loss:  0.5499411267893655\n",
      "Epoch:  1405  Loss:  0.7957665260349002  Validation Loss:  0.5497873122138637\n",
      "Epoch:  1406  Loss:  0.7956382238439151  Validation Loss:  0.5496339058237416\n",
      "Epoch:  1407  Loss:  0.7955103573345003  Validation Loss:  0.549480856529304\n",
      "Epoch:  1408  Loss:  0.7953828679663795  Validation Loss:  0.5493281824248177\n",
      "Epoch:  1409  Loss:  0.7952557795104527  Validation Loss:  0.5491759702563286\n",
      "Epoch:  1410  Loss:  0.7951292789408139  Validation Loss:  0.5490243498768125\n",
      "Epoch:  1411  Loss:  0.7950032639006773  Validation Loss:  0.5488730727561882\n",
      "Epoch:  1412  Loss:  0.7948776391290483  Validation Loss:  0.5487222091427871\n",
      "Epoch:  1413  Loss:  0.7947528876719021  Validation Loss:  0.5485723327313151\n",
      "Epoch:  1414  Loss:  0.7946289735180991  Validation Loss:  0.5484228006431034\n",
      "Epoch:  1415  Loss:  0.794505449278014  Validation Loss:  0.5482736698218754\n",
      "Epoch:  1416  Loss:  0.7943823218700432  Validation Loss:  0.5481248939675945\n",
      "Epoch:  1417  Loss:  0.7942595975030036  Validation Loss:  0.5479765119297164\n",
      "Epoch:  1418  Loss:  0.7941372561312857  Validation Loss:  0.5478284976312092\n",
      "Epoch:  1419  Loss:  0.7940153279120014  Validation Loss:  0.5476809298353535\n",
      "Epoch:  1420  Loss:  0.7938939684203693  Validation Loss:  0.5475339261548859\n",
      "Epoch:  1421  Loss:  0.7937730889590013  Validation Loss:  0.5473873072436878\n",
      "Epoch:  1422  Loss:  0.7936526097002483  Validation Loss:  0.5472410693764687\n",
      "Epoch:  1423  Loss:  0.7935325125498431  Validation Loss:  0.547095179025616\n",
      "Epoch:  1424  Loss:  0.7934128063775244  Validation Loss:  0.5469497064394611\n",
      "Epoch:  1425  Loss:  0.7932934876353968  Validation Loss:  0.5468045632754054\n",
      "Epoch:  1426  Loss:  0.793174570692437  Validation Loss:  0.5466598171208586\n",
      "Epoch:  1427  Loss:  0.7930560507589862  Validation Loss:  0.5465154403022358\n",
      "Epoch:  1428  Loss:  0.7929379191427004  Validation Loss:  0.5463714306907994\n",
      "Epoch:  1429  Loss:  0.7928201767305533  Validation Loss:  0.5462278069130012\n",
      "Epoch:  1430  Loss:  0.7927028197972548  Validation Loss:  0.5460845232009888\n",
      "Epoch:  1431  Loss:  0.792585871049336  Validation Loss:  0.5459416364984853\n",
      "Epoch:  1432  Loss:  0.792469346452327  Validation Loss:  0.5457991728825229\n",
      "Epoch:  1433  Loss:  0.7923532986924762  Validation Loss:  0.545657253158944\n",
      "Epoch:  1434  Loss:  0.7922376621337164  Validation Loss:  0.5455157160758972\n",
      "Epoch:  1435  Loss:  0.7921224397917589  Validation Loss:  0.5453745632299355\n",
      "Epoch:  1436  Loss:  0.7920076045252028  Validation Loss:  0.545233781848635\n",
      "Epoch:  1437  Loss:  0.7918931385945707  Validation Loss:  0.5450933591595718\n",
      "Epoch:  1438  Loss:  0.7917790785431862  Validation Loss:  0.5449532925018242\n",
      "Epoch:  1439  Loss:  0.7916653656533786  Validation Loss:  0.5448136031627655\n",
      "Epoch:  1440  Loss:  0.7915520025860696  Validation Loss:  0.5446742868849209\n",
      "Epoch:  1441  Loss:  0.7914390163052649  Validation Loss:  0.5445353154625211\n",
      "Epoch:  1442  Loss:  0.7913263700902462  Validation Loss:  0.5443966814449855\n",
      "Epoch:  1443  Loss:  0.7912140527651423  Validation Loss:  0.5442584183599267\n",
      "Epoch:  1444  Loss:  0.7911020951966444  Validation Loss:  0.544120480971677\n",
      "Epoch:  1445  Loss:  0.7909904909985406  Validation Loss:  0.5439829432538578\n",
      "Epoch:  1446  Loss:  0.7908792440735158  Validation Loss:  0.54384575491505\n",
      "Epoch:  1447  Loss:  0.7907684040921075  Validation Loss:  0.5437089343156133\n",
      "Epoch:  1448  Loss:  0.7906579456868625  Validation Loss:  0.5435724761337042\n",
      "Epoch:  1449  Loss:  0.7905478695673602  Validation Loss:  0.5434363878199032\n",
      "Epoch:  1450  Loss:  0.7904381723630995  Validation Loss:  0.5433006707046714\n",
      "Epoch:  1451  Loss:  0.7903288797963233  Validation Loss:  0.5431653553886073\n",
      "Epoch:  1452  Loss:  0.7902201188816911  Validation Loss:  0.5430305754499776\n",
      "Epoch:  1453  Loss:  0.7901118016313939  Validation Loss:  0.542896209018571\n",
      "Epoch:  1454  Loss:  0.7900039076450325  Validation Loss:  0.5427621956914663\n",
      "Epoch:  1455  Loss:  0.7898963978957563  Validation Loss:  0.5426285804382392\n",
      "Epoch:  1456  Loss:  0.7897892642234053  Validation Loss:  0.5424952866243464\n",
      "Epoch:  1457  Loss:  0.7896825142559551  Validation Loss:  0.5423623509705067\n",
      "Epoch:  1458  Loss:  0.7895761403654303  Validation Loss:  0.5422298290899822\n",
      "Epoch:  1459  Loss:  0.7894701627748353  Validation Loss:  0.5420976145459073\n",
      "Epoch:  1460  Loss:  0.7893645415703455  Validation Loss:  0.541965789826853\n",
      "Epoch:  1461  Loss:  0.789259327486867  Validation Loss:  0.541834306237953\n",
      "Epoch:  1462  Loss:  0.7891544712086519  Validation Loss:  0.5417032028947558\n",
      "Epoch:  1463  Loss:  0.7890500163748151  Validation Loss:  0.541572463565639\n",
      "Epoch:  1464  Loss:  0.788945927861191  Validation Loss:  0.5414420885166952\n",
      "Epoch:  1465  Loss:  0.7888422301482587  Validation Loss:  0.5413120503404311\n",
      "Epoch:  1466  Loss:  0.7887388881118524  Validation Loss:  0.5411823665989297\n",
      "Epoch:  1467  Loss:  0.7886359398918492  Validation Loss:  0.5410530678927898\n",
      "Epoch:  1468  Loss:  0.7885333716514564  Validation Loss:  0.5409241233553205\n",
      "Epoch:  1469  Loss:  0.7884311671590521  Validation Loss:  0.5407955375100885\n",
      "Epoch:  1470  Loss:  0.7883293564830508  Validation Loss:  0.5406673140823841\n",
      "Epoch:  1471  Loss:  0.7882279230370408  Validation Loss:  0.5405394645141703\n",
      "Epoch:  1472  Loss:  0.7881268830526442  Validation Loss:  0.5404119566082954\n",
      "Epoch:  1473  Loss:  0.7880262042440119  Validation Loss:  0.5402848326734134\n",
      "Epoch:  1474  Loss:  0.7879259150830054  Validation Loss:  0.5401580432163817\n",
      "Epoch:  1475  Loss:  0.7878260089173204  Validation Loss:  0.5400316499705825\n",
      "Epoch:  1476  Loss:  0.7877264783850738  Validation Loss:  0.5399055768336568\n",
      "Epoch:  1477  Loss:  0.7876273265906742  Validation Loss:  0.5397798980453185\n",
      "Epoch:  1478  Loss:  0.7875285585011754  Validation Loss:  0.5396545505417245\n",
      "Epoch:  1479  Loss:  0.787430159392811  Validation Loss:  0.5395295995154551\n",
      "Epoch:  1480  Loss:  0.7873321515286252  Validation Loss:  0.5394050452326026\n",
      "Epoch:  1481  Loss:  0.7872346471995115  Validation Loss:  0.5392809486282724\n",
      "Epoch:  1482  Loss:  0.78713760666904  Validation Loss:  0.5391573184835059\n",
      "Epoch:  1483  Loss:  0.7870409981835456  Validation Loss:  0.539034040910857\n",
      "Epoch:  1484  Loss:  0.7869447540669214  Validation Loss:  0.538911137463791\n",
      "Epoch:  1485  Loss:  0.7868488823906297  Validation Loss:  0.5387886025543723\n",
      "Epoch:  1486  Loss:  0.7867534039098592  Validation Loss:  0.5386663885521037\n",
      "Epoch:  1487  Loss:  0.7866582974259343  Validation Loss:  0.5385445917823485\n",
      "Epoch:  1488  Loss:  0.7865635762434631  Validation Loss:  0.538423099422029\n",
      "Epoch:  1489  Loss:  0.7864692122453735  Validation Loss:  0.538301968947053\n",
      "Epoch:  1490  Loss:  0.7863752542152291  Validation Loss:  0.5381812181855951\n",
      "Epoch:  1491  Loss:  0.7862816319046986  Validation Loss:  0.5380608061594623\n",
      "Epoch:  1492  Loss:  0.7861884001287676  Validation Loss:  0.5379407653318984\n",
      "Epoch:  1493  Loss:  0.7860955294399035  Validation Loss:  0.5378210318407842\n",
      "Epoch:  1494  Loss:  0.7860029888827176  Validation Loss:  0.5377016655568566\n",
      "Epoch:  1495  Loss:  0.7859108118074281  Validation Loss:  0.5375826720680509\n",
      "Epoch:  1496  Loss:  0.7858190192353158  Validation Loss:  0.53746402343469\n",
      "Epoch:  1497  Loss:  0.7857275831380061  Validation Loss:  0.5373457244464329\n",
      "Epoch:  1498  Loss:  0.7856365622331699  Validation Loss:  0.5372277844165053\n",
      "Epoch:  1499  Loss:  0.7855458503500337  Validation Loss:  0.5371102549667869\n",
      "Training session:  4\n",
      "2020_12_10_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_12_10_MV1_run\n",
      "Epoch:  0  Loss:  0.7224862539533818  Validation Loss:  1.0977941110730172\n",
      "Epoch:  1  Loss:  0.7225320016065341  Validation Loss:  1.097870909422636\n",
      "Epoch:  2  Loss:  0.7225777043469166  Validation Loss:  1.0979476537555457\n",
      "Epoch:  3  Loss:  0.7226224654259976  Validation Loss:  1.0980240172396103\n",
      "Epoch:  4  Loss:  0.7226665941684434  Validation Loss:  1.0981002086152634\n",
      "Epoch:  5  Loss:  0.7227106790864066  Validation Loss:  1.0981764016052087\n",
      "Epoch:  6  Loss:  0.7227547833005364  Validation Loss:  1.0982525900006295\n",
      "Epoch:  7  Loss:  0.7227989227584238  Validation Loss:  1.0983287442475558\n",
      "Epoch:  8  Loss:  0.7228429389468739  Validation Loss:  1.0984048689405124\n",
      "Epoch:  9  Loss:  0.7228869343741556  Validation Loss:  1.0984809750070175\n",
      "Epoch:  10  Loss:  0.7229310238126958  Validation Loss:  1.0985571748266618\n",
      "Epoch:  11  Loss:  0.7229751948727651  Validation Loss:  1.0986334846665462\n",
      "Epoch:  12  Loss:  0.7230194124361772  Validation Loss:  1.098709618548552\n",
      "Epoch:  13  Loss:  0.7230635636559363  Validation Loss:  1.0987853195518256\n",
      "Epoch:  14  Loss:  0.7231074497103691  Validation Loss:  1.0988607951750358\n",
      "Epoch:  15  Loss:  0.7231512505016969  Validation Loss:  1.0989359450836977\n",
      "Epoch:  16  Loss:  0.7231949751547883  Validation Loss:  1.0990108147263526\n",
      "Epoch:  17  Loss:  0.7232386459795277  Validation Loss:  1.099085629855593\n",
      "Epoch:  18  Loss:  0.7232823163856951  Validation Loss:  1.0991605115433534\n",
      "Epoch:  19  Loss:  0.723325754944863  Validation Loss:  1.0992354227850833\n",
      "Epoch:  20  Loss:  0.723369138210677  Validation Loss:  1.0993101821591458\n",
      "Epoch:  21  Loss:  0.7234125404796573  Validation Loss:  1.0993850249797106\n",
      "Epoch:  22  Loss:  0.7234559378094887  Validation Loss:  1.0994597993791104\n",
      "Epoch:  23  Loss:  0.7234992145068859  Validation Loss:  1.0995345720400413\n",
      "Epoch:  24  Loss:  0.723542517867316  Validation Loss:  1.09960939163963\n",
      "Epoch:  25  Loss:  0.7235858746793833  Validation Loss:  1.0996842088798682\n",
      "Epoch:  26  Loss:  0.7236292318263081  Validation Loss:  1.0997591378788154\n",
      "Epoch:  27  Loss:  0.7236726966299368  Validation Loss:  1.099834265684088\n",
      "Epoch:  28  Loss:  0.7237162866284338  Validation Loss:  1.0999097778151432\n",
      "Epoch:  29  Loss:  0.7237599668291848  Validation Loss:  1.0999854826678832\n",
      "Epoch:  30  Loss:  0.723803717098879  Validation Loss:  1.10006136285762\n",
      "Epoch:  31  Loss:  0.7238475652306937  Validation Loss:  1.1001376827557883\n",
      "Epoch:  32  Loss:  0.7238915908370125  Validation Loss:  1.1002140099803606\n",
      "Epoch:  33  Loss:  0.7239355999515967  Validation Loss:  1.100290405501922\n",
      "Epoch:  34  Loss:  0.723979676707407  Validation Loss:  1.1003667635222276\n",
      "Epoch:  35  Loss:  0.7240236592426729  Validation Loss:  1.100443143894275\n",
      "Epoch:  36  Loss:  0.7240676002137447  Validation Loss:  1.1005194794386626\n",
      "Epoch:  37  Loss:  0.7241114675161544  Validation Loss:  1.1005958090225856\n",
      "Epoch:  38  Loss:  0.7241553709831801  Validation Loss:  1.1006721900155148\n",
      "Epoch:  39  Loss:  0.7241993174794015  Validation Loss:  1.1007485212137302\n",
      "Epoch:  40  Loss:  0.7242432719284899  Validation Loss:  1.1008249785751105\n",
      "Epoch:  41  Loss:  0.7242872511988945  Validation Loss:  1.100901368012031\n",
      "Epoch:  42  Loss:  0.7243312719916359  Validation Loss:  1.1009778400262198\n",
      "Epoch:  43  Loss:  0.7243752888916584  Validation Loss:  1.1010543014854193\n",
      "Epoch:  44  Loss:  0.7244193311989977  Validation Loss:  1.1011307990799348\n",
      "Epoch:  45  Loss:  0.7244634350364128  Validation Loss:  1.101207328836123\n",
      "Epoch:  46  Loss:  0.7245075449012639  Validation Loss:  1.101283908262849\n",
      "Epoch:  47  Loss:  0.7245516733088521  Validation Loss:  1.1013604667037726\n",
      "Epoch:  48  Loss:  0.7245958378810561  Validation Loss:  1.1014370571821928\n",
      "Epoch:  49  Loss:  0.7246399620192104  Validation Loss:  1.1015136187275252\n",
      "Epoch:  50  Loss:  0.7246839662783602  Validation Loss:  1.1015902367730936\n",
      "Epoch:  51  Loss:  0.7247280210591434  Validation Loss:  1.101666814709703\n",
      "Epoch:  52  Loss:  0.7247720949686645  Validation Loss:  1.1017433864374955\n",
      "Epoch:  53  Loss:  0.7248161874627799  Validation Loss:  1.1018200346579154\n",
      "Epoch:  54  Loss:  0.7248602953603428  Validation Loss:  1.1018967196345328\n",
      "Epoch:  55  Loss:  0.7249044405945232  Validation Loss:  1.1019733693450688\n",
      "Epoch:  56  Loss:  0.7249486086827316  Validation Loss:  1.1020500822613637\n",
      "Epoch:  57  Loss:  0.7249928117635545  Validation Loss:  1.1021268114447593\n",
      "Epoch:  58  Loss:  0.7250370284061084  Validation Loss:  1.1022035282105207\n",
      "Epoch:  59  Loss:  0.7250812887475732  Validation Loss:  1.1022803305337827\n",
      "Epoch:  60  Loss:  0.7251255343971628  Validation Loss:  1.102357086663445\n",
      "Epoch:  61  Loss:  0.7251697770748915  Validation Loss:  1.102433922017614\n",
      "Epoch:  62  Loss:  0.7252139052731937  Validation Loss:  1.1025106374174356\n",
      "Epoch:  63  Loss:  0.7252580050923182  Validation Loss:  1.1025873879591623\n",
      "Epoch:  64  Loss:  0.7253021419132024  Validation Loss:  1.1026641784856717\n",
      "Epoch:  65  Loss:  0.7253462796130877  Validation Loss:  1.102740942190091\n",
      "Epoch:  66  Loss:  0.7253904390368568  Validation Loss:  1.1028177515914044\n",
      "Epoch:  67  Loss:  0.7254346185939365  Validation Loss:  1.1028945958862701\n",
      "Epoch:  68  Loss:  0.7254787930444385  Validation Loss:  1.1029714106271664\n",
      "Epoch:  69  Loss:  0.7255230139145691  Validation Loss:  1.1030482935408752\n",
      "Epoch:  70  Loss:  0.7255671886580713  Validation Loss:  1.1031251100202402\n",
      "Epoch:  71  Loss:  0.7256112568331569  Validation Loss:  1.1032019377996525\n",
      "Epoch:  72  Loss:  0.7256553414999769  Validation Loss:  1.1032787488152584\n",
      "Epoch:  73  Loss:  0.7256994427003888  Validation Loss:  1.1033555575956902\n",
      "Epoch:  74  Loss:  0.725743554323242  Validation Loss:  1.1034324761480092\n",
      "Epoch:  75  Loss:  0.7257876884652658  Validation Loss:  1.1035093322396279\n",
      "Epoch:  76  Loss:  0.7258318436614583  Validation Loss:  1.1035862649480501\n",
      "Epoch:  77  Loss:  0.7258759791429124  Validation Loss:  1.1036631462474664\n",
      "Epoch:  78  Loss:  0.7259200025307998  Validation Loss:  1.103739991535743\n",
      "Epoch:  79  Loss:  0.7259640300206924  Validation Loss:  1.1038168710966905\n",
      "Epoch:  80  Loss:  0.7260080468370004  Validation Loss:  1.1038936739166578\n",
      "Epoch:  81  Loss:  0.7260520937486311  Validation Loss:  1.1039705759535232\n",
      "Epoch:  82  Loss:  0.7260960957893495  Validation Loss:  1.1040474219868581\n",
      "Epoch:  83  Loss:  0.7261400868216258  Validation Loss:  1.1041242744773627\n",
      "Epoch:  84  Loss:  0.7261839288841473  Validation Loss:  1.1042009902497132\n",
      "Epoch:  85  Loss:  0.7262277418140615  Validation Loss:  1.1042777698487043\n",
      "Epoch:  86  Loss:  0.7262715606039829  Validation Loss:  1.1043545735379061\n",
      "Epoch:  87  Loss:  0.7263154127540883  Validation Loss:  1.1044313170015811\n",
      "Epoch:  88  Loss:  0.726359174743797  Validation Loss:  1.104508011912306\n",
      "Epoch:  89  Loss:  0.726402852600545  Validation Loss:  1.1045847001175086\n",
      "Epoch:  90  Loss:  0.7264464978505386  Validation Loss:  1.1046614083151023\n",
      "Epoch:  91  Loss:  0.7264901151817836  Validation Loss:  1.1047380818674961\n",
      "Epoch:  92  Loss:  0.7265336937951238  Validation Loss:  1.1048146598041058\n",
      "Epoch:  93  Loss:  0.7265771622403284  Validation Loss:  1.1048912522693475\n",
      "Epoch:  94  Loss:  0.7266206476376967  Validation Loss:  1.1049679162601629\n",
      "Epoch:  95  Loss:  0.7266641353372107  Validation Loss:  1.105044499784708\n",
      "Epoch:  96  Loss:  0.7267074884658449  Validation Loss:  1.1051210261881352\n",
      "Epoch:  97  Loss:  0.7267508235958855  Validation Loss:  1.1051975696037213\n",
      "Epoch:  98  Loss:  0.7267942067779852  Validation Loss:  1.1052742258956034\n",
      "Epoch:  99  Loss:  0.7268374029839977  Validation Loss:  1.1053507082164287\n",
      "Epoch:  100  Loss:  0.7268806197000354  Validation Loss:  1.1054272091637054\n",
      "Epoch:  101  Loss:  0.7269237367959505  Validation Loss:  1.1055036883801221\n",
      "Epoch:  102  Loss:  0.7269668071792367  Validation Loss:  1.1055801233897606\n",
      "Epoch:  103  Loss:  0.7270098041450039  Validation Loss:  1.1056565401454768\n",
      "Epoch:  104  Loss:  0.727052722251817  Validation Loss:  1.1057329920430978\n",
      "Epoch:  105  Loss:  0.7270955566860987  Validation Loss:  1.1058093203852575\n",
      "Epoch:  106  Loss:  0.727138326032443  Validation Loss:  1.1058856576681138\n",
      "Epoch:  107  Loss:  0.7271809199134286  Validation Loss:  1.1059619129945835\n",
      "Epoch:  108  Loss:  0.727223528193289  Validation Loss:  1.1060381659617027\n",
      "Epoch:  109  Loss:  0.7272659529712093  Validation Loss:  1.1061143490175407\n",
      "Epoch:  110  Loss:  0.727308221035794  Validation Loss:  1.1061904530972242\n",
      "Epoch:  111  Loss:  0.7273504143852866  Validation Loss:  1.1062665215382974\n",
      "Epoch:  112  Loss:  0.7273924784797631  Validation Loss:  1.1063425097614528\n",
      "Epoch:  113  Loss:  0.7274343747687474  Validation Loss:  1.1064184510459503\n",
      "Epoch:  114  Loss:  0.7274760961783736  Validation Loss:  1.1064943029234806\n",
      "Epoch:  115  Loss:  0.7275176335419162  Validation Loss:  1.1065700182070335\n",
      "Epoch:  116  Loss:  0.7275589561361945  Validation Loss:  1.1066456789771715\n",
      "Epoch:  117  Loss:  0.7275999891624022  Validation Loss:  1.1067210897803306\n",
      "Epoch:  118  Loss:  0.727640822153078  Validation Loss:  1.1067965015769006\n",
      "Epoch:  119  Loss:  0.7276813573716732  Validation Loss:  1.1068716902285813\n",
      "Epoch:  120  Loss:  0.7277216086310617  Validation Loss:  1.1069467497368655\n",
      "Epoch:  121  Loss:  0.727761516996314  Validation Loss:  1.1070216453323762\n",
      "Epoch:  122  Loss:  0.7278010379313753  Validation Loss:  1.1070963026334841\n",
      "Epoch:  123  Loss:  0.7278401574977998  Validation Loss:  1.1071707777678967\n",
      "Epoch:  124  Loss:  0.7278788649801458  Validation Loss:  1.1072450502465168\n",
      "Epoch:  125  Loss:  0.7279170475732745  Validation Loss:  1.1073190038402876\n",
      "Epoch:  126  Loss:  0.7279547565103917  Validation Loss:  1.1073927364001672\n",
      "Epoch:  127  Loss:  0.7279918449983168  Validation Loss:  1.1074660763144493\n",
      "Epoch:  128  Loss:  0.7280283101070463  Validation Loss:  1.1075391121208669\n",
      "Epoch:  129  Loss:  0.7280640847813548  Validation Loss:  1.1076117644707362\n",
      "Epoch:  130  Loss:  0.7280990945991506  Validation Loss:  1.1076839573681354\n",
      "Epoch:  131  Loss:  0.7281333437461531  Validation Loss:  1.1077557953695456\n",
      "Epoch:  132  Loss:  0.7281667667577106  Validation Loss:  1.1078271962702275\n",
      "Epoch:  133  Loss:  0.7281993537973822  Validation Loss:  1.1078980854401985\n",
      "Epoch:  134  Loss:  0.7282310850248578  Validation Loss:  1.1079685951272646\n",
      "Epoch:  135  Loss:  0.7282619640817133  Validation Loss:  1.1080385668824115\n",
      "Epoch:  136  Loss:  0.7282920724639063  Validation Loss:  1.1081081829965114\n",
      "Epoch:  137  Loss:  0.7283214831285263  Validation Loss:  1.1081774349013964\n",
      "Epoch:  138  Loss:  0.7283501916387108  Validation Loss:  1.1082463244597116\n",
      "Epoch:  139  Loss:  0.7283783891144093  Validation Loss:  1.1083149266739687\n",
      "Epoch:  140  Loss:  0.7284061189196752  Validation Loss:  1.1083832706014316\n",
      "Epoch:  141  Loss:  0.7284334307808554  Validation Loss:  1.1084514596809945\n",
      "Epoch:  142  Loss:  0.7284604700261288  Validation Loss:  1.1085194418827693\n",
      "Epoch:  143  Loss:  0.7284872727782539  Validation Loss:  1.1085873629897833\n",
      "Epoch:  144  Loss:  0.7285138837825716  Validation Loss:  1.1086550942311684\n",
      "Epoch:  145  Loss:  0.7285403825677512  Validation Loss:  1.1087227899581193\n",
      "Epoch:  146  Loss:  0.7285668258502912  Validation Loss:  1.1087904869268337\n",
      "Epoch:  147  Loss:  0.7285932122907611  Validation Loss:  1.1088580983380476\n",
      "Epoch:  148  Loss:  0.7286196169391107  Validation Loss:  1.1089257800330719\n",
      "Epoch:  149  Loss:  0.7286460598867931  Validation Loss:  1.1089935339987278\n",
      "Epoch:  150  Loss:  0.7286725860047206  Validation Loss:  1.1090612708280483\n",
      "Epoch:  151  Loss:  0.7286991772105854  Validation Loss:  1.1091290863851706\n",
      "Epoch:  152  Loss:  0.7287258285652386  Validation Loss:  1.1091969004521767\n",
      "Epoch:  153  Loss:  0.7287525369293903  Validation Loss:  1.1092648276438315\n",
      "Epoch:  154  Loss:  0.728779333109936  Validation Loss:  1.1093327965587378\n",
      "Epoch:  155  Loss:  0.7288062264410298  Validation Loss:  1.1094007668395838\n",
      "Epoch:  156  Loss:  0.7288331923943557  Validation Loss:  1.1094687604655822\n",
      "Epoch:  157  Loss:  0.7288602380437798  Validation Loss:  1.1095368711898723\n",
      "Epoch:  158  Loss:  0.7288873644357317  Validation Loss:  1.1096050435056288\n",
      "Epoch:  159  Loss:  0.7289146166085527  Validation Loss:  1.1096732334544261\n",
      "Epoch:  160  Loss:  0.7289418982488386  Validation Loss:  1.109741473570466\n",
      "Epoch:  161  Loss:  0.7289692739422402  Validation Loss:  1.1098097894340753\n",
      "Epoch:  162  Loss:  0.7289967478326197  Validation Loss:  1.1098781468967596\n",
      "Epoch:  163  Loss:  0.729024259352617  Validation Loss:  1.1099465186397235\n",
      "Epoch:  164  Loss:  0.7290518560520048  Validation Loss:  1.1100150023897488\n",
      "Epoch:  165  Loss:  0.7290795474323664  Validation Loss:  1.1100834976881742\n",
      "Epoch:  166  Loss:  0.7291072780747762  Validation Loss:  1.1101520312329134\n",
      "Epoch:  167  Loss:  0.7291350933942902  Validation Loss:  1.1102206243822972\n",
      "Epoch:  168  Loss:  0.7291629990416296  Validation Loss:  1.110289225106438\n",
      "Epoch:  169  Loss:  0.7291909703210498  Validation Loss:  1.1103578807165226\n",
      "Epoch:  170  Loss:  0.7292189503067665  Validation Loss:  1.1104265946894885\n",
      "Epoch:  171  Loss:  0.7292470068074344  Validation Loss:  1.1104952762524287\n",
      "Epoch:  172  Loss:  0.7292751060442978  Validation Loss:  1.1105640490849813\n",
      "Epoch:  173  Loss:  0.7293032948555571  Validation Loss:  1.110632863516609\n",
      "Epoch:  174  Loss:  0.7293314618592182  Validation Loss:  1.1107016475250324\n",
      "Epoch:  175  Loss:  0.7293596171010076  Validation Loss:  1.1107704134037097\n",
      "Epoch:  176  Loss:  0.7293878470160319  Validation Loss:  1.1108392705519994\n",
      "Epoch:  177  Loss:  0.7294161465395702  Validation Loss:  1.110908079892397\n",
      "Epoch:  178  Loss:  0.7294445465622323  Validation Loss:  1.1109770064552624\n",
      "Epoch:  179  Loss:  0.7294729560027632  Validation Loss:  1.111045964807272\n",
      "Epoch:  180  Loss:  0.7295014205273618  Validation Loss:  1.1111148759722709\n",
      "Epoch:  181  Loss:  0.7295298912886823  Validation Loss:  1.1111838915695746\n",
      "Epoch:  182  Loss:  0.7295584025259099  Validation Loss:  1.1112528988470634\n",
      "Epoch:  183  Loss:  0.7295869892316588  Validation Loss:  1.1113219206531844\n",
      "Epoch:  184  Loss:  0.729615630268046  Validation Loss:  1.1113909597198168\n",
      "Epoch:  185  Loss:  0.7296443231236399  Validation Loss:  1.1114599950611592\n",
      "Epoch:  186  Loss:  0.7296730435212676  Validation Loss:  1.1115291255215805\n",
      "Epoch:  187  Loss:  0.7297017406044382  Validation Loss:  1.1115982034554084\n",
      "Epoch:  188  Loss:  0.7297304777868008  Validation Loss:  1.1116673339158296\n",
      "Epoch:  189  Loss:  0.7297592348513309  Validation Loss:  1.1117364411552748\n",
      "Epoch:  190  Loss:  0.7297880931684141  Validation Loss:  1.1118056364357471\n",
      "Epoch:  191  Loss:  0.7298170110482848  Validation Loss:  1.1118748889615138\n",
      "Epoch:  192  Loss:  0.7298459617441959  Validation Loss:  1.1119441114366055\n",
      "Epoch:  193  Loss:  0.7298749058685275  Validation Loss:  1.1120133474469185\n",
      "Epoch:  194  Loss:  0.7299038491557154  Validation Loss:  1.1120825427273908\n",
      "Epoch:  195  Loss:  0.7299327885920412  Validation Loss:  1.1121518085400264\n",
      "Epoch:  196  Loss:  0.7299617482035348  Validation Loss:  1.112221027414004\n",
      "Epoch:  197  Loss:  0.7299907180700409  Validation Loss:  1.1122903322180113\n",
      "Epoch:  198  Loss:  0.7300197142228652  Validation Loss:  1.1123595604052146\n",
      "Epoch:  199  Loss:  0.7300487362434355  Validation Loss:  1.112428830564022\n",
      "Epoch:  200  Loss:  0.7300778263656611  Validation Loss:  1.1124982031683126\n",
      "Epoch:  201  Loss:  0.7301070139732924  Validation Loss:  1.1125676547487577\n",
      "Epoch:  202  Loss:  0.7301362310902456  Validation Loss:  1.112637040267388\n",
      "Epoch:  203  Loss:  0.7301655191132862  Validation Loss:  1.112706489985188\n",
      "Epoch:  204  Loss:  0.7301947926537374  Validation Loss:  1.1127759440491596\n",
      "Epoch:  205  Loss:  0.730224075067914  Validation Loss:  1.1128454183538754\n",
      "Epoch:  206  Loss:  0.7302533529196562  Validation Loss:  1.1129148811101914\n",
      "Epoch:  207  Loss:  0.7302825918023506  Validation Loss:  1.1129842404276133\n",
      "Epoch:  208  Loss:  0.7303118358334798  Validation Loss:  1.1130536828190087\n",
      "Epoch:  209  Loss:  0.7303410820411832  Validation Loss:  1.1131230590244134\n",
      "Epoch:  210  Loss:  0.7303703204215912  Validation Loss:  1.1131923854351045\n",
      "Epoch:  211  Loss:  0.730399550346846  Validation Loss:  1.1132617348184188\n",
      "Epoch:  212  Loss:  0.7304288047167022  Validation Loss:  1.1133310191333294\n",
      "Epoch:  213  Loss:  0.7304581314576476  Validation Loss:  1.1134003645430008\n",
      "Epoch:  214  Loss:  0.7304875009347883  Validation Loss:  1.1134697591265044\n",
      "Epoch:  215  Loss:  0.7305169177524159  Validation Loss:  1.113539066289862\n",
      "Epoch:  216  Loss:  0.7305462975264265  Validation Loss:  1.1136083621531725\n",
      "Epoch:  217  Loss:  0.730575690401739  Validation Loss:  1.1136775719622771\n",
      "Epoch:  218  Loss:  0.7306050649854574  Validation Loss:  1.113746888935566\n",
      "Epoch:  219  Loss:  0.73063445681434  Validation Loss:  1.1138161743680637\n",
      "Epoch:  220  Loss:  0.7306638483920794  Validation Loss:  1.1138854986677567\n",
      "Epoch:  221  Loss:  0.730693276636721  Validation Loss:  1.1139548289279142\n",
      "Epoch:  222  Loss:  0.7307227224195272  Validation Loss:  1.1140241336077452\n",
      "Epoch:  223  Loss:  0.7307521436321601  Validation Loss:  1.1140934477249782\n",
      "Epoch:  224  Loss:  0.730781509886297  Validation Loss:  1.1141627579927444\n",
      "Epoch:  225  Loss:  0.7308109092913316  Validation Loss:  1.1142319949964683\n",
      "Epoch:  226  Loss:  0.73084029417192  Validation Loss:  1.1143012903630733\n",
      "Epoch:  227  Loss:  0.7308696969673875  Validation Loss:  1.1143706060945988\n",
      "Epoch:  228  Loss:  0.7308991222820255  Validation Loss:  1.1144399029513201\n",
      "Epoch:  229  Loss:  0.7309285323606448  Validation Loss:  1.114509223898252\n",
      "Epoch:  230  Loss:  0.7309579012099277  Validation Loss:  1.1145783672730127\n",
      "Epoch:  231  Loss:  0.7309872775935056  Validation Loss:  1.114647592852513\n",
      "Epoch:  232  Loss:  0.7310167397424746  Validation Loss:  1.1147168391694626\n",
      "Epoch:  233  Loss:  0.7310462312751942  Validation Loss:  1.1147861974934736\n",
      "Epoch:  234  Loss:  0.7310757554565253  Validation Loss:  1.1148554074267547\n",
      "Epoch:  235  Loss:  0.7311052466543873  Validation Loss:  1.114924681186676\n",
      "Epoch:  236  Loss:  0.7311347473956896  Validation Loss:  1.1149939328432084\n",
      "Epoch:  237  Loss:  0.7311642864781819  Validation Loss:  1.1150632125635942\n",
      "Epoch:  238  Loss:  0.7311937914470609  Validation Loss:  1.1151324927806854\n",
      "Epoch:  239  Loss:  0.7312232479453087  Validation Loss:  1.1152016382664443\n",
      "Epoch:  240  Loss:  0.7312527128987099  Validation Loss:  1.1152708768844604\n",
      "Epoch:  241  Loss:  0.7312821795263987  Validation Loss:  1.1153400377680858\n",
      "Epoch:  242  Loss:  0.7313115789732906  Validation Loss:  1.1154091671109199\n",
      "Epoch:  243  Loss:  0.7313409832756171  Validation Loss:  1.115478333334128\n",
      "Epoch:  244  Loss:  0.7313703971213839  Validation Loss:  1.1155474498867988\n",
      "Epoch:  245  Loss:  0.7313997383867756  Validation Loss:  1.1156164783984424\n",
      "Epoch:  246  Loss:  0.7314290484685576  Validation Loss:  1.1156854906429847\n",
      "Epoch:  247  Loss:  0.7314583560807651  Validation Loss:  1.115754434838891\n",
      "Epoch:  248  Loss:  0.7314875953401743  Validation Loss:  1.1158233769237995\n",
      "Epoch:  249  Loss:  0.731516843557023  Validation Loss:  1.1158923029899597\n",
      "Epoch:  250  Loss:  0.7315460109894865  Validation Loss:  1.1159611317018667\n",
      "Epoch:  251  Loss:  0.7315751557772079  Validation Loss:  1.1160300362855196\n",
      "Epoch:  252  Loss:  0.7316042775853296  Validation Loss:  1.116098793844382\n",
      "Epoch:  253  Loss:  0.7316333183997803  Validation Loss:  1.1161674433698257\n",
      "Epoch:  254  Loss:  0.7316623588793734  Validation Loss:  1.1162360874315103\n",
      "Epoch:  255  Loss:  0.7316912973111265  Validation Loss:  1.11630470516781\n",
      "Epoch:  256  Loss:  0.731720161069645  Validation Loss:  1.1163732161124547\n",
      "Epoch:  257  Loss:  0.7317490225260177  Validation Loss:  1.116441703463594\n",
      "Epoch:  258  Loss:  0.731777775781543  Validation Loss:  1.1165100425481795\n",
      "Epoch:  259  Loss:  0.731806414390213  Validation Loss:  1.116578240071734\n",
      "Epoch:  260  Loss:  0.7318350268799937  Validation Loss:  1.11664643039306\n",
      "Epoch:  261  Loss:  0.7318636201991794  Validation Loss:  1.1167145612339178\n",
      "Epoch:  262  Loss:  0.7318921307666918  Validation Loss:  1.1167825421939293\n",
      "Epoch:  263  Loss:  0.7319205644425382  Validation Loss:  1.1168504379689694\n",
      "Epoch:  264  Loss:  0.7319489103019907  Validation Loss:  1.116918258741498\n",
      "Epoch:  265  Loss:  0.7319771285388577  Validation Loss:  1.116985924169421\n",
      "Epoch:  266  Loss:  0.7320052150929912  Validation Loss:  1.1170534388472637\n",
      "Epoch:  267  Loss:  0.7320331431339296  Validation Loss:  1.1171207146098217\n",
      "Epoch:  268  Loss:  0.7320608695069056  Validation Loss:  1.1171878141661484\n",
      "Epoch:  269  Loss:  0.7320883785991856  Validation Loss:  1.1172546654939652\n",
      "Epoch:  270  Loss:  0.7321156931392262  Validation Loss:  1.1173212371766568\n",
      "Epoch:  271  Loss:  0.7321427618519644  Validation Loss:  1.1173876110464334\n",
      "Epoch:  272  Loss:  0.7321695748591022  Validation Loss:  1.117453758791089\n",
      "Epoch:  273  Loss:  0.7321960962471668  Validation Loss:  1.1175195336341859\n",
      "Epoch:  274  Loss:  0.7322223583299122  Validation Loss:  1.117584986363848\n",
      "Epoch:  275  Loss:  0.7322482185417347  Validation Loss:  1.1176500017444293\n",
      "Epoch:  276  Loss:  0.7322737397939971  Validation Loss:  1.1177146602422\n",
      "Epoch:  277  Loss:  0.7322988604310523  Validation Loss:  1.1177789229899644\n",
      "Epoch:  278  Loss:  0.7323235645890236  Validation Loss:  1.1178427609304586\n",
      "Epoch:  279  Loss:  0.7323478803540884  Validation Loss:  1.117906109864513\n",
      "Epoch:  280  Loss:  0.7323717395827342  Validation Loss:  1.1179689757525921\n",
      "Epoch:  281  Loss:  0.7323951953080263  Validation Loss:  1.11803141074876\n",
      "Epoch:  282  Loss:  0.7324182238387927  Validation Loss:  1.1180933890243372\n",
      "Epoch:  283  Loss:  0.7324408528844962  Validation Loss:  1.118154930944244\n",
      "Epoch:  284  Loss:  0.7324631712242459  Validation Loss:  1.118216249719262\n",
      "Epoch:  285  Loss:  0.7324851902850559  Validation Loss:  1.1182771297792593\n",
      "Epoch:  286  Loss:  0.7325069329628114  Validation Loss:  1.1183378013471763\n",
      "Epoch:  287  Loss:  0.7325284725076027  Validation Loss:  1.118398241698742\n",
      "Epoch:  288  Loss:  0.7325498318571723  Validation Loss:  1.1184585029880205\n",
      "Epoch:  289  Loss:  0.7325710516967131  Validation Loss:  1.1185185694446167\n",
      "Epoch:  290  Loss:  0.7325921490621031  Validation Loss:  1.1185784128805\n",
      "Epoch:  291  Loss:  0.7326131694102556  Validation Loss:  1.1186382083843152\n",
      "Epoch:  292  Loss:  0.7326341204847513  Validation Loss:  1.1186978451907634\n",
      "Epoch:  293  Loss:  0.7326550160566073  Validation Loss:  1.1187574264903863\n",
      "Epoch:  294  Loss:  0.7326758834167143  Validation Loss:  1.1188169525315363\n",
      "Epoch:  295  Loss:  0.7326967281739364  Validation Loss:  1.1188764125108719\n",
      "Epoch:  296  Loss:  0.7327175697918689  Validation Loss:  1.1189359299838544\n",
      "Epoch:  297  Loss:  0.7327384460675582  Validation Loss:  1.1189953797807297\n",
      "Epoch:  298  Loss:  0.73275934394156  Validation Loss:  1.1190548566480478\n",
      "Epoch:  299  Loss:  0.7327802232728245  Validation Loss:  1.119114268446962\n",
      "Epoch:  300  Loss:  0.7328011406522789  Validation Loss:  1.1191737146427234\n",
      "Epoch:  301  Loss:  0.7328220777046145  Validation Loss:  1.1192332349717617\n",
      "Epoch:  302  Loss:  0.7328430569071448  Validation Loss:  1.119292693460981\n",
      "Epoch:  303  Loss:  0.732864075915867  Validation Loss:  1.1193522130449614\n",
      "Epoch:  304  Loss:  0.732885119411048  Validation Loss:  1.119411733125647\n",
      "Epoch:  305  Loss:  0.732906215269579  Validation Loss:  1.1194713203857343\n",
      "Epoch:  306  Loss:  0.732927314141828  Validation Loss:  1.1195308635632197\n",
      "Epoch:  307  Loss:  0.7329485076950507  Validation Loss:  1.1195904705673456\n",
      "Epoch:  308  Loss:  0.7329696751293842  Validation Loss:  1.1196500974396864\n",
      "Epoch:  309  Loss:  0.7329909027125059  Validation Loss:  1.1197098029156527\n",
      "Epoch:  310  Loss:  0.7330121517265111  Validation Loss:  1.119769425690174\n",
      "Epoch:  311  Loss:  0.7330334763346094  Validation Loss:  1.119829135760665\n",
      "Epoch:  312  Loss:  0.7330548885498154  Validation Loss:  1.1198888539026182\n",
      "Epoch:  313  Loss:  0.7330763266746247  Validation Loss:  1.1199486111601193\n",
      "Epoch:  314  Loss:  0.7330978122654925  Validation Loss:  1.1200084206958612\n",
      "Epoch:  315  Loss:  0.7331193392112684  Validation Loss:  1.1200682437668243\n",
      "Epoch:  316  Loss:  0.7331409042889483  Validation Loss:  1.1201279560724895\n",
      "Epoch:  317  Loss:  0.7331625138608258  Validation Loss:  1.1201877807577452\n",
      "Epoch:  318  Loss:  0.7331841500120216  Validation Loss:  1.1202476157496373\n",
      "Epoch:  319  Loss:  0.7332058247136936  Validation Loss:  1.1203074336051941\n",
      "Epoch:  320  Loss:  0.7332274929693575  Validation Loss:  1.1203672602772712\n",
      "Epoch:  321  Loss:  0.7332491749960385  Validation Loss:  1.1204270252337059\n",
      "Epoch:  322  Loss:  0.7332708345035489  Validation Loss:  1.1204867208997409\n",
      "Epoch:  323  Loss:  0.7332925289618165  Validation Loss:  1.1205465409904718\n",
      "Epoch:  324  Loss:  0.7333142661981369  Validation Loss:  1.1206062453488508\n",
      "Epoch:  325  Loss:  0.7333359756412801  Validation Loss:  1.1206659273554882\n",
      "Epoch:  326  Loss:  0.7333577055525914  Validation Loss:  1.1207256184269985\n",
      "Epoch:  327  Loss:  0.7333793766964017  Validation Loss:  1.120785244430105\n",
      "Epoch:  328  Loss:  0.7334010554163644  Validation Loss:  1.1208447797844807\n",
      "Epoch:  329  Loss:  0.7334227592506436  Validation Loss:  1.120904384429256\n",
      "Epoch:  330  Loss:  0.7334444601549192  Validation Loss:  1.120963845650355\n",
      "Epoch:  331  Loss:  0.7334661741604965  Validation Loss:  1.1210233241319656\n",
      "Epoch:  332  Loss:  0.733487840993016  Validation Loss:  1.1210827308396498\n",
      "Epoch:  333  Loss:  0.7335095032631012  Validation Loss:  1.1211420538524786\n",
      "Epoch:  334  Loss:  0.7335311140488373  Validation Loss:  1.121201255917549\n",
      "Epoch:  335  Loss:  0.7335526798799467  Validation Loss:  1.121260452394684\n",
      "Epoch:  336  Loss:  0.7335742831313878  Validation Loss:  1.1213195092976094\n",
      "Epoch:  337  Loss:  0.7335958144303119  Validation Loss:  1.1213784964134297\n",
      "Epoch:  338  Loss:  0.7336173582863942  Validation Loss:  1.1214374002069234\n",
      "Epoch:  339  Loss:  0.7336388563925631  Validation Loss:  1.1214962316056092\n",
      "Epoch:  340  Loss:  0.7336602979915195  Validation Loss:  1.1215549036860466\n",
      "Epoch:  341  Loss:  0.733681680781118  Validation Loss:  1.1216133415699006\n",
      "Epoch:  342  Loss:  0.7337029798563277  Validation Loss:  1.1216715890914202\n",
      "Epoch:  343  Loss:  0.7337241850039932  Validation Loss:  1.1217296914507946\n",
      "Epoch:  344  Loss:  0.7337453176131409  Validation Loss:  1.1217874803890784\n",
      "Epoch:  345  Loss:  0.7337663322268577  Validation Loss:  1.1218450990815958\n",
      "Epoch:  346  Loss:  0.7337872816270656  Validation Loss:  1.1219024535268545\n",
      "Epoch:  347  Loss:  0.733808118473278  Validation Loss:  1.1219595675667127\n",
      "Epoch:  348  Loss:  0.7338288679635256  Validation Loss:  1.1220163508007923\n",
      "Epoch:  349  Loss:  0.7338494560524319  Validation Loss:  1.1220728983481725\n",
      "Epoch:  350  Loss:  0.733869912333033  Validation Loss:  1.1221290503938992\n",
      "Epoch:  351  Loss:  0.7338902038637172  Validation Loss:  1.1221848621964454\n",
      "Epoch:  352  Loss:  0.7339103360440624  Validation Loss:  1.1222402026255927\n",
      "Epoch:  353  Loss:  0.7339302588128642  Validation Loss:  1.1222951176265876\n",
      "Epoch:  354  Loss:  0.7339499481859502  Validation Loss:  1.1223495602607727\n",
      "Epoch:  355  Loss:  0.7339694379839334  Validation Loss:  1.1224034730345012\n",
      "Epoch:  356  Loss:  0.733988658430871  Validation Loss:  1.12245684415102\n",
      "Epoch:  357  Loss:  0.7340076223350642  Validation Loss:  1.1225095950067043\n",
      "Epoch:  358  Loss:  0.7340263355146633  Validation Loss:  1.1225618723779918\n",
      "Epoch:  359  Loss:  0.7340448155496897  Validation Loss:  1.1226135307302079\n",
      "Epoch:  360  Loss:  0.7340630226758089  Validation Loss:  1.1226646926254034\n",
      "Epoch:  361  Loss:  0.7340810254551051  Validation Loss:  1.1227152726302545\n",
      "Epoch:  362  Loss:  0.7340987801886676  Validation Loss:  1.1227654031167427\n",
      "Epoch:  363  Loss:  0.7341162940759337  Validation Loss:  1.1228150483220816\n",
      "Epoch:  364  Loss:  0.7341336198569683  Validation Loss:  1.1228643659502269\n",
      "Epoch:  365  Loss:  0.7341507626802064  Validation Loss:  1.1229134000837804\n",
      "Epoch:  366  Loss:  0.7341677893915873  Validation Loss:  1.1229620651652417\n",
      "Epoch:  367  Loss:  0.7341846769277969  Validation Loss:  1.1230105734119813\n",
      "Epoch:  368  Loss:  0.7342014859399099  Validation Loss:  1.1230589665472508\n",
      "Epoch:  369  Loss:  0.73421822412965  Validation Loss:  1.1231071842213471\n",
      "Epoch:  370  Loss:  0.7342348896971579  Validation Loss:  1.1231553440292676\n",
      "Epoch:  371  Loss:  0.7342515300666348  Validation Loss:  1.1232034428666036\n",
      "Epoch:  372  Loss:  0.7342681413453617  Validation Loss:  1.1232514921575785\n",
      "Epoch:  373  Loss:  0.73428472365891  Validation Loss:  1.1232996087521314\n",
      "Epoch:  374  Loss:  0.7343012959267317  Validation Loss:  1.1233476729442675\n",
      "Epoch:  375  Loss:  0.7343178635484047  Validation Loss:  1.1233957103143135\n",
      "Epoch:  376  Loss:  0.7343344407135182  Validation Loss:  1.1234438170989354\n",
      "Epoch:  377  Loss:  0.7343510213946358  Validation Loss:  1.1234919709463915\n",
      "Epoch:  378  Loss:  0.7343676173954867  Validation Loss:  1.1235401716083289\n",
      "Epoch:  379  Loss:  0.7343842490586672  Validation Loss:  1.1235884290188551\n",
      "Epoch:  380  Loss:  0.7344008694204052  Validation Loss:  1.1236366254587968\n",
      "Epoch:  381  Loss:  0.7344174871451399  Validation Loss:  1.1236849124232928\n",
      "Epoch:  382  Loss:  0.7344340876247106  Validation Loss:  1.123733220497767\n",
      "Epoch:  383  Loss:  0.7344506640782517  Validation Loss:  1.1237814990182717\n",
      "Epoch:  384  Loss:  0.7344672247516305  Validation Loss:  1.1238297693431378\n",
      "Epoch:  385  Loss:  0.7344837781000003  Validation Loss:  1.1238780374328294\n",
      "Epoch:  386  Loss:  0.7345002633467149  Validation Loss:  1.1239263399193684\n",
      "Epoch:  387  Loss:  0.7345167270788316  Validation Loss:  1.1239745837946733\n",
      "Epoch:  388  Loss:  0.7345331505024701  Validation Loss:  1.1240228378524384\n",
      "Epoch:  389  Loss:  0.7345495274227657  Validation Loss:  1.1240710613628229\n",
      "Epoch:  390  Loss:  0.7345658340648319  Validation Loss:  1.1241192422807216\n",
      "Epoch:  391  Loss:  0.7345820852042584  Validation Loss:  1.1241673865665993\n",
      "Epoch:  392  Loss:  0.7345982566057296  Validation Loss:  1.1242154866456986\n",
      "Epoch:  393  Loss:  0.7346143384746621  Validation Loss:  1.1242634925991297\n",
      "Epoch:  394  Loss:  0.7346303422799271  Validation Loss:  1.1243114471435547\n",
      "Epoch:  395  Loss:  0.7346462049427327  Validation Loss:  1.124359280243516\n",
      "Epoch:  396  Loss:  0.7346619613301218  Validation Loss:  1.1244070341189702\n",
      "Epoch:  397  Loss:  0.7346775851557764  Validation Loss:  1.124454674621423\n",
      "Epoch:  398  Loss:  0.7346930351485027  Validation Loss:  1.1245020799338818\n",
      "Epoch:  399  Loss:  0.7347082937282793  Validation Loss:  1.1245493598282337\n",
      "Epoch:  400  Loss:  0.7347233514772372  Validation Loss:  1.1245963369806609\n",
      "Epoch:  401  Loss:  0.7347381736539053  Validation Loss:  1.124643121411403\n",
      "Epoch:  402  Loss:  0.7347527856237432  Validation Loss:  1.1246896707763274\n",
      "Epoch:  403  Loss:  0.7347671134250887  Validation Loss:  1.1247360090414682\n",
      "Epoch:  404  Loss:  0.7347811646340938  Validation Loss:  1.1247820619493722\n",
      "Epoch:  405  Loss:  0.7347949730295144  Validation Loss:  1.1248278910915057\n",
      "Epoch:  406  Loss:  0.7348084821878524  Validation Loss:  1.1248734397192797\n",
      "Epoch:  407  Loss:  0.7348216788403774  Validation Loss:  1.1249187596142292\n",
      "Epoch:  408  Loss:  0.7348345773441068  Validation Loss:  1.1249637924134732\n",
      "Epoch:  409  Loss:  0.7348471454690012  Validation Loss:  1.1250085023542244\n",
      "Epoch:  410  Loss:  0.7348594437405634  Validation Loss:  1.1250530076523622\n",
      "Epoch:  411  Loss:  0.7348714477560493  Validation Loss:  1.1250972277174394\n",
      "Epoch:  412  Loss:  0.7348831849319212  Validation Loss:  1.125141257668535\n",
      "Epoch:  413  Loss:  0.7348946906375081  Validation Loss:  1.1251850329339503\n",
      "Epoch:  414  Loss:  0.7349060224683097  Validation Loss:  1.1252287566661834\n",
      "Epoch:  415  Loss:  0.7349172091802184  Validation Loss:  1.1252723295241593\n",
      "Epoch:  416  Loss:  0.7349282846357046  Validation Loss:  1.1253157938520113\n",
      "Epoch:  417  Loss:  0.7349392662055036  Validation Loss:  1.1253592407951751\n",
      "Epoch:  418  Loss:  0.7349502508308781  Validation Loss:  1.1254026158402364\n",
      "Epoch:  419  Loss:  0.7349611854369051  Validation Loss:  1.1254460869977871\n",
      "Epoch:  420  Loss:  0.7349721327256621  Validation Loss:  1.1254894533505042\n",
      "Epoch:  421  Loss:  0.7349830624343974  Validation Loss:  1.1255328799287478\n",
      "Epoch:  422  Loss:  0.7349940419113368  Validation Loss:  1.1255763651182253\n",
      "Epoch:  423  Loss:  0.735005064836044  Validation Loss:  1.1256198909133672\n",
      "Epoch:  424  Loss:  0.7350161253485117  Validation Loss:  1.1256634953121345\n",
      "Epoch:  425  Loss:  0.735027229685462  Validation Loss:  1.1257071225593487\n",
      "Epoch:  426  Loss:  0.7350384098676483  Validation Loss:  1.1257507630934318\n",
      "Epoch:  427  Loss:  0.7350496973716811  Validation Loss:  1.1257945779711007\n",
      "Epoch:  428  Loss:  0.7350610510519381  Validation Loss:  1.125838407377402\n",
      "Epoch:  429  Loss:  0.7350724819587188  Validation Loss:  1.1258823138972123\n",
      "Epoch:  430  Loss:  0.7350839574434115  Validation Loss:  1.1259261218210062\n",
      "Epoch:  431  Loss:  0.7350954880121718  Validation Loss:  1.125970060750842\n",
      "Epoch:  432  Loss:  0.7351070424813902  Validation Loss:  1.1260139405727387\n",
      "Epoch:  433  Loss:  0.73511868853415  Validation Loss:  1.1260579266895852\n",
      "Epoch:  434  Loss:  0.735130384396971  Validation Loss:  1.1261019671956698\n",
      "Epoch:  435  Loss:  0.7351421710899037  Validation Loss:  1.1261460681756337\n",
      "Epoch:  436  Loss:  0.7351540450550867  Validation Loss:  1.1261903009066978\n",
      "Epoch:  437  Loss:  0.7351659701697613  Validation Loss:  1.1262345393498738\n",
      "Epoch:  438  Loss:  0.7351779660649513  Validation Loss:  1.1262788395086925\n",
      "Epoch:  439  Loss:  0.7351900064543392  Validation Loss:  1.126323198278745\n",
      "Epoch:  440  Loss:  0.7352020812084835  Validation Loss:  1.1263676277051369\n",
      "Epoch:  441  Loss:  0.7352142385887296  Validation Loss:  1.1264120964954296\n",
      "Epoch:  442  Loss:  0.7352264260642984  Validation Loss:  1.126456609616677\n",
      "Epoch:  443  Loss:  0.735238673814227  Validation Loss:  1.1265012465417386\n",
      "Epoch:  444  Loss:  0.7352509992929657  Validation Loss:  1.1265458750228088\n",
      "Epoch:  445  Loss:  0.7352633630291799  Validation Loss:  1.1265905645986398\n",
      "Epoch:  446  Loss:  0.7352758029036308  Validation Loss:  1.1266353306670984\n",
      "Epoch:  447  Loss:  0.7352882344903571  Validation Loss:  1.126680115237832\n",
      "Epoch:  448  Loss:  0.7353007559026226  Validation Loss:  1.126724942525228\n",
      "Epoch:  449  Loss:  0.7353132843050394  Validation Loss:  1.1267696976661683\n",
      "Epoch:  450  Loss:  0.7353258507137888  Validation Loss:  1.1268144721786182\n",
      "Epoch:  451  Loss:  0.7353384039793791  Validation Loss:  1.1268591554214558\n",
      "Epoch:  452  Loss:  0.7353510392850704  Validation Loss:  1.1269040418167908\n",
      "Epoch:  453  Loss:  0.7353636924637837  Validation Loss:  1.1269489442308744\n",
      "Epoch:  454  Loss:  0.7353764173857281  Validation Loss:  1.1269938201953968\n",
      "Epoch:  455  Loss:  0.7353892189481955  Validation Loss:  1.1270388328780732\n",
      "Epoch:  456  Loss:  0.735402066428005  Validation Loss:  1.1270839035511018\n",
      "Epoch:  457  Loss:  0.7354149664804507  Validation Loss:  1.127128996948401\n",
      "Epoch:  458  Loss:  0.7354279096458065  Validation Loss:  1.1271741459767024\n",
      "Epoch:  459  Loss:  0.7354409104903762  Validation Loss:  1.1272193297743798\n",
      "Epoch:  460  Loss:  0.7354539795203155  Validation Loss:  1.1272645769019922\n",
      "Epoch:  461  Loss:  0.7354670685161365  Validation Loss:  1.1273098822683096\n",
      "Epoch:  462  Loss:  0.7354802180374607  Validation Loss:  1.12735511859258\n",
      "Epoch:  463  Loss:  0.7354933799485143  Validation Loss:  1.1274003732949496\n",
      "Epoch:  464  Loss:  0.7355065144012484  Validation Loss:  1.1274456231544414\n",
      "Epoch:  465  Loss:  0.7355197417350967  Validation Loss:  1.1274909247954688\n",
      "Epoch:  466  Loss:  0.7355329748033808  Validation Loss:  1.1275361798703671\n",
      "Epoch:  467  Loss:  0.7355462534960067  Validation Loss:  1.1275815619776646\n",
      "Epoch:  468  Loss:  0.7355595774781168  Validation Loss:  1.1276269253343343\n",
      "Epoch:  469  Loss:  0.7355729433174214  Validation Loss:  1.127672363569339\n",
      "Epoch:  470  Loss:  0.7355863215883126  Validation Loss:  1.127717774361372\n",
      "Epoch:  471  Loss:  0.73559975824999  Validation Loss:  1.127763273815314\n",
      "Epoch:  472  Loss:  0.7356132052503945  Validation Loss:  1.1278086995085082\n",
      "Epoch:  473  Loss:  0.7356266617105248  Validation Loss:  1.1278540638585886\n",
      "Epoch:  474  Loss:  0.7356401237795193  Validation Loss:  1.1278994428614775\n",
      "Epoch:  475  Loss:  0.7356536000381025  Validation Loss:  1.1279448479413987\n",
      "Epoch:  476  Loss:  0.7356671278647492  Validation Loss:  1.1279902818302314\n",
      "Epoch:  477  Loss:  0.7356807093523191  Validation Loss:  1.1280357593049606\n",
      "Epoch:  478  Loss:  0.735694291049175  Validation Loss:  1.1280813040832678\n",
      "Epoch:  479  Loss:  0.7357079403035427  Validation Loss:  1.1281268703440825\n",
      "Epoch:  480  Loss:  0.735721628903673  Validation Loss:  1.1281724053124587\n",
      "Epoch:  481  Loss:  0.7357352858179071  Validation Loss:  1.1282178349792957\n",
      "Epoch:  482  Loss:  0.7357489574658737  Validation Loss:  1.1282632671296597\n",
      "Epoch:  483  Loss:  0.7357626739010382  Validation Loss:  1.128308782974879\n",
      "Epoch:  484  Loss:  0.7357764067023658  Validation Loss:  1.128354272370537\n",
      "Epoch:  485  Loss:  0.7357901870116089  Validation Loss:  1.1283998948832352\n",
      "Epoch:  486  Loss:  0.7358039924770259  Validation Loss:  1.1284452974796295\n",
      "Epoch:  487  Loss:  0.7358177604802539  Validation Loss:  1.128490687534213\n",
      "Epoch:  488  Loss:  0.7358315524676543  Validation Loss:  1.1285361248999835\n",
      "Epoch:  489  Loss:  0.735845386312249  Validation Loss:  1.1285815615206958\n",
      "Epoch:  490  Loss:  0.7358592461501614  Validation Loss:  1.1286270493020614\n",
      "Epoch:  491  Loss:  0.735873138092542  Validation Loss:  1.1286723942806323\n",
      "Epoch:  492  Loss:  0.7358869806434332  Validation Loss:  1.1287177167832851\n",
      "Epoch:  493  Loss:  0.7359008454623517  Validation Loss:  1.1287631048510471\n",
      "Epoch:  494  Loss:  0.7359147427205959  Validation Loss:  1.1288084773967664\n",
      "Epoch:  495  Loss:  0.7359286905423309  Validation Loss:  1.1288537412881852\n",
      "Epoch:  496  Loss:  0.7359425987253029  Validation Loss:  1.1288989788542192\n",
      "Epoch:  497  Loss:  0.7359565172051445  Validation Loss:  1.1289442726721366\n",
      "Epoch:  498  Loss:  0.7359704889273375  Validation Loss:  1.1289895964165528\n",
      "Epoch:  499  Loss:  0.7359844852615608  Validation Loss:  1.1290347473074993\n",
      "Epoch:  500  Loss:  0.7359984612531876  Validation Loss:  1.129079968854785\n",
      "Epoch:  501  Loss:  0.7360124607685576  Validation Loss:  1.1291250603894392\n",
      "Epoch:  502  Loss:  0.736026435797469  Validation Loss:  1.1291701065997282\n",
      "Epoch:  503  Loss:  0.7360404189885332  Validation Loss:  1.1292151754101118\n",
      "Epoch:  504  Loss:  0.7360544280054864  Validation Loss:  1.1292600635439158\n",
      "Epoch:  505  Loss:  0.73606838047337  Validation Loss:  1.1293049534161885\n",
      "Epoch:  506  Loss:  0.7360823961874742  Validation Loss:  1.1293497137725352\n",
      "Epoch:  507  Loss:  0.7360963394886322  Validation Loss:  1.1293944937487443\n",
      "Epoch:  508  Loss:  0.736110330548849  Validation Loss:  1.1294390550504128\n",
      "Epoch:  509  Loss:  0.7361242660645688  Validation Loss:  1.12948364627858\n",
      "Epoch:  510  Loss:  0.7361382146397334  Validation Loss:  1.1295280691236258\n",
      "Epoch:  511  Loss:  0.7361521530854568  Validation Loss:  1.1295724190771579\n",
      "Epoch:  512  Loss:  0.7361660598452842  Validation Loss:  1.1296166970084112\n",
      "Epoch:  513  Loss:  0.7361799541735248  Validation Loss:  1.1296607372661431\n",
      "Epoch:  514  Loss:  0.7361937955105573  Validation Loss:  1.1297047073642412\n",
      "Epoch:  515  Loss:  0.7362076089706984  Validation Loss:  1.1297484035293262\n",
      "Epoch:  516  Loss:  0.7362213970653797  Validation Loss:  1.1297921003152926\n",
      "Epoch:  517  Loss:  0.7362351678730397  Validation Loss:  1.129835562656323\n",
      "Epoch:  518  Loss:  0.7362488974932204  Validation Loss:  1.1298788494120042\n",
      "Epoch:  519  Loss:  0.7362625418921535  Validation Loss:  1.1299218049893776\n",
      "Epoch:  520  Loss:  0.7362761244680105  Validation Loss:  1.129964620868365\n",
      "Epoch:  521  Loss:  0.7362896535085158  Validation Loss:  1.1300071643044551\n",
      "Epoch:  522  Loss:  0.7363031278416682  Validation Loss:  1.1300494311998288\n",
      "Epoch:  523  Loss:  0.7363165114702803  Validation Loss:  1.1300914276391267\n",
      "Epoch:  524  Loss:  0.7363298043106379  Validation Loss:  1.1301331023375194\n",
      "Epoch:  525  Loss:  0.7363430115948902  Validation Loss:  1.1301742985844612\n",
      "Epoch:  526  Loss:  0.7363560680676712  Validation Loss:  1.1302151581893365\n",
      "Epoch:  527  Loss:  0.7363690403237771  Validation Loss:  1.1302555099129676\n",
      "Epoch:  528  Loss:  0.7363817838721731  Validation Loss:  1.1302953202277422\n",
      "Epoch:  529  Loss:  0.7363944189685784  Validation Loss:  1.13033460577329\n",
      "Epoch:  530  Loss:  0.7364068681353264  Validation Loss:  1.1303732437392076\n",
      "Epoch:  531  Loss:  0.7364190710143427  Validation Loss:  1.1304112325112026\n",
      "Epoch:  532  Loss:  0.7364310700069653  Validation Loss:  1.1304484993219375\n",
      "Epoch:  533  Loss:  0.7364428175634212  Validation Loss:  1.130484963580966\n",
      "Epoch:  534  Loss:  0.7364543255292968  Validation Loss:  1.130520576859514\n",
      "Epoch:  535  Loss:  0.7364655119482051  Validation Loss:  1.1305552733441193\n",
      "Epoch:  536  Loss:  0.7364764553861002  Validation Loss:  1.1305891384681066\n",
      "Epoch:  537  Loss:  0.7364870713751638  Validation Loss:  1.1306221016993125\n",
      "Epoch:  538  Loss:  0.7364973897595753  Validation Loss:  1.1306542033950489\n",
      "Epoch:  539  Loss:  0.7365074518942432  Validation Loss:  1.1306854028254747\n",
      "Epoch:  540  Loss:  0.7365172067133898  Validation Loss:  1.1307157962272565\n",
      "Epoch:  541  Loss:  0.7365267370524031  Validation Loss:  1.1307455187042554\n",
      "Epoch:  542  Loss:  0.7365360509060072  Validation Loss:  1.130774672453602\n",
      "Epoch:  543  Loss:  0.7365451790810971  Validation Loss:  1.1308032300323247\n",
      "Epoch:  544  Loss:  0.7365541412924113  Validation Loss:  1.130831420669953\n",
      "Epoch:  545  Loss:  0.736563025649344  Validation Loss:  1.1308593545109034\n",
      "Epoch:  546  Loss:  0.736571831691466  Validation Loss:  1.1308870306859413\n",
      "Epoch:  547  Loss:  0.7365805578700612  Validation Loss:  1.1309145390987396\n",
      "Epoch:  548  Loss:  0.7365892742122158  Validation Loss:  1.1309419240802527\n",
      "Epoch:  549  Loss:  0.7365979807179296  Validation Loss:  1.130969237908721\n",
      "Epoch:  550  Loss:  0.736606677680203  Validation Loss:  1.1309966257462898\n",
      "Epoch:  551  Loss:  0.7366153823023431  Validation Loss:  1.1310239442934593\n",
      "Epoch:  552  Loss:  0.736624127358533  Validation Loss:  1.1310513634234667\n",
      "Epoch:  553  Loss:  0.736632885348596  Validation Loss:  1.131078718478481\n",
      "Epoch:  554  Loss:  0.7366416993017277  Validation Loss:  1.1311062189439933\n",
      "Epoch:  555  Loss:  0.7366505689667852  Validation Loss:  1.1311338387429715\n",
      "Epoch:  556  Loss:  0.7366594483427117  Validation Loss:  1.1311615311851104\n",
      "Epoch:  557  Loss:  0.7366683545490998  Validation Loss:  1.1311892865846553\n",
      "Epoch:  558  Loss:  0.7366773827692096  Validation Loss:  1.1312172175695498\n",
      "Epoch:  559  Loss:  0.7366864318342021  Validation Loss:  1.1312451771150032\n",
      "Epoch:  560  Loss:  0.7366955200775286  Validation Loss:  1.1312733004490534\n",
      "Epoch:  561  Loss:  0.7367046726553628  Validation Loss:  1.1313014590491852\n",
      "Epoch:  562  Loss:  0.7367138868051298  Validation Loss:  1.1313297919929028\n",
      "Epoch:  563  Loss:  0.7367231491743849  Validation Loss:  1.1313581856588522\n",
      "Epoch:  564  Loss:  0.7367324540705493  Validation Loss:  1.1313866785417\n",
      "Epoch:  565  Loss:  0.7367418345189496  Validation Loss:  1.131415295228362\n",
      "Epoch:  566  Loss:  0.7367512525551105  Validation Loss:  1.1314439080655574\n",
      "Epoch:  567  Loss:  0.736760739864928  Validation Loss:  1.1314726843188205\n",
      "Epoch:  568  Loss:  0.7367702929323978  Validation Loss:  1.1315016316870847\n",
      "Epoch:  569  Loss:  0.7367799042650823  Validation Loss:  1.1315306525677442\n",
      "Epoch:  570  Loss:  0.7367895590873916  Validation Loss:  1.1315596457570791\n",
      "Epoch:  571  Loss:  0.7367992870760768  Validation Loss:  1.1315888506670793\n",
      "Epoch:  572  Loss:  0.7368090662561105  Validation Loss:  1.1316181048750877\n",
      "Epoch:  573  Loss:  0.7368188919813445  Validation Loss:  1.131647423406442\n",
      "Epoch:  574  Loss:  0.7368287657586376  Validation Loss:  1.1316768215348323\n",
      "Epoch:  575  Loss:  0.7368386925271387  Validation Loss:  1.131706305469076\n",
      "Epoch:  576  Loss:  0.7368486794444282  Validation Loss:  1.1317359767854214\n",
      "Epoch:  577  Loss:  0.7368587220317862  Validation Loss:  1.1317656487226486\n",
      "Epoch:  578  Loss:  0.7368688022069046  Validation Loss:  1.131795431797703\n",
      "Epoch:  579  Loss:  0.7368789117239164  Validation Loss:  1.1318251093228657\n",
      "Epoch:  580  Loss:  0.7368890568614006  Validation Loss:  1.1318549572179715\n",
      "Epoch:  581  Loss:  0.7368992784719789  Validation Loss:  1.1318849564840396\n",
      "Epoch:  582  Loss:  0.7369095414793223  Validation Loss:  1.1319149317840735\n",
      "Epoch:  583  Loss:  0.7369198171693957  Validation Loss:  1.1319450755914053\n",
      "Epoch:  584  Loss:  0.7369301428369591  Validation Loss:  1.1319750962158044\n",
      "Epoch:  585  Loss:  0.7369404941629828  Validation Loss:  1.132005212828517\n",
      "Epoch:  586  Loss:  0.7369508998615019  Validation Loss:  1.1320354452977577\n",
      "Epoch:  587  Loss:  0.7369613304231943  Validation Loss:  1.1320657973488173\n",
      "Epoch:  588  Loss:  0.7369718405554134  Validation Loss:  1.1320961855351925\n",
      "Epoch:  589  Loss:  0.7369823795272393  Validation Loss:  1.132126575584213\n",
      "Epoch:  590  Loss:  0.736992929423793  Validation Loss:  1.1321570239961147\n",
      "Epoch:  591  Loss:  0.737003506108951  Validation Loss:  1.1321875141312678\n",
      "Epoch:  592  Loss:  0.7370141335668858  Validation Loss:  1.1322180036455394\n",
      "Epoch:  593  Loss:  0.7370247786466995  Validation Loss:  1.1322484658410152\n",
      "Epoch:  594  Loss:  0.7370354708995712  Validation Loss:  1.1322792202234269\n",
      "Epoch:  595  Loss:  0.7370462107440728  Validation Loss:  1.1323100270082553\n",
      "Epoch:  596  Loss:  0.7370570266012395  Validation Loss:  1.1323408078402282\n",
      "Epoch:  597  Loss:  0.7370678437978364  Validation Loss:  1.1323716615637143\n",
      "Epoch:  598  Loss:  0.7370787000053385  Validation Loss:  1.1324024954189857\n",
      "Epoch:  599  Loss:  0.7370895809085851  Validation Loss:  1.1324333818008503\n",
      "Epoch:  600  Loss:  0.737100467253267  Validation Loss:  1.1324642955015103\n",
      "Epoch:  601  Loss:  0.7371113995152913  Validation Loss:  1.1324952298154434\n",
      "Epoch:  602  Loss:  0.7371223623749246  Validation Loss:  1.1325261806448301\n",
      "Epoch:  603  Loss:  0.7371333606876014  Validation Loss:  1.1325572305669387\n",
      "Epoch:  604  Loss:  0.7371444052943353  Validation Loss:  1.1325883929928144\n",
      "Epoch:  605  Loss:  0.7371555149890063  Validation Loss:  1.1326196510344744\n",
      "Epoch:  606  Loss:  0.7371666584205762  Validation Loss:  1.1326509188860654\n",
      "Epoch:  607  Loss:  0.7371778265060334  Validation Loss:  1.1326822359114885\n",
      "Epoch:  608  Loss:  0.7371890199150932  Validation Loss:  1.1327135406434536\n",
      "Epoch:  609  Loss:  0.73720019695799  Validation Loss:  1.1327448980261883\n",
      "Epoch:  610  Loss:  0.7372114342333895  Validation Loss:  1.1327762130647898\n",
      "Epoch:  611  Loss:  0.7372226725133617  Validation Loss:  1.132807590191563\n",
      "Epoch:  612  Loss:  0.7372339462463775  Validation Loss:  1.1328390202174583\n",
      "Epoch:  613  Loss:  0.7372452238302553  Validation Loss:  1.132870396474997\n",
      "Epoch:  614  Loss:  0.7372565345231736  Validation Loss:  1.1329018817593655\n",
      "Epoch:  615  Loss:  0.7372679028115915  Validation Loss:  1.1329333967218795\n",
      "Epoch:  616  Loss:  0.7372792703047227  Validation Loss:  1.1329650012155374\n",
      "Epoch:  617  Loss:  0.7372907154429494  Validation Loss:  1.1329967332382997\n",
      "Epoch:  618  Loss:  0.7373022132375268  Validation Loss:  1.1330285434921583\n",
      "Epoch:  619  Loss:  0.7373137755340404  Validation Loss:  1.1330603869011004\n",
      "Epoch:  620  Loss:  0.7373253273243985  Validation Loss:  1.1330922476947307\n",
      "Epoch:  621  Loss:  0.7373369175815181  Validation Loss:  1.133124124755462\n",
      "Epoch:  622  Loss:  0.737348549486546  Validation Loss:  1.1331560668845972\n",
      "Epoch:  623  Loss:  0.7373601882980111  Validation Loss:  1.133187941958507\n",
      "Epoch:  624  Loss:  0.7373718693433853  Validation Loss:  1.1332199674099683\n",
      "Epoch:  625  Loss:  0.7373835717777858  Validation Loss:  1.1332519249369701\n",
      "Epoch:  626  Loss:  0.737395258222738  Validation Loss:  1.1332836410651603\n",
      "Epoch:  627  Loss:  0.7374068472241417  Validation Loss:  1.133315241833528\n",
      "Epoch:  628  Loss:  0.7374184141668041  Validation Loss:  1.133346755678455\n",
      "Epoch:  629  Loss:  0.7374299401731303  Validation Loss:  1.1333782708893219\n",
      "Epoch:  630  Loss:  0.7374414611565933  Validation Loss:  1.133409839992722\n",
      "Epoch:  631  Loss:  0.7374530082170883  Validation Loss:  1.1334413660069307\n",
      "Epoch:  632  Loss:  0.7374645982230648  Validation Loss:  1.133472934489449\n",
      "Epoch:  633  Loss:  0.7374762266958028  Validation Loss:  1.1335045471787453\n",
      "Epoch:  634  Loss:  0.737487842276525  Validation Loss:  1.1335361876835426\n",
      "Epoch:  635  Loss:  0.7374995378882028  Validation Loss:  1.1335678861786922\n",
      "Epoch:  636  Loss:  0.7375112720922138  Validation Loss:  1.1335997264832258\n",
      "Epoch:  637  Loss:  0.7375230632638663  Validation Loss:  1.1336316434045632\n",
      "Epoch:  638  Loss:  0.7375348602536689  Validation Loss:  1.1336635923633973\n",
      "Epoch:  639  Loss:  0.7375467060908173  Validation Loss:  1.1336955377211173\n",
      "Epoch:  640  Loss:  0.7375585759958524  Validation Loss:  1.1337274911502997\n",
      "Epoch:  641  Loss:  0.737570441673311  Validation Loss:  1.133759485806028\n",
      "Epoch:  642  Loss:  0.7375823100714871  Validation Loss:  1.1337914675474168\n",
      "Epoch:  643  Loss:  0.7375942328421587  Validation Loss:  1.1338234602163235\n",
      "Epoch:  644  Loss:  0.7376061480785354  Validation Loss:  1.1338555071502925\n",
      "Epoch:  645  Loss:  0.7376180993958136  Validation Loss:  1.1338875734557707\n",
      "Epoch:  646  Loss:  0.7376300677071127  Validation Loss:  1.1339196551591157\n",
      "Epoch:  647  Loss:  0.737642050710287  Validation Loss:  1.1339517677823703\n",
      "Epoch:  648  Loss:  0.7376540879603852  Validation Loss:  1.1339839649697145\n",
      "Epoch:  649  Loss:  0.7376661235361957  Validation Loss:  1.1340160548686982\n",
      "Epoch:  650  Loss:  0.7376782197212235  Validation Loss:  1.1340482283383608\n",
      "Epoch:  651  Loss:  0.737690317538682  Validation Loss:  1.1340804686148962\n",
      "Epoch:  652  Loss:  0.7377024468746078  Validation Loss:  1.1341126718868813\n",
      "Epoch:  653  Loss:  0.7377146095288604  Validation Loss:  1.1341449584811927\n",
      "Epoch:  654  Loss:  0.7377268065478695  Validation Loss:  1.1341772258281708\n",
      "Epoch:  655  Loss:  0.7377390044458797  Validation Loss:  1.1342095346500476\n",
      "Epoch:  656  Loss:  0.7377512514423789  Validation Loss:  1.1342418771237135\n",
      "Epoch:  657  Loss:  0.7377635213766205  Validation Loss:  1.1342741706719002\n",
      "Epoch:  658  Loss:  0.7377758246291889  Validation Loss:  1.1343065595875184\n",
      "Epoch:  659  Loss:  0.7377881187987462  Validation Loss:  1.1343389578163623\n",
      "Epoch:  660  Loss:  0.7378004214234566  Validation Loss:  1.1343713800112407\n",
      "Epoch:  661  Loss:  0.7378127602964974  Validation Loss:  1.13440380692482\n",
      "Epoch:  662  Loss:  0.7378251154101296  Validation Loss:  1.13443618491292\n",
      "Epoch:  663  Loss:  0.7378374728677648  Validation Loss:  1.1344687305390835\n",
      "Epoch:  664  Loss:  0.737849890223045  Validation Loss:  1.134501277282834\n",
      "Epoch:  665  Loss:  0.737862340268794  Validation Loss:  1.1345339416215816\n",
      "Epoch:  666  Loss:  0.7378748392456034  Validation Loss:  1.1345666710287332\n",
      "Epoch:  667  Loss:  0.7378873798284638  Validation Loss:  1.134599461654822\n",
      "Epoch:  668  Loss:  0.7378999586269427  Validation Loss:  1.134632206087311\n",
      "Epoch:  669  Loss:  0.7379125493965791  Validation Loss:  1.1346650515993437\n",
      "Epoch:  670  Loss:  0.7379251672059632  Validation Loss:  1.1346978694200516\n",
      "Epoch:  671  Loss:  0.7379378210962488  Validation Loss:  1.1347307377805314\n",
      "Epoch:  672  Loss:  0.737950504412142  Validation Loss:  1.13476364997526\n",
      "Epoch:  673  Loss:  0.7379631924578983  Validation Loss:  1.1347965524842343\n",
      "Epoch:  674  Loss:  0.7379759008881082  Validation Loss:  1.1348294243216515\n",
      "Epoch:  675  Loss:  0.7379885981424471  Validation Loss:  1.1348623563845952\n",
      "Epoch:  676  Loss:  0.7380013183345285  Validation Loss:  1.1348953295499087\n",
      "Epoch:  677  Loss:  0.7380140741052252  Validation Loss:  1.1349283022185166\n",
      "Epoch:  678  Loss:  0.7380268537763799  Validation Loss:  1.134961240614454\n",
      "Epoch:  679  Loss:  0.7380396531622732  Validation Loss:  1.1349943121274313\n",
      "Epoch:  680  Loss:  0.7380524868292085  Validation Loss:  1.1350273157159487\n",
      "Epoch:  681  Loss:  0.7380653316301576  Validation Loss:  1.1350604069729646\n",
      "Epoch:  682  Loss:  0.7380782014198517  Validation Loss:  1.135093486805757\n",
      "Epoch:  683  Loss:  0.7380910998398669  Validation Loss:  1.1351265657693148\n",
      "Epoch:  684  Loss:  0.7381039945345916  Validation Loss:  1.1351596585164467\n",
      "Epoch:  685  Loss:  0.7381169149714909  Validation Loss:  1.135192767654856\n",
      "Epoch:  686  Loss:  0.738129820716515  Validation Loss:  1.135225953658422\n",
      "Epoch:  687  Loss:  0.7381427758948856  Validation Loss:  1.1352590898672739\n",
      "Epoch:  688  Loss:  0.7381557529645689  Validation Loss:  1.1352923184633255\n",
      "Epoch:  689  Loss:  0.7381687695893009  Validation Loss:  1.1353255233416955\n",
      "Epoch:  690  Loss:  0.7381817866326048  Validation Loss:  1.1353585607061782\n",
      "Epoch:  691  Loss:  0.738194728374816  Validation Loss:  1.135391404107213\n",
      "Epoch:  692  Loss:  0.7382075257934211  Validation Loss:  1.1354241561144591\n",
      "Epoch:  693  Loss:  0.7382202829454052  Validation Loss:  1.1354568373411893\n",
      "Epoch:  694  Loss:  0.7382330519429753  Validation Loss:  1.1354895412921906\n",
      "Epoch:  695  Loss:  0.738245856602875  Validation Loss:  1.1355223168929418\n",
      "Epoch:  696  Loss:  0.7382587009852521  Validation Loss:  1.1355550392220417\n",
      "Epoch:  697  Loss:  0.7382715680542287  Validation Loss:  1.135587757329146\n",
      "Epoch:  698  Loss:  0.7382844372579221  Validation Loss:  1.135620574777325\n",
      "Epoch:  699  Loss:  0.738297325506639  Validation Loss:  1.1356533779452245\n",
      "Epoch:  700  Loss:  0.7383102466551106  Validation Loss:  1.1356861885637044\n",
      "Epoch:  701  Loss:  0.73832319856862  Validation Loss:  1.1357190544406572\n",
      "Epoch:  702  Loss:  0.738336147552126  Validation Loss:  1.135751868163546\n",
      "Epoch:  703  Loss:  0.7383490898803379  Validation Loss:  1.135784752294421\n",
      "Epoch:  704  Loss:  0.7383620636014456  Validation Loss:  1.135817655051748\n",
      "Epoch:  705  Loss:  0.738375066538875  Validation Loss:  1.135850557933251\n",
      "Epoch:  706  Loss:  0.7383880740805958  Validation Loss:  1.1358834328750769\n",
      "Epoch:  707  Loss:  0.738401097862908  Validation Loss:  1.1359164260327816\n",
      "Epoch:  708  Loss:  0.7384141380113832  Validation Loss:  1.1359493109087149\n",
      "Epoch:  709  Loss:  0.7384271789551451  Validation Loss:  1.1359822994718949\n",
      "Epoch:  710  Loss:  0.7384402423762204  Validation Loss:  1.1360152559975782\n",
      "Epoch:  711  Loss:  0.7384533194845981  Validation Loss:  1.136048219104608\n",
      "Epoch:  712  Loss:  0.7384664078525612  Validation Loss:  1.1360812731087209\n",
      "Epoch:  713  Loss:  0.7384795157259769  Validation Loss:  1.1361142770697674\n",
      "Epoch:  714  Loss:  0.7384926215902473  Validation Loss:  1.1361473759015401\n",
      "Epoch:  715  Loss:  0.7385057652515642  Validation Loss:  1.1361804552376271\n",
      "Epoch:  716  Loss:  0.7385189017134436  Validation Loss:  1.136213734994332\n",
      "Epoch:  717  Loss:  0.7385320969846811  Validation Loss:  1.136246960858504\n",
      "Epoch:  718  Loss:  0.7385452513195826  Validation Loss:  1.136279933154583\n",
      "Epoch:  719  Loss:  0.738558249108577  Validation Loss:  1.1363127994040647\n",
      "Epoch:  720  Loss:  0.7385711659039005  Validation Loss:  1.1363454215228557\n",
      "Epoch:  721  Loss:  0.7385840111652787  Validation Loss:  1.1363781823466221\n",
      "Epoch:  722  Loss:  0.7385968626215217  Validation Loss:  1.1364108936240276\n",
      "Epoch:  723  Loss:  0.7386096682441369  Validation Loss:  1.1364435507605473\n",
      "Epoch:  724  Loss:  0.7386224376184217  Validation Loss:  1.1364761515210071\n",
      "Epoch:  725  Loss:  0.7386351624566517  Validation Loss:  1.1365088020761809\n",
      "Epoch:  726  Loss:  0.7386478517581238  Validation Loss:  1.136541405444344\n",
      "Epoch:  727  Loss:  0.7386605201309986  Validation Loss:  1.1365739980091651\n",
      "Epoch:  728  Loss:  0.738673131326946  Validation Loss:  1.1366065453737975\n",
      "Epoch:  729  Loss:  0.7386856907455439  Validation Loss:  1.1366390705108642\n",
      "Epoch:  730  Loss:  0.7386982104416644  Validation Loss:  1.136671523998181\n",
      "Epoch:  731  Loss:  0.7387106259970853  Validation Loss:  1.1367039546370505\n",
      "Epoch:  732  Loss:  0.7387229277427947  Validation Loss:  1.1367363229393959\n",
      "Epoch:  733  Loss:  0.7387351628518506  Validation Loss:  1.1367685707906883\n",
      "Epoch:  734  Loss:  0.7387472244209787  Validation Loss:  1.1368002848078806\n",
      "Epoch:  735  Loss:  0.7387590004821841  Validation Loss:  1.136831923077504\n",
      "Epoch:  736  Loss:  0.7387706742862638  Validation Loss:  1.1368634118388097\n",
      "Epoch:  737  Loss:  0.7387822904948438  Validation Loss:  1.136894916370511\n",
      "Epoch:  738  Loss:  0.7387937733045454  Validation Loss:  1.136926301692923\n",
      "Epoch:  739  Loss:  0.7388051477041138  Validation Loss:  1.1369576630493006\n",
      "Epoch:  740  Loss:  0.7388164223579878  Validation Loss:  1.136988872786363\n",
      "Epoch:  741  Loss:  0.7388275265275093  Validation Loss:  1.1370200051615635\n",
      "Epoch:  742  Loss:  0.7388384741092666  Validation Loss:  1.137051002929608\n",
      "Epoch:  743  Loss:  0.738849239947086  Validation Loss:  1.1370817435284455\n",
      "Epoch:  744  Loss:  0.7388597172214074  Validation Loss:  1.1371119561294714\n",
      "Epoch:  745  Loss:  0.738869807525967  Validation Loss:  1.1371419628461201\n",
      "Epoch:  746  Loss:  0.738879679796401  Validation Loss:  1.137171859666705\n",
      "Epoch:  747  Loss:  0.7388893503151582  Validation Loss:  1.1372015656282504\n",
      "Epoch:  748  Loss:  0.738898781034049  Validation Loss:  1.1372310888022183\n",
      "Epoch:  749  Loss:  0.7389079696090703  Validation Loss:  1.1372604231039682\n",
      "Epoch:  750  Loss:  0.7389169584415601  Validation Loss:  1.1372894537945588\n",
      "Epoch:  751  Loss:  0.7389255439799823  Validation Loss:  1.1373179374883573\n",
      "Epoch:  752  Loss:  0.7389338500379177  Validation Loss:  1.1373462926596403\n",
      "Epoch:  753  Loss:  0.7389419968292285  Validation Loss:  1.1373745414117973\n",
      "Epoch:  754  Loss:  0.7389500437074163  Validation Loss:  1.1374028082937002\n",
      "Epoch:  755  Loss:  0.738957956391439  Validation Loss:  1.1374306867520014\n",
      "Epoch:  756  Loss:  0.7389656883360964  Validation Loss:  1.137458236142993\n",
      "Epoch:  757  Loss:  0.7389731879314679  Validation Loss:  1.1374856961270174\n",
      "Epoch:  758  Loss:  0.7389806450417872  Validation Loss:  1.1375131362428268\n",
      "Epoch:  759  Loss:  0.7389881041193946  Validation Loss:  1.137540427967906\n",
      "Epoch:  760  Loss:  0.7389954100415278  Validation Loss:  1.137567344183723\n",
      "Epoch:  761  Loss:  0.7390025624314721  Validation Loss:  1.137594220538934\n",
      "Epoch:  762  Loss:  0.7390097744260611  Validation Loss:  1.1376210678368808\n",
      "Epoch:  763  Loss:  0.7390169265648622  Validation Loss:  1.137647492190202\n",
      "Epoch:  764  Loss:  0.739023892983292  Validation Loss:  1.1376739067335924\n",
      "Epoch:  765  Loss:  0.7390308681080181  Validation Loss:  1.137699934343497\n",
      "Epoch:  766  Loss:  0.7390376514430796  Validation Loss:  1.1377257641404868\n",
      "Epoch:  767  Loss:  0.739044419667694  Validation Loss:  1.1377514154960713\n",
      "Epoch:  768  Loss:  0.7390510485078512  Validation Loss:  1.137776768580079\n",
      "Epoch:  769  Loss:  0.7390576077813513  Validation Loss:  1.1378018399079641\n",
      "Epoch:  770  Loss:  0.7390639878223452  Validation Loss:  1.1378266964107753\n",
      "Epoch:  771  Loss:  0.7390703394841612  Validation Loss:  1.1378511148194472\n",
      "Epoch:  772  Loss:  0.7390764365705211  Validation Loss:  1.1378752128531535\n",
      "Epoch:  773  Loss:  0.7390823938538519  Validation Loss:  1.1378989593436322\n",
      "Epoch:  774  Loss:  0.7390882397133313  Validation Loss:  1.1379222461332879\n",
      "Epoch:  775  Loss:  0.7390938194029117  Validation Loss:  1.1379450640330713\n",
      "Epoch:  776  Loss:  0.7390991579531954  Validation Loss:  1.1379672297586998\n",
      "Epoch:  777  Loss:  0.7391042544433241  Validation Loss:  1.1379888363182544\n",
      "Epoch:  778  Loss:  0.7391090578493777  Validation Loss:  1.1380097368111213\n",
      "Epoch:  779  Loss:  0.7391134566219335  Validation Loss:  1.1380299095064401\n",
      "Epoch:  780  Loss:  0.7391175133793542  Validation Loss:  1.1380493073413769\n",
      "Epoch:  781  Loss:  0.7391212127181921  Validation Loss:  1.138067817563812\n",
      "Epoch:  782  Loss:  0.7391244355128722  Validation Loss:  1.1380852529158194\n",
      "Epoch:  783  Loss:  0.7391271541376462  Validation Loss:  1.1381017075230677\n",
      "Epoch:  784  Loss:  0.739129357374786  Validation Loss:  1.1381170502553384\n",
      "Epoch:  785  Loss:  0.739130994284086  Validation Loss:  1.138131274903814\n",
      "Epoch:  786  Loss:  0.7391320576661089  Validation Loss:  1.138144246240457\n",
      "Epoch:  787  Loss:  0.7391325178441037  Validation Loss:  1.1381559891005357\n",
      "Epoch:  788  Loss:  0.7391323723903532  Validation Loss:  1.138166577493151\n",
      "Epoch:  789  Loss:  0.7391316373780202  Validation Loss:  1.1381759965171416\n",
      "Epoch:  790  Loss:  0.7391303514831522  Validation Loss:  1.138184271256129\n",
      "Epoch:  791  Loss:  0.7391284990930156  Validation Loss:  1.1381917485346398\n",
      "Epoch:  792  Loss:  0.7391262735878483  Validation Loss:  1.1381981570273638\n",
      "Epoch:  793  Loss:  0.7391235750963848  Validation Loss:  1.1382039515922466\n",
      "Epoch:  794  Loss:  0.739120543589083  Validation Loss:  1.1382091144720714\n",
      "Epoch:  795  Loss:  0.7391172535717487  Validation Loss:  1.1382137733201185\n",
      "Epoch:  796  Loss:  0.739113759500592  Validation Loss:  1.1382183058808246\n",
      "Epoch:  797  Loss:  0.739110265387578  Validation Loss:  1.138223034515977\n",
      "Epoch:  798  Loss:  0.7391067392538103  Validation Loss:  1.138227746884028\n",
      "Epoch:  799  Loss:  0.7391032889652788  Validation Loss:  1.1382323391735554\n",
      "Epoch:  800  Loss:  0.7390997936384062  Validation Loss:  1.138236756871144\n",
      "Epoch:  801  Loss:  0.7390962135088578  Validation Loss:  1.138241171836853\n",
      "Epoch:  802  Loss:  0.7390926648140623  Validation Loss:  1.1382457046459118\n",
      "Epoch:  803  Loss:  0.7390891716637639  Validation Loss:  1.1382503184179464\n",
      "Epoch:  804  Loss:  0.7390857811054486  Validation Loss:  1.138255179549257\n",
      "Epoch:  805  Loss:  0.7390825136909994  Validation Loss:  1.1382600990434488\n",
      "Epoch:  806  Loss:  0.7390792998537589  Validation Loss:  1.1382650837302208\n",
      "Epoch:  807  Loss:  0.7390761226834206  Validation Loss:  1.1382700679202875\n",
      "Epoch:  808  Loss:  0.7390729498662306  Validation Loss:  1.1382750685016314\n",
      "Epoch:  809  Loss:  0.7390698504247023  Validation Loss:  1.138280172770222\n",
      "Epoch:  810  Loss:  0.7390668691878908  Validation Loss:  1.1382857542484999\n",
      "Epoch:  811  Loss:  0.7390640863123235  Validation Loss:  1.1382913968215387\n",
      "Epoch:  812  Loss:  0.739061364338974  Validation Loss:  1.1382971198608478\n",
      "Epoch:  813  Loss:  0.7390586784046688  Validation Loss:  1.138302852710088\n",
      "Epoch:  814  Loss:  0.7390560411502806  Validation Loss:  1.138308694958687\n",
      "Epoch:  815  Loss:  0.7390534370049332  Validation Loss:  1.1383145365864038\n",
      "Epoch:  816  Loss:  0.739050987312633  Validation Loss:  1.1383208613842726\n",
      "Epoch:  817  Loss:  0.73904868282294  Validation Loss:  1.1383273368080458\n",
      "Epoch:  818  Loss:  0.7390464994261104  Validation Loss:  1.1383337896317243\n",
      "Epoch:  819  Loss:  0.7390443279585811  Validation Loss:  1.1383403270194927\n",
      "Epoch:  820  Loss:  0.7390421855399448  Validation Loss:  1.1383469142019749\n",
      "Epoch:  821  Loss:  0.7390400689471973  Validation Loss:  1.1383534528315067\n",
      "Epoch:  822  Loss:  0.7390379746224773  Validation Loss:  1.1383600925405821\n",
      "Epoch:  823  Loss:  0.7390359723417277  Validation Loss:  1.1383668648699918\n",
      "Epoch:  824  Loss:  0.7390341226304515  Validation Loss:  1.1383741337805986\n",
      "Epoch:  825  Loss:  0.7390324425663841  Validation Loss:  1.1383814334869384\n",
      "Epoch:  826  Loss:  0.7390307987925042  Validation Loss:  1.1383887744198242\n",
      "Epoch:  827  Loss:  0.739029194155101  Validation Loss:  1.1383961447825035\n",
      "Epoch:  828  Loss:  0.7390276418391908  Validation Loss:  1.1384035213539998\n",
      "Epoch:  829  Loss:  0.7390261067684447  Validation Loss:  1.1384109127024808\n",
      "Epoch:  830  Loss:  0.7390246135130357  Validation Loss:  1.1384183367093403\n",
      "Epoch:  831  Loss:  0.7390231372516477  Validation Loss:  1.1384258862584828\n",
      "Epoch:  832  Loss:  0.7390217016335954  Validation Loss:  1.138433457290133\n",
      "Epoch:  833  Loss:  0.7390203478463581  Validation Loss:  1.1384412616491317\n",
      "Epoch:  834  Loss:  0.7390191277509994  Validation Loss:  1.138449494043986\n",
      "Epoch:  835  Loss:  0.7390180843348584  Validation Loss:  1.13845780454576\n",
      "Epoch:  836  Loss:  0.7390170517597305  Validation Loss:  1.138466098283728\n",
      "Epoch:  837  Loss:  0.7390160987969865  Validation Loss:  1.1384745072573423\n",
      "Epoch:  838  Loss:  0.739015170111415  Validation Loss:  1.138482987259825\n",
      "Epoch:  839  Loss:  0.7390142513459987  Validation Loss:  1.1384915278603633\n",
      "Epoch:  840  Loss:  0.739013393859515  Validation Loss:  1.1384999303768077\n",
      "Epoch:  841  Loss:  0.7390125392193205  Validation Loss:  1.1385085425029198\n",
      "Epoch:  842  Loss:  0.7390117119955882  Validation Loss:  1.1385171240816514\n",
      "Epoch:  843  Loss:  0.7390109395629234  Validation Loss:  1.1385257462660472\n",
      "Epoch:  844  Loss:  0.7390101913655742  Validation Loss:  1.1385343705614408\n",
      "Epoch:  845  Loss:  0.739009471840403  Validation Loss:  1.1385429833084344\n",
      "Epoch:  846  Loss:  0.7390087588868114  Validation Loss:  1.1385516243676344\n",
      "Epoch:  847  Loss:  0.7390080887949868  Validation Loss:  1.1385604001581668\n",
      "Epoch:  848  Loss:  0.7390074623183588  Validation Loss:  1.1385692071169615\n",
      "Epoch:  849  Loss:  0.7390069863183445  Validation Loss:  1.1385785218328237\n",
      "Epoch:  850  Loss:  0.7390066572789395  Validation Loss:  1.1385879198710123\n",
      "Epoch:  851  Loss:  0.7390064274829425  Validation Loss:  1.1385973189026117\n",
      "Epoch:  852  Loss:  0.739006180567353  Validation Loss:  1.1386067509651183\n",
      "Epoch:  853  Loss:  0.7390060032602777  Validation Loss:  1.138616164152821\n",
      "Epoch:  854  Loss:  0.7390058140239019  Validation Loss:  1.1386256661266088\n",
      "Epoch:  855  Loss:  0.739005676439304  Validation Loss:  1.138635149349769\n",
      "Epoch:  856  Loss:  0.739005560997162  Validation Loss:  1.1386447064578533\n",
      "Epoch:  857  Loss:  0.7390054675719041  Validation Loss:  1.13865424990654\n",
      "Epoch:  858  Loss:  0.7390054226591346  Validation Loss:  1.1386638389279444\n",
      "Epoch:  859  Loss:  0.7390053769929356  Validation Loss:  1.1386734079569578\n",
      "Epoch:  860  Loss:  0.7390053892989507  Validation Loss:  1.1386830974370241\n",
      "Epoch:  861  Loss:  0.7390053922708115  Validation Loss:  1.1386927607158819\n",
      "Epoch:  862  Loss:  0.7390054658557592  Validation Loss:  1.138702446098129\n",
      "Epoch:  863  Loss:  0.7390055366362749  Validation Loss:  1.1387121482441822\n",
      "Epoch:  864  Loss:  0.7390056469718392  Validation Loss:  1.1387218977014224\n",
      "Epoch:  865  Loss:  0.7390057258307934  Validation Loss:  1.1387316501388947\n",
      "Epoch:  866  Loss:  0.739005791002445  Validation Loss:  1.1387414004653693\n",
      "Epoch:  867  Loss:  0.7390059180808871  Validation Loss:  1.1387511254598697\n",
      "Epoch:  868  Loss:  0.7390060231424449  Validation Loss:  1.1387609117974837\n",
      "Epoch:  869  Loss:  0.7390061673404795  Validation Loss:  1.1387706914295752\n",
      "Epoch:  870  Loss:  0.7390062441484312  Validation Loss:  1.1387804401417574\n",
      "Epoch:  871  Loss:  0.7390063244305299  Validation Loss:  1.1387902073562146\n",
      "Epoch:  872  Loss:  0.7390063921136133  Validation Loss:  1.1388000153005122\n",
      "Epoch:  873  Loss:  0.739006487255016  Validation Loss:  1.1388098187744617\n",
      "Epoch:  874  Loss:  0.7390066358899132  Validation Loss:  1.1388197490324576\n",
      "Epoch:  875  Loss:  0.7390068641790514  Validation Loss:  1.1388298088063797\n",
      "Epoch:  876  Loss:  0.7390072005853224  Validation Loss:  1.1388401857266823\n",
      "Epoch:  877  Loss:  0.7390077170193865  Validation Loss:  1.1388507654269537\n",
      "Epoch:  878  Loss:  0.7390082554284776  Validation Loss:  1.1388612629224857\n",
      "Epoch:  879  Loss:  0.7390088729058089  Validation Loss:  1.1388718362897634\n",
      "Epoch:  880  Loss:  0.7390094744774063  Validation Loss:  1.1388824171076217\n",
      "Epoch:  881  Loss:  0.7390100846715858  Validation Loss:  1.1388930751631656\n",
      "Epoch:  882  Loss:  0.739010776445437  Validation Loss:  1.138903721794486\n",
      "Epoch:  883  Loss:  0.7390114652055703  Validation Loss:  1.138914371530215\n",
      "Epoch:  884  Loss:  0.7390122074173407  Validation Loss:  1.138925050571561\n",
      "Epoch:  885  Loss:  0.7390129432668177  Validation Loss:  1.1389357979098955\n",
      "Epoch:  886  Loss:  0.7390137145274811  Validation Loss:  1.1389465596526862\n",
      "Epoch:  887  Loss:  0.7390145298637701  Validation Loss:  1.1389573119580745\n",
      "Epoch:  888  Loss:  0.7390153471254901  Validation Loss:  1.1389680994053681\n",
      "Epoch:  889  Loss:  0.7390162152437012  Validation Loss:  1.1389789386341969\n",
      "Epoch:  890  Loss:  0.739017127437538  Validation Loss:  1.1389897930125394\n",
      "Epoch:  891  Loss:  0.7390180350689406  Validation Loss:  1.1390006940811872\n",
      "Epoch:  892  Loss:  0.7390189830088214  Validation Loss:  1.1390115588903427\n",
      "Epoch:  893  Loss:  0.7390199522540141  Validation Loss:  1.139022546261549\n",
      "Epoch:  894  Loss:  0.7390209620588282  Validation Loss:  1.1390334965040287\n",
      "Epoch:  895  Loss:  0.7390219761749331  Validation Loss:  1.139044484620293\n",
      "Epoch:  896  Loss:  0.7390230566765486  Validation Loss:  1.1390554605672756\n",
      "Epoch:  897  Loss:  0.7390241275091519  Validation Loss:  1.1390664928903182\n",
      "Epoch:  898  Loss:  0.7390252397385206  Validation Loss:  1.1390775885432958\n",
      "Epoch:  899  Loss:  0.7390263743614882  Validation Loss:  1.1390886675566434\n",
      "Epoch:  900  Loss:  0.7390275549855125  Validation Loss:  1.139099768549204\n",
      "Epoch:  901  Loss:  0.7390287601378527  Validation Loss:  1.1391109249244133\n",
      "Epoch:  902  Loss:  0.7390299814052126  Validation Loss:  1.1391220645358164\n",
      "Epoch:  903  Loss:  0.7390312397161897  Validation Loss:  1.139133253817757\n",
      "Epoch:  904  Loss:  0.7390325122586127  Validation Loss:  1.139144558707873\n",
      "Epoch:  905  Loss:  0.7390338328530949  Validation Loss:  1.1391557734459639\n",
      "Epoch:  906  Loss:  0.7390351682231667  Validation Loss:  1.1391670708854993\n",
      "Epoch:  907  Loss:  0.7390365261542663  Validation Loss:  1.139178340509534\n",
      "Epoch:  908  Loss:  0.7390379253147024  Validation Loss:  1.1391896919657787\n",
      "Epoch:  909  Loss:  0.7390393540681748  Validation Loss:  1.1392010529836019\n",
      "Epoch:  910  Loss:  0.7390408013643843  Validation Loss:  1.1392124281575282\n",
      "Epoch:  911  Loss:  0.7390422796767749  Validation Loss:  1.1392237806071839\n",
      "Epoch:  912  Loss:  0.739043786326486  Validation Loss:  1.1392352463056643\n",
      "Epoch:  913  Loss:  0.7390453445861179  Validation Loss:  1.1392466753721238\n",
      "Epoch:  914  Loss:  0.7390468948091684  Validation Loss:  1.139258184035619\n",
      "Epoch:  915  Loss:  0.7390485042601489  Validation Loss:  1.1392697056134542\n",
      "Epoch:  916  Loss:  0.7390501483270292  Validation Loss:  1.1392812442034483\n",
      "Epoch:  917  Loss:  0.739051795323913  Validation Loss:  1.139292828241984\n",
      "Epoch:  918  Loss:  0.7390535142314568  Validation Loss:  1.1393044491608937\n",
      "Epoch:  919  Loss:  0.7390552344784308  Validation Loss:  1.1393161005030075\n",
      "Epoch:  920  Loss:  0.7390570080514705  Validation Loss:  1.1393277717133363\n",
      "Epoch:  921  Loss:  0.7390588090828295  Validation Loss:  1.1393394865095616\n",
      "Epoch:  922  Loss:  0.7390606542316716  Validation Loss:  1.139351170261701\n",
      "Epoch:  923  Loss:  0.7390625004269434  Validation Loss:  1.1393629372119904\n",
      "Epoch:  924  Loss:  0.7390643948835603  Validation Loss:  1.1393747489899397\n",
      "Epoch:  925  Loss:  0.7390662566078513  Validation Loss:  1.1393864682565134\n",
      "Epoch:  926  Loss:  0.7390680873578184  Validation Loss:  1.139398237566153\n",
      "Epoch:  927  Loss:  0.7390699493332525  Validation Loss:  1.1394100281099477\n",
      "Epoch:  928  Loss:  0.7390717910079474  Validation Loss:  1.1394218279669681\n",
      "Epoch:  929  Loss:  0.7390735481729668  Validation Loss:  1.1394335651149352\n",
      "Epoch:  930  Loss:  0.7390753314568755  Validation Loss:  1.139445294563969\n",
      "Epoch:  931  Loss:  0.7390771293489451  Validation Loss:  1.139457105100155\n",
      "Epoch:  932  Loss:  0.7390789369100266  Validation Loss:  1.1394688855856656\n",
      "Epoch:  933  Loss:  0.739080803489752  Validation Loss:  1.1394807538638512\n",
      "Epoch:  934  Loss:  0.7390826968162247  Validation Loss:  1.1394926937917869\n",
      "Epoch:  935  Loss:  0.7390846518820591  Validation Loss:  1.13950476522247\n",
      "Epoch:  936  Loss:  0.739086686309134  Validation Loss:  1.1395169474184512\n",
      "Epoch:  937  Loss:  0.7390888352993499  Validation Loss:  1.1395293104151885\n",
      "Epoch:  938  Loss:  0.739091079933255  Validation Loss:  1.1395419333130121\n",
      "Epoch:  939  Loss:  0.7390934107511231  Validation Loss:  1.1395545793076356\n",
      "Epoch:  940  Loss:  0.7390957801613245  Validation Loss:  1.1395672086626292\n",
      "Epoch:  941  Loss:  0.739098187494144  Validation Loss:  1.1395799018442632\n",
      "Epoch:  942  Loss:  0.7391006271407176  Validation Loss:  1.1395926178743443\n",
      "Epoch:  943  Loss:  0.7391030822325958  Validation Loss:  1.1396054061750571\n",
      "Epoch:  944  Loss:  0.7391055690940846  Validation Loss:  1.139618150765697\n",
      "Epoch:  945  Loss:  0.7391080922876181  Validation Loss:  1.1396309357136487\n",
      "Epoch:  946  Loss:  0.7391106212155872  Validation Loss:  1.1396437807629505\n",
      "Epoch:  947  Loss:  0.7391132016279055  Validation Loss:  1.1396566785871982\n",
      "Epoch:  948  Loss:  0.7391157925463794  Validation Loss:  1.139669543877244\n",
      "Epoch:  949  Loss:  0.7391184196713265  Validation Loss:  1.1396824549883604\n",
      "Epoch:  950  Loss:  0.7391210853467497  Validation Loss:  1.1396953591456016\n",
      "Epoch:  951  Loss:  0.7391237490967418  Validation Loss:  1.1397083242734274\n",
      "Epoch:  952  Loss:  0.7391264798601022  Validation Loss:  1.139721357698242\n",
      "Epoch:  953  Loss:  0.7391292083213169  Validation Loss:  1.1397343348711728\n",
      "Epoch:  954  Loss:  0.7391319901504544  Validation Loss:  1.1397473660608133\n",
      "Epoch:  955  Loss:  0.7391347590457188  Validation Loss:  1.139760405694445\n",
      "Epoch:  956  Loss:  0.7391375918987761  Validation Loss:  1.1397735226899386\n",
      "Epoch:  957  Loss:  0.7391404100181012  Validation Loss:  1.1397865675389767\n",
      "Epoch:  958  Loss:  0.7391432002186775  Validation Loss:  1.139799632007877\n",
      "Epoch:  959  Loss:  0.7391459696162282  Validation Loss:  1.1398127408077319\n",
      "Epoch:  960  Loss:  0.7391486831344245  Validation Loss:  1.1398257980744044\n",
      "Epoch:  961  Loss:  0.7391513539164254  Validation Loss:  1.139838818460703\n",
      "Epoch:  962  Loss:  0.739154054584463  Validation Loss:  1.1398518441865841\n",
      "Epoch:  963  Loss:  0.7391567698606615  Validation Loss:  1.1398649640381335\n",
      "Epoch:  964  Loss:  0.7391595354073504  Validation Loss:  1.1398780819028616\n",
      "Epoch:  965  Loss:  0.7391622822438733  Validation Loss:  1.1398912227402132\n",
      "Epoch:  966  Loss:  0.7391650946706199  Validation Loss:  1.1399043504148723\n",
      "Epoch:  967  Loss:  0.7391679584142867  Validation Loss:  1.1399175307403009\n",
      "Epoch:  968  Loss:  0.7391707982574955  Validation Loss:  1.1399307729055483\n",
      "Epoch:  969  Loss:  0.7391736802927563  Validation Loss:  1.1399439658969641\n",
      "Epoch:  970  Loss:  0.739176608161645  Validation Loss:  1.1399572773526112\n",
      "Epoch:  971  Loss:  0.7391795495922646  Validation Loss:  1.1399705215046803\n",
      "Epoch:  972  Loss:  0.7391825137094835  Validation Loss:  1.1399838543186585\n",
      "Epoch:  973  Loss:  0.7391855194746109  Validation Loss:  1.1399972015370925\n",
      "Epoch:  974  Loss:  0.7391885681433624  Validation Loss:  1.1400105771919091\n",
      "Epoch:  975  Loss:  0.739191611454393  Validation Loss:  1.1400239861259858\n",
      "Epoch:  976  Loss:  0.7391947188487883  Validation Loss:  1.1400374166667462\n",
      "Epoch:  977  Loss:  0.7391978395537714  Validation Loss:  1.1400507900863885\n",
      "Epoch:  978  Loss:  0.7392009355630098  Validation Loss:  1.1400642873098452\n",
      "Epoch:  979  Loss:  0.7392039933984869  Validation Loss:  1.1400776921461027\n",
      "Epoch:  980  Loss:  0.7392069724168671  Validation Loss:  1.1400910286853712\n",
      "Epoch:  981  Loss:  0.7392099215910676  Validation Loss:  1.1401043994973104\n",
      "Epoch:  982  Loss:  0.7392128872151456  Validation Loss:  1.1401178173720836\n",
      "Epoch:  983  Loss:  0.739215884399548  Validation Loss:  1.140131174897154\n",
      "Epoch:  984  Loss:  0.7392189377144481  Validation Loss:  1.1401445719103018\n",
      "Epoch:  985  Loss:  0.739222006474653  Validation Loss:  1.1401580903679132\n",
      "Epoch:  986  Loss:  0.7392250950333108  Validation Loss:  1.140171551828583\n",
      "Epoch:  987  Loss:  0.7392282334020298  Validation Loss:  1.1401850547641517\n",
      "Epoch:  988  Loss:  0.7392313642783112  Validation Loss:  1.1401986082394917\n",
      "Epoch:  989  Loss:  0.7392345645119635  Validation Loss:  1.1402121485521397\n",
      "Epoch:  990  Loss:  0.7392377868880716  Validation Loss:  1.1402257637431223\n",
      "Epoch:  991  Loss:  0.7392410201470504  Validation Loss:  1.1402393524845442\n",
      "Epoch:  992  Loss:  0.7392442338587193  Validation Loss:  1.1402529017378886\n",
      "Epoch:  993  Loss:  0.7392474018204748  Validation Loss:  1.1402664680033923\n",
      "Epoch:  994  Loss:  0.7392504794125476  Validation Loss:  1.1402800109237432\n",
      "Epoch:  995  Loss:  0.7392535466658935  Validation Loss:  1.1402935478836298\n",
      "Epoch:  996  Loss:  0.7392566428007035  Validation Loss:  1.1403070725500584\n",
      "Epoch:  997  Loss:  0.7392597884525743  Validation Loss:  1.14032067929705\n",
      "Epoch:  998  Loss:  0.7392629337695877  Validation Loss:  1.140334265679121\n",
      "Epoch:  999  Loss:  0.7392661276828038  Validation Loss:  1.1403479587286711\n",
      "Epoch:  1000  Loss:  0.7392693252794529  Validation Loss:  1.1403616035978\n",
      "Epoch:  1001  Loss:  0.7392725757417384  Validation Loss:  1.1403752826154232\n",
      "Epoch:  1002  Loss:  0.739275828338741  Validation Loss:  1.140388980259498\n",
      "Epoch:  1003  Loss:  0.7392790507148491  Validation Loss:  1.1404026594012975\n",
      "Epoch:  1004  Loss:  0.7392821181774809  Validation Loss:  1.1404162014524142\n",
      "Epoch:  1005  Loss:  0.7392851947649811  Validation Loss:  1.140429806088408\n",
      "Epoch:  1006  Loss:  0.7392883080612408  Validation Loss:  1.140443435932199\n",
      "Epoch:  1007  Loss:  0.7392914147859209  Validation Loss:  1.1404570857683818\n",
      "Epoch:  1008  Loss:  0.7392945807803882  Validation Loss:  1.1404707558453082\n",
      "Epoch:  1009  Loss:  0.7392977786281806  Validation Loss:  1.1404844475289186\n",
      "Epoch:  1010  Loss:  0.7393010036412919  Validation Loss:  1.1404981710016728\n",
      "Epoch:  1011  Loss:  0.7393040999435307  Validation Loss:  1.1405118343730767\n",
      "Epoch:  1012  Loss:  0.7393071050389429  Validation Loss:  1.1405254072199265\n",
      "Epoch:  1013  Loss:  0.7393101283422346  Validation Loss:  1.140539016202092\n",
      "Epoch:  1014  Loss:  0.7393131763412711  Validation Loss:  1.1405526984483003\n",
      "Epoch:  1015  Loss:  0.7393162690437911  Validation Loss:  1.1405664355804523\n",
      "Epoch:  1016  Loss:  0.7393193984132135  Validation Loss:  1.1405801409234604\n",
      "Epoch:  1017  Loss:  0.7393224189120732  Validation Loss:  1.1405937568595013\n",
      "Epoch:  1018  Loss:  0.739325329159083  Validation Loss:  1.140607326477766\n",
      "Epoch:  1019  Loss:  0.7393282581581159  Validation Loss:  1.1406210175404945\n",
      "Epoch:  1020  Loss:  0.7393312184663301  Validation Loss:  1.1406346455216407\n",
      "Epoch:  1021  Loss:  0.7393342202131667  Validation Loss:  1.1406482689082622\n",
      "Epoch:  1022  Loss:  0.7393370971418498  Validation Loss:  1.140661899993817\n",
      "Epoch:  1023  Loss:  0.7393398753294115  Validation Loss:  1.1406754589329162\n",
      "Epoch:  1024  Loss:  0.7393426862911562  Validation Loss:  1.1406890506545702\n",
      "Epoch:  1025  Loss:  0.7393455242507914  Validation Loss:  1.1407026541729768\n",
      "Epoch:  1026  Loss:  0.7393483093029327  Validation Loss:  1.1407161956032117\n",
      "Epoch:  1027  Loss:  0.7393509069185579  Validation Loss:  1.140729712570707\n",
      "Epoch:  1028  Loss:  0.7393535574835338  Validation Loss:  1.1407432183623314\n",
      "Epoch:  1029  Loss:  0.7393562299398224  Validation Loss:  1.1407567037890354\n",
      "Epoch:  1030  Loss:  0.739358719145314  Validation Loss:  1.1407701831310988\n",
      "Epoch:  1031  Loss:  0.7393611605498898  Validation Loss:  1.1407835549364487\n",
      "Epoch:  1032  Loss:  0.7393636340589336  Validation Loss:  1.1407969685892263\n",
      "Epoch:  1033  Loss:  0.7393659081603035  Validation Loss:  1.1408103117098412\n",
      "Epoch:  1034  Loss:  0.7393681443390552  Validation Loss:  1.1408236306160688\n",
      "Epoch:  1035  Loss:  0.7393703343911787  Validation Loss:  1.140836896871527\n",
      "Epoch:  1036  Loss:  0.7393723682741101  Validation Loss:  1.140850119292736\n",
      "Epoch:  1037  Loss:  0.739374399896753  Validation Loss:  1.140863310918212\n",
      "Epoch:  1038  Loss:  0.7393762339534384  Validation Loss:  1.1408763355265061\n",
      "Epoch:  1039  Loss:  0.7393780508905314  Validation Loss:  1.1408894454439482\n",
      "Epoch:  1040  Loss:  0.7393796350179094  Validation Loss:  1.1409023291120926\n",
      "Epoch:  1041  Loss:  0.7393812383158823  Validation Loss:  1.1409153196960689\n",
      "Epoch:  1042  Loss:  0.7393825998048434  Validation Loss:  1.1409281397859254\n",
      "Epoch:  1043  Loss:  0.7393838034921818  Validation Loss:  1.1409408347060284\n",
      "Epoch:  1044  Loss:  0.7393849087732561  Validation Loss:  1.1409535302470128\n",
      "Epoch:  1045  Loss:  0.7393858045590728  Validation Loss:  1.140966062868635\n",
      "Epoch:  1046  Loss:  0.7393864376491375  Validation Loss:  1.1409784303357204\n",
      "Epoch:  1047  Loss:  0.7393869370473235  Validation Loss:  1.1409907201925913\n",
      "Epoch:  1048  Loss:  0.7393871994500749  Validation Loss:  1.1410029355436564\n",
      "Epoch:  1049  Loss:  0.7393872362425488  Validation Loss:  1.1410149651269117\n",
      "Epoch:  1050  Loss:  0.7393869882386722  Validation Loss:  1.141026841600736\n",
      "Epoch:  1051  Loss:  0.7393864300729853  Validation Loss:  1.1410384926944972\n",
      "Epoch:  1052  Loss:  0.7393855664753513  Validation Loss:  1.1410500388592482\n",
      "Epoch:  1053  Loss:  0.7393844329406706  Validation Loss:  1.1410614110529422\n",
      "Epoch:  1054  Loss:  0.7393828337865599  Validation Loss:  1.1410724520683289\n",
      "Epoch:  1055  Loss:  0.7393809050070436  Validation Loss:  1.1410832991202673\n",
      "Epoch:  1056  Loss:  0.7393784801779169  Validation Loss:  1.1410938313851753\n",
      "Epoch:  1057  Loss:  0.7393755250181375  Validation Loss:  1.1411040696005026\n",
      "Epoch:  1058  Loss:  0.7393720662744527  Validation Loss:  1.1411139541616042\n",
      "Epoch:  1059  Loss:  0.7393680425005013  Validation Loss:  1.1411235322554907\n",
      "Epoch:  1060  Loss:  0.7393632959365175  Validation Loss:  1.1411326953520378\n",
      "Epoch:  1061  Loss:  0.739357930304629  Validation Loss:  1.1411414525161188\n",
      "Epoch:  1062  Loss:  0.7393517794317743  Validation Loss:  1.1411496834208568\n",
      "Epoch:  1063  Loss:  0.7393447143140803  Validation Loss:  1.1411574347565572\n",
      "Epoch:  1064  Loss:  0.7393367407278398  Validation Loss:  1.1411646300305922\n",
      "Epoch:  1065  Loss:  0.7393277852555339  Validation Loss:  1.1411711572359005\n",
      "Epoch:  1066  Loss:  0.7393177998869607  Validation Loss:  1.1411771029233932\n",
      "Epoch:  1067  Loss:  0.7393067051353079  Validation Loss:  1.1411823220551014\n",
      "Epoch:  1068  Loss:  0.739294553824355  Validation Loss:  1.141186902175347\n",
      "Epoch:  1069  Loss:  0.7392813077803408  Validation Loss:  1.1411909233778714\n",
      "Epoch:  1070  Loss:  0.7392670292449132  Validation Loss:  1.1411942765116692\n",
      "Epoch:  1071  Loss:  0.7392517142416386  Validation Loss:  1.1411970095088084\n",
      "Epoch:  1072  Loss:  0.7392354446431894  Validation Loss:  1.1411992287884156\n",
      "Epoch:  1073  Loss:  0.739218396919497  Validation Loss:  1.1412010001639525\n",
      "Epoch:  1074  Loss:  0.7392006182017621  Validation Loss:  1.141202295695742\n",
      "Epoch:  1075  Loss:  0.7391822962195016  Validation Loss:  1.1412033918003242\n",
      "Epoch:  1076  Loss:  0.7391635222632563  Validation Loss:  1.1412041722486417\n",
      "Epoch:  1077  Loss:  0.7391444464747825  Validation Loss:  1.1412048588196437\n",
      "Epoch:  1078  Loss:  0.7391251259891505  Validation Loss:  1.1412054186065992\n",
      "Epoch:  1079  Loss:  0.7391056571197644  Validation Loss:  1.1412058923393489\n",
      "Epoch:  1080  Loss:  0.7390861030291306  Validation Loss:  1.1412064152459303\n",
      "Epoch:  1081  Loss:  0.7390665701600942  Validation Loss:  1.1412069375316303\n",
      "Epoch:  1082  Loss:  0.7390470631588041  Validation Loss:  1.1412075282384953\n",
      "Epoch:  1083  Loss:  0.7390276662419352  Validation Loss:  1.1412081920852264\n",
      "Epoch:  1084  Loss:  0.7390083572670315  Validation Loss:  1.1412090094139178\n",
      "Epoch:  1085  Loss:  0.7389891269836533  Validation Loss:  1.1412098767856758\n",
      "Epoch:  1086  Loss:  0.7389700013851181  Validation Loss:  1.1412107942004999\n",
      "Epoch:  1087  Loss:  0.7389509998931644  Validation Loss:  1.141211861371994\n",
      "Epoch:  1088  Loss:  0.7389322460283724  Validation Loss:  1.141213092704614\n",
      "Epoch:  1089  Loss:  0.7389135923697038  Validation Loss:  1.1412145093083381\n",
      "Epoch:  1090  Loss:  0.738895056915752  Validation Loss:  1.141215897599856\n",
      "Epoch:  1091  Loss:  0.7388767603826657  Validation Loss:  1.1412174745152395\n",
      "Epoch:  1092  Loss:  0.7388585849424426  Validation Loss:  1.1412192466358344\n",
      "Epoch:  1093  Loss:  0.7388405383386639  Validation Loss:  1.1412210548917452\n",
      "Epoch:  1094  Loss:  0.7388227300697499  Validation Loss:  1.1412230188647905\n",
      "Epoch:  1095  Loss:  0.7388050399218382  Validation Loss:  1.1412250999361278\n",
      "Epoch:  1096  Loss:  0.7387874695273597  Validation Loss:  1.1412272837013007\n",
      "Epoch:  1097  Loss:  0.7387700673988026  Validation Loss:  1.141229580839475\n",
      "Epoch:  1098  Loss:  0.7387528117285685  Validation Loss:  1.1412320494651795\n",
      "Epoch:  1099  Loss:  0.7387356849784932  Validation Loss:  1.14123461432755\n",
      "Epoch:  1100  Loss:  0.7387186821675702  Validation Loss:  1.1412371954570213\n",
      "Epoch:  1101  Loss:  0.7387018425997054  Validation Loss:  1.1412399634718895\n",
      "Epoch:  1102  Loss:  0.7386851401560093  Validation Loss:  1.1412428464740514\n",
      "Epoch:  1103  Loss:  0.7386685608980361  Validation Loss:  1.1412458322942256\n",
      "Epoch:  1104  Loss:  0.7386520659404524  Validation Loss:  1.1412488562365373\n",
      "Epoch:  1105  Loss:  0.7386357163110476  Validation Loss:  1.1412520217398803\n",
      "Epoch:  1106  Loss:  0.7386195080333882  Validation Loss:  1.1412552951524655\n",
      "Epoch:  1107  Loss:  0.7386033890789814  Validation Loss:  1.1412586009750763\n",
      "Epoch:  1108  Loss:  0.7385873514112462  Validation Loss:  1.141262082507213\n",
      "Epoch:  1109  Loss:  0.7385713866168864  Validation Loss:  1.1412655120094617\n",
      "Epoch:  1110  Loss:  0.738555581717009  Validation Loss:  1.1412691762049993\n",
      "Epoch:  1111  Loss:  0.7385398581456603  Validation Loss:  1.1412728548049926\n",
      "Epoch:  1112  Loss:  0.7385242592668935  Validation Loss:  1.141276622315248\n",
      "Epoch:  1113  Loss:  0.738508695757456  Validation Loss:  1.1412803964068492\n",
      "Epoch:  1114  Loss:  0.7384931739377841  Validation Loss:  1.1412842681010564\n",
      "Epoch:  1115  Loss:  0.738477764462822  Validation Loss:  1.1412882241110007\n",
      "Epoch:  1116  Loss:  0.7384624474504021  Validation Loss:  1.1412922179947296\n",
      "Epoch:  1117  Loss:  0.7384472187566623  Validation Loss:  1.1412963134547074\n",
      "Epoch:  1118  Loss:  0.7384320108659481  Validation Loss:  1.1413004421939452\n",
      "Epoch:  1119  Loss:  0.7384168738813213  Validation Loss:  1.141304591173927\n",
      "Epoch:  1120  Loss:  0.7384017119079493  Validation Loss:  1.1413087651133538\n",
      "Epoch:  1121  Loss:  0.7383865497252914  Validation Loss:  1.1413129647572835\n",
      "Epoch:  1122  Loss:  0.738371494236622  Validation Loss:  1.1413171676297982\n",
      "Epoch:  1123  Loss:  0.7383564760427127  Validation Loss:  1.1413214246431986\n",
      "Epoch:  1124  Loss:  0.7383414714942488  Validation Loss:  1.1413257109622161\n",
      "Epoch:  1125  Loss:  0.7383264537607686  Validation Loss:  1.1413299990197023\n",
      "Epoch:  1126  Loss:  0.7383114292045657  Validation Loss:  1.1413342108329136\n",
      "Epoch:  1127  Loss:  0.7382963018470936  Validation Loss:  1.1413384169340133\n",
      "Epoch:  1128  Loss:  0.7382811338462857  Validation Loss:  1.1413425527513028\n",
      "Epoch:  1129  Loss:  0.7382658624582077  Validation Loss:  1.1413466550409794\n",
      "Epoch:  1130  Loss:  0.738250518573469  Validation Loss:  1.1413507242997487\n",
      "Epoch:  1131  Loss:  0.7382351742701584  Validation Loss:  1.1413547039031982\n",
      "Epoch:  1132  Loss:  0.7382197200079982  Validation Loss:  1.1413586124777795\n",
      "Epoch:  1133  Loss:  0.7382041616469956  Validation Loss:  1.141362468401591\n",
      "Epoch:  1134  Loss:  0.7381884810211283  Validation Loss:  1.1413661638895671\n",
      "Epoch:  1135  Loss:  0.7381726489140746  Validation Loss:  1.1413697893420856\n",
      "Epoch:  1136  Loss:  0.7381566626888313  Validation Loss:  1.1413732488950095\n",
      "Epoch:  1137  Loss:  0.7381404869342119  Validation Loss:  1.1413765519857406\n",
      "Epoch:  1138  Loss:  0.73812416873956  Validation Loss:  1.1413797691464425\n",
      "Epoch:  1139  Loss:  0.7381077272336135  Validation Loss:  1.1413828792671363\n",
      "Epoch:  1140  Loss:  0.7380911285957593  Validation Loss:  1.1413859536250432\n",
      "Epoch:  1141  Loss:  0.7380744770504115  Validation Loss:  1.1413888812065125\n",
      "Epoch:  1142  Loss:  0.7380578553073862  Validation Loss:  1.1413919001817703\n",
      "Epoch:  1143  Loss:  0.7380412181609133  Validation Loss:  1.141394949456056\n",
      "Epoch:  1144  Loss:  0.7380246148769105  Validation Loss:  1.1413979490598043\n",
      "Epoch:  1145  Loss:  0.738008051022385  Validation Loss:  1.1414010293781758\n",
      "Epoch:  1146  Loss:  0.7379915359314908  Validation Loss:  1.1414041457076867\n",
      "Epoch:  1147  Loss:  0.7379751023784112  Validation Loss:  1.1414073780179024\n",
      "Epoch:  1148  Loss:  0.7379587232396844  Validation Loss:  1.1414106331765652\n",
      "Epoch:  1149  Loss:  0.7379424451023675  Validation Loss:  1.1414140217006206\n",
      "Epoch:  1150  Loss:  0.7379262339365616  Validation Loss:  1.1414175011217593\n",
      "Epoch:  1151  Loss:  0.7379101709452238  Validation Loss:  1.1414210813740888\n",
      "Epoch:  1152  Loss:  0.73789419949557  Validation Loss:  1.1414247743785382\n",
      "Epoch:  1153  Loss:  0.7378783462924904  Validation Loss:  1.141428546110789\n",
      "Epoch:  1154  Loss:  0.737862602336688  Validation Loss:  1.141432457168897\n",
      "Epoch:  1155  Loss:  0.7378469741578852  Validation Loss:  1.141436501344045\n",
      "Epoch:  1156  Loss:  0.7378314937349786  Validation Loss:  1.1414406632383665\n",
      "Epoch:  1157  Loss:  0.7378162164450361  Validation Loss:  1.1414449781179428\n",
      "Epoch:  1158  Loss:  0.7378010970404308  Validation Loss:  1.1414494521915912\n",
      "Epoch:  1159  Loss:  0.7377861483294642  Validation Loss:  1.1414541013538837\n",
      "Epoch:  1160  Loss:  0.7377713456582488  Validation Loss:  1.1414588173230489\n",
      "Epoch:  1161  Loss:  0.7377567218428247  Validation Loss:  1.1414637597898643\n",
      "Epoch:  1162  Loss:  0.7377422242268418  Validation Loss:  1.1414687618613244\n",
      "Epoch:  1163  Loss:  0.7377278369882804  Validation Loss:  1.1414739035069943\n",
      "Epoch:  1164  Loss:  0.7377135756143024  Validation Loss:  1.14147920285662\n",
      "Epoch:  1165  Loss:  0.7376994612009338  Validation Loss:  1.1414845275382202\n",
      "Epoch:  1166  Loss:  0.7376854783028699  Validation Loss:  1.1414900628228983\n",
      "Epoch:  1167  Loss:  0.7376715782820509  Validation Loss:  1.1414956390857696\n",
      "Epoch:  1168  Loss:  0.7376578189432621  Validation Loss:  1.1415014232198397\n",
      "Epoch:  1169  Loss:  0.7376442043047943  Validation Loss:  1.1415072540442148\n",
      "Epoch:  1170  Loss:  0.7376306931373109  Validation Loss:  1.1415132952233156\n",
      "Epoch:  1171  Loss:  0.7376173238657163  Validation Loss:  1.1415193791190783\n",
      "Epoch:  1172  Loss:  0.737604057772106  Validation Loss:  1.1415256227056185\n",
      "Epoch:  1173  Loss:  0.7375909293049507  Validation Loss:  1.1415319311122099\n",
      "Epoch:  1174  Loss:  0.7375779037646363  Validation Loss:  1.1415383838117124\n",
      "Epoch:  1175  Loss:  0.7375650135067742  Validation Loss:  1.141544948766629\n",
      "Epoch:  1176  Loss:  0.7375522398630555  Validation Loss:  1.1415516316890717\n",
      "Epoch:  1177  Loss:  0.7375395704437507  Validation Loss:  1.1415584767858187\n",
      "Epoch:  1178  Loss:  0.7375270444690512  Validation Loss:  1.1415653837223847\n",
      "Epoch:  1179  Loss:  0.7375146832442685  Validation Loss:  1.1415724990268548\n",
      "Epoch:  1180  Loss:  0.7375025169902973  Validation Loss:  1.1415796816349029\n",
      "Epoch:  1181  Loss:  0.7374904765171951  Validation Loss:  1.1415870033204556\n",
      "Epoch:  1182  Loss:  0.7374785693592569  Validation Loss:  1.141594546288252\n",
      "Epoch:  1183  Loss:  0.7374668007904894  Validation Loss:  1.141602119555076\n",
      "Epoch:  1184  Loss:  0.7374552016177874  Validation Loss:  1.1416098430752755\n",
      "Epoch:  1185  Loss:  0.7374437119016487  Validation Loss:  1.1416177116334438\n",
      "Epoch:  1186  Loss:  0.7374323683508327  Validation Loss:  1.1416256368160247\n",
      "Epoch:  1187  Loss:  0.737421105626259  Validation Loss:  1.1416337393224238\n",
      "Epoch:  1188  Loss:  0.7374099723241302  Validation Loss:  1.1416419697304567\n",
      "Epoch:  1189  Loss:  0.7373989741788821  Validation Loss:  1.1416502582530181\n",
      "Epoch:  1190  Loss:  0.7373880611711674  Validation Loss:  1.1416586585342885\n",
      "Epoch:  1191  Loss:  0.7373773062580757  Validation Loss:  1.1416672425965468\n",
      "Epoch:  1192  Loss:  0.7373666284040788  Validation Loss:  1.1416759006679058\n",
      "Epoch:  1193  Loss:  0.7373561034962702  Validation Loss:  1.141684682915608\n",
      "Epoch:  1194  Loss:  0.7373456902634562  Validation Loss:  1.1416935957968235\n",
      "Epoch:  1195  Loss:  0.7373353763996215  Validation Loss:  1.1417025717596212\n",
      "Epoch:  1196  Loss:  0.7373251932558049  Validation Loss:  1.1417117029428483\n",
      "Epoch:  1197  Loss:  0.7373151309955656  Validation Loss:  1.1417209116121134\n",
      "Epoch:  1198  Loss:  0.7373051849308978  Validation Loss:  1.14173031548659\n",
      "Epoch:  1199  Loss:  0.7372953555222308  Validation Loss:  1.1417397330204646\n",
      "Epoch:  1200  Loss:  0.7372856421835636  Validation Loss:  1.1417493857443333\n",
      "Epoch:  1201  Loss:  0.7372760561744819  Validation Loss:  1.1417590379714966\n",
      "Epoch:  1202  Loss:  0.737266583430968  Validation Loss:  1.1417688384652138\n",
      "Epoch:  1203  Loss:  0.7372572044894267  Validation Loss:  1.1417787740627925\n",
      "Epoch:  1204  Loss:  0.7372480043618197  Validation Loss:  1.1417888569335142\n",
      "Epoch:  1205  Loss:  0.7372388683175772  Validation Loss:  1.1417989693582058\n",
      "Epoch:  1206  Loss:  0.7372298889029562  Validation Loss:  1.1418091863393784\n",
      "Epoch:  1207  Loss:  0.7372210181914689  Validation Loss:  1.1418196839590868\n",
      "Epoch:  1208  Loss:  0.7372122492766782  Validation Loss:  1.1418301699062188\n",
      "Epoch:  1209  Loss:  0.7372035963481731  Validation Loss:  1.1418408247331777\n",
      "Epoch:  1210  Loss:  0.7371950894175621  Validation Loss:  1.1418515520791213\n",
      "Epoch:  1211  Loss:  0.7371866762889235  Validation Loss:  1.1418624140322209\n",
      "Epoch:  1212  Loss:  0.7371784040516012  Validation Loss:  1.1418734471003213\n",
      "Epoch:  1213  Loss:  0.7371702518188552  Validation Loss:  1.1418845370411872\n",
      "Epoch:  1214  Loss:  0.737162234156989  Validation Loss:  1.1418957628309727\n",
      "Epoch:  1215  Loss:  0.7371544123867925  Validation Loss:  1.1419070857266584\n",
      "Epoch:  1216  Loss:  0.7371467167741796  Validation Loss:  1.14191856905818\n",
      "Epoch:  1217  Loss:  0.7371391593321656  Validation Loss:  1.141930202394724\n",
      "Epoch:  1218  Loss:  0.7371317205552974  Validation Loss:  1.1419419556856156\n",
      "Epoch:  1219  Loss:  0.7371244027875783  Validation Loss:  1.1419537576536338\n",
      "Epoch:  1220  Loss:  0.737117260317789  Validation Loss:  1.1419658516844113\n",
      "Epoch:  1221  Loss:  0.7371102732219054  Validation Loss:  1.1419780413309732\n",
      "Epoch:  1222  Loss:  0.7371034417929274  Validation Loss:  1.1419903991123042\n",
      "Epoch:  1223  Loss:  0.7370967363541046  Validation Loss:  1.1420028641819955\n",
      "Epoch:  1224  Loss:  0.7370902008973481  Validation Loss:  1.1420156002044677\n",
      "Epoch:  1225  Loss:  0.7370837744785829  Validation Loss:  1.1420283628006775\n",
      "Epoch:  1226  Loss:  0.7370775100053026  Validation Loss:  1.1420413749913374\n",
      "Epoch:  1227  Loss:  0.7370713800191879  Validation Loss:  1.1420545185605684\n",
      "Epoch:  1228  Loss:  0.7370654289307219  Validation Loss:  1.1420678762098153\n",
      "Epoch:  1229  Loss:  0.7370596022418375  Validation Loss:  1.1420814290642738\n",
      "Epoch:  1230  Loss:  0.737053946916307  Validation Loss:  1.142095235735178\n",
      "Epoch:  1231  Loss:  0.7370485037230374  Validation Loss:  1.1421091581384342\n",
      "Epoch:  1232  Loss:  0.7370433583855629  Validation Loss:  1.1421233229339123\n",
      "Epoch:  1233  Loss:  0.7370383670825637  Validation Loss:  1.142137622833252\n",
      "Epoch:  1234  Loss:  0.7370334969979994  Validation Loss:  1.14215197712183\n",
      "Epoch:  1235  Loss:  0.7370287594751695  Validation Loss:  1.1421665099759897\n",
      "Epoch:  1236  Loss:  0.7370241295671864  Validation Loss:  1.1421811774373054\n",
      "Epoch:  1237  Loss:  0.7370196223844973  Validation Loss:  1.1421959502001604\n",
      "Epoch:  1238  Loss:  0.7370152477216855  Validation Loss:  1.1422107989589374\n",
      "Epoch:  1239  Loss:  0.7370109892963024  Validation Loss:  1.1422258188327155\n",
      "Epoch:  1240  Loss:  0.7370068500802088  Validation Loss:  1.1422409201661745\n",
      "Epoch:  1241  Loss:  0.7370028332964088  Validation Loss:  1.1422561667859554\n",
      "Epoch:  1242  Loss:  0.7369989443863376  Validation Loss:  1.1422715018192926\n",
      "Epoch:  1243  Loss:  0.7369951634678278  Validation Loss:  1.1422870216270289\n",
      "Epoch:  1244  Loss:  0.7369915218082037  Validation Loss:  1.1423025993009408\n",
      "Epoch:  1245  Loss:  0.7369879987718684  Validation Loss:  1.1423183334370455\n",
      "Epoch:  1246  Loss:  0.7369845967028248  Validation Loss:  1.1423341194788614\n",
      "Epoch:  1247  Loss:  0.7369812962630492  Validation Loss:  1.1423500798642636\n",
      "Epoch:  1248  Loss:  0.7369781499833203  Validation Loss:  1.1423661510149639\n",
      "Epoch:  1249  Loss:  0.736975107593148  Validation Loss:  1.1423823808630307\n",
      "Epoch:  1250  Loss:  0.7369721890584137  Validation Loss:  1.1423986934125423\n",
      "Epoch:  1251  Loss:  0.7369693747899505  Validation Loss:  1.14241518030564\n",
      "Epoch:  1252  Loss:  0.7369667266945491  Validation Loss:  1.1424316942691803\n",
      "Epoch:  1253  Loss:  0.73696417344755  Validation Loss:  1.1424483448266982\n",
      "Epoch:  1254  Loss:  0.7369617458139912  Validation Loss:  1.1424651744465033\n",
      "Epoch:  1255  Loss:  0.736959459992607  Validation Loss:  1.142482119301955\n",
      "Epoch:  1256  Loss:  0.7369572796094953  Validation Loss:  1.142499154061079\n",
      "Epoch:  1257  Loss:  0.7369552028229397  Validation Loss:  1.1425163974364598\n",
      "Epoch:  1258  Loss:  0.7369532734155655  Validation Loss:  1.1425336269040902\n",
      "Epoch:  1259  Loss:  0.7369514825136474  Validation Loss:  1.1425510702033839\n",
      "Epoch:  1260  Loss:  0.7369497986405753  Validation Loss:  1.1425685813029607\n",
      "Epoch:  1261  Loss:  0.736948244148091  Validation Loss:  1.14258623868227\n",
      "Epoch:  1262  Loss:  0.7369468047628912  Validation Loss:  1.1426040137807527\n",
      "Epoch:  1263  Loss:  0.7369454415996423  Validation Loss:  1.1426218681037426\n",
      "Epoch:  1264  Loss:  0.7369441995711139  Validation Loss:  1.1426397499938805\n",
      "Epoch:  1265  Loss:  0.7369430235932383  Validation Loss:  1.1426578300694625\n",
      "Epoch:  1266  Loss:  0.736941946775056  Validation Loss:  1.1426759660243988\n",
      "Epoch:  1267  Loss:  0.736940966060992  Validation Loss:  1.1426942345996698\n",
      "Epoch:  1268  Loss:  0.7369400782698996  Validation Loss:  1.1427125655114652\n",
      "Epoch:  1269  Loss:  0.736939304372233  Validation Loss:  1.1427310896416505\n",
      "Epoch:  1270  Loss:  0.7369386627433006  Validation Loss:  1.1427496860424677\n",
      "Epoch:  1271  Loss:  0.7369381905104337  Validation Loss:  1.1427684878309567\n",
      "Epoch:  1272  Loss:  0.7369378559040219  Validation Loss:  1.1427873921891054\n",
      "Epoch:  1273  Loss:  0.7369376112068637  Validation Loss:  1.1428064569830894\n",
      "Epoch:  1274  Loss:  0.7369375333943394  Validation Loss:  1.1428255786498387\n",
      "Epoch:  1275  Loss:  0.7369376310053166  Validation Loss:  1.1428448709348837\n",
      "Epoch:  1276  Loss:  0.7369378505044439  Validation Loss:  1.142864352464676\n",
      "Epoch:  1277  Loss:  0.7369382051604517  Validation Loss:  1.1428839405377706\n",
      "Epoch:  1278  Loss:  0.7369387259895213  Validation Loss:  1.1429036517937978\n",
      "Epoch:  1279  Loss:  0.7369393465642848  Validation Loss:  1.1429234062631926\n",
      "Epoch:  1280  Loss:  0.7369401152716594  Validation Loss:  1.1429433934390545\n",
      "Epoch:  1281  Loss:  0.7369410108900472  Validation Loss:  1.1429634913802147\n",
      "Epoch:  1282  Loss:  0.736942057696621  Validation Loss:  1.1429836702843508\n",
      "Epoch:  1283  Loss:  0.7369432317490658  Validation Loss:  1.143004020055135\n",
      "Epoch:  1284  Loss:  0.736944546525398  Validation Loss:  1.1430244840681554\n",
      "Epoch:  1285  Loss:  0.7369459780833024  Validation Loss:  1.1430450851718585\n",
      "Epoch:  1286  Loss:  0.736947556518102  Validation Loss:  1.1430657878518105\n",
      "Epoch:  1287  Loss:  0.7369492554597641  Validation Loss:  1.1430866221586864\n",
      "Epoch:  1288  Loss:  0.7369510979716027  Validation Loss:  1.143107615162929\n",
      "Epoch:  1289  Loss:  0.7369530324018403  Validation Loss:  1.1431287325918675\n",
      "Epoch:  1290  Loss:  0.7369551242988431  Validation Loss:  1.1431498907506465\n",
      "Epoch:  1291  Loss:  0.736957350390011  Validation Loss:  1.143171245108048\n",
      "Epoch:  1292  Loss:  0.7369596804125925  Validation Loss:  1.143192794919014\n",
      "Epoch:  1293  Loss:  0.7369621556377812  Validation Loss:  1.1432143499453862\n",
      "Epoch:  1294  Loss:  0.7369647642199912  Validation Loss:  1.1432361076275508\n",
      "Epoch:  1295  Loss:  0.7369674997550718  Validation Loss:  1.1432579611738523\n",
      "Epoch:  1296  Loss:  0.7369703590200188  Validation Loss:  1.143279988070329\n",
      "Epoch:  1297  Loss:  0.736973360431998  Validation Loss:  1.1433020728329817\n",
      "Epoch:  1298  Loss:  0.7369764750676878  Validation Loss:  1.1433243247369924\n",
      "Epoch:  1299  Loss:  0.7369797266182605  Validation Loss:  1.1433467182020347\n",
      "Epoch:  1300  Loss:  0.7369831137024285  Validation Loss:  1.1433691973487536\n",
      "Epoch:  1301  Loss:  0.7369866148893083  Validation Loss:  1.1433918744325637\n",
      "Epoch:  1302  Loss:  0.7369902757195275  Validation Loss:  1.1434145835538705\n",
      "Epoch:  1303  Loss:  0.7369940669767643  Validation Loss:  1.1434375002980233\n",
      "Epoch:  1304  Loss:  0.7369979689881373  Validation Loss:  1.1434605573614438\n",
      "Epoch:  1305  Loss:  0.7370020277965604  Validation Loss:  1.1434836998581885\n",
      "Epoch:  1306  Loss:  0.7370061886109663  Validation Loss:  1.1435070085028807\n",
      "Epoch:  1307  Loss:  0.7370105071432804  Validation Loss:  1.1435303963720798\n",
      "Epoch:  1308  Loss:  0.737014947647459  Validation Loss:  1.1435539796948433\n",
      "Epoch:  1309  Loss:  0.7370195323915294  Validation Loss:  1.1435776829719544\n",
      "Epoch:  1310  Loss:  0.7370242410747523  Validation Loss:  1.1436014908055465\n",
      "Epoch:  1311  Loss:  0.7370290768364173  Validation Loss:  1.1436254546046256\n",
      "Epoch:  1312  Loss:  0.7370340701485618  Validation Loss:  1.143649511039257\n",
      "Epoch:  1313  Loss:  0.7370391744659858  Validation Loss:  1.1436737755934396\n",
      "Epoch:  1314  Loss:  0.7370444172470088  Validation Loss:  1.1436981104314328\n",
      "Epoch:  1315  Loss:  0.7370497912921933  Validation Loss:  1.143722558269898\n",
      "Epoch:  1316  Loss:  0.7370553199997109  Validation Loss:  1.1437471732497215\n",
      "Epoch:  1317  Loss:  0.7370609865848268  Validation Loss:  1.1437719461818536\n",
      "Epoch:  1318  Loss:  0.7370667674819406  Validation Loss:  1.1437967774768671\n",
      "Epoch:  1319  Loss:  0.7370727050505327  Validation Loss:  1.1438218086957932\n",
      "Epoch:  1320  Loss:  0.7370787513641159  Validation Loss:  1.1438469767570496\n",
      "Epoch:  1321  Loss:  0.7370849386108725  Validation Loss:  1.1438722893595696\n",
      "Epoch:  1322  Loss:  0.7370912898541166  Validation Loss:  1.1438976583381495\n",
      "Epoch:  1323  Loss:  0.7370977536513564  Validation Loss:  1.143923240651687\n",
      "Epoch:  1324  Loss:  0.7371043747060755  Validation Loss:  1.143948935965697\n",
      "Epoch:  1325  Loss:  0.7371111185279455  Validation Loss:  1.143974756449461\n",
      "Epoch:  1326  Loss:  0.7371180108591412  Validation Loss:  1.1440007075667382\n",
      "Epoch:  1327  Loss:  0.737125028343348  Validation Loss:  1.1440268283089001\n",
      "Epoch:  1328  Loss:  0.7371321827424376  Validation Loss:  1.144053057084481\n",
      "Epoch:  1329  Loss:  0.7371394804605608  Validation Loss:  1.1440793866912524\n",
      "Epoch:  1330  Loss:  0.7371469192374288  Validation Loss:  1.1441059430440268\n",
      "Epoch:  1331  Loss:  0.7371544973150398  Validation Loss:  1.1441325816015402\n",
      "Epoch:  1332  Loss:  0.7371622105913885  Validation Loss:  1.144159312794606\n",
      "Epoch:  1333  Loss:  0.7371700509043222  Validation Loss:  1.1441863069931666\n",
      "Epoch:  1334  Loss:  0.7371780478887344  Validation Loss:  1.1442133737107119\n",
      "Epoch:  1335  Loss:  0.7371861736677335  Validation Loss:  1.1442405541737874\n",
      "Epoch:  1336  Loss:  0.737194452392921  Validation Loss:  1.1442678630352021\n",
      "Epoch:  1337  Loss:  0.7372028874547294  Validation Loss:  1.1442953253785768\n",
      "Epoch:  1338  Loss:  0.7372114397585392  Validation Loss:  1.1443229615688324\n",
      "Epoch:  1339  Loss:  0.7372201133644982  Validation Loss:  1.1443507015705108\n",
      "Epoch:  1340  Loss:  0.7372289679191085  Validation Loss:  1.1443786429862182\n",
      "Epoch:  1341  Loss:  0.7372379513101631  Validation Loss:  1.1444066365559895\n",
      "Epoch:  1342  Loss:  0.7372470611099446  Validation Loss:  1.1444348198672136\n",
      "Epoch:  1343  Loss:  0.7372563249023443  Validation Loss:  1.1444631591439247\n",
      "Epoch:  1344  Loss:  0.7372657287070591  Validation Loss:  1.1444915962715945\n",
      "Epoch:  1345  Loss:  0.7372752758726645  Validation Loss:  1.1445201391975084\n",
      "Epoch:  1346  Loss:  0.7372849832676099  Validation Loss:  1.144548883040746\n",
      "Epoch:  1347  Loss:  0.7372948027979792  Validation Loss:  1.1445778007308642\n",
      "Epoch:  1348  Loss:  0.7373047855295493  Validation Loss:  1.14460684855779\n",
      "Epoch:  1349  Loss:  0.7373149137567269  Validation Loss:  1.1446360091368357\n",
      "Epoch:  1350  Loss:  0.7373251795266451  Validation Loss:  1.1446653090417385\n",
      "Epoch:  1351  Loss:  0.7373355925501732  Validation Loss:  1.1446946993470193\n",
      "Epoch:  1352  Loss:  0.7373461462557316  Validation Loss:  1.1447243149081865\n",
      "Epoch:  1353  Loss:  0.7373568549584807  Validation Loss:  1.144754053155581\n",
      "Epoch:  1354  Loss:  0.7373676845029499  Validation Loss:  1.1447839163243771\n",
      "Epoch:  1355  Loss:  0.7373786807646242  Validation Loss:  1.1448139367004235\n",
      "Epoch:  1356  Loss:  0.7373898237776221  Validation Loss:  1.1448441321651142\n",
      "Epoch:  1357  Loss:  0.7374011091469379  Validation Loss:  1.1448744123180707\n",
      "Epoch:  1358  Loss:  0.7374125238131272  Validation Loss:  1.144904841730992\n",
      "Epoch:  1359  Loss:  0.7374240960716532  Validation Loss:  1.1449354569117227\n",
      "Epoch:  1360  Loss:  0.7374358158767893  Validation Loss:  1.144966180374225\n",
      "Epoch:  1361  Loss:  0.7374476933998338  Validation Loss:  1.1449970732132593\n",
      "Epoch:  1362  Loss:  0.7374597070843316  Validation Loss:  1.1450280949473381\n",
      "Epoch:  1363  Loss:  0.7374718678131532  Validation Loss:  1.1450592728952567\n",
      "Epoch:  1364  Loss:  0.7374841866784552  Validation Loss:  1.1450906266768774\n",
      "Epoch:  1365  Loss:  0.7374966612106628  Validation Loss:  1.1451221185425917\n",
      "Epoch:  1366  Loss:  0.7375092862613415  Validation Loss:  1.1451538478334744\n",
      "Epoch:  1367  Loss:  0.7375220720436466  Validation Loss:  1.1451856277883052\n",
      "Epoch:  1368  Loss:  0.737535001772843  Validation Loss:  1.1452176243066787\n",
      "Epoch:  1369  Loss:  0.7375480766627895  Validation Loss:  1.1452497767905394\n",
      "Epoch:  1370  Loss:  0.737561325762379  Validation Loss:  1.1452821093300978\n",
      "Epoch:  1371  Loss:  0.7375747003916944  Validation Loss:  1.1453144736588001\n",
      "Epoch:  1372  Loss:  0.7375882663502452  Validation Loss:  1.145347144951423\n",
      "Epoch:  1373  Loss:  0.7376019002430225  Validation Loss:  1.1453797742724419\n",
      "Epoch:  1374  Loss:  0.7376156396996439  Validation Loss:  1.1454125843942164\n",
      "Epoch:  1375  Loss:  0.7376294462114907  Validation Loss:  1.1454455266396204\n",
      "Epoch:  1376  Loss:  0.737643372769771  Validation Loss:  1.1454785155753295\n",
      "Epoch:  1377  Loss:  0.7376574755049823  Validation Loss:  1.1455117533604304\n",
      "Epoch:  1378  Loss:  0.7376717384276765  Validation Loss:  1.1455450544754664\n",
      "Epoch:  1379  Loss:  0.7376861733415824  Validation Loss:  1.1455785100658735\n",
      "Epoch:  1380  Loss:  0.737700756597385  Validation Loss:  1.145612223694722\n",
      "Epoch:  1381  Loss:  0.7377155091236817  Validation Loss:  1.145646042873462\n",
      "Epoch:  1382  Loss:  0.737730422256033  Validation Loss:  1.1456800416111945\n",
      "Epoch:  1383  Loss:  0.7377454658991165  Validation Loss:  1.1457141568263371\n",
      "Epoch:  1384  Loss:  0.7377607012900074  Validation Loss:  1.1457484836379688\n",
      "Epoch:  1385  Loss:  0.7377760742236389  Validation Loss:  1.145782943069935\n",
      "Epoch:  1386  Loss:  0.7377915945364518  Validation Loss:  1.1458175353705884\n",
      "Epoch:  1387  Loss:  0.7378072882217638  Validation Loss:  1.1458522592981657\n",
      "Epoch:  1388  Loss:  0.7378231169802419  Validation Loss:  1.1458871066570282\n",
      "Epoch:  1389  Loss:  0.7378391179392177  Validation Loss:  1.1459222093224526\n",
      "Epoch:  1390  Loss:  0.7378552687050921  Validation Loss:  1.1459573589265346\n",
      "Epoch:  1391  Loss:  0.7378715701987234  Validation Loss:  1.1459926900764306\n",
      "Epoch:  1392  Loss:  0.7378880264802595  Validation Loss:  1.146028113613526\n",
      "Epoch:  1393  Loss:  0.7379046416098483  Validation Loss:  1.1460638009011745\n",
      "Epoch:  1394  Loss:  0.7379213810971613  Validation Loss:  1.146099577844143\n",
      "Epoch:  1395  Loss:  0.7379383205781492  Validation Loss:  1.1461355085174243\n",
      "Epoch:  1396  Loss:  0.7379553808589999  Validation Loss:  1.1461716160178184\n",
      "Epoch:  1397  Loss:  0.7379726202049283  Validation Loss:  1.146207869797945\n",
      "Epoch:  1398  Loss:  0.7379899879687288  Validation Loss:  1.1462442340950172\n",
      "Epoch:  1399  Loss:  0.7380075312816026  Validation Loss:  1.146280788630247\n",
      "Epoch:  1400  Loss:  0.7380252183739389  Validation Loss:  1.1463174877067408\n",
      "Epoch:  1401  Loss:  0.7380430703417639  Validation Loss:  1.1463543680806956\n",
      "Epoch:  1402  Loss:  0.7380610731210602  Validation Loss:  1.1463913636902967\n",
      "Epoch:  1403  Loss:  0.7380792565978644  Validation Loss:  1.1464285634458065\n",
      "Epoch:  1404  Loss:  0.7380975810078423  Validation Loss:  1.1464658305048943\n",
      "Epoch:  1405  Loss:  0.7381160532574306  Validation Loss:  1.146503311395645\n",
      "Epoch:  1406  Loss:  0.7381346846062146  Validation Loss:  1.1465409678717455\n",
      "Epoch:  1407  Loss:  0.7381534807049157  Validation Loss:  1.1465787736078104\n",
      "Epoch:  1408  Loss:  0.7381724336843812  Validation Loss:  1.1466166851421198\n",
      "Epoch:  1409  Loss:  0.7381915282667353  Validation Loss:  1.146654837578535\n",
      "Epoch:  1410  Loss:  0.7382107703956995  Validation Loss:  1.146693025281032\n",
      "Epoch:  1411  Loss:  0.7382301959010322  Validation Loss:  1.1467314471801122\n",
      "Epoch:  1412  Loss:  0.7382497715899784  Validation Loss:  1.146769974132379\n",
      "Epoch:  1413  Loss:  0.7382693972982718  Validation Loss:  1.1468076199293136\n",
      "Epoch:  1414  Loss:  0.7382887959731429  Validation Loss:  1.1468448350826899\n",
      "Epoch:  1415  Loss:  0.738308117756348  Validation Loss:  1.146881576627493\n",
      "Epoch:  1416  Loss:  0.7383274577055754  Validation Loss:  1.1469184545179207\n",
      "Epoch:  1417  Loss:  0.7383469559587119  Validation Loss:  1.1469554059207439\n",
      "Epoch:  1418  Loss:  0.7383666337373551  Validation Loss:  1.1469925753772259\n",
      "Epoch:  1419  Loss:  0.7383864523236001  Validation Loss:  1.1470298449198404\n",
      "Epoch:  1420  Loss:  0.7384064417290553  Validation Loss:  1.1470673951009909\n",
      "Epoch:  1421  Loss:  0.7384266182361694  Validation Loss:  1.147104950249195\n",
      "Epoch:  1422  Loss:  0.7384469134502867  Validation Loss:  1.1471426775058111\n",
      "Epoch:  1423  Loss:  0.738467307531097  Validation Loss:  1.1471804862221082\n",
      "Epoch:  1424  Loss:  0.7384877379858092  Validation Loss:  1.1472183843453725\n",
      "Epoch:  1425  Loss:  0.7385083142291294  Validation Loss:  1.1472564687331517\n",
      "Epoch:  1426  Loss:  0.7385290265920457  Validation Loss:  1.147294652213653\n",
      "Epoch:  1427  Loss:  0.7385499063837394  Validation Loss:  1.1473329921563467\n",
      "Epoch:  1428  Loss:  0.7385709346010444  Validation Loss:  1.1473715302844842\n",
      "Epoch:  1429  Loss:  0.7385921458180031  Validation Loss:  1.1474102549254894\n",
      "Epoch:  1430  Loss:  0.7386135042885716  Validation Loss:  1.1474490689734618\n",
      "Epoch:  1431  Loss:  0.7386350308157755  Validation Loss:  1.1474880752464136\n",
      "Epoch:  1432  Loss:  0.7386567251484716  Validation Loss:  1.1475272503991922\n",
      "Epoch:  1433  Loss:  0.738678592267666  Validation Loss:  1.1475665743152301\n",
      "Epoch:  1434  Loss:  0.7387006321315015  Validation Loss:  1.147606043269237\n",
      "Epoch:  1435  Loss:  0.73872281129608  Validation Loss:  1.1476456965009372\n",
      "Epoch:  1436  Loss:  0.7387451649633017  Validation Loss:  1.147685540219148\n",
      "Epoch:  1437  Loss:  0.7387677004581756  Validation Loss:  1.147725516806046\n",
      "Epoch:  1438  Loss:  0.7387904037585419  Validation Loss:  1.147765621294578\n",
      "Epoch:  1439  Loss:  0.738813251508086  Validation Loss:  1.1478059716522693\n",
      "Epoch:  1440  Loss:  0.7388362758949901  Validation Loss:  1.147846470028162\n",
      "Epoch:  1441  Loss:  0.7388594595903761  Validation Loss:  1.1478870876133442\n",
      "Epoch:  1442  Loss:  0.7388828251134144  Validation Loss:  1.1479278770585855\n",
      "Epoch:  1443  Loss:  0.7389063345833441  Validation Loss:  1.14796884059906\n",
      "Epoch:  1444  Loss:  0.7389300388566563  Validation Loss:  1.148009899755319\n",
      "Epoch:  1445  Loss:  0.7389539106843177  Validation Loss:  1.1480512286225955\n",
      "Epoch:  1446  Loss:  0.7389779237381527  Validation Loss:  1.1480926799277464\n",
      "Epoch:  1447  Loss:  0.7390021364089479  Validation Loss:  1.1481343698998292\n",
      "Epoch:  1448  Loss:  0.7390265052907923  Validation Loss:  1.1481761713822682\n",
      "Epoch:  1449  Loss:  0.739051045033704  Validation Loss:  1.1482180915772915\n",
      "Epoch:  1450  Loss:  0.7390757541308243  Validation Loss:  1.1482601962983607\n",
      "Epoch:  1451  Loss:  0.7391006440091669  Validation Loss:  1.1483024743696053\n",
      "Epoch:  1452  Loss:  0.7391256491203656  Validation Loss:  1.1483448314170042\n",
      "Epoch:  1453  Loss:  0.7391508366870746  Validation Loss:  1.1483873608211677\n",
      "Epoch:  1454  Loss:  0.7391762042815766  Validation Loss:  1.1484301197032134\n",
      "Epoch:  1455  Loss:  0.7392017078282458  Validation Loss:  1.1484729029238223\n",
      "Epoch:  1456  Loss:  0.7392274106151602  Validation Loss:  1.1485159705082575\n",
      "Epoch:  1457  Loss:  0.7392532979085874  Validation Loss:  1.1485591933131218\n",
      "Epoch:  1458  Loss:  0.7392793357204855  Validation Loss:  1.1486025435229144\n",
      "Epoch:  1459  Loss:  0.7393055511743165  Validation Loss:  1.1486460874478022\n",
      "Epoch:  1460  Loss:  0.739331939665789  Validation Loss:  1.1486897605160873\n",
      "Epoch:  1461  Loss:  0.7393584019514952  Validation Loss:  1.1487333970765272\n",
      "Epoch:  1462  Loss:  0.739384743144338  Validation Loss:  1.14877708380421\n",
      "Epoch:  1463  Loss:  0.7394112046347575  Validation Loss:  1.1488209036489327\n",
      "Epoch:  1464  Loss:  0.739437821164225  Validation Loss:  1.148864842702945\n",
      "Epoch:  1465  Loss:  0.7394646026528953  Validation Loss:  1.1489090691010158\n",
      "Epoch:  1466  Loss:  0.7394915735453702  Validation Loss:  1.1489533506333829\n",
      "Epoch:  1467  Loss:  0.7395187080576179  Validation Loss:  1.1489978216588497\n",
      "Epoch:  1468  Loss:  0.7395460348618165  Validation Loss:  1.149042515208324\n",
      "Epoch:  1469  Loss:  0.7395735011341866  Validation Loss:  1.1490873324374358\n",
      "Epoch:  1470  Loss:  0.7396011698279488  Validation Loss:  1.149132391065359\n",
      "Epoch:  1471  Loss:  0.7396290159125006  Validation Loss:  1.1491775609552861\n",
      "Epoch:  1472  Loss:  0.7396570458338502  Validation Loss:  1.1492229166130226\n",
      "Epoch:  1473  Loss:  0.7396852032522138  Validation Loss:  1.1492681704461574\n",
      "Epoch:  1474  Loss:  0.7397133157996649  Validation Loss:  1.1493120583395162\n",
      "Epoch:  1475  Loss:  0.7397410514649381  Validation Loss:  1.1493555416663488\n",
      "Epoch:  1476  Loss:  0.7397689106089346  Validation Loss:  1.149399254222711\n",
      "Epoch:  1477  Loss:  0.7397969838106231  Validation Loss:  1.1494431473314761\n",
      "Epoch:  1478  Loss:  0.7398252025079192  Validation Loss:  1.1494872522850832\n",
      "Epoch:  1479  Loss:  0.7398536078883021  Validation Loss:  1.1495314791798592\n",
      "Epoch:  1480  Loss:  0.7398821904083316  Validation Loss:  1.1495758903523285\n",
      "Epoch:  1481  Loss:  0.7399109644668825  Validation Loss:  1.149620459228754\n",
      "Epoch:  1482  Loss:  0.7399399033590649  Validation Loss:  1.1496652357280255\n",
      "Epoch:  1483  Loss:  0.7399690274274751  Validation Loss:  1.1497101495663324\n",
      "Epoch:  1484  Loss:  0.7399983104695095  Validation Loss:  1.1497552628318468\n",
      "Epoch:  1485  Loss:  0.7400277907426438  Validation Loss:  1.1498005911707878\n",
      "Epoch:  1486  Loss:  0.7400574288174008  Validation Loss:  1.1498461030423641\n",
      "Epoch:  1487  Loss:  0.7400871938031711  Validation Loss:  1.1498914711177348\n",
      "Epoch:  1488  Loss:  0.7401167962993129  Validation Loss:  1.1499369032680988\n",
      "Epoch:  1489  Loss:  0.7401465183396018  Validation Loss:  1.1499825164675712\n",
      "Epoch:  1490  Loss:  0.7401764283186933  Validation Loss:  1.1500282193223634\n",
      "Epoch:  1491  Loss:  0.7402065017082718  Validation Loss:  1.1500741822024187\n",
      "Epoch:  1492  Loss:  0.7402367825421055  Validation Loss:  1.150120354195436\n",
      "Epoch:  1493  Loss:  0.7402672035138259  Validation Loss:  1.1501666121184826\n",
      "Epoch:  1494  Loss:  0.7402976948893472  Validation Loss:  1.1502114864687125\n",
      "Epoch:  1495  Loss:  0.7403277357140284  Validation Loss:  1.1502557943264644\n",
      "Epoch:  1496  Loss:  0.7403578818514106  Validation Loss:  1.1503002931674322\n",
      "Epoch:  1497  Loss:  0.7403882094815876  Validation Loss:  1.150344973554214\n",
      "Epoch:  1498  Loss:  0.74041873425915  Validation Loss:  1.1503898200889429\n",
      "Epoch:  1499  Loss:  0.7404494364275022  Validation Loss:  1.150434805949529\n",
      "Training session:  5\n",
      "2020_12_4_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_12_4_MV1_run\n",
      "Epoch:  0  Loss:  0.8144129266412082  Validation Loss:  0.7206218424413738\n",
      "Epoch:  1  Loss:  0.8144967557904734  Validation Loss:  0.720670643423138\n",
      "Epoch:  2  Loss:  0.8145782520401884  Validation Loss:  0.7207161424488857\n",
      "Epoch:  3  Loss:  0.8146567317572507  Validation Loss:  0.7207595360433233\n",
      "Epoch:  4  Loss:  0.8147332837847485  Validation Loss:  0.720801197763147\n",
      "Epoch:  5  Loss:  0.8148080305916003  Validation Loss:  0.7208417603938744\n",
      "Epoch:  6  Loss:  0.814881399104541  Validation Loss:  0.7208804238330702\n",
      "Epoch:  7  Loss:  0.8149526354602792  Validation Loss:  0.7209175447451657\n",
      "Epoch:  8  Loss:  0.8150227423122322  Validation Loss:  0.7209538855300895\n",
      "Epoch:  9  Loss:  0.815091815226796  Validation Loss:  0.7209891166281084\n",
      "Epoch:  10  Loss:  0.8151593456806784  Validation Loss:  0.7210230024467255\n",
      "Epoch:  11  Loss:  0.815225513143973  Validation Loss:  0.7210548119940634\n",
      "Epoch:  12  Loss:  0.8152903072451326  Validation Loss:  0.7210854937418781\n",
      "Epoch:  13  Loss:  0.815353587968275  Validation Loss:  0.7211151261781824\n",
      "Epoch:  14  Loss:  0.8154160081281919  Validation Loss:  0.7211441259574274\n",
      "Epoch:  15  Loss:  0.8154775655235756  Validation Loss:  0.7211722608912607\n",
      "Epoch:  16  Loss:  0.815537542506883  Validation Loss:  0.7211991187570423\n",
      "Epoch:  17  Loss:  0.8155964264773171  Validation Loss:  0.7212247312197397\n",
      "Epoch:  18  Loss:  0.8156539977909151  Validation Loss:  0.7212486911308149\n",
      "Epoch:  19  Loss:  0.8157100162934512  Validation Loss:  0.7212708032336729\n",
      "Epoch:  20  Loss:  0.8157634500583465  Validation Loss:  0.7212914004921913\n",
      "Epoch:  21  Loss:  0.8158155561805788  Validation Loss:  0.721310882283182\n",
      "Epoch:  22  Loss:  0.8158663969529285  Validation Loss:  0.7213289401782997\n",
      "Epoch:  23  Loss:  0.8159153124275194  Validation Loss:  0.7213450486546961\n",
      "Epoch:  24  Loss:  0.8159620958084072  Validation Loss:  0.7213596702264301\n",
      "Epoch:  25  Loss:  0.816007309529761  Validation Loss:  0.7213729276353943\n",
      "Epoch:  26  Loss:  0.8160507739944891  Validation Loss:  0.7213840970191462\n",
      "Epoch:  27  Loss:  0.8160912706940011  Validation Loss:  0.7213927933239731\n",
      "Epoch:  28  Loss:  0.816129481271756  Validation Loss:  0.7213996527395372\n",
      "Epoch:  29  Loss:  0.8161655164704743  Validation Loss:  0.7214041909138704\n",
      "Epoch:  30  Loss:  0.8161983370823278  Validation Loss:  0.7214056581644148\n",
      "Epoch:  31  Loss:  0.8162279234648767  Validation Loss:  0.7214046640899675\n",
      "Epoch:  32  Loss:  0.8162545549725606  Validation Loss:  0.7214005496995203\n",
      "Epoch:  33  Loss:  0.8162775702181865  Validation Loss:  0.7213932214112118\n",
      "Epoch:  34  Loss:  0.8162966511127624  Validation Loss:  0.721382407214621\n",
      "Epoch:  35  Loss:  0.816312060225755  Validation Loss:  0.7213684353848984\n",
      "Epoch:  36  Loss:  0.8163234619635411  Validation Loss:  0.7213504838532415\n",
      "Epoch:  37  Loss:  0.8163309475745667  Validation Loss:  0.7213294341004101\n",
      "Epoch:  38  Loss:  0.8163349397522821  Validation Loss:  0.7213049651733761\n",
      "Epoch:  39  Loss:  0.8163351522208276  Validation Loss:  0.7212773819036525\n",
      "Epoch:  40  Loss:  0.8163324272979728  Validation Loss:  0.7212471444930496\n",
      "Epoch:  41  Loss:  0.8163265040652319  Validation Loss:  0.7212139734805658\n",
      "Epoch:  42  Loss:  0.8163181300571357  Validation Loss:  0.7211785454559942\n",
      "Epoch:  43  Loss:  0.8163072591308843  Validation Loss:  0.7211407762149284\n",
      "Epoch:  44  Loss:  0.8162945835343138  Validation Loss:  0.7211012801733511\n",
      "Epoch:  45  Loss:  0.8162799852434546  Validation Loss:  0.7210598585420641\n",
      "Epoch:  46  Loss:  0.8162639362271875  Validation Loss:  0.7210168387612392\n",
      "Epoch:  47  Loss:  0.8162464057942006  Validation Loss:  0.720972129175889\n",
      "Epoch:  48  Loss:  0.8162274449344047  Validation Loss:  0.720925717775164\n",
      "Epoch:  49  Loss:  0.8162071278996088  Validation Loss:  0.7208775887586947\n",
      "Epoch:  50  Loss:  0.8161854830316522  Validation Loss:  0.7208276541967844\n",
      "Epoch:  51  Loss:  0.816162215820937  Validation Loss:  0.720775745231016\n",
      "Epoch:  52  Loss:  0.8161371818489649  Validation Loss:  0.7207216843320378\n",
      "Epoch:  53  Loss:  0.8161106133325533  Validation Loss:  0.7206658872550932\n",
      "Epoch:  54  Loss:  0.8160825468684462  Validation Loss:  0.7206079051669302\n",
      "Epoch:  55  Loss:  0.8160525963811035  Validation Loss:  0.72054766452518\n",
      "Epoch:  56  Loss:  0.8160209245768122  Validation Loss:  0.7204856105020334\n",
      "Epoch:  57  Loss:  0.8159874399954622  Validation Loss:  0.720421190341485\n",
      "Epoch:  58  Loss:  0.8159519314596598  Validation Loss:  0.7203546184404143\n",
      "Epoch:  59  Loss:  0.8159137965095314  Validation Loss:  0.7202857911972136\n",
      "Epoch:  60  Loss:  0.8158736850389026  Validation Loss:  0.7202150883345768\n",
      "Epoch:  61  Loss:  0.8158316261727702  Validation Loss:  0.7201428361365507\n",
      "Epoch:  62  Loss:  0.8157877894965085  Validation Loss:  0.720068831510585\n",
      "Epoch:  63  Loss:  0.8157415744128891  Validation Loss:  0.7199929724608002\n",
      "Epoch:  64  Loss:  0.8156932705420662  Validation Loss:  0.719915546027237\n",
      "Epoch:  65  Loss:  0.8156428443140943  Validation Loss:  0.7198365822691342\n",
      "Epoch:  66  Loss:  0.8155899126167324  Validation Loss:  0.7197558851591472\n",
      "Epoch:  67  Loss:  0.8155344048811292  Validation Loss:  0.7196735148799831\n",
      "Epoch:  68  Loss:  0.8154763447290118  Validation Loss:  0.7195893316047972\n",
      "Epoch:  69  Loss:  0.8154150736094876  Validation Loss:  0.7195029786049292\n",
      "Epoch:  70  Loss:  0.8153505283831195  Validation Loss:  0.7194144470809862\n",
      "Epoch:  71  Loss:  0.8152827548540451  Validation Loss:  0.7193240362123169\n",
      "Epoch:  72  Loss:  0.8152117837135765  Validation Loss:  0.7192312895866304\n",
      "Epoch:  73  Loss:  0.8151372368235819  Validation Loss:  0.7191361297435802\n",
      "Epoch:  74  Loss:  0.8150591132527386  Validation Loss:  0.7190385651614132\n",
      "Epoch:  75  Loss:  0.814977773105387  Validation Loss:  0.7189392902213951\n",
      "Epoch:  76  Loss:  0.8148936259729619  Validation Loss:  0.7188380420978727\n",
      "Epoch:  77  Loss:  0.8148068759844385  Validation Loss:  0.718735765408853\n",
      "Epoch:  78  Loss:  0.814717849610712  Validation Loss:  0.7186319698932869\n",
      "Epoch:  79  Loss:  0.8146267478057946  Validation Loss:  0.7185269411781738\n",
      "Epoch:  80  Loss:  0.8145342280622572  Validation Loss:  0.7184213624689085\n",
      "Epoch:  81  Loss:  0.814440844728696  Validation Loss:  0.7183151598377474\n",
      "Epoch:  82  Loss:  0.814346381992271  Validation Loss:  0.7182083497915802\n",
      "Epoch:  83  Loss:  0.8142514448951591  Validation Loss:  0.7181020154264467\n",
      "Epoch:  84  Loss:  0.8141566054387526  Validation Loss:  0.7179956552411976\n",
      "Epoch:  85  Loss:  0.8140613309277053  Validation Loss:  0.7178891363457359\n",
      "Epoch:  86  Loss:  0.8139662206045944  Validation Loss:  0.7177829202264547\n",
      "Epoch:  87  Loss:  0.8138708283024078  Validation Loss:  0.7176765610046428\n",
      "Epoch:  88  Loss:  0.8137755323921076  Validation Loss:  0.7175703654386874\n",
      "Epoch:  89  Loss:  0.8136805006705056  Validation Loss:  0.7174644327626146\n",
      "Epoch:  90  Loss:  0.8135860824576494  Validation Loss:  0.71735969873081\n",
      "Epoch:  91  Loss:  0.8134926757563583  Validation Loss:  0.7172553782062284\n",
      "Epoch:  92  Loss:  0.813399403874593  Validation Loss:  0.7171512057298216\n",
      "Epoch:  93  Loss:  0.8133065918121826  Validation Loss:  0.7170476816466143\n",
      "Epoch:  94  Loss:  0.8132148840443485  Validation Loss:  0.7169449699978376\n",
      "Epoch:  95  Loss:  0.8131237078712068  Validation Loss:  0.7168424731313154\n",
      "Epoch:  96  Loss:  0.8130328486334871  Validation Loss:  0.7167403194411047\n",
      "Epoch:  97  Loss:  0.8129426439462061  Validation Loss:  0.716638641110782\n",
      "Epoch:  98  Loss:  0.812852831853723  Validation Loss:  0.7165371732593611\n",
      "Epoch:  99  Loss:  0.8127633170013062  Validation Loss:  0.7164359903926479\n",
      "Epoch:  100  Loss:  0.8126745672727173  Validation Loss:  0.7163360039864121\n",
      "Epoch:  101  Loss:  0.8125865860757503  Validation Loss:  0.7162363429007859\n",
      "Epoch:  102  Loss:  0.8124987246278166  Validation Loss:  0.7161365855999035\n",
      "Epoch:  103  Loss:  0.8124109948985279  Validation Loss:  0.7160375612820017\n",
      "Epoch:  104  Loss:  0.8123240249485455  Validation Loss:  0.7159387905407568\n",
      "Epoch:  105  Loss:  0.8122372060209851  Validation Loss:  0.7158401368892399\n",
      "Epoch:  106  Loss:  0.8121506869475442  Validation Loss:  0.7157418343142189\n",
      "Epoch:  107  Loss:  0.8120648732874542  Validation Loss:  0.715644058803546\n",
      "Epoch:  108  Loss:  0.8119793908924542  Validation Loss:  0.7155464330110056\n",
      "Epoch:  109  Loss:  0.8118940582287244  Validation Loss:  0.7154488702272547\n",
      "Epoch:  110  Loss:  0.8118089830121872  Validation Loss:  0.7153516143945784\n",
      "Epoch:  111  Loss:  0.8117244282568042  Validation Loss:  0.7152548480522016\n",
      "Epoch:  112  Loss:  0.8116404018894007  Validation Loss:  0.7151582957855587\n",
      "Epoch:  113  Loss:  0.8115559575063261  Validation Loss:  0.7150611967362207\n",
      "Epoch:  114  Loss:  0.8114712077235295  Validation Loss:  0.7149642478546192\n",
      "Epoch:  115  Loss:  0.8113870659038763  Validation Loss:  0.7148685751418615\n",
      "Epoch:  116  Loss:  0.8113043108341199  Validation Loss:  0.7147737911677566\n",
      "Epoch:  117  Loss:  0.8112220096571202  Validation Loss:  0.7146791910174591\n",
      "Epoch:  118  Loss:  0.811139873419465  Validation Loss:  0.7145846916426872\n",
      "Epoch:  119  Loss:  0.8110579105453904  Validation Loss:  0.7144903406372358\n",
      "Epoch:  120  Loss:  0.8109758277317848  Validation Loss:  0.7143956194150036\n",
      "Epoch:  121  Loss:  0.8108933036406101  Validation Loss:  0.7143011466953261\n",
      "Epoch:  122  Loss:  0.8108115056212145  Validation Loss:  0.7142070118209412\n",
      "Epoch:  123  Loss:  0.8107299393741414  Validation Loss:  0.7141130717535471\n",
      "Epoch:  124  Loss:  0.8106485073116015  Validation Loss:  0.7140192406830089\n",
      "Epoch:  125  Loss:  0.8105671177512374  Validation Loss:  0.7139252317619735\n",
      "Epoch:  126  Loss:  0.810485076773065  Validation Loss:  0.7138309446002903\n",
      "Epoch:  127  Loss:  0.8104030728890476  Validation Loss:  0.713736804202199\n",
      "Epoch:  128  Loss:  0.8103213377550922  Validation Loss:  0.7136430090357517\n",
      "Epoch:  129  Loss:  0.81024015432393  Validation Loss:  0.7135494084193789\n",
      "Epoch:  130  Loss:  0.8101585606240075  Validation Loss:  0.7134555348933771\n",
      "Epoch:  131  Loss:  0.8100769719828598  Validation Loss:  0.7133618002307827\n",
      "Epoch:  132  Loss:  0.8099955265643075  Validation Loss:  0.7132681580581541\n",
      "Epoch:  133  Loss:  0.809913930461996  Validation Loss:  0.7131747431924631\n",
      "Epoch:  134  Loss:  0.8098326029615815  Validation Loss:  0.7130816707965629\n",
      "Epoch:  135  Loss:  0.8097513976866718  Validation Loss:  0.7129884935787012\n",
      "Epoch:  136  Loss:  0.8096695796438408  Validation Loss:  0.7128950015095801\n",
      "Epoch:  137  Loss:  0.8095878634538333  Validation Loss:  0.712801747345205\n",
      "Epoch:  138  Loss:  0.8095060444373469  Validation Loss:  0.7127083225882259\n",
      "Epoch:  139  Loss:  0.8094242782416669  Validation Loss:  0.7126149846048191\n",
      "Epoch:  140  Loss:  0.8093419814461165  Validation Loss:  0.7125211848781027\n",
      "Epoch:  141  Loss:  0.8092594285051085  Validation Loss:  0.7124272199540302\n",
      "Epoch:  142  Loss:  0.8091762539803643  Validation Loss:  0.712333036458184\n",
      "Epoch:  143  Loss:  0.8090925675033677  Validation Loss:  0.7122383178693468\n",
      "Epoch:  144  Loss:  0.809008381890387  Validation Loss:  0.7121433243155479\n",
      "Epoch:  145  Loss:  0.8089234824504026  Validation Loss:  0.7120479171902969\n",
      "Epoch:  146  Loss:  0.8088378078537062  Validation Loss:  0.7119519592359148\n",
      "Epoch:  147  Loss:  0.8087512848009779  Validation Loss:  0.7118554400472805\n",
      "Epoch:  148  Loss:  0.8086638893106614  Validation Loss:  0.7117583638635175\n",
      "Epoch:  149  Loss:  0.8085756006079133  Validation Loss:  0.7116607541282629\n",
      "Epoch:  150  Loss:  0.8084864647932012  Validation Loss:  0.7115626008859997\n",
      "Epoch:  151  Loss:  0.8083966092566367  Validation Loss:  0.7114642335680025\n",
      "Epoch:  152  Loss:  0.8083055285546421  Validation Loss:  0.7113648328673223\n",
      "Epoch:  153  Loss:  0.8082129916239699  Validation Loss:  0.7112645468963631\n",
      "Epoch:  154  Loss:  0.8081188978288661  Validation Loss:  0.7111631961988991\n",
      "Epoch:  155  Loss:  0.808023139633323  Validation Loss:  0.7110607523856491\n",
      "Epoch:  156  Loss:  0.8079255812759087  Validation Loss:  0.710957068114959\n",
      "Epoch:  157  Loss:  0.8078261842549016  Validation Loss:  0.7108521941920807\n",
      "Epoch:  158  Loss:  0.8077249746579169  Validation Loss:  0.7107461657503555\n",
      "Epoch:  159  Loss:  0.8076219253707677  Validation Loss:  0.7106389224786183\n",
      "Epoch:  160  Loss:  0.8075173406396061  Validation Loss:  0.7105309609966032\n",
      "Epoch:  161  Loss:  0.8074114066971974  Validation Loss:  0.7104221141800798\n",
      "Epoch:  162  Loss:  0.8073039929678832  Validation Loss:  0.7103122879333538\n",
      "Epoch:  163  Loss:  0.8071953146295114  Validation Loss:  0.7102018240839243\n",
      "Epoch:  164  Loss:  0.807085629563186  Validation Loss:  0.7100907514064476\n",
      "Epoch:  165  Loss:  0.8069749963152307  Validation Loss:  0.7099790896834999\n",
      "Epoch:  166  Loss:  0.8068638873625208  Validation Loss:  0.7098673267996517\n",
      "Epoch:  167  Loss:  0.8067525892243297  Validation Loss:  0.7097558329074547\n",
      "Epoch:  168  Loss:  0.8066412755499848  Validation Loss:  0.7096439211404529\n",
      "Epoch:  169  Loss:  0.8065297155196525  Validation Loss:  0.7095322274313919\n",
      "Epoch:  170  Loss:  0.8064183977707713  Validation Loss:  0.7094207108020782\n",
      "Epoch:  171  Loss:  0.8063072675458071  Validation Loss:  0.7093093821714664\n",
      "Epoch:  172  Loss:  0.8061963620870798  Validation Loss:  0.7091982183528358\n",
      "Epoch:  173  Loss:  0.8060856604927473  Validation Loss:  0.7090872611593584\n",
      "Epoch:  174  Loss:  0.8059751535871659  Validation Loss:  0.7089764843855438\n",
      "Epoch:  175  Loss:  0.8058648829411884  Validation Loss:  0.7088658877744757\n",
      "Epoch:  176  Loss:  0.8057547762926499  Validation Loss:  0.708755494320187\n",
      "Epoch:  177  Loss:  0.8056449371241879  Validation Loss:  0.7086453150700907\n",
      "Epoch:  178  Loss:  0.8055354072183202  Validation Loss:  0.7085355845247877\n",
      "Epoch:  179  Loss:  0.8054261809659444  Validation Loss:  0.7084261861726128\n",
      "Epoch:  180  Loss:  0.8053176026177508  Validation Loss:  0.7083174762283934\n",
      "Epoch:  181  Loss:  0.8052097813818943  Validation Loss:  0.7082090363677206\n",
      "Epoch:  182  Loss:  0.8051022128519517  Validation Loss:  0.7081007944612667\n",
      "Epoch:  183  Loss:  0.8049948133676398  Validation Loss:  0.7079927413884936\n",
      "Epoch:  184  Loss:  0.8048876329981298  Validation Loss:  0.7078848505585358\n",
      "Epoch:  185  Loss:  0.804780667679469  Validation Loss:  0.7077771382855957\n",
      "Epoch:  186  Loss:  0.8046741857595573  Validation Loss:  0.7076701189166513\n",
      "Epoch:  187  Loss:  0.8045685780446299  Validation Loss:  0.7075633776598963\n",
      "Epoch:  188  Loss:  0.8044631952441044  Validation Loss:  0.7074568985222742\n",
      "Epoch:  189  Loss:  0.8043580561749298  Validation Loss:  0.7073505969140036\n",
      "Epoch:  190  Loss:  0.8042531760451808  Validation Loss:  0.707244526016815\n",
      "Epoch:  191  Loss:  0.8041487771975384  Validation Loss:  0.7071389255980993\n",
      "Epoch:  192  Loss:  0.8040448982501402  Validation Loss:  0.7070335959694509\n",
      "Epoch:  193  Loss:  0.8039413237605583  Validation Loss:  0.7069285972493475\n",
      "Epoch:  194  Loss:  0.80383861315733  Validation Loss:  0.7068242616309174\n",
      "Epoch:  195  Loss:  0.8037363852966916  Validation Loss:  0.70672014766726\n",
      "Epoch:  196  Loss:  0.8036343833135272  Validation Loss:  0.7066161450127075\n",
      "Epoch:  197  Loss:  0.803532546851784  Validation Loss:  0.7065123802629011\n",
      "Epoch:  198  Loss:  0.8034309316744012  Validation Loss:  0.7064087439071516\n",
      "Epoch:  199  Loss:  0.8033294978403401  Validation Loss:  0.7063053203425531\n",
      "Epoch:  200  Loss:  0.8032282996732234  Validation Loss:  0.706202098971297\n",
      "Epoch:  201  Loss:  0.8031273059631613  Validation Loss:  0.7060990113893459\n",
      "Epoch:  202  Loss:  0.803026528944346  Validation Loss:  0.7059961477744168\n",
      "Epoch:  203  Loss:  0.8029260621300306  Validation Loss:  0.7058936572665798\n",
      "Epoch:  204  Loss:  0.8028264052171091  Validation Loss:  0.7057917345443676\n",
      "Epoch:  205  Loss:  0.8027272808937017  Validation Loss:  0.7056902217967757\n",
      "Epoch:  206  Loss:  0.802628724581816  Validation Loss:  0.7055891843448425\n",
      "Epoch:  207  Loss:  0.8025304976300421  Validation Loss:  0.7054883232019071\n",
      "Epoch:  208  Loss:  0.8024324739711698  Validation Loss:  0.7053876167869774\n",
      "Epoch:  209  Loss:  0.8023346452127126  Validation Loss:  0.7052870902136482\n",
      "Epoch:  210  Loss:  0.8022369971625846  Validation Loss:  0.7051867356459642\n",
      "Epoch:  211  Loss:  0.8021395508919589  Validation Loss:  0.7050865614979431\n",
      "Epoch:  212  Loss:  0.8020423172909598  Validation Loss:  0.704986552483049\n",
      "Epoch:  213  Loss:  0.8019452879036014  Validation Loss:  0.7048867414866028\n",
      "Epoch:  214  Loss:  0.8018484674923291  Validation Loss:  0.7047871262605848\n",
      "Epoch:  215  Loss:  0.801751854120415  Validation Loss:  0.7046876308861477\n",
      "Epoch:  216  Loss:  0.8016554482429373  Validation Loss:  0.7045883683423544\n",
      "Epoch:  217  Loss:  0.8015592121730812  Validation Loss:  0.704489236890242\n",
      "Epoch:  218  Loss:  0.8014635713665154  Validation Loss:  0.7043908085545589\n",
      "Epoch:  219  Loss:  0.801368661023761  Validation Loss:  0.7042926244180778\n",
      "Epoch:  220  Loss:  0.801273927886293  Validation Loss:  0.7041946022032664\n",
      "Epoch:  221  Loss:  0.8011793956922536  Validation Loss:  0.7040967387628967\n",
      "Epoch:  222  Loss:  0.8010850691300054  Validation Loss:  0.7039990723775379\n",
      "Epoch:  223  Loss:  0.8009909330549735  Validation Loss:  0.7039015495443138\n",
      "Epoch:  224  Loss:  0.800896965073083  Validation Loss:  0.7038042073876694\n",
      "Epoch:  225  Loss:  0.8008032864256  Validation Loss:  0.7037072718657297\n",
      "Epoch:  226  Loss:  0.8007098739670421  Validation Loss:  0.7036106378996166\n",
      "Epoch:  227  Loss:  0.8006167192625898  Validation Loss:  0.7035141561565728\n",
      "Epoch:  228  Loss:  0.8005237656708976  Validation Loss:  0.7034178832867022\n",
      "Epoch:  229  Loss:  0.8004310233835977  Validation Loss:  0.7033218259056067\n",
      "Epoch:  230  Loss:  0.800338543581099  Validation Loss:  0.7032259127189373\n",
      "Epoch:  231  Loss:  0.8002463230355219  Validation Loss:  0.7031302631286711\n",
      "Epoch:  232  Loss:  0.8001545128222047  Validation Loss:  0.7030349981425137\n",
      "Epoch:  233  Loss:  0.8000631694025784  Validation Loss:  0.7029400064513601\n",
      "Epoch:  234  Loss:  0.7999720990192145  Validation Loss:  0.7028452000612843\n",
      "Epoch:  235  Loss:  0.7998812180647458  Validation Loss:  0.7027505030534391\n",
      "Epoch:  236  Loss:  0.7997905348787423  Validation Loss:  0.7026560106796438\n",
      "Epoch:  237  Loss:  0.7997000355654481  Validation Loss:  0.7025616859439118\n",
      "Epoch:  238  Loss:  0.799609715510583  Validation Loss:  0.7024675374529485\n",
      "Epoch:  239  Loss:  0.7995195924092762  Validation Loss:  0.7023735251919977\n",
      "Epoch:  240  Loss:  0.7994296679865908  Validation Loss:  0.7022796649614285\n",
      "Epoch:  241  Loss:  0.7993399331515486  Validation Loss:  0.7021859766722753\n",
      "Epoch:  242  Loss:  0.7992503873114898  Validation Loss:  0.7020924990547115\n",
      "Epoch:  243  Loss:  0.799161409959197  Validation Loss:  0.7019996533876863\n",
      "Epoch:  244  Loss:  0.7990731248441576  Validation Loss:  0.7019070539109665\n",
      "Epoch:  245  Loss:  0.7989850317720663  Validation Loss:  0.7018146216869354\n",
      "Epoch:  246  Loss:  0.7988971460144967  Validation Loss:  0.7017223633311945\n",
      "Epoch:  247  Loss:  0.7988094642377374  Validation Loss:  0.7016303276578928\n",
      "Epoch:  248  Loss:  0.7987219884843481  Validation Loss:  0.70153841048736\n",
      "Epoch:  249  Loss:  0.7986347084780309  Validation Loss:  0.7014466727088238\n",
      "Epoch:  250  Loss:  0.7985475956017829  Validation Loss:  0.7013550894013767\n",
      "Epoch:  251  Loss:  0.7984606893733144  Validation Loss:  0.701263677328825\n",
      "Epoch:  252  Loss:  0.7983739447928119  Validation Loss:  0.7011724104783659\n",
      "Epoch:  253  Loss:  0.7982874071987515  Validation Loss:  0.7010813397837097\n",
      "Epoch:  254  Loss:  0.798201045635241  Validation Loss:  0.7009904150176665\n",
      "Epoch:  255  Loss:  0.7981148752574385  Validation Loss:  0.7008996275093021\n",
      "Epoch:  256  Loss:  0.7980289000340484  Validation Loss:  0.7008090145757486\n",
      "Epoch:  257  Loss:  0.7979431184516712  Validation Loss:  0.7007185895124386\n",
      "Epoch:  258  Loss:  0.7978575018721379  Validation Loss:  0.7006283043402022\n",
      "Epoch:  259  Loss:  0.7977720945650204  Validation Loss:  0.7005381980461294\n",
      "Epoch:  260  Loss:  0.7976868637752804  Validation Loss:  0.7004482216233837\n",
      "Epoch:  261  Loss:  0.797601806296205  Validation Loss:  0.7003584371173176\n",
      "Epoch:  262  Loss:  0.7975169459082694  Validation Loss:  0.7002688047058624\n",
      "Epoch:  263  Loss:  0.7974322803466666  Validation Loss:  0.700179301587672\n",
      "Epoch:  264  Loss:  0.7973478024148128  Validation Loss:  0.7000900187754425\n",
      "Epoch:  265  Loss:  0.7972634880253199  Validation Loss:  0.7000008552367317\n",
      "Epoch:  266  Loss:  0.7971793967616659  Validation Loss:  0.6999119040395679\n",
      "Epoch:  267  Loss:  0.7970955225067552  Validation Loss:  0.6998231358312327\n",
      "Epoch:  268  Loss:  0.7970118347809396  Validation Loss:  0.699734507899346\n",
      "Epoch:  269  Loss:  0.7969283545178107  Validation Loss:  0.6996460810046772\n",
      "Epoch:  270  Loss:  0.7968450943113897  Validation Loss:  0.6995578323458803\n",
      "Epoch:  271  Loss:  0.7967620377259498  Validation Loss:  0.6994697165771805\n",
      "Epoch:  272  Loss:  0.7966791738713668  Validation Loss:  0.6993818241974403\n",
      "Epoch:  273  Loss:  0.7965964876559817  Validation Loss:  0.6992940448609919\n",
      "Epoch:  274  Loss:  0.7965140058129857  Validation Loss:  0.6992064248770475\n",
      "Epoch:  275  Loss:  0.7964317138433795  Validation Loss:  0.6991189761279986\n",
      "Epoch:  276  Loss:  0.7963495871517807  Validation Loss:  0.6990317217363365\n",
      "Epoch:  277  Loss:  0.7962676610437814  Validation Loss:  0.6989446024827916\n",
      "Epoch:  278  Loss:  0.7961859082993628  Validation Loss:  0.6988576276805895\n",
      "Epoch:  279  Loss:  0.7961043422110379  Validation Loss:  0.6987708373444861\n",
      "Epoch:  280  Loss:  0.7960229914698919  Validation Loss:  0.6986842008371805\n",
      "Epoch:  281  Loss:  0.7959418191193518  Validation Loss:  0.698597749759411\n",
      "Epoch:  282  Loss:  0.7958608108509163  Validation Loss:  0.6985114049808733\n",
      "Epoch:  283  Loss:  0.7957800069548697  Validation Loss:  0.6984252586703876\n",
      "Epoch:  284  Loss:  0.7956993840740655  Validation Loss:  0.6983392650968042\n",
      "Epoch:  285  Loss:  0.795618943287991  Validation Loss:  0.6982534227828527\n",
      "Epoch:  286  Loss:  0.7955387043343349  Validation Loss:  0.6981677687887488\n",
      "Epoch:  287  Loss:  0.7954586387865923  Validation Loss:  0.6980822767805437\n",
      "Epoch:  288  Loss:  0.7953787593869492  Validation Loss:  0.6979969430971762\n",
      "Epoch:  289  Loss:  0.7952991207553581  Validation Loss:  0.6979117631783773\n",
      "Epoch:  290  Loss:  0.795219652746296  Validation Loss:  0.6978267979776037\n",
      "Epoch:  291  Loss:  0.7951403818177906  Validation Loss:  0.6977419704198837\n",
      "Epoch:  292  Loss:  0.7950613120867108  Validation Loss:  0.6976573493588587\n",
      "Epoch:  293  Loss:  0.7949824072949757  Validation Loss:  0.69757288598038\n",
      "Epoch:  294  Loss:  0.7949037109713324  Validation Loss:  0.6974885508032709\n",
      "Epoch:  295  Loss:  0.7948252185861665  Validation Loss:  0.6974044005418646\n",
      "Epoch:  296  Loss:  0.7947470709596846  Validation Loss:  0.6973206707886581\n",
      "Epoch:  297  Loss:  0.7946695290421221  Validation Loss:  0.6972373745179382\n",
      "Epoch:  298  Loss:  0.7945924052566459  Validation Loss:  0.6971542892399533\n",
      "Epoch:  299  Loss:  0.7945154684447598  Validation Loss:  0.6970713785367793\n",
      "Epoch:  300  Loss:  0.7944388511400162  Validation Loss:  0.6969888349673872\n",
      "Epoch:  301  Loss:  0.7943626722236249  Validation Loss:  0.6969065916692389\n",
      "Epoch:  302  Loss:  0.794286765793169  Validation Loss:  0.6968246948873175\n",
      "Epoch:  303  Loss:  0.7942111397543076  Validation Loss:  0.6967429277840359\n",
      "Epoch:  304  Loss:  0.7941356988898902  Validation Loss:  0.6966613116192406\n",
      "Epoch:  305  Loss:  0.7940604367653247  Validation Loss:  0.6965798689373608\n",
      "Epoch:  306  Loss:  0.7939853483853354  Validation Loss:  0.696498581625778\n",
      "Epoch:  307  Loss:  0.793910454842262  Validation Loss:  0.6964174752476914\n",
      "Epoch:  308  Loss:  0.7938357481351969  Validation Loss:  0.6963365129355726\n",
      "Epoch:  309  Loss:  0.7937612015521154  Validation Loss:  0.6962556972585875\n",
      "Epoch:  310  Loss:  0.7936869334768165  Validation Loss:  0.6961750931523997\n",
      "Epoch:  311  Loss:  0.7936128317695957  Validation Loss:  0.6960946614372319\n",
      "Epoch:  312  Loss:  0.7935390556231141  Validation Loss:  0.6960144759765987\n",
      "Epoch:  313  Loss:  0.7934655845906078  Validation Loss:  0.6959345299622108\n",
      "Epoch:  314  Loss:  0.793392465269955  Validation Loss:  0.6958548664275942\n",
      "Epoch:  315  Loss:  0.7933196103284982  Validation Loss:  0.6957753792019754\n",
      "Epoch:  316  Loss:  0.7932469725333662  Validation Loss:  0.6956960591648159\n",
      "Epoch:  317  Loss:  0.793174527712505  Validation Loss:  0.6956169092064274\n",
      "Epoch:  318  Loss:  0.79310226355764  Validation Loss:  0.6955379004236953\n",
      "Epoch:  319  Loss:  0.7930302028120919  Validation Loss:  0.6954590934489308\n",
      "Epoch:  320  Loss:  0.792958298264156  Validation Loss:  0.6953804058761432\n",
      "Epoch:  321  Loss:  0.7928865749960426  Validation Loss:  0.6953018738021111\n",
      "Epoch:  322  Loss:  0.7928150298327885  Validation Loss:  0.6952235023651657\n",
      "Epoch:  323  Loss:  0.7927436735692688  Validation Loss:  0.6951452941987021\n",
      "Epoch:  324  Loss:  0.7926725064488974  Validation Loss:  0.6950672257306247\n",
      "Epoch:  325  Loss:  0.7926014924675904  Validation Loss:  0.6949893351130444\n",
      "Epoch:  326  Loss:  0.7925307214873928  Validation Loss:  0.6949116847766884\n",
      "Epoch:  327  Loss:  0.7924601762365042  Validation Loss:  0.6948343579625261\n",
      "Epoch:  328  Loss:  0.7923898810139772  Validation Loss:  0.6947572704019218\n",
      "Epoch:  329  Loss:  0.7923197964079339  Validation Loss:  0.6946803389181351\n",
      "Epoch:  330  Loss:  0.7922498909227381  Validation Loss:  0.694603593120801\n",
      "Epoch:  331  Loss:  0.7921801663152027  Validation Loss:  0.6945269831681046\n",
      "Epoch:  332  Loss:  0.7921106433284215  Validation Loss:  0.6944505197863127\n",
      "Epoch:  333  Loss:  0.7920412809418683  Validation Loss:  0.6943742031038835\n",
      "Epoch:  334  Loss:  0.7919720917918973  Validation Loss:  0.6942980634369726\n",
      "Epoch:  335  Loss:  0.7919031021142886  Validation Loss:  0.694222074644319\n",
      "Epoch:  336  Loss:  0.7918342932614244  Validation Loss:  0.6941462428919201\n",
      "Epoch:  337  Loss:  0.7917656614233486  Validation Loss:  0.6940706085799069\n",
      "Epoch:  338  Loss:  0.7916972011391242  Validation Loss:  0.693995119811132\n",
      "Epoch:  339  Loss:  0.7916289511750537  Validation Loss:  0.6939197981023583\n",
      "Epoch:  340  Loss:  0.7915608790300955  Validation Loss:  0.6938445898222512\n",
      "Epoch:  341  Loss:  0.7914929841962558  Validation Loss:  0.6937695766702808\n",
      "Epoch:  342  Loss:  0.7914252668957819  Validation Loss:  0.6936947502966585\n",
      "Epoch:  343  Loss:  0.7913577383680438  Validation Loss:  0.6936200690166704\n",
      "Epoch:  344  Loss:  0.7912904067197815  Validation Loss:  0.6935455555674331\n",
      "Epoch:  345  Loss:  0.7912232492076741  Validation Loss:  0.6934712114904461\n",
      "Epoch:  346  Loss:  0.7911562848180025  Validation Loss:  0.6933970412175203\n",
      "Epoch:  347  Loss:  0.7910894799808209  Validation Loss:  0.6933230408949071\n",
      "Epoch:  348  Loss:  0.7910229279553856  Validation Loss:  0.6932492289563705\n",
      "Epoch:  349  Loss:  0.7909565386891534  Validation Loss:  0.6931755740580887\n",
      "Epoch:  350  Loss:  0.790890330014835  Validation Loss:  0.6931020880824533\n",
      "Epoch:  351  Loss:  0.7908243267288939  Validation Loss:  0.6930287832330013\n",
      "Epoch:  352  Loss:  0.7907585093370554  Validation Loss:  0.692955651930694\n",
      "Epoch:  353  Loss:  0.7906928695103322  Validation Loss:  0.6928826331578452\n",
      "Epoch:  354  Loss:  0.7906274369452149  Validation Loss:  0.6928098671266745\n",
      "Epoch:  355  Loss:  0.7905621849931777  Validation Loss:  0.6927372623106529\n",
      "Epoch:  356  Loss:  0.7904971317515116  Validation Loss:  0.6926647824845438\n",
      "Epoch:  357  Loss:  0.7904322593769227  Validation Loss:  0.6925924906571364\n",
      "Epoch:  358  Loss:  0.7903675421522084  Validation Loss:  0.6925203228562042\n",
      "Epoch:  359  Loss:  0.7903030330357566  Validation Loss:  0.6924483269966882\n",
      "Epoch:  360  Loss:  0.7902386900333856  Validation Loss:  0.6923764750104526\n",
      "Epoch:  361  Loss:  0.7901745111025362  Validation Loss:  0.6923048063341913\n",
      "Epoch:  362  Loss:  0.7901105202565138  Validation Loss:  0.6922332669511951\n",
      "Epoch:  363  Loss:  0.7900467121825469  Validation Loss:  0.692161841189553\n",
      "Epoch:  364  Loss:  0.7899830859598957  Validation Loss:  0.6920906247506882\n",
      "Epoch:  365  Loss:  0.7899196302539415  Validation Loss:  0.6920195318244654\n",
      "Epoch:  366  Loss:  0.7898563567802988  Validation Loss:  0.6919486143080325\n",
      "Epoch:  367  Loss:  0.7897932582788847  Validation Loss:  0.6918778262133228\n",
      "Epoch:  368  Loss:  0.7897303242194043  Validation Loss:  0.6918072035728857\n",
      "Epoch:  369  Loss:  0.7896675826791166  Validation Loss:  0.6917367347612463\n",
      "Epoch:  370  Loss:  0.7896050063110042  Validation Loss:  0.6916664108505537\n",
      "Epoch:  371  Loss:  0.7895426275420256  Validation Loss:  0.6915962473842604\n",
      "Epoch:  372  Loss:  0.7894804217556323  Validation Loss:  0.6915262152023357\n",
      "Epoch:  373  Loss:  0.7894183857980269  Validation Loss:  0.6914563891959602\n",
      "Epoch:  374  Loss:  0.7893565335332162  Validation Loss:  0.6913866603682781\n",
      "Epoch:  375  Loss:  0.7892948558278889  Validation Loss:  0.6913170905077252\n",
      "Epoch:  376  Loss:  0.789233367212794  Validation Loss:  0.6912476979196072\n",
      "Epoch:  377  Loss:  0.7891720227622003  Validation Loss:  0.691178440405377\n",
      "Epoch:  378  Loss:  0.7891108901028268  Validation Loss:  0.6911093317743006\n",
      "Epoch:  379  Loss:  0.7890499117255042  Validation Loss:  0.6910403945708069\n",
      "Epoch:  380  Loss:  0.788989120237106  Validation Loss:  0.6909715980933658\n",
      "Epoch:  381  Loss:  0.7889285185797648  Validation Loss:  0.6909029267985245\n",
      "Epoch:  382  Loss:  0.7888680814172734  Validation Loss:  0.6908344618076908\n",
      "Epoch:  383  Loss:  0.7888078268892555  Validation Loss:  0.690766119301833\n",
      "Epoch:  384  Loss:  0.7887477432377636  Validation Loss:  0.6906979157878407\n",
      "Epoch:  385  Loss:  0.7886878290128979  Validation Loss:  0.6906299172932732\n",
      "Epoch:  386  Loss:  0.7886281235947866  Validation Loss:  0.6905620443666803\n",
      "Epoch:  387  Loss:  0.7885686025150459  Validation Loss:  0.6904943705504311\n",
      "Epoch:  388  Loss:  0.788509240776131  Validation Loss:  0.6904267556323059\n",
      "Epoch:  389  Loss:  0.7884500525383786  Validation Loss:  0.6903593431644398\n",
      "Epoch:  390  Loss:  0.7883910237472843  Validation Loss:  0.6902920474651558\n",
      "Epoch:  391  Loss:  0.7883321904704313  Validation Loss:  0.6902249510689028\n",
      "Epoch:  392  Loss:  0.7882735347057778  Validation Loss:  0.6901579735607937\n",
      "Epoch:  393  Loss:  0.7882150455102832  Validation Loss:  0.6900911670948925\n",
      "Epoch:  394  Loss:  0.7881567261329937  Validation Loss:  0.6900244685339516\n",
      "Epoch:  395  Loss:  0.7880986101015217  Validation Loss:  0.6899579710102287\n",
      "Epoch:  396  Loss:  0.7880406525113027  Validation Loss:  0.6898916267372411\n",
      "Epoch:  397  Loss:  0.7879828788890418  Validation Loss:  0.6898254185015785\n",
      "Epoch:  398  Loss:  0.7879252656235952  Validation Loss:  0.6897593509277393\n",
      "Epoch:  399  Loss:  0.7878678661601787  Validation Loss:  0.689693457928711\n",
      "Epoch:  400  Loss:  0.7878106121312488  Validation Loss:  0.689627693002594\n",
      "Epoch:  401  Loss:  0.7877535259626298  Validation Loss:  0.6895620972560398\n",
      "Epoch:  402  Loss:  0.78769662943457  Validation Loss:  0.6894966322800209\n",
      "Epoch:  403  Loss:  0.7876399144297466  Validation Loss:  0.6894313369331688\n",
      "Epoch:  404  Loss:  0.7875833834881302  Validation Loss:  0.6893661586118156\n",
      "Epoch:  405  Loss:  0.7875270057914101  Validation Loss:  0.6893011753543697\n",
      "Epoch:  406  Loss:  0.787470825841989  Validation Loss:  0.6892363430354101\n",
      "Epoch:  407  Loss:  0.7874148127368905  Validation Loss:  0.6891716493229414\n",
      "Epoch:  408  Loss:  0.7873589777472344  Validation Loss:  0.6891071034017308\n",
      "Epoch:  409  Loss:  0.7873033583693375  Validation Loss:  0.6890427301284568\n",
      "Epoch:  410  Loss:  0.7872479330346157  Validation Loss:  0.688978575555415\n",
      "Epoch:  411  Loss:  0.7871926794442433  Validation Loss:  0.6889145622222588\n",
      "Epoch:  412  Loss:  0.7871376397723163  Validation Loss:  0.6888507252623295\n",
      "Epoch:  413  Loss:  0.7870827731358904  Validation Loss:  0.6887870219632469\n",
      "Epoch:  414  Loss:  0.7870280549078333  Validation Loss:  0.6887234676115471\n",
      "Epoch:  415  Loss:  0.7869735596680336  Validation Loss:  0.6886600651617708\n",
      "Epoch:  416  Loss:  0.7869192057035186  Validation Loss:  0.6885968056218378\n",
      "Epoch:  417  Loss:  0.786865039929663  Validation Loss:  0.6885337162891338\n",
      "Epoch:  418  Loss:  0.7868110342692076  Validation Loss:  0.6884707569562155\n",
      "Epoch:  419  Loss:  0.7867572142700241  Validation Loss:  0.6884079603799458\n",
      "Epoch:  420  Loss:  0.7867036029294302  Validation Loss:  0.6883452991987097\n",
      "Epoch:  421  Loss:  0.7866501169893044  Validation Loss:  0.6882828068116615\n",
      "Epoch:  422  Loss:  0.7865968419408257  Validation Loss:  0.6882204555360407\n",
      "Epoch:  423  Loss:  0.7865437238519504  Validation Loss:  0.6881582717700251\n",
      "Epoch:  424  Loss:  0.7864907749039545  Validation Loss:  0.6880962038091545\n",
      "Epoch:  425  Loss:  0.7864380223591897  Validation Loss:  0.6880343329675239\n",
      "Epoch:  426  Loss:  0.7863854284038428  Validation Loss:  0.6879725488994656\n",
      "Epoch:  427  Loss:  0.7863330201203511  Validation Loss:  0.6879109650336462\n",
      "Epoch:  428  Loss:  0.7862807916456156  Validation Loss:  0.6878495482278282\n",
      "Epoch:  429  Loss:  0.7862287341849878  Validation Loss:  0.6877882342528681\n",
      "Epoch:  430  Loss:  0.7861768247199837  Validation Loss:  0.6877270699318113\n",
      "Epoch:  431  Loss:  0.7861251228234984  Validation Loss:  0.6876660945728935\n",
      "Epoch:  432  Loss:  0.7860735976454717  Validation Loss:  0.687605250883719\n",
      "Epoch:  433  Loss:  0.7860222238285298  Validation Loss:  0.6875445363593513\n",
      "Epoch:  434  Loss:  0.7859710269946266  Validation Loss:  0.6874839745718857\n",
      "Epoch:  435  Loss:  0.7859200036301363  Validation Loss:  0.687423559933387\n",
      "Epoch:  436  Loss:  0.7858691734198312  Validation Loss:  0.6873633047758505\n",
      "Epoch:  437  Loss:  0.7858185053972359  Validation Loss:  0.6873031722317482\n",
      "Epoch:  438  Loss:  0.7857679819730534  Validation Loss:  0.6872431568416029\n",
      "Epoch:  439  Loss:  0.7857176522851329  Validation Loss:  0.6871833000332117\n",
      "Epoch:  440  Loss:  0.7856674847637557  Validation Loss:  0.6871235901810999\n",
      "Epoch:  441  Loss:  0.7856175077507611  Validation Loss:  0.6870639971617994\n",
      "Epoch:  442  Loss:  0.7855676884911108  Validation Loss:  0.6870045701748339\n",
      "Epoch:  443  Loss:  0.7855180269742216  Validation Loss:  0.6869453395363586\n",
      "Epoch:  444  Loss:  0.7854685595428402  Validation Loss:  0.6868861853305636\n",
      "Epoch:  445  Loss:  0.7854192534419284  Validation Loss:  0.6868271895138354\n",
      "Epoch:  446  Loss:  0.7853701015913181  Validation Loss:  0.6867683480397381\n",
      "Epoch:  447  Loss:  0.7853211570023135  Validation Loss:  0.6867096681019356\n",
      "Epoch:  448  Loss:  0.7852723586097867  Validation Loss:  0.6866511069238186\n",
      "Epoch:  449  Loss:  0.7852237514664673  Validation Loss:  0.6865926930873558\n",
      "Epoch:  450  Loss:  0.7851753166495737  Validation Loss:  0.6865344503573303\n",
      "Epoch:  451  Loss:  0.7851270510370589  Validation Loss:  0.6864763040994776\n",
      "Epoch:  452  Loss:  0.7850789566926489  Validation Loss:  0.6864183552820107\n",
      "Epoch:  453  Loss:  0.7850310443053868  Validation Loss:  0.6863605278576242\n",
      "Epoch:  454  Loss:  0.7849832892798904  Validation Loss:  0.6863028840643579\n",
      "Epoch:  455  Loss:  0.7849357276519929  Validation Loss:  0.6862453797767902\n",
      "Epoch:  456  Loss:  0.7848883225392043  Validation Loss:  0.6861879805681007\n",
      "Epoch:  457  Loss:  0.7848410918694836  Validation Loss:  0.6861307735972363\n",
      "Epoch:  458  Loss:  0.7847940529357981  Validation Loss:  0.6860737148672342\n",
      "Epoch:  459  Loss:  0.784747174221345  Validation Loss:  0.6860168054057606\n",
      "Epoch:  460  Loss:  0.7847004632084545  Validation Loss:  0.6859600444420658\n",
      "Epoch:  461  Loss:  0.7846539451486685  Validation Loss:  0.6859033987054537\n",
      "Epoch:  462  Loss:  0.7846075940919532  Validation Loss:  0.685846928250173\n",
      "Epoch:  463  Loss:  0.7845614051065323  Validation Loss:  0.685790591841114\n",
      "Epoch:  464  Loss:  0.7845153999409046  Validation Loss:  0.6857344253181383\n",
      "Epoch:  465  Loss:  0.7844695649321445  Validation Loss:  0.6856784083206078\n",
      "Epoch:  466  Loss:  0.7844239088431508  Validation Loss:  0.6856225567131207\n",
      "Epoch:  467  Loss:  0.7843784184343267  Validation Loss:  0.6855668650361998\n",
      "Epoch:  468  Loss:  0.784333118787882  Validation Loss:  0.6855113169756429\n",
      "Epoch:  469  Loss:  0.7842879656871612  Validation Loss:  0.6854559240284664\n",
      "Epoch:  470  Loss:  0.7842430070529438  Validation Loss:  0.6854007287785925\n",
      "Epoch:  471  Loss:  0.7841982319845225  Validation Loss:  0.6853456418832828\n",
      "Epoch:  472  Loss:  0.7841536143836989  Validation Loss:  0.6852907664303122\n",
      "Epoch:  473  Loss:  0.7841091937893494  Validation Loss:  0.6852360142330671\n",
      "Epoch:  474  Loss:  0.7840649285142056  Validation Loss:  0.6851814250493872\n",
      "Epoch:  475  Loss:  0.7840208493024957  Validation Loss:  0.6851269717103449\n",
      "Epoch:  476  Loss:  0.7839769197373905  Validation Loss:  0.6850727340527649\n",
      "Epoch:  477  Loss:  0.7839331882794134  Validation Loss:  0.6850185817557162\n",
      "Epoch:  478  Loss:  0.7838896305342629  Validation Loss:  0.684964615530495\n",
      "Epoch:  479  Loss:  0.7838462381517853  Validation Loss:  0.6849108001795309\n",
      "Epoch:  480  Loss:  0.7838030239694159  Validation Loss:  0.684857121443954\n",
      "Epoch:  481  Loss:  0.783759998739697  Validation Loss:  0.6848035825352217\n",
      "Epoch:  482  Loss:  0.7837171282471073  Validation Loss:  0.6847502108149487\n",
      "Epoch:  483  Loss:  0.7836744226197797  Validation Loss:  0.6846969733335848\n",
      "Epoch:  484  Loss:  0.7836319009074941  Validation Loss:  0.6846439011780352\n",
      "Epoch:  485  Loss:  0.783589550039985  Validation Loss:  0.68459095985725\n",
      "Epoch:  486  Loss:  0.7835473599632017  Validation Loss:  0.6845381769897609\n",
      "Epoch:  487  Loss:  0.7835053508910774  Validation Loss:  0.6844855721012272\n",
      "Epoch:  488  Loss:  0.783463510134342  Validation Loss:  0.6844331080672043\n",
      "Epoch:  489  Loss:  0.783421845831485  Validation Loss:  0.684380729201025\n",
      "Epoch:  490  Loss:  0.7833803486586972  Validation Loss:  0.6843285584372694\n",
      "Epoch:  491  Loss:  0.7833390092921697  Validation Loss:  0.6842765172236952\n",
      "Epoch:  492  Loss:  0.7832978564864871  Validation Loss:  0.6842246221314217\n",
      "Epoch:  493  Loss:  0.7832568831403147  Validation Loss:  0.6841728716831783\n",
      "Epoch:  494  Loss:  0.7832160862586037  Validation Loss:  0.6841212737791497\n",
      "Epoch:  495  Loss:  0.7831754378275946  Validation Loss:  0.684069836961812\n",
      "Epoch:  496  Loss:  0.7831349790900607  Validation Loss:  0.6840185433754633\n",
      "Epoch:  497  Loss:  0.7830946820428256  Validation Loss:  0.6839673840280237\n",
      "Epoch:  498  Loss:  0.7830545731333338  Validation Loss:  0.6839163845469212\n",
      "Epoch:  499  Loss:  0.7830146297135137  Validation Loss:  0.6838654943838202\n",
      "Epoch:  500  Loss:  0.7829748499736359  Validation Loss:  0.6838148664683104\n",
      "Epoch:  501  Loss:  0.7829354790737852  Validation Loss:  0.6837645253359244\n",
      "Epoch:  502  Loss:  0.7828964130974121  Validation Loss:  0.6837144132446626\n",
      "Epoch:  503  Loss:  0.7828577091091905  Validation Loss:  0.6836645529958708\n",
      "Epoch:  504  Loss:  0.7828192874916237  Validation Loss:  0.6836148859483415\n",
      "Epoch:  505  Loss:  0.7827810652300038  Validation Loss:  0.6835653339352074\n",
      "Epoch:  506  Loss:  0.7827430052090097  Validation Loss:  0.6835159570107172\n",
      "Epoch:  507  Loss:  0.7827051228272136  Validation Loss:  0.6834666941571852\n",
      "Epoch:  508  Loss:  0.7826674037020315  Validation Loss:  0.6834175900138658\n",
      "Epoch:  509  Loss:  0.7826298728098415  Validation Loss:  0.6833686218436422\n",
      "Epoch:  510  Loss:  0.7825924781341613  Validation Loss:  0.6833198209261072\n",
      "Epoch:  511  Loss:  0.7825552798617124  Validation Loss:  0.6832711326664892\n",
      "Epoch:  512  Loss:  0.7825182392579418  Validation Loss:  0.6832225856467568\n",
      "Epoch:  513  Loss:  0.7824813491051  Validation Loss:  0.6831742236069565\n",
      "Epoch:  514  Loss:  0.7824446578531272  Validation Loss:  0.6831259610580986\n",
      "Epoch:  515  Loss:  0.7824081341968849  Validation Loss:  0.6830778527234135\n",
      "Epoch:  516  Loss:  0.7823717559327964  Validation Loss:  0.6830299107422089\n",
      "Epoch:  517  Loss:  0.7823355635310608  Validation Loss:  0.6829820929159378\n",
      "Epoch:  518  Loss:  0.782299520490183  Validation Loss:  0.6829344178068226\n",
      "Epoch:  519  Loss:  0.7822636483787474  Validation Loss:  0.6828868682014531\n",
      "Epoch:  520  Loss:  0.7822279555892403  Validation Loss:  0.6828395055028899\n",
      "Epoch:  521  Loss:  0.7821924229237166  Validation Loss:  0.6827922513515785\n",
      "Epoch:  522  Loss:  0.7821570679820566  Validation Loss:  0.6827451647098722\n",
      "Epoch:  523  Loss:  0.7821218567180701  Validation Loss:  0.6826982085175556\n",
      "Epoch:  524  Loss:  0.7820868318350139  Validation Loss:  0.6826513750671312\n",
      "Epoch:  525  Loss:  0.7820519835857506  Validation Loss:  0.6826047266608682\n",
      "Epoch:  526  Loss:  0.7820173249876295  Validation Loss:  0.6825582132642639\n",
      "Epoch:  527  Loss:  0.7819828518496995  Validation Loss:  0.6825118342350269\n",
      "Epoch:  528  Loss:  0.7819485269613903  Validation Loss:  0.6824656327351414\n",
      "Epoch:  529  Loss:  0.7819144174202599  Validation Loss:  0.6824195751085363\n",
      "Epoch:  530  Loss:  0.781880580957725  Validation Loss:  0.6823736962316365\n",
      "Epoch:  531  Loss:  0.7818469670177861  Validation Loss:  0.682328017749663\n",
      "Epoch:  532  Loss:  0.7818135086933828  Validation Loss:  0.6822824868020313\n",
      "Epoch:  533  Loss:  0.781780328813263  Validation Loss:  0.6822371424400601\n",
      "Epoch:  534  Loss:  0.7817473657196388  Validation Loss:  0.6821919096441105\n",
      "Epoch:  535  Loss:  0.781714554071765  Validation Loss:  0.6821468509733677\n",
      "Epoch:  536  Loss:  0.7816819185602732  Validation Loss:  0.6821019320652403\n",
      "Epoch:  537  Loss:  0.7816494429081847  Validation Loss:  0.6820571493871254\n",
      "Epoch:  538  Loss:  0.7816171340686693  Validation Loss:  0.6820125053797302\n",
      "Epoch:  539  Loss:  0.7815850064137273  Validation Loss:  0.6819680104481762\n",
      "Epoch:  540  Loss:  0.781553012213077  Validation Loss:  0.6819236292664347\n",
      "Epoch:  541  Loss:  0.781521208605475  Validation Loss:  0.6818793992800959\n",
      "Epoch:  542  Loss:  0.7814895513425157  Validation Loss:  0.6818353271047617\n",
      "Epoch:  543  Loss:  0.7814580472080376  Validation Loss:  0.6817913853145879\n",
      "Epoch:  544  Loss:  0.7814267356139184  Validation Loss:  0.6817475742307203\n",
      "Epoch:  545  Loss:  0.7813955902502957  Validation Loss:  0.6817039025240931\n",
      "Epoch:  546  Loss:  0.7813645885643464  Validation Loss:  0.6816603683962904\n",
      "Epoch:  547  Loss:  0.781333735032769  Validation Loss:  0.6816169841793077\n",
      "Epoch:  548  Loss:  0.7813030569179152  Validation Loss:  0.6815737523780815\n",
      "Epoch:  549  Loss:  0.7812725646124984  Validation Loss:  0.6815306211596933\n",
      "Epoch:  550  Loss:  0.7812422075287693  Validation Loss:  0.6814876433847279\n",
      "Epoch:  551  Loss:  0.7812119970225136  Validation Loss:  0.6814447762765761\n",
      "Epoch:  552  Loss:  0.7811819752678275  Validation Loss:  0.681402065694846\n",
      "Epoch:  553  Loss:  0.7811521065887064  Validation Loss:  0.6813594403451887\n",
      "Epoch:  554  Loss:  0.7811223792060363  Validation Loss:  0.6813169570703959\n",
      "Epoch:  555  Loss:  0.7810928252186965  Validation Loss:  0.6812746091906366\n",
      "Epoch:  556  Loss:  0.7810634020504288  Validation Loss:  0.6812323977978065\n",
      "Epoch:  557  Loss:  0.7810341720469296  Validation Loss:  0.6811903052931202\n",
      "Epoch:  558  Loss:  0.7810050972144712  Validation Loss:  0.681148384344475\n",
      "Epoch:  559  Loss:  0.7809761631493033  Validation Loss:  0.6811065687316245\n",
      "Epoch:  560  Loss:  0.7809474023948  Validation Loss:  0.6810648796501858\n",
      "Epoch:  561  Loss:  0.7809187961551785  Validation Loss:  0.6810233321297785\n",
      "Epoch:  562  Loss:  0.780890342705375  Validation Loss:  0.680981923665466\n",
      "Epoch:  563  Loss:  0.7808620663444427  Validation Loss:  0.680940674810574\n",
      "Epoch:  564  Loss:  0.7808339573569935  Validation Loss:  0.6808995196017725\n",
      "Epoch:  565  Loss:  0.7808060037628324  Validation Loss:  0.6808585372335952\n",
      "Epoch:  566  Loss:  0.7807782050222158  Validation Loss:  0.6808176797268719\n",
      "Epoch:  567  Loss:  0.7807505654954267  Validation Loss:  0.680776945347416\n",
      "Epoch:  568  Loss:  0.7807231012266129  Validation Loss:  0.6807363783491069\n",
      "Epoch:  569  Loss:  0.7806957907741889  Validation Loss:  0.6806959594632017\n",
      "Epoch:  570  Loss:  0.7806686198190701  Validation Loss:  0.6806556146334986\n",
      "Epoch:  571  Loss:  0.780641654072414  Validation Loss:  0.6806154621058497\n",
      "Epoch:  572  Loss:  0.7806148266483267  Validation Loss:  0.6805754233280132\n",
      "Epoch:  573  Loss:  0.7805881608616222  Validation Loss:  0.6805355386358911\n",
      "Epoch:  574  Loss:  0.7805616616334935  Validation Loss:  0.6804957960186333\n",
      "Epoch:  575  Loss:  0.7805353261911395  Validation Loss:  0.6804561636185852\n",
      "Epoch:  576  Loss:  0.7805091399826448  Validation Loss:  0.6804166885799375\n",
      "Epoch:  577  Loss:  0.7804831191368232  Validation Loss:  0.6803773604975693\n",
      "Epoch:  578  Loss:  0.780457259462723  Validation Loss:  0.6803381296581236\n",
      "Epoch:  579  Loss:  0.7804315792269666  Validation Loss:  0.6802990597126812\n",
      "Epoch:  580  Loss:  0.7804060229629447  Validation Loss:  0.680260129337167\n",
      "Epoch:  581  Loss:  0.7803806549848311  Validation Loss:  0.6802213329436451\n",
      "Epoch:  582  Loss:  0.7803554493531754  Validation Loss:  0.6801827081061643\n",
      "Epoch:  583  Loss:  0.780330376106907  Validation Loss:  0.6801441577744896\n",
      "Epoch:  584  Loss:  0.78030547645705  Validation Loss:  0.6801057689148804\n",
      "Epoch:  585  Loss:  0.7802807314173233  Validation Loss:  0.6800675128811392\n",
      "Epoch:  586  Loss:  0.7802561701021411  Validation Loss:  0.680029407657426\n",
      "Epoch:  587  Loss:  0.7802317489933391  Validation Loss:  0.6799914396271624\n",
      "Epoch:  588  Loss:  0.7802074800922789  Validation Loss:  0.6799536092399523\n",
      "Epoch:  589  Loss:  0.7801833931166171  Validation Loss:  0.6799158889414936\n",
      "Epoch:  590  Loss:  0.7801594527607615  Validation Loss:  0.6798783292801216\n",
      "Epoch:  591  Loss:  0.7801356902981008  Validation Loss:  0.679840901352722\n",
      "Epoch:  592  Loss:  0.7801120819481597  Validation Loss:  0.6798035979014019\n",
      "Epoch:  593  Loss:  0.7800886216573417  Validation Loss:  0.6797664237433466\n",
      "Epoch:  594  Loss:  0.7800653202840212  Validation Loss:  0.6797294292984337\n",
      "Epoch:  595  Loss:  0.7800421856597743  Validation Loss:  0.6796925441715224\n",
      "Epoch:  596  Loss:  0.780019216874445  Validation Loss:  0.6796557867321474\n",
      "Epoch:  597  Loss:  0.7799963955979117  Validation Loss:  0.6796191831215702\n",
      "Epoch:  598  Loss:  0.7799737370594151  Validation Loss:  0.6795826777173527\n",
      "Epoch:  599  Loss:  0.779951240401715  Validation Loss:  0.6795463255638706\n",
      "Epoch:  600  Loss:  0.779928893856281  Validation Loss:  0.6795101100257759\n",
      "Epoch:  601  Loss:  0.7799067265481096  Validation Loss:  0.679474043948897\n",
      "Epoch:  602  Loss:  0.7798847072038122  Validation Loss:  0.6794381216810695\n",
      "Epoch:  603  Loss:  0.7798628397180106  Validation Loss:  0.6794023136126583\n",
      "Epoch:  604  Loss:  0.7798411342929202  Validation Loss:  0.6793666462060707\n",
      "Epoch:  605  Loss:  0.7798195956592363  Validation Loss:  0.6793310955038359\n",
      "Epoch:  606  Loss:  0.7797982216685672  Validation Loss:  0.6792957077509371\n",
      "Epoch:  607  Loss:  0.7797769896093417  Validation Loss:  0.6792604614306113\n",
      "Epoch:  608  Loss:  0.7797559282996438  Validation Loss:  0.6792253169777065\n",
      "Epoch:  609  Loss:  0.7797350126466799  Validation Loss:  0.6791903347033879\n",
      "Epoch:  610  Loss:  0.7797142533924092  Validation Loss:  0.6791554689407349\n",
      "Epoch:  611  Loss:  0.7796936699146912  Validation Loss:  0.6791207731283945\n",
      "Epoch:  612  Loss:  0.7796732228757306  Validation Loss:  0.6790861979383847\n",
      "Epoch:  613  Loss:  0.7796529502375051  Validation Loss:  0.6790517734941738\n",
      "Epoch:  614  Loss:  0.7796329196902331  Validation Loss:  0.6790176076364929\n",
      "Epoch:  615  Loss:  0.7796131360916082  Validation Loss:  0.6789836234830576\n",
      "Epoch:  616  Loss:  0.7795935774920508  Validation Loss:  0.678949853212669\n",
      "Epoch:  617  Loss:  0.7795742146924816  Validation Loss:  0.6789162411386597\n",
      "Epoch:  618  Loss:  0.7795550358608704  Validation Loss:  0.6788827992076504\n",
      "Epoch:  619  Loss:  0.7795360505221073  Validation Loss:  0.6788495202259771\n",
      "Epoch:  620  Loss:  0.7795172409387305  Validation Loss:  0.6788163739417133\n",
      "Epoch:  621  Loss:  0.7794985378436237  Validation Loss:  0.6787833229092688\n",
      "Epoch:  622  Loss:  0.7794799870832569  Validation Loss:  0.6787504383587631\n",
      "Epoch:  623  Loss:  0.7794616657880727  Validation Loss:  0.6787176689711111\n",
      "Epoch:  624  Loss:  0.7794434351592578  Validation Loss:  0.678684055227144\n",
      "Epoch:  625  Loss:  0.7794248864626173  Validation Loss:  0.6786499638752691\n",
      "Epoch:  626  Loss:  0.7794060886689377  Validation Loss:  0.678615517850066\n",
      "Epoch:  627  Loss:  0.7793871214062992  Validation Loss:  0.6785806300568169\n",
      "Epoch:  628  Loss:  0.7793682226276194  Validation Loss:  0.6785457420708805\n",
      "Epoch:  629  Loss:  0.7793494510908865  Validation Loss:  0.6785110079137415\n",
      "Epoch:  630  Loss:  0.7793308497533541  Validation Loss:  0.6784764118492603\n",
      "Epoch:  631  Loss:  0.7793123998615722  Validation Loss:  0.6784419590157682\n",
      "Epoch:  632  Loss:  0.7792941060192375  Validation Loss:  0.6784076287957101\n",
      "Epoch:  633  Loss:  0.7792759635591541  Validation Loss:  0.6783734260705011\n",
      "Epoch:  634  Loss:  0.7792579727247357  Validation Loss:  0.6783393528954736\n",
      "Epoch:  635  Loss:  0.7792401601327583  Validation Loss:  0.6783053919287592\n",
      "Epoch:  636  Loss:  0.7792224811749872  Validation Loss:  0.6782715931406309\n",
      "Epoch:  637  Loss:  0.7792049495672638  Validation Loss:  0.6782379389965328\n",
      "Epoch:  638  Loss:  0.7791875877883285  Validation Loss:  0.6782044086219936\n",
      "Epoch:  639  Loss:  0.7791703888638453  Validation Loss:  0.6781709833263323\n",
      "Epoch:  640  Loss:  0.7791533271824433  Validation Loss:  0.6781377136578848\n",
      "Epoch:  641  Loss:  0.7791364208096638  Validation Loss:  0.678104552536689\n",
      "Epoch:  642  Loss:  0.7791196705921638  Validation Loss:  0.6780715171761554\n",
      "Epoch:  643  Loss:  0.7791030761595308  Validation Loss:  0.6780386457926241\n",
      "Epoch:  644  Loss:  0.7790866446554322  Validation Loss:  0.6780058972152143\n",
      "Epoch:  645  Loss:  0.7790703551780264  Validation Loss:  0.6779732692601352\n",
      "Epoch:  646  Loss:  0.7790542436361482  Validation Loss:  0.6779407874263567\n",
      "Epoch:  647  Loss:  0.7790382441387258  Validation Loss:  0.6779084142682881\n",
      "Epoch:  648  Loss:  0.7790224318159744  Validation Loss:  0.6778761766979406\n",
      "Epoch:  649  Loss:  0.7790067605991763  Validation Loss:  0.6778440813951451\n",
      "Epoch:  650  Loss:  0.7789912475167181  Validation Loss:  0.6778121176336346\n",
      "Epoch:  651  Loss:  0.7789758984211155  Validation Loss:  0.6777802647958542\n",
      "Epoch:  652  Loss:  0.7789606854891066  Validation Loss:  0.6777485558955834\n",
      "Epoch:  653  Loss:  0.7789456280879676  Validation Loss:  0.6777169798854096\n",
      "Epoch:  654  Loss:  0.7789307321548801  Validation Loss:  0.6776855309204809\n",
      "Epoch:  655  Loss:  0.778915952922861  Validation Loss:  0.6776541420098009\n",
      "Epoch:  656  Loss:  0.7789013774282384  Validation Loss:  0.6776229007619208\n",
      "Epoch:  657  Loss:  0.7788868791910566  Validation Loss:  0.6775917983774481\n",
      "Epoch:  658  Loss:  0.7788725714093413  Validation Loss:  0.6775607949058557\n",
      "Epoch:  659  Loss:  0.7788584038763392  Validation Loss:  0.6775299252877975\n",
      "Epoch:  660  Loss:  0.7788443782324479  Validation Loss:  0.6774991615835962\n",
      "Epoch:  661  Loss:  0.7788304824233901  Validation Loss:  0.6774685304483463\n",
      "Epoch:  662  Loss:  0.7788167789218609  Validation Loss:  0.6774380026577875\n",
      "Epoch:  663  Loss:  0.7788031974659216  Validation Loss:  0.6774076304944425\n",
      "Epoch:  664  Loss:  0.7787897638362747  Validation Loss:  0.6773773472242314\n",
      "Epoch:  665  Loss:  0.7787764492995021  Validation Loss:  0.6773471734647093\n",
      "Epoch:  666  Loss:  0.7787633124548434  Validation Loss:  0.677317136063658\n",
      "Epoch:  667  Loss:  0.778750306640921  Validation Loss:  0.6772872338007236\n",
      "Epoch:  668  Loss:  0.7787374625702135  Validation Loss:  0.6772574685385515\n",
      "Epoch:  669  Loss:  0.7787247702945024  Validation Loss:  0.6772277885084522\n",
      "Epoch:  670  Loss:  0.7787122333591635  Validation Loss:  0.677198288512641\n",
      "Epoch:  671  Loss:  0.7786998493512246  Validation Loss:  0.6771688953298947\n",
      "Epoch:  672  Loss:  0.7786876275733282  Validation Loss:  0.677139642487826\n",
      "Epoch:  673  Loss:  0.7786755343179472  Validation Loss:  0.6771105026890492\n",
      "Epoch:  674  Loss:  0.7786636189663444  Validation Loss:  0.6770815114522802\n",
      "Epoch:  675  Loss:  0.7786518219032917  Validation Loss:  0.6770526454623403\n",
      "Epoch:  676  Loss:  0.7786402000876312  Validation Loss:  0.6770238920018591\n",
      "Epoch:  677  Loss:  0.7786287210818211  Validation Loss:  0.6769952978938818\n",
      "Epoch:  678  Loss:  0.7786173954902386  Validation Loss:  0.6769667958262665\n",
      "Epoch:  679  Loss:  0.7786062421086668  Validation Loss:  0.6769384245291866\n",
      "Epoch:  680  Loss:  0.7785952008138834  Validation Loss:  0.6769102301833958\n",
      "Epoch:  681  Loss:  0.7785843398993496  Validation Loss:  0.6768821106645567\n",
      "Epoch:  682  Loss:  0.7785736060785976  Validation Loss:  0.676854116071401\n",
      "Epoch:  683  Loss:  0.7785630268785595  Validation Loss:  0.6768262330442667\n",
      "Epoch:  684  Loss:  0.7785525740526448  Validation Loss:  0.6767984530406779\n",
      "Epoch:  685  Loss:  0.7785422935954888  Validation Loss:  0.6767707966781896\n",
      "Epoch:  686  Loss:  0.7785321331096136  Validation Loss:  0.676741905253509\n",
      "Epoch:  687  Loss:  0.778521380609494  Validation Loss:  0.6767125035282867\n",
      "Epoch:  688  Loss:  0.778510275053453  Validation Loss:  0.6766824403071198\n",
      "Epoch:  689  Loss:  0.7784992871827192  Validation Loss:  0.6766525801785034\n",
      "Epoch:  690  Loss:  0.7784884740090505  Validation Loss:  0.6766229119023373\n",
      "Epoch:  691  Loss:  0.7784778156571768  Validation Loss:  0.6765934189075026\n",
      "Epoch:  692  Loss:  0.778467345781709  Validation Loss:  0.6765641200131384\n",
      "Epoch:  693  Loss:  0.7784570548260077  Validation Loss:  0.6765349605602438\n",
      "Epoch:  694  Loss:  0.7784468917684122  Validation Loss:  0.6765059325201758\n",
      "Epoch:  695  Loss:  0.7784368961160495  Validation Loss:  0.6764770620984251\n",
      "Epoch:  696  Loss:  0.7784270855217156  Validation Loss:  0.6764482955994278\n",
      "Epoch:  697  Loss:  0.77841739367101  Validation Loss:  0.6764197023906584\n",
      "Epoch:  698  Loss:  0.7784078673417256  Validation Loss:  0.6763912350710096\n",
      "Epoch:  699  Loss:  0.7783984953156587  Validation Loss:  0.6763628628747217\n",
      "Epoch:  700  Loss:  0.778389277328229  Validation Loss:  0.6763346385981502\n",
      "Epoch:  701  Loss:  0.7783802016320723  Validation Loss:  0.676306523960726\n",
      "Epoch:  702  Loss:  0.7783712723758072  Validation Loss:  0.6762785386165668\n",
      "Epoch:  703  Loss:  0.778362482405183  Validation Loss:  0.6762506627188675\n",
      "Epoch:  704  Loss:  0.7783538304502144  Validation Loss:  0.6762228584366625\n",
      "Epoch:  705  Loss:  0.7783453083300794  Validation Loss:  0.6761952045148817\n",
      "Epoch:  706  Loss:  0.778336953509345  Validation Loss:  0.6761676807213446\n",
      "Epoch:  707  Loss:  0.7783286899053068  Validation Loss:  0.6761387477404085\n",
      "Epoch:  708  Loss:  0.7783194576834582  Validation Loss:  0.6761086958877999\n",
      "Epoch:  709  Loss:  0.7783102187836035  Validation Loss:  0.6760787983778221\n",
      "Epoch:  710  Loss:  0.7783011108827353  Validation Loss:  0.6760490042767648\n",
      "Epoch:  711  Loss:  0.7782921343618496  Validation Loss:  0.6760193958621601\n",
      "Epoch:  712  Loss:  0.7782833289185708  Validation Loss:  0.6759898990135769\n",
      "Epoch:  713  Loss:  0.7782746447483078  Validation Loss:  0.675960519062034\n",
      "Epoch:  714  Loss:  0.7782660985513675  Validation Loss:  0.6759312845895002\n",
      "Epoch:  715  Loss:  0.7782577511706305  Validation Loss:  0.6759021574438646\n",
      "Epoch:  716  Loss:  0.77824949757831  Validation Loss:  0.6758731859254425\n",
      "Epoch:  717  Loss:  0.7782414214346897  Validation Loss:  0.6758443300194782\n",
      "Epoch:  718  Loss:  0.7782333671559833  Validation Loss:  0.6758136260483799\n",
      "Epoch:  719  Loss:  0.7782243520592932  Validation Loss:  0.6757822231999759\n",
      "Epoch:  720  Loss:  0.7782153561287983  Validation Loss:  0.675750916887974\n",
      "Epoch:  721  Loss:  0.778206540081142  Validation Loss:  0.675719728693366\n",
      "Epoch:  722  Loss:  0.7781978415917944  Validation Loss:  0.6756886551477785\n",
      "Epoch:  723  Loss:  0.7781892885898494  Validation Loss:  0.6756576835980703\n",
      "Epoch:  724  Loss:  0.7781808917749334  Validation Loss:  0.6756254606077383\n",
      "Epoch:  725  Loss:  0.7781715717865154  Validation Loss:  0.6755920028121307\n",
      "Epoch:  726  Loss:  0.7781621627615426  Validation Loss:  0.6755586350657816\n",
      "Epoch:  727  Loss:  0.778152906272391  Validation Loss:  0.6755254211482303\n",
      "Epoch:  728  Loss:  0.778143802033314  Validation Loss:  0.6754923390931097\n",
      "Epoch:  729  Loss:  0.7781347117640756  Validation Loss:  0.6754573156479103\n",
      "Epoch:  730  Loss:  0.7781246566446498  Validation Loss:  0.675421696862784\n",
      "Epoch:  731  Loss:  0.7781146910697729  Validation Loss:  0.6753861575933366\n",
      "Epoch:  732  Loss:  0.7781048152511093  Validation Loss:  0.6753490778521217\n",
      "Epoch:  733  Loss:  0.7780939832499082  Validation Loss:  0.6753110129000812\n",
      "Epoch:  734  Loss:  0.7780831115299158  Validation Loss:  0.6752730296475107\n",
      "Epoch:  735  Loss:  0.7780722503825515  Validation Loss:  0.6752330194516428\n",
      "Epoch:  736  Loss:  0.7780603998107836  Validation Loss:  0.6751925337031998\n",
      "Epoch:  737  Loss:  0.7780485899420455  Validation Loss:  0.6751501222365889\n",
      "Epoch:  738  Loss:  0.7780357691544023  Validation Loss:  0.6751065595910467\n",
      "Epoch:  739  Loss:  0.7780223849589344  Validation Loss:  0.6750609310151174\n",
      "Epoch:  740  Loss:  0.7780085082949054  Validation Loss:  0.6750138533333766\n",
      "Epoch:  741  Loss:  0.777993744683706  Validation Loss:  0.6749649552050335\n",
      "Epoch:  742  Loss:  0.7779781188688834  Validation Loss:  0.6749141657853435\n",
      "Epoch:  743  Loss:  0.7779619683807885  Validation Loss:  0.6748612455638319\n",
      "Epoch:  744  Loss:  0.7779447667787529  Validation Loss:  0.6748058725276898\n",
      "Epoch:  745  Loss:  0.7779264770003713  Validation Loss:  0.674747959228939\n",
      "Epoch:  746  Loss:  0.7779070694655688  Validation Loss:  0.6746874395436768\n",
      "Epoch:  747  Loss:  0.7778865490849554  Validation Loss:  0.6746242811967587\n",
      "Epoch:  748  Loss:  0.7778648815583438  Validation Loss:  0.6745584138251585\n",
      "Epoch:  749  Loss:  0.7778420796596699  Validation Loss:  0.67448991058587\n",
      "Epoch:  750  Loss:  0.7778181337899613  Validation Loss:  0.6744187589863251\n",
      "Epoch:  751  Loss:  0.7777931165817956  Validation Loss:  0.6743450833420301\n",
      "Epoch:  752  Loss:  0.7777670296861536  Validation Loss:  0.6742690388627094\n",
      "Epoch:  753  Loss:  0.7777399781625718  Validation Loss:  0.6741908861581107\n",
      "Epoch:  754  Loss:  0.7777119739171625  Validation Loss:  0.674111327798716\n",
      "Epoch:  755  Loss:  0.7776838799367066  Validation Loss:  0.674030595459044\n",
      "Epoch:  756  Loss:  0.7776549203342504  Validation Loss:  0.6739485997642423\n",
      "Epoch:  757  Loss:  0.7776259220819074  Validation Loss:  0.6738667758181691\n",
      "Epoch:  758  Loss:  0.7775970961030741  Validation Loss:  0.6737847122010486\n",
      "Epoch:  759  Loss:  0.7775682319294323  Validation Loss:  0.6737013635514625\n",
      "Epoch:  760  Loss:  0.7775387413037772  Validation Loss:  0.6736175530622232\n",
      "Epoch:  761  Loss:  0.7775092098163441  Validation Loss:  0.673533551427054\n",
      "Epoch:  762  Loss:  0.7774798274251886  Validation Loss:  0.6734496844803979\n",
      "Epoch:  763  Loss:  0.7774506709750064  Validation Loss:  0.6733659661278643\n",
      "Epoch:  764  Loss:  0.7774216763527048  Validation Loss:  0.6732823312089875\n",
      "Epoch:  765  Loss:  0.7773928532525051  Validation Loss:  0.6731988998643798\n",
      "Epoch:  766  Loss:  0.7773644050943073  Validation Loss:  0.6731162036223144\n",
      "Epoch:  767  Loss:  0.7773363844872537  Validation Loss:  0.6730353895510579\n",
      "Epoch:  768  Loss:  0.7773091847881336  Validation Loss:  0.6729551459630502\n",
      "Epoch:  769  Loss:  0.7772823221219535  Validation Loss:  0.6728750530566121\n",
      "Epoch:  770  Loss:  0.7772556186590175  Validation Loss:  0.6727950874523356\n",
      "Epoch:  771  Loss:  0.7772291193038903  Validation Loss:  0.6727152692860571\n",
      "Epoch:  772  Loss:  0.7772027698811144  Validation Loss:  0.6726356052697219\n",
      "Epoch:  773  Loss:  0.7771766214017671  Validation Loss:  0.6725560614261133\n",
      "Epoch:  774  Loss:  0.7771506659390236  Validation Loss:  0.6724766706405528\n",
      "Epoch:  775  Loss:  0.7771248580591584  Validation Loss:  0.6723973873424632\n",
      "Epoch:  776  Loss:  0.7770992141343992  Validation Loss:  0.6723182640712837\n",
      "Epoch:  777  Loss:  0.7770737601253628  Validation Loss:  0.672239305098252\n",
      "Epoch:  778  Loss:  0.7770484887402166  Validation Loss:  0.672160422911161\n",
      "Epoch:  779  Loss:  0.7770235602299429  Validation Loss:  0.6720822362293457\n",
      "Epoch:  780  Loss:  0.7769991030641408  Validation Loss:  0.6720062941955082\n",
      "Epoch:  781  Loss:  0.7769755740353669  Validation Loss:  0.6719305387152166\n",
      "Epoch:  782  Loss:  0.7769522230691192  Validation Loss:  0.6718548720959445\n",
      "Epoch:  783  Loss:  0.7769290568222377  Validation Loss:  0.6717793594339284\n",
      "Epoch:  784  Loss:  0.7769060312791474  Validation Loss:  0.6717039586590796\n",
      "Epoch:  785  Loss:  0.7768831927519799  Validation Loss:  0.6716287095292375\n",
      "Epoch:  786  Loss:  0.7768605414629829  Validation Loss:  0.6715535210959357\n",
      "Epoch:  787  Loss:  0.7768380414186553  Validation Loss:  0.6714784879687017\n",
      "Epoch:  788  Loss:  0.7768157399682836  Validation Loss:  0.6714036036282778\n",
      "Epoch:  789  Loss:  0.7767935719616204  Validation Loss:  0.6713287958811069\n",
      "Epoch:  790  Loss:  0.7767715687884695  Validation Loss:  0.6712541174914303\n",
      "Epoch:  791  Loss:  0.7767497656591744  Validation Loss:  0.6711795293758142\n",
      "Epoch:  792  Loss:  0.7767281029902567  Validation Loss:  0.6711050531152507\n",
      "Epoch:  793  Loss:  0.7767066046891903  Validation Loss:  0.6710307344087753\n",
      "Epoch:  794  Loss:  0.7766852904936637  Validation Loss:  0.670956472802008\n",
      "Epoch:  795  Loss:  0.7766641172241758  Validation Loss:  0.6708823594039884\n",
      "Epoch:  796  Loss:  0.7766431280919774  Validation Loss:  0.6708083064455924\n",
      "Epoch:  797  Loss:  0.7766222618943588  Validation Loss:  0.6707343915477395\n",
      "Epoch:  798  Loss:  0.7766015997939658  Validation Loss:  0.6706605417782376\n",
      "Epoch:  799  Loss:  0.7765812407967381  Validation Loss:  0.6705874859130588\n",
      "Epoch:  800  Loss:  0.776561344222335  Validation Loss:  0.6705163309735984\n",
      "Epoch:  801  Loss:  0.7765422387429598  Validation Loss:  0.6704454507100684\n",
      "Epoch:  802  Loss:  0.7765233785189181  Validation Loss:  0.6703746678821486\n",
      "Epoch:  803  Loss:  0.7765046570619399  Validation Loss:  0.6703039497972049\n",
      "Epoch:  804  Loss:  0.7764860879079524  Validation Loss:  0.6702333506967487\n",
      "Epoch:  805  Loss:  0.7764676940860227  Validation Loss:  0.6701628605610338\n",
      "Epoch:  806  Loss:  0.7764494217276066  Validation Loss:  0.6700924077424509\n",
      "Epoch:  807  Loss:  0.7764312567147003  Validation Loss:  0.6700220763811777\n",
      "Epoch:  808  Loss:  0.7764132724312897  Validation Loss:  0.6699518462771485\n",
      "Epoch:  809  Loss:  0.7763954172101379  Validation Loss:  0.6698817103330431\n",
      "Epoch:  810  Loss:  0.7763776943637904  Validation Loss:  0.6698116202806604\n",
      "Epoch:  811  Loss:  0.7763601294612851  Validation Loss:  0.6697415898329225\n",
      "Epoch:  812  Loss:  0.7763426726980304  Validation Loss:  0.6696716073001253\n",
      "Epoch:  813  Loss:  0.7763253676556897  Validation Loss:  0.6696016821881821\n",
      "Epoch:  814  Loss:  0.7763082005866718  Validation Loss:  0.6695317826394377\n",
      "Epoch:  815  Loss:  0.7762911666015332  Validation Loss:  0.669461929656822\n",
      "Epoch:  816  Loss:  0.7762742547784001  Validation Loss:  0.6693920581440987\n",
      "Epoch:  817  Loss:  0.776257453115911  Validation Loss:  0.669322252691049\n",
      "Epoch:  818  Loss:  0.7762408040527423  Validation Loss:  0.6692524425171572\n",
      "Epoch:  819  Loss:  0.7762242461639371  Validation Loss:  0.669182605848744\n",
      "Epoch:  820  Loss:  0.776207833529704  Validation Loss:  0.6691127820903885\n",
      "Epoch:  821  Loss:  0.7761915211078965  Validation Loss:  0.6690429715953511\n",
      "Epoch:  822  Loss:  0.7761752975956452  Validation Loss:  0.6689730801715933\n",
      "Epoch:  823  Loss:  0.7761592119720511  Validation Loss:  0.6689031286614722\n",
      "Epoch:  824  Loss:  0.776143197848631  Validation Loss:  0.6688331363658453\n",
      "Epoch:  825  Loss:  0.7761272646656091  Validation Loss:  0.6687630142310056\n",
      "Epoch:  826  Loss:  0.7761114148994569  Validation Loss:  0.6686927978398984\n",
      "Epoch:  827  Loss:  0.7760956323896111  Validation Loss:  0.6686224851693059\n",
      "Epoch:  828  Loss:  0.7760799294443462  Validation Loss:  0.6685519921753941\n",
      "Epoch:  829  Loss:  0.7760642526396127  Validation Loss:  0.6684813003922845\n",
      "Epoch:  830  Loss:  0.7760486430594359  Validation Loss:  0.6684104391084663\n",
      "Epoch:  831  Loss:  0.7760330600431189  Validation Loss:  0.6683392953448768\n",
      "Epoch:  832  Loss:  0.7760174932826142  Validation Loss:  0.6682678857689788\n",
      "Epoch:  833  Loss:  0.7760018977040256  Validation Loss:  0.6681961858131248\n",
      "Epoch:  834  Loss:  0.7759862902404909  Validation Loss:  0.6681241380243466\n",
      "Epoch:  835  Loss:  0.77597066515591  Validation Loss:  0.6680517539638897\n",
      "Epoch:  836  Loss:  0.7759549863086167  Validation Loss:  0.6679789262727417\n",
      "Epoch:  837  Loss:  0.7759392217690633  Validation Loss:  0.6679055715493601\n",
      "Epoch:  838  Loss:  0.7759233751990409  Validation Loss:  0.6678317372269672\n",
      "Epoch:  839  Loss:  0.775907435994172  Validation Loss:  0.667757329306212\n",
      "Epoch:  840  Loss:  0.7758913855703379  Validation Loss:  0.6676823366112237\n",
      "Epoch:  841  Loss:  0.7758752214933999  Validation Loss:  0.6676067931513334\n",
      "Epoch:  842  Loss:  0.7758589364926923  Validation Loss:  0.6675306132448644\n",
      "Epoch:  843  Loss:  0.7758425464853644  Validation Loss:  0.6674538562716595\n",
      "Epoch:  844  Loss:  0.7758260440631685  Validation Loss:  0.6673765286867475\n",
      "Epoch:  845  Loss:  0.7758094314274124  Validation Loss:  0.6672987583703522\n",
      "Epoch:  846  Loss:  0.7757928102404218  Validation Loss:  0.6672206015550884\n",
      "Epoch:  847  Loss:  0.7757761205588891  Validation Loss:  0.6671420372059119\n",
      "Epoch:  848  Loss:  0.7757594436195425  Validation Loss:  0.6670632396728314\n",
      "Epoch:  849  Loss:  0.7757427962708541  Validation Loss:  0.6669842308579848\n",
      "Epoch:  850  Loss:  0.7757262618767775  Validation Loss:  0.6669052793997629\n",
      "Epoch:  851  Loss:  0.7757099586411972  Validation Loss:  0.6668267408385873\n",
      "Epoch:  852  Loss:  0.7756939836968244  Validation Loss:  0.6667493239751664\n",
      "Epoch:  853  Loss:  0.7756784591739151  Validation Loss:  0.6666727067645768\n",
      "Epoch:  854  Loss:  0.7756634361047129  Validation Loss:  0.6665963676661767\n",
      "Epoch:  855  Loss:  0.7756486139895226  Validation Loss:  0.6665202041060246\n",
      "Epoch:  856  Loss:  0.7756339843829416  Validation Loss:  0.666444211555966\n",
      "Epoch:  857  Loss:  0.7756195082011718  Validation Loss:  0.6663683870935748\n",
      "Epoch:  858  Loss:  0.7756052739092741  Validation Loss:  0.6662927349579746\n",
      "Epoch:  859  Loss:  0.7755912350257859  Validation Loss:  0.6662173228145674\n",
      "Epoch:  860  Loss:  0.7755774062084542  Validation Loss:  0.6661420862736374\n",
      "Epoch:  861  Loss:  0.7755637885156003  Validation Loss:  0.6660670896285567\n",
      "Epoch:  862  Loss:  0.7755503975257109  Validation Loss:  0.6659922894604248\n",
      "Epoch:  863  Loss:  0.7755372073945843  Validation Loss:  0.6659177094376807\n",
      "Epoch:  864  Loss:  0.7755242567615245  Validation Loss:  0.6658433511339384\n",
      "Epoch:  865  Loss:  0.7755115294236351  Validation Loss:  0.6657692051717433\n",
      "Epoch:  866  Loss:  0.7754990027010948  Validation Loss:  0.665695303569323\n",
      "Epoch:  867  Loss:  0.7754867135928097  Validation Loss:  0.6656215994072885\n",
      "Epoch:  868  Loss:  0.7754746323705397  Validation Loss:  0.6655481157760168\n",
      "Epoch:  869  Loss:  0.7754627753006802  Validation Loss:  0.6654748407288872\n",
      "Epoch:  870  Loss:  0.7754511062203991  Validation Loss:  0.6654018283468383\n",
      "Epoch:  871  Loss:  0.7754396286115728  Validation Loss:  0.6653290590399812\n",
      "Epoch:  872  Loss:  0.7754283775892955  Validation Loss:  0.6652565116126989\n",
      "Epoch:  873  Loss:  0.7754173590272496  Validation Loss:  0.6651841688836957\n",
      "Epoch:  874  Loss:  0.7754065042192285  Validation Loss:  0.6651120345782617\n",
      "Epoch:  875  Loss:  0.7753958894066851  Validation Loss:  0.6650401402329063\n",
      "Epoch:  876  Loss:  0.7753854823954911  Validation Loss:  0.6649684192741225\n",
      "Epoch:  877  Loss:  0.7753752960548312  Validation Loss:  0.6648969318203884\n",
      "Epoch:  878  Loss:  0.7753653151872144  Validation Loss:  0.664825615665779\n",
      "Epoch:  879  Loss:  0.7753555450948294  Validation Loss:  0.6647545054298023\n",
      "Epoch:  880  Loss:  0.7753459840526127  Validation Loss:  0.6646836031356762\n",
      "Epoch:  881  Loss:  0.7753366107883101  Validation Loss:  0.664612878274558\n",
      "Epoch:  882  Loss:  0.7753274695714936  Validation Loss:  0.6645423910291545\n",
      "Epoch:  883  Loss:  0.7753184809963304  Validation Loss:  0.664472133884656\n",
      "Epoch:  884  Loss:  0.7753097007834268  Validation Loss:  0.6644020751439805\n",
      "Epoch:  885  Loss:  0.775301127133637  Validation Loss:  0.6643322135867744\n",
      "Epoch:  886  Loss:  0.7752927549776029  Validation Loss:  0.6642625399640408\n",
      "Epoch:  887  Loss:  0.775284575721757  Validation Loss:  0.6641930577762681\n",
      "Epoch:  888  Loss:  0.7752766095694493  Validation Loss:  0.6641237917837912\n",
      "Epoch:  889  Loss:  0.7752688439901579  Validation Loss:  0.6640546925301696\n",
      "Epoch:  890  Loss:  0.7752612765074115  Validation Loss:  0.6639857885010284\n",
      "Epoch:  891  Loss:  0.7752539311027662  Validation Loss:  0.6639170445951408\n",
      "Epoch:  892  Loss:  0.7752467479069971  Validation Loss:  0.663848511778332\n",
      "Epoch:  893  Loss:  0.7752397583416578  Validation Loss:  0.6637802059473149\n",
      "Epoch:  894  Loss:  0.7752329660897058  Validation Loss:  0.6637121304420048\n",
      "Epoch:  895  Loss:  0.7752263459630988  Validation Loss:  0.663644211720033\n",
      "Epoch:  896  Loss:  0.7752199364212257  Validation Loss:  0.6635764537314917\n",
      "Epoch:  897  Loss:  0.7752137135354463  Validation Loss:  0.6635088831957044\n",
      "Epoch:  898  Loss:  0.7752077063884247  Validation Loss:  0.6634415064071273\n",
      "Epoch:  899  Loss:  0.7752018888396296  Validation Loss:  0.6633742850530764\n",
      "Epoch:  900  Loss:  0.7751962594497441  Validation Loss:  0.6633072569645171\n",
      "Epoch:  901  Loss:  0.775190801507878  Validation Loss:  0.6632404708271397\n",
      "Epoch:  902  Loss:  0.7751855298199437  Validation Loss:  0.6631738678070491\n",
      "Epoch:  903  Loss:  0.7751804475397379  Validation Loss:  0.6631074576670754\n",
      "Epoch:  904  Loss:  0.7751755757066845  Validation Loss:  0.6630411964102552\n",
      "Epoch:  905  Loss:  0.7751708817139099  Validation Loss:  0.662975140750922\n",
      "Epoch:  906  Loss:  0.7751663924956863  Validation Loss:  0.6629092498072262\n",
      "Epoch:  907  Loss:  0.7751620870866728  Validation Loss:  0.6628435029937275\n",
      "Epoch:  908  Loss:  0.7751579232175242  Validation Loss:  0.6627780312415341\n",
      "Epoch:  909  Loss:  0.7751539870249954  Validation Loss:  0.6627127368902338\n",
      "Epoch:  910  Loss:  0.7751502130942588  Validation Loss:  0.6626475706760739\n",
      "Epoch:  911  Loss:  0.775146632338874  Validation Loss:  0.662582597245687\n",
      "Epoch:  912  Loss:  0.7751432449493388  Validation Loss:  0.6625178106257628\n",
      "Epoch:  913  Loss:  0.775140055031939  Validation Loss:  0.6624531911942979\n",
      "Epoch:  914  Loss:  0.7751370110887695  Validation Loss:  0.6623888402406511\n",
      "Epoch:  915  Loss:  0.7751341422554106  Validation Loss:  0.6623245930170705\n",
      "Epoch:  916  Loss:  0.7751314769266173  Validation Loss:  0.6622605322185775\n",
      "Epoch:  917  Loss:  0.7751289917664095  Validation Loss:  0.6621966806144036\n",
      "Epoch:  918  Loss:  0.7751267003318802  Validation Loss:  0.6621329680020953\n",
      "Epoch:  919  Loss:  0.7751245460134338  Validation Loss:  0.6620695084526107\n",
      "Epoch:  920  Loss:  0.7751226120374419  Validation Loss:  0.662006242136503\n",
      "Epoch:  921  Loss:  0.7751208366297017  Validation Loss:  0.6619431133671053\n",
      "Epoch:  922  Loss:  0.7751192559212954  Validation Loss:  0.6618801532313228\n",
      "Epoch:  923  Loss:  0.7751178302251819  Validation Loss:  0.6618173586782711\n",
      "Epoch:  924  Loss:  0.775116571129977  Validation Loss:  0.6617548394755557\n",
      "Epoch:  925  Loss:  0.7751155263659629  Validation Loss:  0.6616924269895615\n",
      "Epoch:  926  Loss:  0.7751146470492875  Validation Loss:  0.6616302091821\n",
      "Epoch:  927  Loss:  0.7751139130930162  Validation Loss:  0.6615682421894423\n",
      "Epoch:  928  Loss:  0.7751133562891152  Validation Loss:  0.6615064310809148\n",
      "Epoch:  929  Loss:  0.7751129807015373  Validation Loss:  0.6614447880600547\n",
      "Epoch:  930  Loss:  0.7751128196250647  Validation Loss:  0.6613833201599533\n",
      "Epoch:  931  Loss:  0.7751127563162961  Validation Loss:  0.6613220576325367\n",
      "Epoch:  932  Loss:  0.7751128980784084  Validation Loss:  0.6612609781902926\n",
      "Epoch:  933  Loss:  0.7751132034887136  Validation Loss:  0.6612000436811097\n",
      "Epoch:  934  Loss:  0.7751136536138471  Validation Loss:  0.66113934242006\n",
      "Epoch:  935  Loss:  0.7751142929032953  Validation Loss:  0.6610788468207265\n",
      "Epoch:  936  Loss:  0.7751150875648652  Validation Loss:  0.6610185595807331\n",
      "Epoch:  937  Loss:  0.7751160627971827  Validation Loss:  0.660958475882894\n",
      "Epoch:  938  Loss:  0.7751172142717141  Validation Loss:  0.6608985344204923\n",
      "Epoch:  939  Loss:  0.7751184805740856  Validation Loss:  0.660838792004205\n",
      "Epoch:  940  Loss:  0.7751199495766989  Validation Loss:  0.6607792837673734\n",
      "Epoch:  941  Loss:  0.7751215383918448  Validation Loss:  0.660719924670612\n",
      "Epoch:  942  Loss:  0.7751232742607086  Validation Loss:  0.6606607298719985\n",
      "Epoch:  943  Loss:  0.7751251811436801  Validation Loss:  0.66060180528539\n",
      "Epoch:  944  Loss:  0.7751272331224754  Validation Loss:  0.6605430319584136\n",
      "Epoch:  945  Loss:  0.7751294262389737  Validation Loss:  0.6604844619166749\n",
      "Epoch:  946  Loss:  0.7751317879036915  Validation Loss:  0.6604261349180135\n",
      "Epoch:  947  Loss:  0.7751342932672494  Validation Loss:  0.6603679939911797\n",
      "Epoch:  948  Loss:  0.7751369561830704  Validation Loss:  0.6603100496055238\n",
      "Epoch:  949  Loss:  0.7751397567335516  Validation Loss:  0.6602524241175631\n",
      "Epoch:  950  Loss:  0.7751427362567153  Validation Loss:  0.6601949621570008\n",
      "Epoch:  951  Loss:  0.7751458761049435  Validation Loss:  0.6601377054085505\n",
      "Epoch:  952  Loss:  0.775149138612588  Validation Loss:  0.66008068216515\n",
      "Epoch:  953  Loss:  0.7751525021263991  Validation Loss:  0.6600238844944999\n",
      "Epoch:  954  Loss:  0.775156010132791  Validation Loss:  0.6599672567420478\n",
      "Epoch:  955  Loss:  0.7751596250296147  Validation Loss:  0.6599109097672947\n",
      "Epoch:  956  Loss:  0.77516337021635  Validation Loss:  0.6598548264852886\n",
      "Epoch:  957  Loss:  0.7751672519053417  Validation Loss:  0.6597989655966903\n",
      "Epoch:  958  Loss:  0.7751712157200514  Validation Loss:  0.6597433303771861\n",
      "Epoch:  959  Loss:  0.7751753352455456  Validation Loss:  0.6596879648237393\n",
      "Epoch:  960  Loss:  0.7751795321554792  Validation Loss:  0.6596328747812016\n",
      "Epoch:  961  Loss:  0.7751838828500529  Validation Loss:  0.6595780572308034\n",
      "Epoch:  962  Loss:  0.7751882707975297  Validation Loss:  0.6595235353913801\n",
      "Epoch:  963  Loss:  0.7751927790126171  Validation Loss:  0.6594692196953913\n",
      "Epoch:  964  Loss:  0.7751973583574661  Validation Loss:  0.6594152863554913\n",
      "Epoch:  965  Loss:  0.775201995211484  Validation Loss:  0.6593615723260003\n",
      "Epoch:  966  Loss:  0.7752067260867492  Validation Loss:  0.6593081663073651\n",
      "Epoch:  967  Loss:  0.7752115018348295  Validation Loss:  0.6592550852239646\n",
      "Epoch:  968  Loss:  0.7752163322134451  Validation Loss:  0.6592023557308933\n",
      "Epoch:  969  Loss:  0.7752211650791154  Validation Loss:  0.6591499917658752\n",
      "Epoch:  970  Loss:  0.7752260487018661  Validation Loss:  0.6590979473087294\n",
      "Epoch:  971  Loss:  0.7752309098776261  Validation Loss:  0.6590463217540548\n",
      "Epoch:  972  Loss:  0.7752357394836674  Validation Loss:  0.6589950929106824\n",
      "Epoch:  973  Loss:  0.7752405933464285  Validation Loss:  0.6589442961046408\n",
      "Epoch:  974  Loss:  0.7752453637605702  Validation Loss:  0.6588939640927931\n",
      "Epoch:  975  Loss:  0.7752500985092907  Validation Loss:  0.6588441307560123\n",
      "Epoch:  976  Loss:  0.7752547106515109  Validation Loss:  0.6587948082014918\n",
      "Epoch:  977  Loss:  0.7752592256292701  Validation Loss:  0.6587460671776327\n",
      "Epoch:  978  Loss:  0.7752635809698735  Validation Loss:  0.6586979178005251\n",
      "Epoch:  979  Loss:  0.775267791362818  Validation Loss:  0.6586504294055289\n",
      "Epoch:  980  Loss:  0.7752717845882713  Validation Loss:  0.6586036026670501\n",
      "Epoch:  981  Loss:  0.7752755311931568  Validation Loss:  0.6585574932075267\n",
      "Epoch:  982  Loss:  0.775279007576914  Validation Loss:  0.6585121321459783\n",
      "Epoch:  983  Loss:  0.7752821857575327  Validation Loss:  0.6584675834546315\n",
      "Epoch:  984  Loss:  0.775285018353977  Validation Loss:  0.6584239208685427\n",
      "Epoch:  985  Loss:  0.7752874814799394  Validation Loss:  0.658381115580941\n",
      "Epoch:  986  Loss:  0.7752895907244899  Validation Loss:  0.6583391691333261\n",
      "Epoch:  987  Loss:  0.7752913418649272  Validation Loss:  0.6582981617478975\n",
      "Epoch:  988  Loss:  0.7752926887796175  Validation Loss:  0.658258005816104\n",
      "Epoch:  989  Loss:  0.7752937274371189  Validation Loss:  0.6582187133809102\n",
      "Epoch:  990  Loss:  0.7752944692038  Validation Loss:  0.6581802068213964\n",
      "Epoch:  991  Loss:  0.7752949843204326  Validation Loss:  0.6581424408239024\n",
      "Epoch:  992  Loss:  0.7752952732632614  Validation Loss:  0.6581053093139981\n",
      "Epoch:  993  Loss:  0.7752954456426034  Validation Loss:  0.6580687381712527\n",
      "Epoch:  994  Loss:  0.7752955384891141  Validation Loss:  0.6580326592806598\n",
      "Epoch:  995  Loss:  0.7752956133335829  Validation Loss:  0.6579969906537183\n",
      "Epoch:  996  Loss:  0.7752957234307277  Validation Loss:  0.6579616519397703\n",
      "Epoch:  997  Loss:  0.7752958792050115  Validation Loss:  0.6579266253152284\n",
      "Epoch:  998  Loss:  0.7752961581255394  Validation Loss:  0.6578918595252365\n",
      "Epoch:  999  Loss:  0.775296564182182  Validation Loss:  0.657857284624258\n",
      "Epoch:  1000  Loss:  0.7752971386600455  Validation Loss:  0.6578228971118043\n",
      "Epoch:  1001  Loss:  0.7752978704044257  Validation Loss:  0.6577886864221816\n",
      "Epoch:  1002  Loss:  0.7752987897573885  Validation Loss:  0.6577545755767616\n",
      "Epoch:  1003  Loss:  0.7752999115460129  Validation Loss:  0.6577206085403932\n",
      "Epoch:  1004  Loss:  0.7753012297378684  Validation Loss:  0.6576867273141598\n",
      "Epoch:  1005  Loss:  0.7753027291672135  Validation Loss:  0.6576529369721639\n",
      "Epoch:  1006  Loss:  0.7753044970502908  Validation Loss:  0.6576192681838212\n",
      "Epoch:  1007  Loss:  0.7753064424667339  Validation Loss:  0.6575856955143912\n",
      "Epoch:  1008  Loss:  0.775308609104038  Validation Loss:  0.6575522687414597\n",
      "Epoch:  1009  Loss:  0.7753109710756689  Validation Loss:  0.6575189558467989\n",
      "Epoch:  1010  Loss:  0.7753135665235195  Validation Loss:  0.6574857772873908\n",
      "Epoch:  1011  Loss:  0.7753163800066845  Validation Loss:  0.6574526892589598\n",
      "Epoch:  1012  Loss:  0.775319374769672  Validation Loss:  0.6574197869169814\n",
      "Epoch:  1013  Loss:  0.7753225908381864  Validation Loss:  0.6573870329443237\n",
      "Epoch:  1014  Loss:  0.7753260370703753  Validation Loss:  0.6573543315753341\n",
      "Epoch:  1015  Loss:  0.7753296778431501  Validation Loss:  0.6573217361202014\n",
      "Epoch:  1016  Loss:  0.7753335337620229  Validation Loss:  0.6572892894518787\n",
      "Epoch:  1017  Loss:  0.7753375698600642  Validation Loss:  0.6572569315482316\n",
      "Epoch:  1018  Loss:  0.775341828152622  Validation Loss:  0.6572247184491877\n",
      "Epoch:  1019  Loss:  0.7753463045757433  Validation Loss:  0.6571926198064767\n",
      "Epoch:  1020  Loss:  0.7753509843552654  Validation Loss:  0.6571605884116786\n",
      "Epoch:  1021  Loss:  0.7753558639034798  Validation Loss:  0.6571286513052624\n",
      "Epoch:  1022  Loss:  0.7753609280758114  Validation Loss:  0.6570968216542026\n",
      "Epoch:  1023  Loss:  0.7753662211100825  Validation Loss:  0.657065057870129\n",
      "Epoch:  1024  Loss:  0.7753716777290471  Validation Loss:  0.6570334130705431\n",
      "Epoch:  1025  Loss:  0.7753773607123136  Validation Loss:  0.6570018570677474\n",
      "Epoch:  1026  Loss:  0.77538319748022  Validation Loss:  0.6569703994961135\n",
      "Epoch:  1027  Loss:  0.775389253934422  Validation Loss:  0.6569390678135999\n",
      "Epoch:  1028  Loss:  0.7753954995529387  Validation Loss:  0.6569078410815062\n",
      "Epoch:  1029  Loss:  0.7754019291817464  Validation Loss:  0.6568766932549148\n",
      "Epoch:  1030  Loss:  0.7754085643894293  Validation Loss:  0.6568456643164672\n",
      "Epoch:  1031  Loss:  0.7754153753842481  Validation Loss:  0.6568147552938297\n",
      "Epoch:  1032  Loss:  0.7754223611607979  Validation Loss:  0.6567839312463485\n",
      "Epoch:  1033  Loss:  0.7754295412874357  Validation Loss:  0.6567532048913939\n",
      "Epoch:  1034  Loss:  0.7754369073928419  Validation Loss:  0.6567226100777244\n",
      "Epoch:  1035  Loss:  0.775444446226836  Validation Loss:  0.656692123329588\n",
      "Epoch:  1036  Loss:  0.7754521838452836  Validation Loss:  0.6566617006500219\n",
      "Epoch:  1037  Loss:  0.7754600660303946  Validation Loss:  0.6566313975972349\n",
      "Epoch:  1038  Loss:  0.7754681667164814  Validation Loss:  0.6566011819603115\n",
      "Epoch:  1039  Loss:  0.7754764213353734  Validation Loss:  0.6565710845050113\n",
      "Epoch:  1040  Loss:  0.7754848625151102  Validation Loss:  0.6565410681390043\n",
      "Epoch:  1041  Loss:  0.775493486456319  Validation Loss:  0.6565112064688884\n",
      "Epoch:  1042  Loss:  0.7755022874546491  Validation Loss:  0.6564814554977005\n",
      "Epoch:  1043  Loss:  0.7755112710874528  Validation Loss:  0.656451768370281\n",
      "Epoch:  1044  Loss:  0.775520414442078  Validation Loss:  0.6564222040168685\n",
      "Epoch:  1045  Loss:  0.7755297402618453  Validation Loss:  0.6563927710441679\n",
      "Epoch:  1046  Loss:  0.7755392449907959  Validation Loss:  0.6563634538444979\n",
      "Epoch:  1047  Loss:  0.7755489549493756  Validation Loss:  0.6563342409529562\n",
      "Epoch:  1048  Loss:  0.7755588173485276  Validation Loss:  0.6563051411368209\n",
      "Epoch:  1049  Loss:  0.7755688467190008  Validation Loss:  0.6562761318516629\n",
      "Epoch:  1050  Loss:  0.7755790698151528  Validation Loss:  0.6562472922599007\n",
      "Epoch:  1051  Loss:  0.7755894530352883  Validation Loss:  0.6562185094467011\n",
      "Epoch:  1052  Loss:  0.7756000105291605  Validation Loss:  0.6561898568259745\n",
      "Epoch:  1053  Loss:  0.7756107468052175  Validation Loss:  0.6561613329846797\n",
      "Epoch:  1054  Loss:  0.7756216251291335  Validation Loss:  0.6561329149608982\n",
      "Epoch:  1055  Loss:  0.7756327253829857  Validation Loss:  0.6561046016948491\n",
      "Epoch:  1056  Loss:  0.7756439773260023  Validation Loss:  0.6560764011188314\n",
      "Epoch:  1057  Loss:  0.7756554188354957  Validation Loss:  0.6560483290653291\n",
      "Epoch:  1058  Loss:  0.7756670015461912  Validation Loss:  0.6560203461618773\n",
      "Epoch:  1059  Loss:  0.7756787851897322  Validation Loss:  0.6559924967265849\n",
      "Epoch:  1060  Loss:  0.7756907160986554  Validation Loss:  0.6559648042994326\n",
      "Epoch:  1061  Loss:  0.7757028207839043  Validation Loss:  0.6559372092436614\n",
      "Epoch:  1062  Loss:  0.7757151080824604  Validation Loss:  0.6559096826561566\n",
      "Epoch:  1063  Loss:  0.775727567284114  Validation Loss:  0.6558822866464997\n",
      "Epoch:  1064  Loss:  0.7757401854879308  Validation Loss:  0.6558550032305306\n",
      "Epoch:  1065  Loss:  0.7757529724516313  Validation Loss:  0.6558278851724905\n",
      "Epoch:  1066  Loss:  0.775765912649645  Validation Loss:  0.6558008728035051\n",
      "Epoch:  1067  Loss:  0.775779031555761  Validation Loss:  0.6557739570030364\n",
      "Epoch:  1068  Loss:  0.7757923157928004  Validation Loss:  0.6557472295224153\n",
      "Epoch:  1069  Loss:  0.7758057800396769  Validation Loss:  0.6557205581780652\n",
      "Epoch:  1070  Loss:  0.775819428878921  Validation Loss:  0.6556940144891369\n",
      "Epoch:  1071  Loss:  0.7758332218509167  Validation Loss:  0.6556675925786639\n",
      "Epoch:  1072  Loss:  0.7758471833393824  Validation Loss:  0.6556412847712636\n",
      "Epoch:  1073  Loss:  0.7758613106032665  Validation Loss:  0.6556151327195352\n",
      "Epoch:  1074  Loss:  0.7758756001183594  Validation Loss:  0.6555891036987305\n",
      "Epoch:  1075  Loss:  0.7758900540648028  Validation Loss:  0.655563230176681\n",
      "Epoch:  1076  Loss:  0.7759046824013983  Validation Loss:  0.6555374614444787\n",
      "Epoch:  1077  Loss:  0.7759194568603892  Validation Loss:  0.6555117938731765\n",
      "Epoch:  1078  Loss:  0.7759344391736456  Validation Loss:  0.6554862518698491\n",
      "Epoch:  1079  Loss:  0.7759495627939362  Validation Loss:  0.655460813500244\n",
      "Epoch:  1080  Loss:  0.7759648694402792  Validation Loss:  0.655435491834992\n",
      "Epoch:  1081  Loss:  0.7759803174889054  Validation Loss:  0.6554102896680606\n",
      "Epoch:  1082  Loss:  0.7759959321701899  Validation Loss:  0.6553852341683775\n",
      "Epoch:  1083  Loss:  0.7760117130290548  Validation Loss:  0.6553603218996833\n",
      "Epoch:  1084  Loss:  0.7760276342424649  Validation Loss:  0.6553355132968262\n",
      "Epoch:  1085  Loss:  0.7760437235384333  Validation Loss:  0.6553107946789984\n",
      "Epoch:  1086  Loss:  0.7760599860604006  Validation Loss:  0.6552862394922252\n",
      "Epoch:  1087  Loss:  0.7760764066002924  Validation Loss:  0.6552618056985324\n",
      "Epoch:  1088  Loss:  0.7760930128861219  Validation Loss:  0.655237416479865\n",
      "Epoch:  1089  Loss:  0.7761097515361722  Validation Loss:  0.6552132103784845\n",
      "Epoch:  1090  Loss:  0.776126701744612  Validation Loss:  0.6551890427182461\n",
      "Epoch:  1091  Loss:  0.776143786687912  Validation Loss:  0.6551650546105772\n",
      "Epoch:  1092  Loss:  0.776161028622565  Validation Loss:  0.6551411308926242\n",
      "Epoch:  1093  Loss:  0.7761784394864332  Validation Loss:  0.6551173429550796\n",
      "Epoch:  1094  Loss:  0.7761959814127873  Validation Loss:  0.6550936981521803\n",
      "Epoch:  1095  Loss:  0.7762136844791133  Validation Loss:  0.655070139480562\n",
      "Epoch:  1096  Loss:  0.7762315530668605  Validation Loss:  0.6550467505344543\n",
      "Epoch:  1097  Loss:  0.7762495552676476  Validation Loss:  0.6550234840412078\n",
      "Epoch:  1098  Loss:  0.7762677236989309  Validation Loss:  0.6550002673576618\n",
      "Epoch:  1099  Loss:  0.7762860714415596  Validation Loss:  0.6549772034431326\n",
      "Epoch:  1100  Loss:  0.7763045586285774  Validation Loss:  0.6549542883154134\n",
      "Epoch:  1101  Loss:  0.776323219486089  Validation Loss:  0.65493146005761\n",
      "Epoch:  1102  Loss:  0.7763420345939018  Validation Loss:  0.654908752614825\n",
      "Epoch:  1103  Loss:  0.7763610284838994  Validation Loss:  0.6548861272889992\n",
      "Epoch:  1104  Loss:  0.7763801998014308  Validation Loss:  0.6548636027708136\n",
      "Epoch:  1105  Loss:  0.7763995161407035  Validation Loss:  0.6548412302187805\n",
      "Epoch:  1106  Loss:  0.7764189961070026  Validation Loss:  0.654818960979324\n",
      "Epoch:  1107  Loss:  0.776438616935841  Validation Loss:  0.6547968274881614\n",
      "Epoch:  1108  Loss:  0.7764584255425937  Validation Loss:  0.654774814651444\n",
      "Epoch:  1109  Loss:  0.7764783615500412  Validation Loss:  0.6547529463624132\n",
      "Epoch:  1110  Loss:  0.7764984465902671  Validation Loss:  0.6547311771468356\n",
      "Epoch:  1111  Loss:  0.7765187213874676  Validation Loss:  0.6547095730643848\n",
      "Epoch:  1112  Loss:  0.7765391258290038  Validation Loss:  0.6546880783320501\n",
      "Epoch:  1113  Loss:  0.7765596937176518  Validation Loss:  0.6546666849533032\n",
      "Epoch:  1114  Loss:  0.7765804295618595  Validation Loss:  0.6546454337457644\n",
      "Epoch:  1115  Loss:  0.7766013078455051  Validation Loss:  0.6546243141758544\n",
      "Epoch:  1116  Loss:  0.7766223608897153  Validation Loss:  0.6546032596379519\n",
      "Epoch:  1117  Loss:  0.7766435521506619  Validation Loss:  0.6545823696229992\n",
      "Epoch:  1118  Loss:  0.7766649152300406  Validation Loss:  0.6545615801908846\n",
      "Epoch:  1119  Loss:  0.7766864136686887  Validation Loss:  0.6545409161019428\n",
      "Epoch:  1120  Loss:  0.7767081122676079  Validation Loss:  0.6545203477465387\n",
      "Epoch:  1121  Loss:  0.776729965487241  Validation Loss:  0.6544998863326579\n",
      "Epoch:  1122  Loss:  0.7767519871915944  Validation Loss:  0.6544795200100233\n",
      "Epoch:  1123  Loss:  0.776774151398885  Validation Loss:  0.6544592850359863\n",
      "Epoch:  1124  Loss:  0.7767964982194826  Validation Loss:  0.6544392339821006\n",
      "Epoch:  1125  Loss:  0.7768189945914359  Validation Loss:  0.6544192715323177\n",
      "Epoch:  1126  Loss:  0.7768416586332023  Validation Loss:  0.6543994542403981\n",
      "Epoch:  1127  Loss:  0.7768644662573934  Validation Loss:  0.6543797434725124\n",
      "Epoch:  1128  Loss:  0.7768874447686936  Validation Loss:  0.6543601721782109\n",
      "Epoch:  1129  Loss:  0.7769105752019889  Validation Loss:  0.654340724653468\n",
      "Epoch:  1130  Loss:  0.7769338468259032  Validation Loss:  0.6543213833958424\n",
      "Epoch:  1131  Loss:  0.7769572802776978  Validation Loss:  0.6543021813227698\n",
      "Epoch:  1132  Loss:  0.7769808710912581  Validation Loss:  0.6542831461491256\n",
      "Epoch:  1133  Loss:  0.7770046134352345  Validation Loss:  0.654264198166543\n",
      "Epoch:  1134  Loss:  0.7770285162630237  Validation Loss:  0.654245397654073\n",
      "Epoch:  1135  Loss:  0.777052556333894  Validation Loss:  0.654226695701223\n",
      "Epoch:  1136  Loss:  0.7770767538406124  Validation Loss:  0.6542081369151329\n",
      "Epoch:  1137  Loss:  0.7771011119263924  Validation Loss:  0.6541896541442337\n",
      "Epoch:  1138  Loss:  0.7771256021329794  Validation Loss:  0.6541713157604481\n",
      "Epoch:  1139  Loss:  0.7771502539769493  Validation Loss:  0.6541530749086162\n",
      "Epoch:  1140  Loss:  0.7771750722630796  Validation Loss:  0.6541349792467623\n",
      "Epoch:  1141  Loss:  0.7772000312212516  Validation Loss:  0.6541169278066734\n",
      "Epoch:  1142  Loss:  0.7772251418791711  Validation Loss:  0.6540990840836332\n",
      "Epoch:  1143  Loss:  0.7772504458711906  Validation Loss:  0.6540812880828463\n",
      "Epoch:  1144  Loss:  0.7772758771792393  Validation Loss:  0.6540636161406492\n",
      "Epoch:  1145  Loss:  0.7773015056525103  Validation Loss:  0.6540460454556962\n",
      "Epoch:  1146  Loss:  0.7773272694744677  Validation Loss:  0.6540285930165957\n",
      "Epoch:  1147  Loss:  0.777353184054267  Validation Loss:  0.6540112660170115\n",
      "Epoch:  1148  Loss:  0.7773792472011833  Validation Loss:  0.6539940648423187\n",
      "Epoch:  1149  Loss:  0.7774054544491016  Validation Loss:  0.653976985670883\n",
      "Epoch:  1150  Loss:  0.7774318073855035  Validation Loss:  0.6539600113856381\n",
      "Epoch:  1151  Loss:  0.7774583467345854  Validation Loss:  0.6539431813911631\n",
      "Epoch:  1152  Loss:  0.7774849942335013  Validation Loss:  0.6539264445931747\n",
      "Epoch:  1153  Loss:  0.777511835320514  Validation Loss:  0.6539098521501854\n",
      "Epoch:  1154  Loss:  0.7775388062317771  Validation Loss:  0.6538933624095958\n",
      "Epoch:  1155  Loss:  0.777565905940719  Validation Loss:  0.6538770178910988\n",
      "Epoch:  1156  Loss:  0.7775931847916747  Validation Loss:  0.6538607780661049\n",
      "Epoch:  1157  Loss:  0.7776206141676415  Validation Loss:  0.6538446738609466\n",
      "Epoch:  1158  Loss:  0.7776481974764134  Validation Loss:  0.6538286611180881\n",
      "Epoch:  1159  Loss:  0.7776759347285737  Validation Loss:  0.653812783641805\n",
      "Epoch:  1160  Loss:  0.7777037920790132  Validation Loss:  0.6537969990729772\n",
      "Epoch:  1161  Loss:  0.7777318148979578  Validation Loss:  0.6537813914554387\n",
      "Epoch:  1162  Loss:  0.7777600264473056  Validation Loss:  0.6537658788328027\n",
      "Epoch:  1163  Loss:  0.7777883469084785  Validation Loss:  0.6537505016694295\n",
      "Epoch:  1164  Loss:  0.777816827133806  Validation Loss:  0.6537352056595785\n",
      "Epoch:  1165  Loss:  0.7778454447080466  Validation Loss:  0.653720059528433\n",
      "Epoch:  1166  Loss:  0.7778742242054167  Validation Loss:  0.65370500389615\n",
      "Epoch:  1167  Loss:  0.777903164758093  Validation Loss:  0.6536900994271554\n",
      "Epoch:  1168  Loss:  0.7779322475067932  Validation Loss:  0.6536752812178999\n",
      "Epoch:  1169  Loss:  0.7779614813202484  Validation Loss:  0.6536605813829549\n",
      "Epoch:  1170  Loss:  0.7779908467570997  Validation Loss:  0.6536459796901407\n",
      "Epoch:  1171  Loss:  0.778020375101319  Validation Loss:  0.653631484392902\n",
      "Epoch:  1172  Loss:  0.77805005018176  Validation Loss:  0.6536170921834379\n",
      "Epoch:  1173  Loss:  0.7780798572242599  Validation Loss:  0.6536028148156816\n",
      "Epoch:  1174  Loss:  0.778109845885245  Validation Loss:  0.6535886173810939\n",
      "Epoch:  1175  Loss:  0.7781399639259855  Validation Loss:  0.6535745266953419\n",
      "Epoch:  1176  Loss:  0.7781702597964216  Validation Loss:  0.6535605307796906\n",
      "Epoch:  1177  Loss:  0.7782006647056815  Validation Loss:  0.6535466341944091\n",
      "Epoch:  1178  Loss:  0.7782312096202407  Validation Loss:  0.6535328007142606\n",
      "Epoch:  1179  Loss:  0.7782619307452644  Validation Loss:  0.6535190864112871\n",
      "Epoch:  1180  Loss:  0.7782927409068428  Validation Loss:  0.6535054994104751\n",
      "Epoch:  1181  Loss:  0.7783237263263966  Validation Loss:  0.6534919951689141\n",
      "Epoch:  1182  Loss:  0.7783548032907261  Validation Loss:  0.6534785060533161\n",
      "Epoch:  1183  Loss:  0.7783860153709115  Validation Loss:  0.6534651640545706\n",
      "Epoch:  1184  Loss:  0.7784173469778828  Validation Loss:  0.6534518796372516\n",
      "Epoch:  1185  Loss:  0.7784488045673986  Validation Loss:  0.6534386678630936\n",
      "Epoch:  1186  Loss:  0.7784803864884783  Validation Loss:  0.6534254921214848\n",
      "Epoch:  1187  Loss:  0.7785120407775552  Validation Loss:  0.6534124466686927\n",
      "Epoch:  1188  Loss:  0.7785438550953668  Validation Loss:  0.6533994578981194\n",
      "Epoch:  1189  Loss:  0.7785757886436344  Validation Loss:  0.6533865870201382\n",
      "Epoch:  1190  Loss:  0.778607891565612  Validation Loss:  0.6533738701957567\n",
      "Epoch:  1191  Loss:  0.7786401212215424  Validation Loss:  0.65336121410003\n",
      "Epoch:  1192  Loss:  0.7786725059955973  Validation Loss:  0.6533487171320052\n",
      "Epoch:  1193  Loss:  0.7787050128787417  Validation Loss:  0.6533363387630932\n",
      "Epoch:  1194  Loss:  0.7787376979302446  Validation Loss:  0.6533240370837778\n",
      "Epoch:  1195  Loss:  0.7787704844641584  Validation Loss:  0.6533118453968702\n",
      "Epoch:  1196  Loss:  0.7788034216183323  Validation Loss:  0.6532997934404632\n",
      "Epoch:  1197  Loss:  0.7788365131498061  Validation Loss:  0.6532877774523764\n",
      "Epoch:  1198  Loss:  0.7788697351299395  Validation Loss:  0.653275941691265\n",
      "Epoch:  1199  Loss:  0.7789030913475223  Validation Loss:  0.6532642176888627\n",
      "Epoch:  1200  Loss:  0.778936628209935  Validation Loss:  0.6532525766383985\n",
      "Epoch:  1201  Loss:  0.7789702808844264  Validation Loss:  0.6532410504938714\n",
      "Epoch:  1202  Loss:  0.7790040698918429  Validation Loss:  0.6532296539637549\n",
      "Epoch:  1203  Loss:  0.7790380371522836  Validation Loss:  0.6532183841577378\n",
      "Epoch:  1204  Loss:  0.7790721065301279  Validation Loss:  0.6532071981065232\n",
      "Epoch:  1205  Loss:  0.7791063634424724  Validation Loss:  0.6531961375590543\n",
      "Epoch:  1206  Loss:  0.7791407441572201  Validation Loss:  0.6531852163567111\n",
      "Epoch:  1207  Loss:  0.7791752833449705  Validation Loss:  0.6531744065919313\n",
      "Epoch:  1208  Loss:  0.7792099650674076  Validation Loss:  0.6531636821876826\n",
      "Epoch:  1209  Loss:  0.7792447704864158  Validation Loss:  0.6531530973212473\n",
      "Epoch:  1210  Loss:  0.779279738156633  Validation Loss:  0.6531426767208452\n",
      "Epoch:  1211  Loss:  0.7793148344975304  Validation Loss:  0.6531322827755377\n",
      "Epoch:  1212  Loss:  0.7793500944654542  Validation Loss:  0.6531220525824304\n",
      "Epoch:  1213  Loss:  0.7793854863848537  Validation Loss:  0.6531119202424226\n",
      "Epoch:  1214  Loss:  0.7794210171136498  Validation Loss:  0.6531019032579558\n",
      "Epoch:  1215  Loss:  0.7794567079452629  Validation Loss:  0.6530919935361579\n",
      "Epoch:  1216  Loss:  0.7794925100593404  Validation Loss:  0.6530821687574017\n",
      "Epoch:  1217  Loss:  0.7795284693658521  Validation Loss:  0.6530724356015181\n",
      "Epoch:  1218  Loss:  0.7795645692068237  Validation Loss:  0.6530628523243398\n",
      "Epoch:  1219  Loss:  0.7796007971363988  Validation Loss:  0.6530533671892923\n",
      "Epoch:  1220  Loss:  0.7796371832955629  Validation Loss:  0.6530439695343375\n",
      "Epoch:  1221  Loss:  0.7796737234616145  Validation Loss:  0.6530346924695989\n",
      "Epoch:  1222  Loss:  0.7797104050405324  Validation Loss:  0.6530255352885559\n",
      "Epoch:  1223  Loss:  0.7797472350595688  Validation Loss:  0.6530164642066791\n",
      "Epoch:  1224  Loss:  0.7797842031365938  Validation Loss:  0.653007537062312\n",
      "Epoch:  1225  Loss:  0.7798213462387635  Validation Loss:  0.6529987096979186\n",
      "Epoch:  1226  Loss:  0.7798586327011104  Validation Loss:  0.6529899493887507\n",
      "Epoch:  1227  Loss:  0.7798960376848382  Validation Loss:  0.6529813053985608\n",
      "Epoch:  1228  Loss:  0.7799335992154242  Validation Loss:  0.6529727814526394\n",
      "Epoch:  1229  Loss:  0.7799713223516433  Validation Loss:  0.6529644023113209\n",
      "Epoch:  1230  Loss:  0.7800091747617857  Validation Loss:  0.6529561089480231\n",
      "Epoch:  1231  Loss:  0.7800471607003022  Validation Loss:  0.6529479411848146\n",
      "Epoch:  1232  Loss:  0.7800852812572636  Validation Loss:  0.6529398322555011\n",
      "Epoch:  1233  Loss:  0.780123533977365  Validation Loss:  0.6529318795635782\n",
      "Epoch:  1234  Loss:  0.7801619306926362  Validation Loss:  0.6529239666616095\n",
      "Epoch:  1235  Loss:  0.7802004582163963  Validation Loss:  0.6529162160024561\n",
      "Epoch:  1236  Loss:  0.7802391252903775  Validation Loss:  0.652908588920174\n",
      "Epoch:  1237  Loss:  0.7802779387407512  Validation Loss:  0.6529009898739129\n",
      "Epoch:  1238  Loss:  0.780316889074377  Validation Loss:  0.652893590708745\n",
      "Epoch:  1239  Loss:  0.7803559846096587  Validation Loss:  0.6528862510197635\n",
      "Epoch:  1240  Loss:  0.7803952347339046  Validation Loss:  0.6528790425509214\n",
      "Epoch:  1241  Loss:  0.780434607274153  Validation Loss:  0.6528719451021532\n",
      "Epoch:  1242  Loss:  0.7804741261272945  Validation Loss:  0.6528649616922284\n",
      "Epoch:  1243  Loss:  0.7805137917484072  Validation Loss:  0.6528580746581328\n",
      "Epoch:  1244  Loss:  0.7805535902099853  Validation Loss:  0.6528513160502089\n",
      "Epoch:  1245  Loss:  0.7805935186016458  Validation Loss:  0.6528446710315244\n",
      "Epoch:  1246  Loss:  0.7806336059531366  Validation Loss:  0.6528381145848282\n",
      "Epoch:  1247  Loss:  0.7806737896118482  Validation Loss:  0.6528316249685555\n",
      "Epoch:  1248  Loss:  0.780714116778902  Validation Loss:  0.6528252721282428\n",
      "Epoch:  1249  Loss:  0.7807545934549787  Validation Loss:  0.6528190132551666\n",
      "Epoch:  1250  Loss:  0.7807952055855739  Validation Loss:  0.652812872306797\n",
      "Epoch:  1251  Loss:  0.7808359524616125  Validation Loss:  0.6528068496042798\n",
      "Epoch:  1252  Loss:  0.7808768564242531  Validation Loss:  0.6528009339396296\n",
      "Epoch:  1253  Loss:  0.7809178769609637  Validation Loss:  0.6527951120174137\n",
      "Epoch:  1254  Loss:  0.7809590325394477  Validation Loss:  0.652789417268901\n",
      "Epoch:  1255  Loss:  0.7810003618625078  Validation Loss:  0.6527837999486203\n",
      "Epoch:  1256  Loss:  0.7810417877785354  Validation Loss:  0.6527782906938729\n",
      "Epoch:  1257  Loss:  0.7810833744112063  Validation Loss:  0.6527729083880268\n",
      "Epoch:  1258  Loss:  0.7811250664314933  Validation Loss:  0.6527676304866528\n",
      "Epoch:  1259  Loss:  0.7811669406946748  Validation Loss:  0.6527624457496507\n",
      "Epoch:  1260  Loss:  0.7812089309286834  Validation Loss:  0.6527573619166325\n",
      "Epoch:  1261  Loss:  0.781251047515649  Validation Loss:  0.6527524264850493\n",
      "Epoch:  1262  Loss:  0.7812932994089682  Validation Loss:  0.652747540156646\n",
      "Epoch:  1263  Loss:  0.7813356859418987  Validation Loss:  0.652742802582938\n",
      "Epoch:  1264  Loss:  0.7813782207985324  Validation Loss:  0.6527381386800573\n",
      "Epoch:  1265  Loss:  0.7814208984755996  Validation Loss:  0.6527335968446629\n",
      "Epoch:  1266  Loss:  0.781463687371632  Validation Loss:  0.6527291602487194\n",
      "Epoch:  1267  Loss:  0.7815066243056208  Validation Loss:  0.6527248386550566\n",
      "Epoch:  1268  Loss:  0.7815496903759512  Validation Loss:  0.6527205898651275\n",
      "Epoch:  1269  Loss:  0.7815928969701583  Validation Loss:  0.6527164610552376\n",
      "Epoch:  1270  Loss:  0.7816362405111167  Validation Loss:  0.6527124093203195\n",
      "Epoch:  1271  Loss:  0.7816797205860812  Validation Loss:  0.6527085134374171\n",
      "Epoch:  1272  Loss:  0.7817233482862569  Validation Loss:  0.6527046813982827\n",
      "Epoch:  1273  Loss:  0.7817670834801075  Validation Loss:  0.6527009786524135\n",
      "Epoch:  1274  Loss:  0.7818109827983956  Validation Loss:  0.6526973468797475\n",
      "Epoch:  1275  Loss:  0.7818549889330328  Validation Loss:  0.6526938192546368\n",
      "Epoch:  1276  Loss:  0.7818991254739971  Validation Loss:  0.6526904550926953\n",
      "Epoch:  1277  Loss:  0.7819434155667708  Validation Loss:  0.6526871442730571\n",
      "Epoch:  1278  Loss:  0.7819878291127018  Validation Loss:  0.652683929379644\n",
      "Epoch:  1279  Loss:  0.7820323774781586  Validation Loss:  0.6526808350443326\n",
      "Epoch:  1280  Loss:  0.7820770548000424  Validation Loss:  0.6526778477790027\n",
      "Epoch:  1281  Loss:  0.782121874360283  Validation Loss:  0.652674935147937\n",
      "Epoch:  1282  Loss:  0.7821668257661671  Validation Loss:  0.652672178368887\n",
      "Epoch:  1283  Loss:  0.7822119053029879  Validation Loss:  0.6526694570764385\n",
      "Epoch:  1284  Loss:  0.782257112219337  Validation Loss:  0.6526668745189391\n",
      "Epoch:  1285  Loss:  0.7823024778309363  Validation Loss:  0.6526643801801677\n",
      "Epoch:  1286  Loss:  0.7823479482904077  Validation Loss:  0.6526619830522044\n",
      "Epoch:  1287  Loss:  0.7823935859011147  Validation Loss:  0.652659710721466\n",
      "Epoch:  1288  Loss:  0.7824393230680884  Validation Loss:  0.6526575136672834\n",
      "Epoch:  1289  Loss:  0.7824851895089854  Validation Loss:  0.6526554570501221\n",
      "Epoch:  1290  Loss:  0.7825312118511647  Validation Loss:  0.6526534805588168\n",
      "Epoch:  1291  Loss:  0.7825773413060233  Validation Loss:  0.6526515607176155\n",
      "Epoch:  1292  Loss:  0.7826236128087409  Validation Loss:  0.6526497566173303\n",
      "Epoch:  1293  Loss:  0.7826700201575559  Validation Loss:  0.6526480601972033\n",
      "Epoch:  1294  Loss:  0.7827165666015141  Validation Loss:  0.6526464592536976\n",
      "Epoch:  1295  Loss:  0.7827632059978152  Validation Loss:  0.6526449695550676\n",
      "Epoch:  1296  Loss:  0.7828100166833875  Validation Loss:  0.6526435514719322\n",
      "Epoch:  1297  Loss:  0.7828569531821731  Validation Loss:  0.6526422278056371\n",
      "Epoch:  1298  Loss:  0.782904030289501  Validation Loss:  0.6526410155447906\n",
      "Epoch:  1299  Loss:  0.7829512104773048  Validation Loss:  0.652639901265502\n",
      "Epoch:  1300  Loss:  0.7829985454022377  Validation Loss:  0.6526389045576597\n",
      "Epoch:  1301  Loss:  0.7830460143952884  Validation Loss:  0.6526379206956461\n",
      "Epoch:  1302  Loss:  0.7830936099106277  Validation Loss:  0.6526370881253789\n",
      "Epoch:  1303  Loss:  0.783141351590695  Validation Loss:  0.6526363192383071\n",
      "Epoch:  1304  Loss:  0.7831892216662791  Validation Loss:  0.652635638602078\n",
      "Epoch:  1305  Loss:  0.7832372081042691  Validation Loss:  0.6526350622418625\n",
      "Epoch:  1306  Loss:  0.7832853393100033  Validation Loss:  0.6526345466424165\n",
      "Epoch:  1307  Loss:  0.7833335966358639  Validation Loss:  0.6526341362181922\n",
      "Epoch:  1308  Loss:  0.7833819829922338  Validation Loss:  0.6526338058555948\n",
      "Epoch:  1309  Loss:  0.7834305002629249  Validation Loss:  0.6526335930323293\n",
      "Epoch:  1310  Loss:  0.7834791455904699  Validation Loss:  0.652633451985131\n",
      "Epoch:  1311  Loss:  0.7835279493486847  Validation Loss:  0.6526334363774493\n",
      "Epoch:  1312  Loss:  0.7835768284699456  Validation Loss:  0.6526334739836126\n",
      "Epoch:  1313  Loss:  0.7836258570049804  Validation Loss:  0.6526336235732868\n",
      "Epoch:  1314  Loss:  0.7836750224338506  Validation Loss:  0.6526338997264874\n",
      "Epoch:  1315  Loss:  0.7837242840535261  Validation Loss:  0.652634212169154\n",
      "Epoch:  1316  Loss:  0.7837737009818242  Validation Loss:  0.6526346828403145\n",
      "Epoch:  1317  Loss:  0.7838232376379892  Validation Loss:  0.6526352226220328\n",
      "Epoch:  1318  Loss:  0.7838728968054056  Validation Loss:  0.6526358589401533\n",
      "Epoch:  1319  Loss:  0.783922685585408  Validation Loss:  0.6526365505274514\n",
      "Epoch:  1320  Loss:  0.7839725875211033  Validation Loss:  0.6526373837400099\n",
      "Epoch:  1321  Loss:  0.7840226103382354  Validation Loss:  0.652638299133757\n",
      "Epoch:  1322  Loss:  0.784072749295526  Validation Loss:  0.6526392945249019\n",
      "Epoch:  1323  Loss:  0.7841230314542454  Validation Loss:  0.6526403839796268\n",
      "Epoch:  1324  Loss:  0.7841734308537773  Validation Loss:  0.6526415859316957\n",
      "Epoch:  1325  Loss:  0.7842239411971108  Validation Loss:  0.6526429039458262\n",
      "Epoch:  1326  Loss:  0.7842745918314904  Validation Loss:  0.6526442515374772\n",
      "Epoch:  1327  Loss:  0.7843253677605059  Validation Loss:  0.6526457451219703\n",
      "Epoch:  1328  Loss:  0.7843762296886946  Validation Loss:  0.6526472985359102\n",
      "Epoch:  1329  Loss:  0.7844272680813447  Validation Loss:  0.6526489542989895\n",
      "Epoch:  1330  Loss:  0.7844783874461427  Validation Loss:  0.6526507179670292\n",
      "Epoch:  1331  Loss:  0.7845296270468018  Validation Loss:  0.6526525363261844\n",
      "Epoch:  1332  Loss:  0.7845810068009252  Validation Loss:  0.6526544491985234\n",
      "Epoch:  1333  Loss:  0.7846324883549559  Validation Loss:  0.6526564357416897\n",
      "Epoch:  1334  Loss:  0.784684102146209  Validation Loss:  0.6526585636531999\n",
      "Epoch:  1335  Loss:  0.7847358212404122  Validation Loss:  0.652660727019197\n",
      "Epoch:  1336  Loss:  0.7847876742545684  Validation Loss:  0.6526629755209232\n",
      "Epoch:  1337  Loss:  0.7848396372177046  Validation Loss:  0.6526654671620706\n",
      "Epoch:  1338  Loss:  0.7848917145747691  Validation Loss:  0.6526681105445685\n",
      "Epoch:  1339  Loss:  0.7849439086117358  Validation Loss:  0.6526709229139418\n",
      "Epoch:  1340  Loss:  0.7849962434583259  Validation Loss:  0.6526738434130775\n",
      "Epoch:  1341  Loss:  0.7850486659974029  Validation Loss:  0.652676915782022\n",
      "Epoch:  1342  Loss:  0.7851012153021822  Validation Loss:  0.6526801366808599\n",
      "Epoch:  1343  Loss:  0.7851538700792431  Validation Loss:  0.6526835023521863\n",
      "Epoch:  1344  Loss:  0.7852066440020942  Validation Loss:  0.652686956595501\n",
      "Epoch:  1345  Loss:  0.7852595343826  Validation Loss:  0.6526905594650527\n",
      "Epoch:  1346  Loss:  0.7853125068782405  Validation Loss:  0.652694340987966\n",
      "Epoch:  1347  Loss:  0.7853656044780192  Validation Loss:  0.6526982910802652\n",
      "Epoch:  1348  Loss:  0.785418829033998  Validation Loss:  0.6527024584276409\n",
      "Epoch:  1349  Loss:  0.7854720951184969  Validation Loss:  0.652706924279959\n",
      "Epoch:  1350  Loss:  0.7855255351698195  Validation Loss:  0.6527115692673572\n",
      "Epoch:  1351  Loss:  0.7855790113098919  Validation Loss:  0.6527165452275296\n",
      "Epoch:  1352  Loss:  0.7856326592472297  Validation Loss:  0.6527215971386638\n",
      "Epoch:  1353  Loss:  0.785686429547654  Validation Loss:  0.6527267561197795\n",
      "Epoch:  1354  Loss:  0.7857402803651481  Validation Loss:  0.6527320237766052\n",
      "Epoch:  1355  Loss:  0.7857941996242682  Validation Loss:  0.6527374205982377\n",
      "Epoch:  1356  Loss:  0.7858482620319013  Validation Loss:  0.652742964568837\n",
      "Epoch:  1357  Loss:  0.7859024204292588  Validation Loss:  0.6527485488432234\n",
      "Epoch:  1358  Loss:  0.7859566741284322  Validation Loss:  0.6527541784954995\n",
      "Epoch:  1359  Loss:  0.7860110047358003  Validation Loss:  0.6527598595632047\n",
      "Epoch:  1360  Loss:  0.7860654503509233  Validation Loss:  0.6527655491091567\n",
      "Epoch:  1361  Loss:  0.7861199902836233  Validation Loss:  0.6527713484227143\n",
      "Epoch:  1362  Loss:  0.7861746131040325  Validation Loss:  0.6527771759970948\n",
      "Epoch:  1363  Loss:  0.7862293316707523  Validation Loss:  0.6527830481786152\n",
      "Epoch:  1364  Loss:  0.7862841199702498  Validation Loss:  0.6527889630082866\n",
      "Epoch:  1365  Loss:  0.7863390247062356  Validation Loss:  0.6527949338778853\n",
      "Epoch:  1366  Loss:  0.7863939687694338  Validation Loss:  0.6528008919658845\n",
      "Epoch:  1367  Loss:  0.7864490273112262  Validation Loss:  0.6528068886234842\n",
      "Epoch:  1368  Loss:  0.786504130503586  Validation Loss:  0.6528129401327721\n",
      "Epoch:  1369  Loss:  0.7865593347973614  Validation Loss:  0.6528190305328061\n",
      "Epoch:  1370  Loss:  0.7866146165284921  Validation Loss:  0.652825115087988\n",
      "Epoch:  1371  Loss:  0.7866699778453701  Validation Loss:  0.6528312340699907\n",
      "Epoch:  1372  Loss:  0.7867253802886064  Validation Loss:  0.6528373652876451\n",
      "Epoch:  1373  Loss:  0.7867808630689979  Validation Loss:  0.6528434533433154\n",
      "Epoch:  1374  Loss:  0.7868363935373385  Validation Loss:  0.6528495629478631\n",
      "Epoch:  1375  Loss:  0.7868919825837524  Validation Loss:  0.6528557144940413\n",
      "Epoch:  1376  Loss:  0.7869476085338234  Validation Loss:  0.6528618049583045\n",
      "Epoch:  1377  Loss:  0.7870032870507037  Validation Loss:  0.6528678540589994\n",
      "Epoch:  1378  Loss:  0.7870589987988669  Validation Loss:  0.6528739365267342\n",
      "Epoch:  1379  Loss:  0.7871147443709726  Validation Loss:  0.6528799147184553\n",
      "Epoch:  1380  Loss:  0.7871705423193899  Validation Loss:  0.6528858935524677\n",
      "Epoch:  1381  Loss:  0.7872263304995034  Validation Loss:  0.652891841973981\n",
      "Epoch:  1382  Loss:  0.7872821414229375  Validation Loss:  0.652897664185228\n",
      "Epoch:  1383  Loss:  0.7873379765290089  Validation Loss:  0.6529034207221763\n",
      "Epoch:  1384  Loss:  0.7873937709320505  Validation Loss:  0.6529090769974322\n",
      "Epoch:  1385  Loss:  0.7874495658748359  Validation Loss:  0.6529146483296464\n",
      "Epoch:  1386  Loss:  0.787505318728191  Validation Loss:  0.6529200655119173\n",
      "Epoch:  1387  Loss:  0.7875610243698413  Validation Loss:  0.6529253483268207\n",
      "Epoch:  1388  Loss:  0.7876166861440818  Validation Loss:  0.6529304605812348\n",
      "Epoch:  1389  Loss:  0.7876722826516595  Validation Loss:  0.6529353653434021\n",
      "Epoch:  1390  Loss:  0.7877277886727825  Validation Loss:  0.6529400980356952\n",
      "Epoch:  1391  Loss:  0.7877831944179806  Validation Loss:  0.6529445798489554\n",
      "Epoch:  1392  Loss:  0.787838479546322  Validation Loss:  0.6529487368554391\n",
      "Epoch:  1393  Loss:  0.7878936104878614  Validation Loss:  0.6529525999172494\n",
      "Epoch:  1394  Loss:  0.7879485751459883  Validation Loss:  0.6529561616159205\n",
      "Epoch:  1395  Loss:  0.7880033443216234  Validation Loss:  0.6529592771468491\n",
      "Epoch:  1396  Loss:  0.7880578619766642  Validation Loss:  0.6529620143681251\n",
      "Epoch:  1397  Loss:  0.7881121599665758  Validation Loss:  0.652964200985072\n",
      "Epoch:  1398  Loss:  0.7881661571498791  Validation Loss:  0.6529659086774136\n",
      "Epoch:  1399  Loss:  0.7882197988007895  Validation Loss:  0.6529670547501281\n",
      "Epoch:  1400  Loss:  0.788273104371249  Validation Loss:  0.6529675369183051\n",
      "Epoch:  1401  Loss:  0.7883260110710663  Validation Loss:  0.6529674038997498\n",
      "Epoch:  1402  Loss:  0.7883785307534378  Validation Loss:  0.6529665652919432\n",
      "Epoch:  1403  Loss:  0.7884306376270781  Validation Loss:  0.6529650049091413\n",
      "Epoch:  1404  Loss:  0.7884822844485329  Validation Loss:  0.6529627643397142\n",
      "Epoch:  1405  Loss:  0.7885335162493654  Validation Loss:  0.6529598591271145\n",
      "Epoch:  1406  Loss:  0.7885843573180451  Validation Loss:  0.6529562943454447\n",
      "Epoch:  1407  Loss:  0.7886348275298422  Validation Loss:  0.6529521559332979\n",
      "Epoch:  1408  Loss:  0.788684996183623  Validation Loss:  0.6529475007976951\n",
      "Epoch:  1409  Loss:  0.7887348846998066  Validation Loss:  0.6529424373895444\n",
      "Epoch:  1410  Loss:  0.7887845669915392  Validation Loss:  0.6529370332779042\n",
      "Epoch:  1411  Loss:  0.7888341103892096  Validation Loss:  0.6529313353821635\n",
      "Epoch:  1412  Loss:  0.7888835625172678  Validation Loss:  0.6529254926175907\n",
      "Epoch:  1413  Loss:  0.7889329531674527  Validation Loss:  0.6529195371629863\n",
      "Epoch:  1414  Loss:  0.7889823775039986  Validation Loss:  0.6529135436526147\n",
      "Epoch:  1415  Loss:  0.7890318178423595  Validation Loss:  0.6529075073014046\n",
      "Epoch:  1416  Loss:  0.7890813429416581  Validation Loss:  0.6529015478645933\n",
      "Epoch:  1417  Loss:  0.7891309552254494  Validation Loss:  0.6528956164316885\n",
      "Epoch:  1418  Loss:  0.7891806728545238  Validation Loss:  0.6528898498428792\n",
      "Epoch:  1419  Loss:  0.7892305291871625  Validation Loss:  0.6528841610034478\n",
      "Epoch:  1420  Loss:  0.7892805224559694  Validation Loss:  0.6528786126652668\n",
      "Epoch:  1421  Loss:  0.78933067842048  Validation Loss:  0.6528731846282708\n",
      "Epoch:  1422  Loss:  0.7893809727922251  Validation Loss:  0.6528679290144094\n",
      "Epoch:  1423  Loss:  0.7894314283568581  Validation Loss:  0.6528628217698685\n",
      "Epoch:  1424  Loss:  0.7894820542371069  Validation Loss:  0.6528578680329795\n",
      "Epoch:  1425  Loss:  0.7895328463901851  Validation Loss:  0.6528530750616357\n",
      "Epoch:  1426  Loss:  0.7895838021597062  Validation Loss:  0.6528484526186668\n",
      "Epoch:  1427  Loss:  0.7896349365632473  Validation Loss:  0.6528439783202163\n",
      "Epoch:  1428  Loss:  0.7896862219786271  Validation Loss:  0.6528396670674456\n",
      "Epoch:  1429  Loss:  0.7897376816148277  Validation Loss:  0.6528355297150796\n",
      "Epoch:  1430  Loss:  0.7897893066560342  Validation Loss:  0.6528315056629223\n",
      "Epoch:  1431  Loss:  0.7898410907629031  Validation Loss:  0.6528276496020884\n",
      "Epoch:  1432  Loss:  0.789893039883199  Validation Loss:  0.6528239564263615\n",
      "Epoch:  1433  Loss:  0.7899451562499796  Validation Loss:  0.6528204291866258\n",
      "Epoch:  1434  Loss:  0.7899974567540498  Validation Loss:  0.6528170308868947\n",
      "Epoch:  1435  Loss:  0.790049861005338  Validation Loss:  0.6528137830439312\n",
      "Epoch:  1436  Loss:  0.7901024538176981  Validation Loss:  0.6528107030638333\n",
      "Epoch:  1437  Loss:  0.7901552169350907  Validation Loss:  0.6528077606946744\n",
      "Epoch:  1438  Loss:  0.7902081383032385  Validation Loss:  0.6528049475545513\n",
      "Epoch:  1439  Loss:  0.790261195379902  Validation Loss:  0.6528022491276778\n",
      "Epoch:  1440  Loss:  0.7903144245713272  Validation Loss:  0.6527997287439888\n",
      "Epoch:  1441  Loss:  0.7903677893971855  Validation Loss:  0.6527973190913426\n",
      "Epoch:  1442  Loss:  0.7904213156064295  Validation Loss:  0.6527950730624383\n",
      "Epoch:  1443  Loss:  0.7904749892398037  Validation Loss:  0.6527929616257034\n",
      "Epoch:  1444  Loss:  0.7905288172293116  Validation Loss:  0.6527909827579198\n",
      "Epoch:  1445  Loss:  0.7905828044749796  Validation Loss:  0.6527891114418363\n",
      "Epoch:  1446  Loss:  0.7906369274291634  Validation Loss:  0.65278736437703\n",
      "Epoch:  1447  Loss:  0.7906911985906349  Validation Loss:  0.6527857326998793\n",
      "Epoch:  1448  Loss:  0.7907456293257631  Validation Loss:  0.6527842692388542\n",
      "Epoch:  1449  Loss:  0.7908001808153297  Validation Loss:  0.6527828930652347\n",
      "Epoch:  1450  Loss:  0.7908548861636188  Validation Loss:  0.6527816698212048\n",
      "Epoch:  1451  Loss:  0.7909097453388809  Validation Loss:  0.6527805550923121\n",
      "Epoch:  1452  Loss:  0.7909647357247939  Validation Loss:  0.6527795556868459\n",
      "Epoch:  1453  Loss:  0.7910198760642246  Validation Loss:  0.6527786753300963\n",
      "Epoch:  1454  Loss:  0.791075134861537  Validation Loss:  0.6527779370803257\n",
      "Epoch:  1455  Loss:  0.7911305462475866  Validation Loss:  0.652777303556173\n",
      "Epoch:  1456  Loss:  0.7911861270179295  Validation Loss:  0.6527767772946892\n",
      "Epoch:  1457  Loss:  0.7912418135463006  Validation Loss:  0.6527763658749133\n",
      "Epoch:  1458  Loss:  0.7912976610135626  Validation Loss:  0.6527760549737461\n",
      "Epoch:  1459  Loss:  0.7913536462001503  Validation Loss:  0.6527758807521956\n",
      "Epoch:  1460  Loss:  0.7914097558876331  Validation Loss:  0.6527758070492539\n",
      "Epoch:  1461  Loss:  0.7914660078875552  Validation Loss:  0.6527758089761282\n",
      "Epoch:  1462  Loss:  0.7915224060204558  Validation Loss:  0.6527759682001739\n",
      "Epoch:  1463  Loss:  0.7915789426664229  Validation Loss:  0.6527762238642779\n",
      "Epoch:  1464  Loss:  0.79163562185766  Validation Loss:  0.6527765606819041\n",
      "Epoch:  1465  Loss:  0.7916924094950611  Validation Loss:  0.6527770185714652\n",
      "Epoch:  1466  Loss:  0.7917493487581272  Validation Loss:  0.6527775801589777\n",
      "Epoch:  1467  Loss:  0.7918064038015225  Validation Loss:  0.6527782655160489\n",
      "Epoch:  1468  Loss:  0.7918636084915224  Validation Loss:  0.6527790345958081\n",
      "Epoch:  1469  Loss:  0.7919209444662556  Validation Loss:  0.6527799299500626\n",
      "Epoch:  1470  Loss:  0.7919784224147655  Validation Loss:  0.6527809228041562\n",
      "Epoch:  1471  Loss:  0.792036019180986  Validation Loss:  0.6527820110064129\n",
      "Epoch:  1472  Loss:  0.7920937460042875  Validation Loss:  0.6527832039985163\n",
      "Epoch:  1473  Loss:  0.7921516121767292  Validation Loss:  0.652784530619352\n",
      "Epoch:  1474  Loss:  0.7922095997703515  Validation Loss:  0.6527859116743865\n",
      "Epoch:  1475  Loss:  0.7922677374550734  Validation Loss:  0.652787424559737\n",
      "Epoch:  1476  Loss:  0.7923259737329896  Validation Loss:  0.6527890883193448\n",
      "Epoch:  1477  Loss:  0.7923843522492627  Validation Loss:  0.652790785767138\n",
      "Epoch:  1478  Loss:  0.7924428625794296  Validation Loss:  0.652792646260611\n",
      "Epoch:  1479  Loss:  0.7925014798106118  Validation Loss:  0.6527945957435616\n",
      "Epoch:  1480  Loss:  0.7925602393859829  Validation Loss:  0.6527966598755327\n",
      "Epoch:  1481  Loss:  0.7926191351037811  Validation Loss:  0.6527988266135598\n",
      "Epoch:  1482  Loss:  0.7926781500202857  Validation Loss:  0.6528011038899422\n",
      "Epoch:  1483  Loss:  0.7927372805372049  Validation Loss:  0.6528034734636031\n",
      "Epoch:  1484  Loss:  0.7927965442544188  Validation Loss:  0.6528059341784181\n",
      "Epoch:  1485  Loss:  0.7928559292552315  Validation Loss:  0.6528085182774169\n",
      "Epoch:  1486  Loss:  0.7929154483770783  Validation Loss:  0.6528112288435985\n",
      "Epoch:  1487  Loss:  0.79297506602862  Validation Loss:  0.6528140238068741\n",
      "Epoch:  1488  Loss:  0.793034840978428  Validation Loss:  0.652816938300585\n",
      "Epoch:  1489  Loss:  0.7930947187547148  Validation Loss:  0.6528199180832197\n",
      "Epoch:  1490  Loss:  0.7931547397218476  Validation Loss:  0.6528230664031259\n",
      "Epoch:  1491  Loss:  0.7932148573242805  Validation Loss:  0.6528262699600952\n",
      "Epoch:  1492  Loss:  0.7932751110903072  Validation Loss:  0.6528296021038088\n",
      "Epoch:  1493  Loss:  0.7933354841714556  Validation Loss:  0.6528329913151162\n",
      "Epoch:  1494  Loss:  0.7933959384046664  Validation Loss:  0.6528365131917184\n",
      "Epoch:  1495  Loss:  0.7934565036980943  Validation Loss:  0.6528400561354798\n",
      "Epoch:  1496  Loss:  0.7935171824647114  Validation Loss:  0.6528436763469001\n",
      "Epoch:  1497  Loss:  0.7935779902618378  Validation Loss:  0.6528474271361684\n",
      "Epoch:  1498  Loss:  0.793638895869001  Validation Loss:  0.6528512493803583\n",
      "Epoch:  1499  Loss:  0.793699936687269  Validation Loss:  0.6528551578521729\n",
      "Training session:  6\n",
      "2021_1_12_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2021_1_12_MV1_run\n",
      "Epoch:  0  Loss:  0.8857396485021753  Validation Loss:  1.0392036195034566\n",
      "Epoch:  1  Loss:  0.8859217831699937  Validation Loss:  1.0393695634101396\n",
      "Epoch:  2  Loss:  0.8860975848618234  Validation Loss:  1.0395280786088088\n",
      "Epoch:  3  Loss:  0.8862662321127255  Validation Loss:  1.0396795811408295\n",
      "Epoch:  4  Loss:  0.8864298217338781  Validation Loss:  1.0398264729816034\n",
      "Epoch:  5  Loss:  0.8865884097781286  Validation Loss:  1.0399683917555418\n",
      "Epoch:  6  Loss:  0.8867450827660347  Validation Loss:  1.0401099036427457\n",
      "Epoch:  7  Loss:  0.8869018124120346  Validation Loss:  1.0402515202497498\n",
      "Epoch:  8  Loss:  0.8870585364457988  Validation Loss:  1.0403929473629787\n",
      "Epoch:  9  Loss:  0.8872149922241891  Validation Loss:  1.0405328601187067\n",
      "Epoch:  10  Loss:  0.887365750535007  Validation Loss:  1.0406654521728447\n",
      "Epoch:  11  Loss:  0.8875141999858333  Validation Loss:  1.040798219791411\n",
      "Epoch:  12  Loss:  0.8876628728161874  Validation Loss:  1.0409312132422044\n",
      "Epoch:  13  Loss:  0.8878117470433529  Validation Loss:  1.0410644130956759\n",
      "Epoch:  14  Loss:  0.8879612659898731  Validation Loss:  1.0411987603655544\n",
      "Epoch:  15  Loss:  0.8881112529305081  Validation Loss:  1.0413328911940418\n",
      "Epoch:  16  Loss:  0.8882609451482371  Validation Loss:  1.0414670476541463\n",
      "Epoch:  17  Loss:  0.8884107901650318  Validation Loss:  1.041601114852381\n",
      "Epoch:  18  Loss:  0.888557820527213  Validation Loss:  1.041729924424241\n",
      "Epoch:  19  Loss:  0.8887016728494398  Validation Loss:  1.041857739434699\n",
      "Epoch:  20  Loss:  0.8888456116411247  Validation Loss:  1.0419858339971497\n",
      "Epoch:  21  Loss:  0.888989730207453  Validation Loss:  1.0421140298173102\n",
      "Epoch:  22  Loss:  0.8891342389267345  Validation Loss:  1.0422431653756918\n",
      "Epoch:  23  Loss:  0.8892798236604029  Validation Loss:  1.0423730792329255\n",
      "Epoch:  24  Loss:  0.8894237380749456  Validation Loss:  1.0424977501658588\n",
      "Epoch:  25  Loss:  0.8895622662514973  Validation Loss:  1.042619635452233\n",
      "Epoch:  26  Loss:  0.8897006298913801  Validation Loss:  1.0427416873778608\n",
      "Epoch:  27  Loss:  0.8898393228476035  Validation Loss:  1.042864548916375\n",
      "Epoch:  28  Loss:  0.8899783485578102  Validation Loss:  1.042985143031979\n",
      "Epoch:  29  Loss:  0.8901117848219956  Validation Loss:  1.0431006520487152\n",
      "Epoch:  30  Loss:  0.8902441526964325  Validation Loss:  1.0432164000138047\n",
      "Epoch:  31  Loss:  0.8903750653578719  Validation Loss:  1.0433273511985992\n",
      "Epoch:  32  Loss:  0.8905003818082036  Validation Loss:  1.0434350195658002\n",
      "Epoch:  33  Loss:  0.8906249664401753  Validation Loss:  1.0435404908013246\n",
      "Epoch:  34  Loss:  0.8907445181625696  Validation Loss:  1.0436415112597626\n",
      "Epoch:  35  Loss:  0.8908611982976068  Validation Loss:  1.0437372005747065\n",
      "Epoch:  36  Loss:  0.8909721408944659  Validation Loss:  1.043827941712073\n",
      "Epoch:  37  Loss:  0.8910769440789789  Validation Loss:  1.043911034356047\n",
      "Epoch:  38  Loss:  0.8911742847446732  Validation Loss:  1.0439857146196554\n",
      "Epoch:  39  Loss:  0.8912633326728557  Validation Loss:  1.0440511581440712\n",
      "Epoch:  40  Loss:  0.8913425119702243  Validation Loss:  1.0441046802907425\n",
      "Epoch:  41  Loss:  0.8914084259575477  Validation Loss:  1.0441431900810287\n",
      "Epoch:  42  Loss:  0.8914594698874777  Validation Loss:  1.044165009231158\n",
      "Epoch:  43  Loss:  0.8914925703746086  Validation Loss:  1.0441654772275006\n",
      "Epoch:  44  Loss:  0.8915024570192808  Validation Loss:  1.0441390567769606\n",
      "Epoch:  45  Loss:  0.8914843803363202  Validation Loss:  1.0440807047542995\n",
      "Epoch:  46  Loss:  0.8914330632983056  Validation Loss:  1.0439849396310477\n",
      "Epoch:  47  Loss:  0.8913449350460794  Validation Loss:  1.0438492913170299\n",
      "Epoch:  48  Loss:  0.8912198532031379  Validation Loss:  1.0436761338007299\n",
      "Epoch:  49  Loss:  0.8910625367419731  Validation Loss:  1.043472038899157\n",
      "Epoch:  50  Loss:  0.8908814244431181  Validation Loss:  1.043247467868597\n",
      "Epoch:  51  Loss:  0.8906855226400562  Validation Loss:  1.0430104319998266\n",
      "Epoch:  52  Loss:  0.8904827903827327  Validation Loss:  1.042769801867046\n",
      "Epoch:  53  Loss:  0.8902777289678976  Validation Loss:  1.0425277905288977\n",
      "Epoch:  54  Loss:  0.8900738728364921  Validation Loss:  1.0422894299482468\n",
      "Epoch:  55  Loss:  0.8898730089444921  Validation Loss:  1.042052167940183\n",
      "Epoch:  56  Loss:  0.8896724006762384  Validation Loss:  1.0418150857009965\n",
      "Epoch:  57  Loss:  0.8894756223630043  Validation Loss:  1.0415857062013685\n",
      "Epoch:  58  Loss:  0.889283215658156  Validation Loss:  1.0413573156718328\n",
      "Epoch:  59  Loss:  0.889092224732593  Validation Loss:  1.0411332365145665\n",
      "Epoch:  60  Loss:  0.8889073775668664  Validation Loss:  1.0409136659539966\n",
      "Epoch:  61  Loss:  0.8887235947864275  Validation Loss:  1.040694336420384\n",
      "Epoch:  62  Loss:  0.8885403093638902  Validation Loss:  1.0404758729290324\n",
      "Epoch:  63  Loss:  0.8883612314911641  Validation Loss:  1.040264718167052\n",
      "Epoch:  64  Loss:  0.8881858019107383  Validation Loss:  1.0400542183374257\n",
      "Epoch:  65  Loss:  0.8880106054209127  Validation Loss:  1.0398438962385652\n",
      "Epoch:  66  Loss:  0.8878356358997108  Validation Loss:  1.039633862465026\n",
      "Epoch:  67  Loss:  0.8876625821067843  Validation Loss:  1.0394276214655542\n",
      "Epoch:  68  Loss:  0.8874930665049549  Validation Loss:  1.0392253982659052\n",
      "Epoch:  69  Loss:  0.8873275095795833  Validation Loss:  1.039025698380167\n",
      "Epoch:  70  Loss:  0.8871626000895473  Validation Loss:  1.038826245635721\n",
      "Epoch:  71  Loss:  0.8869982637437874  Validation Loss:  1.0386279721818594\n",
      "Epoch:  72  Loss:  0.8868362809722402  Validation Loss:  1.0384327652931646\n",
      "Epoch:  73  Loss:  0.8866758451845669  Validation Loss:  1.0382380359873609\n",
      "Epoch:  74  Loss:  0.8865156197362101  Validation Loss:  1.0380434842098611\n",
      "Epoch:  75  Loss:  0.8863558129088737  Validation Loss:  1.0378496377168736\n",
      "Epoch:  76  Loss:  0.8861980807664578  Validation Loss:  1.0376592431305165\n",
      "Epoch:  77  Loss:  0.8860424505829251  Validation Loss:  1.0374695786099504\n",
      "Epoch:  78  Loss:  0.8858870954820163  Validation Loss:  1.0372801436199064\n",
      "Epoch:  79  Loss:  0.8857319856207203  Validation Loss:  1.037090915231628\n",
      "Epoch:  80  Loss:  0.8855770905897726  Validation Loss:  1.036901892507044\n",
      "Epoch:  81  Loss:  0.8854233975515439  Validation Loss:  1.0367156452047166\n",
      "Epoch:  82  Loss:  0.885272525785518  Validation Loss:  1.0365310840619106\n",
      "Epoch:  83  Loss:  0.8851220841978414  Validation Loss:  1.036346733381135\n",
      "Epoch:  84  Loss:  0.8849718629323778  Validation Loss:  1.0361625730141026\n",
      "Epoch:  85  Loss:  0.8848218547272975  Validation Loss:  1.0359786520509615\n",
      "Epoch:  86  Loss:  0.8846720581856168  Validation Loss:  1.0357949239255833\n",
      "Epoch:  87  Loss:  0.8845224927215684  Validation Loss:  1.035611443079846\n",
      "Epoch:  88  Loss:  0.8843731853039483  Validation Loss:  1.0354282644010433\n",
      "Epoch:  89  Loss:  0.8842254438419438  Validation Loss:  1.0352483421422378\n",
      "Epoch:  90  Loss:  0.8840804185392788  Validation Loss:  1.0350696939867043\n",
      "Epoch:  91  Loss:  0.8839356855532263  Validation Loss:  1.0348912917678177\n",
      "Epoch:  92  Loss:  0.8837914756472105  Validation Loss:  1.0347136208193675\n",
      "Epoch:  93  Loss:  0.8836479889651652  Validation Loss:  1.0345369315017825\n",
      "Epoch:  94  Loss:  0.8835051736220247  Validation Loss:  1.0343604905773764\n",
      "Epoch:  95  Loss:  0.8833625677778629  Validation Loss:  1.0341842831146189\n",
      "Epoch:  96  Loss:  0.8832201775405285  Validation Loss:  1.0340082915567295\n",
      "Epoch:  97  Loss:  0.8830779843920733  Validation Loss:  1.033832495249268\n",
      "Epoch:  98  Loss:  0.8829359907365305  Validation Loss:  1.0336568777726127\n",
      "Epoch:  99  Loss:  0.8827942083352381  Validation Loss:  1.0334814983298597\n",
      "Epoch:  100  Loss:  0.8826526117949629  Validation Loss:  1.0333062697647382\n",
      "Epoch:  101  Loss:  0.8825119806247881  Validation Loss:  1.0331329333703911\n",
      "Epoch:  102  Loss:  0.8823734767151797  Validation Loss:  1.032961932287646\n",
      "Epoch:  103  Loss:  0.8822363496224568  Validation Loss:  1.0327914204259498\n",
      "Epoch:  104  Loss:  0.882099472194259  Validation Loss:  1.03262121494576\n",
      "Epoch:  105  Loss:  0.8819628482022169  Validation Loss:  1.0324511992866579\n",
      "Epoch:  106  Loss:  0.8818264065809928  Validation Loss:  1.0322814069526351\n",
      "Epoch:  107  Loss:  0.881690174949274  Validation Loss:  1.0321117929668855\n",
      "Epoch:  108  Loss:  0.8815542195259042  Validation Loss:  1.0319426259282383\n",
      "Epoch:  109  Loss:  0.8814186563984338  Validation Loss:  1.031773886397022\n",
      "Epoch:  110  Loss:  0.8812835298024244  Validation Loss:  1.031605597096158\n",
      "Epoch:  111  Loss:  0.8811489017058652  Validation Loss:  1.0314379103441278\n",
      "Epoch:  112  Loss:  0.881014571472035  Validation Loss:  1.031270435201409\n",
      "Epoch:  113  Loss:  0.8808804961255959  Validation Loss:  1.0311031823309704\n",
      "Epoch:  114  Loss:  0.8807466216351457  Validation Loss:  1.0309361713479503\n",
      "Epoch:  115  Loss:  0.8806129721755126  Validation Loss:  1.0307693529428672\n",
      "Epoch:  116  Loss:  0.8804795284816561  Validation Loss:  1.0306027753116644\n",
      "Epoch:  117  Loss:  0.8803463140751226  Validation Loss:  1.0304363688616\n",
      "Epoch:  118  Loss:  0.8802133159558243  Validation Loss:  1.0302702303388682\n",
      "Epoch:  119  Loss:  0.8800805084457061  Validation Loss:  1.030104293241638\n",
      "Epoch:  120  Loss:  0.8799479625355091  Validation Loss:  1.0299385787237543\n",
      "Epoch:  121  Loss:  0.879815626483709  Validation Loss:  1.0297730985549751\n",
      "Epoch:  122  Loss:  0.8796838612184923  Validation Loss:  1.029608583452342\n",
      "Epoch:  123  Loss:  0.8795539613731784  Validation Loss:  1.0294470300870961\n",
      "Epoch:  124  Loss:  0.8794260782469968  Validation Loss:  1.0292862870163568\n",
      "Epoch:  125  Loss:  0.8792985838813057  Validation Loss:  1.0291258891558517\n",
      "Epoch:  126  Loss:  0.8791713079537075  Validation Loss:  1.0289656687257946\n",
      "Epoch:  127  Loss:  0.8790442382824128  Validation Loss:  1.0288056478484708\n",
      "Epoch:  128  Loss:  0.8789173527112122  Validation Loss:  1.028645864583255\n",
      "Epoch:  129  Loss:  0.8787906875786399  Validation Loss:  1.0284862904978134\n",
      "Epoch:  130  Loss:  0.878664242389648  Validation Loss:  1.0283269617213882\n",
      "Epoch:  131  Loss:  0.8785380502299234  Validation Loss:  1.028167834016157\n",
      "Epoch:  132  Loss:  0.8784120654318825  Validation Loss:  1.0280089468216065\n",
      "Epoch:  133  Loss:  0.8782863254337888  Validation Loss:  1.0278503060563589\n",
      "Epoch:  134  Loss:  0.8781609372834865  Validation Loss:  1.0276921224490185\n",
      "Epoch:  135  Loss:  0.8780359137572746  Validation Loss:  1.0275337569638276\n",
      "Epoch:  136  Loss:  0.8779100938067201  Validation Loss:  1.0273746081249977\n",
      "Epoch:  137  Loss:  0.877783122003413  Validation Loss:  1.0272138388591239\n",
      "Epoch:  138  Loss:  0.8776557733298017  Validation Loss:  1.0270533054405688\n",
      "Epoch:  139  Loss:  0.8775286520209652  Validation Loss:  1.026892957854611\n",
      "Epoch:  140  Loss:  0.8774017056662734  Validation Loss:  1.0267328379534022\n",
      "Epoch:  141  Loss:  0.8772749699837555  Validation Loss:  1.0265729395314998\n",
      "Epoch:  142  Loss:  0.877148485290411  Validation Loss:  1.0264132874646643\n",
      "Epoch:  143  Loss:  0.877022235536749  Validation Loss:  1.0262538499732003\n",
      "Epoch:  144  Loss:  0.8768962151280523  Validation Loss:  1.0260946759312968\n",
      "Epoch:  145  Loss:  0.8767704378883581  Validation Loss:  1.025935743206545\n",
      "Epoch:  146  Loss:  0.8766449007083599  Validation Loss:  1.0257770081617585\n",
      "Epoch:  147  Loss:  0.8765195940182662  Validation Loss:  1.0256185382368395\n",
      "Epoch:  148  Loss:  0.8763944635075038  Validation Loss:  1.0254602607110164\n",
      "Epoch:  149  Loss:  0.8762695725240917  Validation Loss:  1.0253022370718257\n",
      "Epoch:  150  Loss:  0.8761449466194976  Validation Loss:  1.0251444465264785\n",
      "Epoch:  151  Loss:  0.8760205591221801  Validation Loss:  1.0249868761275664\n",
      "Epoch:  152  Loss:  0.8758963571795833  Validation Loss:  1.0248295406581482\n",
      "Epoch:  153  Loss:  0.8757723839964844  Validation Loss:  1.0246723940616231\n",
      "Epoch:  154  Loss:  0.8756485507140859  Validation Loss:  1.024515382088451\n",
      "Epoch:  155  Loss:  0.8755248797948934  Validation Loss:  1.0243585256562717\n",
      "Epoch:  156  Loss:  0.8754013863107353  Validation Loss:  1.0242018459020588\n",
      "Epoch:  157  Loss:  0.8752781298560841  Validation Loss:  1.0240454530795577\n",
      "Epoch:  158  Loss:  0.8751550555597647  Validation Loss:  1.0238892508474975\n",
      "Epoch:  159  Loss:  0.8750322004633241  Validation Loss:  1.0237332759931197\n",
      "Epoch:  160  Loss:  0.8749095915592936  Validation Loss:  1.0235775299134084\n",
      "Epoch:  161  Loss:  0.8747871545905211  Validation Loss:  1.0234219865954441\n",
      "Epoch:  162  Loss:  0.8746650138365792  Validation Loss:  1.0232668429802076\n",
      "Epoch:  163  Loss:  0.874543139079215  Validation Loss:  1.02311184490437\n",
      "Epoch:  164  Loss:  0.8744214834347006  Validation Loss:  1.0229571013124255\n",
      "Epoch:  165  Loss:  0.8743000273090941  Validation Loss:  1.0228025675919987\n",
      "Epoch:  166  Loss:  0.8741787829553908  Validation Loss:  1.0226482945035442\n",
      "Epoch:  167  Loss:  0.8740577607639405  Validation Loss:  1.0224941925321152\n",
      "Epoch:  168  Loss:  0.8739369241678997  Validation Loss:  1.0223403154312214\n",
      "Epoch:  169  Loss:  0.873816302759365  Validation Loss:  1.0221867126891848\n",
      "Epoch:  170  Loss:  0.8736966476805093  Validation Loss:  1.0220346145460084\n",
      "Epoch:  171  Loss:  0.873578460071037  Validation Loss:  1.0218843840690248\n",
      "Epoch:  172  Loss:  0.873461522333758  Validation Loss:  1.0217349331157848\n",
      "Epoch:  173  Loss:  0.8733452066770094  Validation Loss:  1.0215858687086543\n",
      "Epoch:  174  Loss:  0.8732290660162249  Validation Loss:  1.0214369781112864\n",
      "Epoch:  175  Loss:  0.8731130006840652  Validation Loss:  1.0212882124731129\n",
      "Epoch:  176  Loss:  0.8729970727197247  Validation Loss:  1.0211395917703276\n",
      "Epoch:  177  Loss:  0.872881216207266  Validation Loss:  1.0209910630322723\n",
      "Epoch:  178  Loss:  0.8727653958355484  Validation Loss:  1.0208426372829718\n",
      "Epoch:  179  Loss:  0.8726495754457467  Validation Loss:  1.0206941825310714\n",
      "Epoch:  180  Loss:  0.8725336900860234  Validation Loss:  1.02054572098659\n",
      "Epoch:  181  Loss:  0.8724176614405135  Validation Loss:  1.0203971486315941\n",
      "Epoch:  182  Loss:  0.872301423898446  Validation Loss:  1.0202484940806322\n",
      "Epoch:  183  Loss:  0.8721848406164355  Validation Loss:  1.0200995374538437\n",
      "Epoch:  184  Loss:  0.8720678462775749  Validation Loss:  1.0199502691511821\n",
      "Epoch:  185  Loss:  0.8719503810952499  Validation Loss:  1.0198006998659854\n",
      "Epoch:  186  Loss:  0.8718324564137379  Validation Loss:  1.0196508515383238\n",
      "Epoch:  187  Loss:  0.8717142065763203  Validation Loss:  1.0195008563923824\n",
      "Epoch:  188  Loss:  0.87159579498942  Validation Loss:  1.0193509226226234\n",
      "Epoch:  189  Loss:  0.8714773968614873  Validation Loss:  1.0192010475700533\n",
      "Epoch:  190  Loss:  0.8713591413276306  Validation Loss:  1.0190513988356174\n",
      "Epoch:  191  Loss:  0.871241148219905  Validation Loss:  1.0189020780751994\n",
      "Epoch:  192  Loss:  0.8711234102911741  Validation Loss:  1.0187525558589108\n",
      "Epoch:  193  Loss:  0.8710045753424372  Validation Loss:  1.018601368420987\n",
      "Epoch:  194  Loss:  0.8708841201648098  Validation Loss:  1.018448653485815\n",
      "Epoch:  195  Loss:  0.8707634374743454  Validation Loss:  1.0182961917286604\n",
      "Epoch:  196  Loss:  0.870643063041481  Validation Loss:  1.018144108662112\n",
      "Epoch:  197  Loss:  0.8705230137656524  Validation Loss:  1.0179922705468978\n",
      "Epoch:  198  Loss:  0.8704032644163817  Validation Loss:  1.0178407993963987\n",
      "Epoch:  199  Loss:  0.8702838379636552  Validation Loss:  1.0176895888070103\n",
      "Epoch:  200  Loss:  0.8701647102269932  Validation Loss:  1.0175386835530777\n",
      "Epoch:  201  Loss:  0.8700458697716986  Validation Loss:  1.0173880641375654\n",
      "Epoch:  202  Loss:  0.8699273466476176  Validation Loss:  1.0172377583584276\n",
      "Epoch:  203  Loss:  0.869809112032351  Validation Loss:  1.0170877736628703\n",
      "Epoch:  204  Loss:  0.8696911845026194  Validation Loss:  1.0169380772892602\n",
      "Epoch:  205  Loss:  0.8695735522315304  Validation Loss:  1.0167886599142482\n",
      "Epoch:  206  Loss:  0.8694562032441292  Validation Loss:  1.0166395404612294\n",
      "Epoch:  207  Loss:  0.8693391710657681  Validation Loss:  1.0164906850584068\n",
      "Epoch:  208  Loss:  0.8692224153150234  Validation Loss:  1.0163421408151803\n",
      "Epoch:  209  Loss:  0.8691059159888045  Validation Loss:  1.0161938899891803\n",
      "Epoch:  210  Loss:  0.8689897584534494  Validation Loss:  1.016045964680666\n",
      "Epoch:  211  Loss:  0.8688738861672797  Validation Loss:  1.0158982559417684\n",
      "Epoch:  212  Loss:  0.868758281892916  Validation Loss:  1.0157508849895194\n",
      "Epoch:  213  Loss:  0.8686429436501676  Validation Loss:  1.0156037862635339\n",
      "Epoch:  214  Loss:  0.8685279296252207  Validation Loss:  1.0154570180963238\n",
      "Epoch:  215  Loss:  0.8684132060079013  Validation Loss:  1.0153104999183638\n",
      "Epoch:  216  Loss:  0.868298751212774  Validation Loss:  1.0151639145029627\n",
      "Epoch:  217  Loss:  0.8681832511120394  Validation Loss:  1.0150154871609656\n",
      "Epoch:  218  Loss:  0.868065868290729  Validation Loss:  1.014865395548902\n",
      "Epoch:  219  Loss:  0.8679482158131048  Validation Loss:  1.0147156192468938\n",
      "Epoch:  220  Loss:  0.8678308842563549  Validation Loss:  1.014566141406776\n",
      "Epoch:  221  Loss:  0.8677138434881254  Validation Loss:  1.014416949769509\n",
      "Epoch:  222  Loss:  0.8675970870795777  Validation Loss:  1.014268039867444\n",
      "Epoch:  223  Loss:  0.8674806069573658  Validation Loss:  1.0141194221847083\n",
      "Epoch:  224  Loss:  0.8673644116797113  Validation Loss:  1.013971093903714\n",
      "Epoch:  225  Loss:  0.8672484051678059  Validation Loss:  1.0138228138017913\n",
      "Epoch:  226  Loss:  0.8671323004703136  Validation Loss:  1.013674600340048\n",
      "Epoch:  227  Loss:  0.8670163386991898  Validation Loss:  1.0135267025932833\n",
      "Epoch:  228  Loss:  0.8669008541438565  Validation Loss:  1.0133793761049383\n",
      "Epoch:  229  Loss:  0.8667861249758998  Validation Loss:  1.013232900990524\n",
      "Epoch:  230  Loss:  0.8666717005041382  Validation Loss:  1.0130854642180644\n",
      "Epoch:  231  Loss:  0.8665545446361931  Validation Loss:  1.0129351332797196\n",
      "Epoch:  232  Loss:  0.8664368397479388  Validation Loss:  1.0127851064350673\n",
      "Epoch:  233  Loss:  0.8663194174414899  Validation Loss:  1.012635394235722\n",
      "Epoch:  234  Loss:  0.8662022640815602  Validation Loss:  1.0124859426008619\n",
      "Epoch:  235  Loss:  0.8660854134625005  Validation Loss:  1.0123368112397366\n",
      "Epoch:  236  Loss:  0.8659688473726596  Validation Loss:  1.0121879351048635\n",
      "Epoch:  237  Loss:  0.8658525543739495  Validation Loss:  1.01203937979712\n",
      "Epoch:  238  Loss:  0.8657365059446164  Validation Loss:  1.0118904342044792\n",
      "Epoch:  239  Loss:  0.8656180105375542  Validation Loss:  1.011738015183558\n",
      "Epoch:  240  Loss:  0.8654985481260561  Validation Loss:  1.0115859553798277\n",
      "Epoch:  241  Loss:  0.8653794448546956  Validation Loss:  1.0114342270526981\n",
      "Epoch:  242  Loss:  0.8652606495832391  Validation Loss:  1.0112827684244383\n",
      "Epoch:  243  Loss:  0.865142142080286  Validation Loss:  1.0111316329009994\n",
      "Epoch:  244  Loss:  0.8650237836251126  Validation Loss:  1.0109796526544876\n",
      "Epoch:  245  Loss:  0.8649027531964306  Validation Loss:  1.0108246907989993\n",
      "Epoch:  246  Loss:  0.8647810991828611  Validation Loss:  1.0106700105302413\n",
      "Epoch:  247  Loss:  0.864659723620048  Validation Loss:  1.0105156538150935\n",
      "Epoch:  248  Loss:  0.8645386208149433  Validation Loss:  1.0103611306159124\n",
      "Epoch:  249  Loss:  0.8644152222963014  Validation Loss:  1.01020295082497\n",
      "Epoch:  250  Loss:  0.8642907004037113  Validation Loss:  1.010045063233111\n",
      "Epoch:  251  Loss:  0.8641662591281664  Validation Loss:  1.0098870293763669\n",
      "Epoch:  252  Loss:  0.8640406834519947  Validation Loss:  1.009726333634361\n",
      "Epoch:  253  Loss:  0.8639126659271498  Validation Loss:  1.009564635704906\n",
      "Epoch:  254  Loss:  0.863784835367572  Validation Loss:  1.0094025954772867\n",
      "Epoch:  255  Loss:  0.8636545986739593  Validation Loss:  1.0092371242573026\n",
      "Epoch:  256  Loss:  0.8635233625808043  Validation Loss:  1.0090715239951522\n",
      "Epoch:  257  Loss:  0.8633898645820259  Validation Loss:  1.0089022399203016\n",
      "Epoch:  258  Loss:  0.8632550697041296  Validation Loss:  1.0087321191904661\n",
      "Epoch:  259  Loss:  0.8631175949443946  Validation Loss:  1.0085587702536334\n",
      "Epoch:  260  Loss:  0.8629778667219724  Validation Loss:  1.0083824039902538\n",
      "Epoch:  261  Loss:  0.8628351493971422  Validation Loss:  1.0082032301638653\n",
      "Epoch:  262  Loss:  0.8626893475952386  Validation Loss:  1.0080203483070151\n",
      "Epoch:  263  Loss:  0.862539974706998  Validation Loss:  1.0078332183842102\n",
      "Epoch:  264  Loss:  0.8623860612064057  Validation Loss:  1.0076404582486367\n",
      "Epoch:  265  Loss:  0.8622270032087594  Validation Loss:  1.0074420831220197\n",
      "Epoch:  266  Loss:  0.8620620453526782  Validation Loss:  1.0072370626444025\n",
      "Epoch:  267  Loss:  0.8618900464730138  Validation Loss:  1.0070232867762663\n",
      "Epoch:  268  Loss:  0.8617097336914191  Validation Loss:  1.006799781728752\n",
      "Epoch:  269  Loss:  0.8615197482218206  Validation Loss:  1.006565059238262\n",
      "Epoch:  270  Loss:  0.8613178427760643  Validation Loss:  1.0063161083861538\n",
      "Epoch:  271  Loss:  0.8611009279322512  Validation Loss:  1.0060491958849025\n",
      "Epoch:  272  Loss:  0.8608658764436751  Validation Loss:  1.0057606792441853\n",
      "Epoch:  273  Loss:  0.8606082823419111  Validation Loss:  1.005445370140175\n",
      "Epoch:  274  Loss:  0.8603231067005184  Validation Loss:  1.0050973918194464\n",
      "Epoch:  275  Loss:  0.8600047700461995  Validation Loss:  1.0047108320370857\n",
      "Epoch:  276  Loss:  0.859648513893633  Validation Loss:  1.0042814048398556\n",
      "Epoch:  277  Loss:  0.8592519571923298  Validation Loss:  1.00380843388848\n",
      "Epoch:  278  Loss:  0.8588174035573758  Validation Loss:  1.003296963593828\n",
      "Epoch:  279  Loss:  0.8583518533777554  Validation Loss:  1.0027564886613223\n",
      "Epoch:  280  Loss:  0.85786515463017  Validation Loss:  1.002198033824401\n",
      "Epoch:  281  Loss:  0.8573663320914544  Validation Loss:  1.0016299029508524\n",
      "Epoch:  282  Loss:  0.856861963030629  Validation Loss:  1.0010586612776893\n",
      "Epoch:  283  Loss:  0.8563569747555766  Validation Loss:  1.0004878350587534\n",
      "Epoch:  284  Loss:  0.8558535077292653  Validation Loss:  0.9999204473502502\n",
      "Epoch:  285  Loss:  0.855353470776429  Validation Loss:  0.9993555024873627\n",
      "Epoch:  286  Loss:  0.8548564459864069  Validation Loss:  0.9987951154395452\n",
      "Epoch:  287  Loss:  0.8543634276251643  Validation Loss:  0.9982390435095336\n",
      "Epoch:  288  Loss:  0.8538735939282471  Validation Loss:  0.997686224554301\n",
      "Epoch:  289  Loss:  0.8533863429278497  Validation Loss:  0.9971357582616147\n",
      "Epoch:  290  Loss:  0.85290169203993  Validation Loss:  0.9965899377264946\n",
      "Epoch:  291  Loss:  0.852420527762643  Validation Loss:  0.9960475293278316\n",
      "Epoch:  292  Loss:  0.8519430208727446  Validation Loss:  0.9955076420396243\n",
      "Epoch:  293  Loss:  0.851467564692992  Validation Loss:  0.9949714570319739\n",
      "Epoch:  294  Loss:  0.850995139605411  Validation Loss:  0.9944368033008515\n",
      "Epoch:  295  Loss:  0.8505238653691847  Validation Loss:  0.9939048902158611\n",
      "Epoch:  296  Loss:  0.8500560117112382  Validation Loss:  0.9933754863568406\n",
      "Epoch:  297  Loss:  0.8495889303593182  Validation Loss:  0.9928464712642565\n",
      "Epoch:  298  Loss:  0.8491239002713644  Validation Loss:  0.9923216795710765\n",
      "Epoch:  299  Loss:  0.8486616326263174  Validation Loss:  0.9917980520648585\n",
      "Epoch:  300  Loss:  0.848200277693217  Validation Loss:  0.9912755243426216\n",
      "Epoch:  301  Loss:  0.8477411164429708  Validation Loss:  0.9907567918543583\n",
      "Epoch:  302  Loss:  0.8472848771314038  Validation Loss:  0.9902392630060406\n",
      "Epoch:  303  Loss:  0.8468284899169959  Validation Loss:  0.9897215875891455\n",
      "Epoch:  304  Loss:  0.8463721496496096  Validation Loss:  0.9892042386683001\n",
      "Epoch:  305  Loss:  0.8459168701993247  Validation Loss:  0.988689616592466\n",
      "Epoch:  306  Loss:  0.8454649795007269  Validation Loss:  0.9881774767005034\n",
      "Epoch:  307  Loss:  0.8450138697737503  Validation Loss:  0.9876658061681234\n",
      "Epoch:  308  Loss:  0.8445631596180656  Validation Loss:  0.9871545531247081\n",
      "Epoch:  309  Loss:  0.8441128443668877  Validation Loss:  0.9866437053145922\n",
      "Epoch:  310  Loss:  0.8436629698629879  Validation Loss:  0.9861332946996866\n",
      "Epoch:  311  Loss:  0.843215125348437  Validation Loss:  0.9856270521379791\n",
      "Epoch:  312  Loss:  0.8427700399516096  Validation Loss:  0.9851218748405792\n",
      "Epoch:  313  Loss:  0.8423254066892872  Validation Loss:  0.9846171634744151\n",
      "Epoch:  314  Loss:  0.8418810749290855  Validation Loss:  0.9841126949134944\n",
      "Epoch:  315  Loss:  0.8414362506834718  Validation Loss:  0.9836084686314174\n",
      "Epoch:  316  Loss:  0.8409916010879668  Validation Loss:  0.9831046191705526\n",
      "Epoch:  317  Loss:  0.8405473654890813  Validation Loss:  0.9826012309910594\n",
      "Epoch:  318  Loss:  0.8401035481964428  Validation Loss:  0.9820983044573687\n",
      "Epoch:  319  Loss:  0.8396617709998113  Validation Loss:  0.9815994791173632\n",
      "Epoch:  320  Loss:  0.8392227868893121  Validation Loss:  0.9811018088738016\n",
      "Epoch:  321  Loss:  0.8387842112315764  Validation Loss:  0.9806045196491523\n",
      "Epoch:  322  Loss:  0.8383460473495273  Validation Loss:  0.9801075819650314\n",
      "Epoch:  323  Loss:  0.8379080143499469  Validation Loss:  0.979610745207933\n",
      "Epoch:  324  Loss:  0.8374694387939333  Validation Loss:  0.979114204192993\n",
      "Epoch:  325  Loss:  0.8370313628811787  Validation Loss:  0.9786183807485993\n",
      "Epoch:  326  Loss:  0.836593886744683  Validation Loss:  0.9781229945601545\n",
      "Epoch:  327  Loss:  0.8361568449978328  Validation Loss:  0.9776280505609685\n",
      "Epoch:  328  Loss:  0.8357197131681283  Validation Loss:  0.9771332247182727\n",
      "Epoch:  329  Loss:  0.8352822686287855  Validation Loss:  0.9766387793140999\n",
      "Epoch:  330  Loss:  0.8348452029388073  Validation Loss:  0.9761446694829974\n",
      "Epoch:  331  Loss:  0.8344084649048384  Validation Loss:  0.975652794515633\n",
      "Epoch:  332  Loss:  0.8339740703610288  Validation Loss:  0.9751633775784917\n",
      "Epoch:  333  Loss:  0.83354012158844  Validation Loss:  0.974674369060043\n",
      "Epoch:  334  Loss:  0.8331059436065154  Validation Loss:  0.9741854945778091\n",
      "Epoch:  335  Loss:  0.8326710153538373  Validation Loss:  0.9736967632628005\n",
      "Epoch:  336  Loss:  0.8322352252819223  Validation Loss:  0.9732079945936583\n",
      "Epoch:  337  Loss:  0.8317982117844366  Validation Loss:  0.9727192009677705\n",
      "Epoch:  338  Loss:  0.8313597708813918  Validation Loss:  0.9722302042190796\n",
      "Epoch:  339  Loss:  0.8309193400042222  Validation Loss:  0.9717409427453211\n",
      "Epoch:  340  Loss:  0.8304765589729639  Validation Loss:  0.9712512056086806\n",
      "Epoch:  341  Loss:  0.8300312581580602  Validation Loss:  0.9707611243213541\n",
      "Epoch:  342  Loss:  0.8295836823798028  Validation Loss:  0.9702707971378729\n",
      "Epoch:  343  Loss:  0.8291342993384426  Validation Loss:  0.9697803957590266\n",
      "Epoch:  344  Loss:  0.8286838051546546  Validation Loss:  0.969290097169848\n",
      "Epoch:  345  Loss:  0.8282330469273537  Validation Loss:  0.9688001519028583\n",
      "Epoch:  346  Loss:  0.827781867778417  Validation Loss:  0.9683104736217554\n",
      "Epoch:  347  Loss:  0.8273310171648209  Validation Loss:  0.9678213318836861\n",
      "Epoch:  348  Loss:  0.8268806872622662  Validation Loss:  0.9673327402670638\n",
      "Epoch:  349  Loss:  0.8264315024004725  Validation Loss:  0.9668448596814836\n",
      "Epoch:  350  Loss:  0.8259831916956791  Validation Loss:  0.9663572888888851\n",
      "Epoch:  351  Loss:  0.8255352180482801  Validation Loss:  0.9658700630838133\n",
      "Epoch:  352  Loss:  0.8250876652343578  Validation Loss:  0.9653833102353889\n",
      "Epoch:  353  Loss:  0.8246415159687653  Validation Loss:  0.964899002270692\n",
      "Epoch:  354  Loss:  0.8241979078823719  Validation Loss:  0.964417540056604\n",
      "Epoch:  355  Loss:  0.8237568590274641  Validation Loss:  0.9639370436780155\n",
      "Epoch:  356  Loss:  0.823316961178755  Validation Loss:  0.9634577975257476\n",
      "Epoch:  357  Loss:  0.8228781181138949  Validation Loss:  0.9629794975837179\n",
      "Epoch:  358  Loss:  0.8224402479307491  Validation Loss:  0.9625022490441367\n",
      "Epoch:  359  Loss:  0.8220032921323137  Validation Loss:  0.9620259836167637\n",
      "Epoch:  360  Loss:  0.8215666437268402  Validation Loss:  0.9615496996776673\n",
      "Epoch:  361  Loss:  0.8211302534921221  Validation Loss:  0.9610741658649151\n",
      "Epoch:  362  Loss:  0.8206947236276657  Validation Loss:  0.9605992850172671\n",
      "Epoch:  363  Loss:  0.8202601308545586  Validation Loss:  0.960125231285296\n",
      "Epoch:  364  Loss:  0.8198267595856044  Validation Loss:  0.959651733627138\n",
      "Epoch:  365  Loss:  0.8193939609873534  Validation Loss:  0.9591787490129903\n",
      "Epoch:  366  Loss:  0.8189616358242205  Validation Loss:  0.9587061985976238\n",
      "Epoch:  367  Loss:  0.818529722099961  Validation Loss:  0.9582339370744708\n",
      "Epoch:  368  Loss:  0.8180977900453744  Validation Loss:  0.9577614710517768\n",
      "Epoch:  369  Loss:  0.8176661326405276  Validation Loss:  0.9572894842080448\n",
      "Epoch:  370  Loss:  0.8172349894116406  Validation Loss:  0.956818044077659\n",
      "Epoch:  371  Loss:  0.8168043346410997  Validation Loss:  0.9563470778217458\n",
      "Epoch:  372  Loss:  0.8163741950660004  Validation Loss:  0.9558766227606954\n",
      "Epoch:  373  Loss:  0.8159445504481606  Validation Loss:  0.9554066818032035\n",
      "Epoch:  374  Loss:  0.8155154076323492  Validation Loss:  0.9549372155435275\n",
      "Epoch:  375  Loss:  0.8150867729795898  Validation Loss:  0.9544683160543765\n",
      "Epoch:  376  Loss:  0.8146586482259399  Validation Loss:  0.9539998668731878\n",
      "Epoch:  377  Loss:  0.8142310230138269  Validation Loss:  0.9535319476685338\n",
      "Epoch:  378  Loss:  0.8138039252331969  Validation Loss:  0.953064503175193\n",
      "Epoch:  379  Loss:  0.8133771836427628  Validation Loss:  0.9525973693454179\n",
      "Epoch:  380  Loss:  0.8129507452905069  Validation Loss:  0.952130561100616\n",
      "Epoch:  381  Loss:  0.8125247502749225  Validation Loss:  0.9516642573222086\n",
      "Epoch:  382  Loss:  0.8120992561323044  Validation Loss:  0.9511984432305115\n",
      "Epoch:  383  Loss:  0.8116742933815508  Validation Loss:  0.9507330568925734\n",
      "Epoch:  384  Loss:  0.8112492011475729  Validation Loss:  0.9502673574480349\n",
      "Epoch:  385  Loss:  0.8108241745243663  Validation Loss:  0.9498021401856365\n",
      "Epoch:  386  Loss:  0.8103996988847056  Validation Loss:  0.9493375586318797\n",
      "Epoch:  387  Loss:  0.8099763587623545  Validation Loss:  0.948873725314827\n",
      "Epoch:  388  Loss:  0.8095538657434393  Validation Loss:  0.9484101731829562\n",
      "Epoch:  389  Loss:  0.8091318500069992  Validation Loss:  0.9479472093432602\n",
      "Epoch:  390  Loss:  0.8087104219418851  Validation Loss:  0.9474848754218091\n",
      "Epoch:  391  Loss:  0.8082895604328443  Validation Loss:  0.9470230834153683\n",
      "Epoch:  392  Loss:  0.8078692314820817  Validation Loss:  0.946561826683203\n",
      "Epoch:  393  Loss:  0.8074494226229856  Validation Loss:  0.946101085404339\n",
      "Epoch:  394  Loss:  0.8070300895634822  Validation Loss:  0.9456406964893467\n",
      "Epoch:  395  Loss:  0.8066109898907033  Validation Loss:  0.9451805797904946\n",
      "Epoch:  396  Loss:  0.8061923327317769  Validation Loss:  0.9447209860427656\n",
      "Epoch:  397  Loss:  0.8057739422430547  Validation Loss:  0.9442612314934208\n",
      "Epoch:  398  Loss:  0.8053552521306805  Validation Loss:  0.9438016887052335\n",
      "Epoch:  399  Loss:  0.8049370435482451  Validation Loss:  0.9433425887406844\n",
      "Epoch:  400  Loss:  0.8045190621791317  Validation Loss:  0.9428836764443828\n",
      "Epoch:  401  Loss:  0.804101495212396  Validation Loss:  0.9424252641873191\n",
      "Epoch:  402  Loss:  0.8036848052938297  Validation Loss:  0.9419681999184515\n",
      "Epoch:  403  Loss:  0.8032701856556158  Validation Loss:  0.941513857939213\n",
      "Epoch:  404  Loss:  0.8028571586897687  Validation Loss:  0.9410607023097143\n",
      "Epoch:  405  Loss:  0.8024452065492899  Validation Loss:  0.9406080356650595\n",
      "Epoch:  406  Loss:  0.8020329860681035  Validation Loss:  0.9401552092918344\n",
      "Epoch:  407  Loss:  0.8016209224175698  Validation Loss:  0.9397026248870121\n",
      "Epoch:  408  Loss:  0.8012091002711863  Validation Loss:  0.9392504152855363\n",
      "Epoch:  409  Loss:  0.8007977837674066  Validation Loss:  0.9387987292358193\n",
      "Epoch:  410  Loss:  0.800386873189161  Validation Loss:  0.9383472951695971\n",
      "Epoch:  411  Loss:  0.799976053900872  Validation Loss:  0.9378957122267373\n",
      "Epoch:  412  Loss:  0.7995649383141143  Validation Loss:  0.9374441076812429\n",
      "Epoch:  413  Loss:  0.7991539363713157  Validation Loss:  0.9369927327202606\n",
      "Epoch:  414  Loss:  0.7987433726609983  Validation Loss:  0.9365417964796982\n",
      "Epoch:  415  Loss:  0.7983330463000474  Validation Loss:  0.9360908769826958\n",
      "Epoch:  416  Loss:  0.7979223800244407  Validation Loss:  0.9356395691511747\n",
      "Epoch:  417  Loss:  0.7975116104737503  Validation Loss:  0.9351885027076671\n",
      "Epoch:  418  Loss:  0.797101184162899  Validation Loss:  0.9347376538899498\n",
      "Epoch:  419  Loss:  0.7966904237016457  Validation Loss:  0.9342861406140678\n",
      "Epoch:  420  Loss:  0.7962793382540236  Validation Loss:  0.9338347965284534\n",
      "Epoch:  421  Loss:  0.7958684023108008  Validation Loss:  0.9333832829353818\n",
      "Epoch:  422  Loss:  0.7954569491716011  Validation Loss:  0.9329313408191977\n",
      "Epoch:  423  Loss:  0.7950453520322996  Validation Loss:  0.9324792944353776\n",
      "Epoch:  424  Loss:  0.7946331414746718  Validation Loss:  0.9320265240494864\n",
      "Epoch:  425  Loss:  0.7942205055919702  Validation Loss:  0.9315733048470988\n",
      "Epoch:  426  Loss:  0.7938070847942196  Validation Loss:  0.9311195118960155\n",
      "Epoch:  427  Loss:  0.793392884217257  Validation Loss:  0.9306646365321417\n",
      "Epoch:  428  Loss:  0.7929778045463801  Validation Loss:  0.9302089347949495\n",
      "Epoch:  429  Loss:  0.792561554469765  Validation Loss:  0.929752043131199\n",
      "Epoch:  430  Loss:  0.7921439191548028  Validation Loss:  0.9292937408309376\n",
      "Epoch:  431  Loss:  0.7917246643625634  Validation Loss:  0.928833678310764\n",
      "Epoch:  432  Loss:  0.7913033829762338  Validation Loss:  0.9283715680349565\n",
      "Epoch:  433  Loss:  0.7908797861230605  Validation Loss:  0.9279069644398987\n",
      "Epoch:  434  Loss:  0.790453259589024  Validation Loss:  0.9274392362306083\n",
      "Epoch:  435  Loss:  0.790023246624064  Validation Loss:  0.9269679778093554\n",
      "Epoch:  436  Loss:  0.7895888897016174  Validation Loss:  0.9264919369049587\n",
      "Epoch:  437  Loss:  0.7891492637629323  Validation Loss:  0.9260103429897107\n",
      "Epoch:  438  Loss:  0.7887030901405417  Validation Loss:  0.9255217404671662\n",
      "Epoch:  439  Loss:  0.7882487093261217  Validation Loss:  0.9250243291042853\n",
      "Epoch:  440  Loss:  0.7877840605695524  Validation Loss:  0.9245158837217352\n",
      "Epoch:  441  Loss:  0.787306734634274  Validation Loss:  0.9239941031159158\n",
      "Epoch:  442  Loss:  0.7868142552759715  Validation Loss:  0.9234564342212094\n",
      "Epoch:  443  Loss:  0.7863043579092086  Validation Loss:  0.9229012596407447\n",
      "Epoch:  444  Loss:  0.7857763048903383  Validation Loss:  0.9223287661181951\n",
      "Epoch:  445  Loss:  0.7852316182694461  Validation Loss:  0.9217416541853353\n",
      "Epoch:  446  Loss:  0.7846740380187238  Validation Loss:  0.9211440985293492\n",
      "Epoch:  447  Loss:  0.784108026129492  Validation Loss:  0.9205403713023533\n",
      "Epoch:  448  Loss:  0.7835376016700695  Validation Loss:  0.919933854845231\n",
      "Epoch:  449  Loss:  0.7829656310117288  Validation Loss:  0.9193269539475981\n",
      "Epoch:  450  Loss:  0.7823939540794174  Validation Loss:  0.9187206212039767\n",
      "Epoch:  451  Loss:  0.7818235537123152  Validation Loss:  0.9181162570130782\n",
      "Epoch:  452  Loss:  0.7812551386921115  Validation Loss:  0.9175135933227189\n",
      "Epoch:  453  Loss:  0.7806887236509689  Validation Loss:  0.9169128364680902\n",
      "Epoch:  454  Loss:  0.78012435452886  Validation Loss:  0.9163142386081534\n",
      "Epoch:  455  Loss:  0.7795620839681151  Validation Loss:  0.9157177876424638\n",
      "Epoch:  456  Loss:  0.7790018668267152  Validation Loss:  0.9151230601836806\n",
      "Epoch:  457  Loss:  0.7784436068845714  Validation Loss:  0.9145300159352305\n",
      "Epoch:  458  Loss:  0.777887020685068  Validation Loss:  0.9139390172693285\n",
      "Epoch:  459  Loss:  0.7773322781561467  Validation Loss:  0.9133492675407425\n",
      "Epoch:  460  Loss:  0.7767791087553809  Validation Loss:  0.9127614563128547\n",
      "Epoch:  461  Loss:  0.7762275912722084  Validation Loss:  0.9121747850710391\n",
      "Epoch:  462  Loss:  0.775677409839084  Validation Loss:  0.9115897451554411\n",
      "Epoch:  463  Loss:  0.775128868159847  Validation Loss:  0.9110059351660311\n",
      "Epoch:  464  Loss:  0.7745813062726474  Validation Loss:  0.9104231559684959\n",
      "Epoch:  465  Loss:  0.774035305010824  Validation Loss:  0.9098422092358596\n",
      "Epoch:  466  Loss:  0.7734907206884829  Validation Loss:  0.9092620804338999\n",
      "Epoch:  467  Loss:  0.7729469358116317  Validation Loss:  0.9086828806801982\n",
      "Epoch:  468  Loss:  0.7724043902900359  Validation Loss:  0.9081049967638176\n",
      "Epoch:  469  Loss:  0.7718631032791025  Validation Loss:  0.907528154997398\n",
      "Epoch:  470  Loss:  0.7713226949303293  Validation Loss:  0.9069519801659213\n",
      "Epoch:  471  Loss:  0.7707830422639268  Validation Loss:  0.9063767732822917\n",
      "Epoch:  472  Loss:  0.7702445970753262  Validation Loss:  0.9058029315555873\n",
      "Epoch:  473  Loss:  0.76970758423598  Validation Loss:  0.9052302270479824\n",
      "Epoch:  474  Loss:  0.769171560038496  Validation Loss:  0.9046583517076636\n",
      "Epoch:  475  Loss:  0.768636217207458  Validation Loss:  0.9040870801748141\n",
      "Epoch:  476  Loss:  0.7681016292088457  Validation Loss:  0.9035167088462175\n",
      "Epoch:  477  Loss:  0.767567928502951  Validation Loss:  0.9029471056090425\n",
      "Epoch:  478  Loss:  0.767035378785171  Validation Loss:  0.9023790386289466\n",
      "Epoch:  479  Loss:  0.7665041374603232  Validation Loss:  0.9018117536696187\n",
      "Epoch:  480  Loss:  0.7659737624847376  Validation Loss:  0.9012454235858783\n",
      "Epoch:  481  Loss:  0.7654441570053871  Validation Loss:  0.9006797201067641\n",
      "Epoch:  482  Loss:  0.7649151972445288  Validation Loss:  0.9001146314557695\n",
      "Epoch:  483  Loss:  0.764386922948388  Validation Loss:  0.8995502646067652\n",
      "Epoch:  484  Loss:  0.7638595119543663  Validation Loss:  0.8989868650239878\n",
      "Epoch:  485  Loss:  0.7633328867682879  Validation Loss:  0.8984240286754094\n",
      "Epoch:  486  Loss:  0.7628073609700806  Validation Loss:  0.8978627792600057\n",
      "Epoch:  487  Loss:  0.7622831219703284  Validation Loss:  0.8973022323857615\n",
      "Epoch:  488  Loss:  0.7617596042392215  Validation Loss:  0.8967425240122754\n",
      "Epoch:  489  Loss:  0.7612370000790479  Validation Loss:  0.8961836367953515\n",
      "Epoch:  490  Loss:  0.7607151370685439  Validation Loss:  0.8956254504189112\n",
      "Epoch:  491  Loss:  0.7601939600381494  Validation Loss:  0.8950679249575605\n",
      "Epoch:  492  Loss:  0.7596734503840178  Validation Loss:  0.8945110207018645\n",
      "Epoch:  493  Loss:  0.7591536102264903  Validation Loss:  0.8939547882401857\n",
      "Epoch:  494  Loss:  0.7586345040099243  Validation Loss:  0.8933993338647744\n",
      "Epoch:  495  Loss:  0.7581162806193443  Validation Loss:  0.8928448146722023\n",
      "Epoch:  496  Loss:  0.7575988883347007  Validation Loss:  0.8922910100469986\n",
      "Epoch:  497  Loss:  0.7570822062422928  Validation Loss:  0.8917378858676639\n",
      "Epoch:  498  Loss:  0.7565664500337166  Validation Loss:  0.8911860202425632\n",
      "Epoch:  499  Loss:  0.7560521310615779  Validation Loss:  0.8906351966324492\n",
      "Epoch:  500  Loss:  0.7555385769448849  Validation Loss:  0.8900849751426257\n",
      "Epoch:  501  Loss:  0.7550256695571238  Validation Loss:  0.8895354317771136\n",
      "Epoch:  502  Loss:  0.7545135179195481  Validation Loss:  0.8889866786455547\n",
      "Epoch:  503  Loss:  0.7540022375184174  Validation Loss:  0.8884388663792524\n",
      "Epoch:  504  Loss:  0.7534917934879082  Validation Loss:  0.8878917586112368\n",
      "Epoch:  505  Loss:  0.7529820539147675  Validation Loss:  0.8873453628595757\n",
      "Epoch:  506  Loss:  0.7524730145605734  Validation Loss:  0.8867996014465672\n",
      "Epoch:  507  Loss:  0.7519646832918369  Validation Loss:  0.8862545816767691\n",
      "Epoch:  508  Loss:  0.751457104992881  Validation Loss:  0.8857103275891015\n",
      "Epoch:  509  Loss:  0.7509502725838457  Validation Loss:  0.885166794318112\n",
      "Epoch:  510  Loss:  0.7504441905631096  Validation Loss:  0.8846239525473852\n",
      "Epoch:  511  Loss:  0.749938799538514  Validation Loss:  0.8840817881991034\n",
      "Epoch:  512  Loss:  0.7494341215814997  Validation Loss:  0.8835403412931423\n",
      "Epoch:  513  Loss:  0.7489302620716682  Validation Loss:  0.8829998490603074\n",
      "Epoch:  514  Loss:  0.748427341872989  Validation Loss:  0.882460244661332\n",
      "Epoch:  515  Loss:  0.7479252270648925  Validation Loss:  0.8819213001381444\n",
      "Epoch:  516  Loss:  0.7474237908744841  Validation Loss:  0.881383009524881\n",
      "Epoch:  517  Loss:  0.7469230089562683  Validation Loss:  0.8808453828906235\n",
      "Epoch:  518  Loss:  0.7464229094443245  Validation Loss:  0.8803084067109487\n",
      "Epoch:  519  Loss:  0.7459234932654546  Validation Loss:  0.8797721074543138\n",
      "Epoch:  520  Loss:  0.7454250354672448  Validation Loss:  0.8792370685875632\n",
      "Epoch:  521  Loss:  0.7449279805889479  Validation Loss:  0.8787030896198922\n",
      "Epoch:  522  Loss:  0.7444317190573343  Validation Loss:  0.8781697642247098\n",
      "Epoch:  523  Loss:  0.7439361056900646  Validation Loss:  0.8776370794714793\n",
      "Epoch:  524  Loss:  0.7434411989977059  Validation Loss:  0.8771050607083716\n",
      "Epoch:  525  Loss:  0.742946939438907  Validation Loss:  0.876573670938935\n",
      "Epoch:  526  Loss:  0.7424533577427919  Validation Loss:  0.8760429641798787\n",
      "Epoch:  527  Loss:  0.7419604696785507  Validation Loss:  0.87551289462093\n",
      "Epoch:  528  Loss:  0.7414683274047684  Validation Loss:  0.8749836416024229\n",
      "Epoch:  529  Loss:  0.7409770203600592  Validation Loss:  0.8744553003487163\n",
      "Epoch:  530  Loss:  0.7404865846625592  Validation Loss:  0.8739277039911004\n",
      "Epoch:  531  Loss:  0.7399968538315768  Validation Loss:  0.8734007783477074\n",
      "Epoch:  532  Loss:  0.7395078265243797  Validation Loss:  0.8728745117027691\n",
      "Epoch:  533  Loss:  0.73901949709426  Validation Loss:  0.8723489267319657\n",
      "Epoch:  534  Loss:  0.7385318551926865  Validation Loss:  0.8718240418862822\n",
      "Epoch:  535  Loss:  0.7380449019996359  Validation Loss:  0.871299812529722\n",
      "Epoch:  536  Loss:  0.7375586484016362  Validation Loss:  0.8707762388917415\n",
      "Epoch:  537  Loss:  0.7370730942721  Validation Loss:  0.8702533792812324\n",
      "Epoch:  538  Loss:  0.7365882440009018  Validation Loss:  0.8697311878744243\n",
      "Epoch:  539  Loss:  0.7361040996405684  Validation Loss:  0.8692096965927361\n",
      "Epoch:  540  Loss:  0.7356206476462336  Validation Loss:  0.8686888673059319\n",
      "Epoch:  541  Loss:  0.7351378736140441  Validation Loss:  0.8681686477114757\n",
      "Epoch:  542  Loss:  0.7346557041503561  Validation Loss:  0.8676490317220273\n",
      "Epoch:  543  Loss:  0.7341742211844302  Validation Loss:  0.8671300926151267\n",
      "Epoch:  544  Loss:  0.7336934556081457  Validation Loss:  0.8666118511093267\n",
      "Epoch:  545  Loss:  0.7332133876060326  Validation Loss:  0.8660942892800423\n",
      "Epoch:  546  Loss:  0.7327340360848432  Validation Loss:  0.8655774268065242\n",
      "Epoch:  547  Loss:  0.7322553933950738  Validation Loss:  0.86506127078842\n",
      "Epoch:  548  Loss:  0.7317774664719128  Validation Loss:  0.8645458015059864\n",
      "Epoch:  549  Loss:  0.7313002573362398  Validation Loss:  0.8640310151664459\n",
      "Epoch:  550  Loss:  0.7308237531032522  Validation Loss:  0.8635169439071763\n",
      "Epoch:  551  Loss:  0.7303479869886148  Validation Loss:  0.8630035609492789\n",
      "Epoch:  552  Loss:  0.7298729925787131  Validation Loss:  0.8624910431360637\n",
      "Epoch:  553  Loss:  0.7293988774322624  Validation Loss:  0.861979402574724\n",
      "Epoch:  554  Loss:  0.72892563661687  Validation Loss:  0.8614685321631639\n",
      "Epoch:  555  Loss:  0.7284531249456758  Validation Loss:  0.8609584108318972\n",
      "Epoch:  556  Loss:  0.727981352455263  Validation Loss:  0.8604489357575126\n",
      "Epoch:  557  Loss:  0.7275102993572872  Validation Loss:  0.8599402020698872\n",
      "Epoch:  558  Loss:  0.7270399689158985  Validation Loss:  0.8594321473029213\n",
      "Epoch:  559  Loss:  0.7265703576002089  Validation Loss:  0.8589248312367261\n",
      "Epoch:  560  Loss:  0.7261014777977128  Validation Loss:  0.858418190959787\n",
      "Epoch:  561  Loss:  0.7256333395449933  Validation Loss:  0.8579123001275719\n",
      "Epoch:  562  Loss:  0.7251659360560543  Validation Loss:  0.8574070926296754\n",
      "Epoch:  563  Loss:  0.7246992342327767  Validation Loss:  0.8569026100516751\n",
      "Epoch:  564  Loss:  0.7242332962160767  Validation Loss:  0.8563988309866493\n",
      "Epoch:  565  Loss:  0.7237680711403706  Validation Loss:  0.8558957504945389\n",
      "Epoch:  566  Loss:  0.7233035537929645  Validation Loss:  0.8553933761474015\n",
      "Epoch:  567  Loss:  0.7228397591970861  Validation Loss:  0.854891675065501\n",
      "Epoch:  568  Loss:  0.7223766360667001  Validation Loss:  0.8543905819212829\n",
      "Epoch:  569  Loss:  0.7219141256832744  Validation Loss:  0.8538902056120012\n",
      "Epoch:  570  Loss:  0.7214526848740948  Validation Loss:  0.8533911464897834\n",
      "Epoch:  571  Loss:  0.7209925333634742  Validation Loss:  0.8528930168814849\n",
      "Epoch:  572  Loss:  0.7205331634495009  Validation Loss:  0.8523955589187318\n",
      "Epoch:  573  Loss:  0.7200745281908046  Validation Loss:  0.8518988575813347\n",
      "Epoch:  574  Loss:  0.7196166405219186  Validation Loss:  0.8514028590010561\n",
      "Epoch:  575  Loss:  0.7191594829873263  Validation Loss:  0.8509075645951257\n",
      "Epoch:  576  Loss:  0.7187030714014274  Validation Loss:  0.8504129970932136\n",
      "Epoch:  577  Loss:  0.7182474066096457  Validation Loss:  0.8499191779967236\n",
      "Epoch:  578  Loss:  0.7177924956195056  Validation Loss:  0.8494260972635685\n",
      "Epoch:  579  Loss:  0.7173383275128322  Validation Loss:  0.848933730341926\n",
      "Epoch:  580  Loss:  0.7168849102872451  Validation Loss:  0.8484420892715022\n",
      "Epoch:  581  Loss:  0.7164322402626637  Validation Loss:  0.8479512003992778\n",
      "Epoch:  582  Loss:  0.715980315603569  Validation Loss:  0.8474610382151129\n",
      "Epoch:  583  Loss:  0.7155291536162851  Validation Loss:  0.846971583944084\n",
      "Epoch:  584  Loss:  0.7150787368091276  Validation Loss:  0.8464828895242966\n",
      "Epoch:  585  Loss:  0.7146290739980138  Validation Loss:  0.8459949205103128\n",
      "Epoch:  586  Loss:  0.7141801748081174  Validation Loss:  0.845507681072838\n",
      "Epoch:  587  Loss:  0.7137320134291444  Validation Loss:  0.8450211972079199\n",
      "Epoch:  588  Loss:  0.7132846258074335  Validation Loss:  0.8445354621803415\n",
      "Epoch:  589  Loss:  0.7128379922405391  Validation Loss:  0.8440504269944369\n",
      "Epoch:  590  Loss:  0.71239210660705  Validation Loss:  0.8435661539408392\n",
      "Epoch:  591  Loss:  0.7119470015936757  Validation Loss:  0.8430826360953675\n",
      "Epoch:  592  Loss:  0.7115026504633207  Validation Loss:  0.8425998591777423\n",
      "Epoch:  593  Loss:  0.711059114348722  Validation Loss:  0.8421179096659889\n",
      "Epoch:  594  Loss:  0.7106164455079266  Validation Loss:  0.84163682717506\n",
      "Epoch:  595  Loss:  0.7101746609624366  Validation Loss:  0.8411566843076245\n",
      "Epoch:  596  Loss:  0.7097337610061163  Validation Loss:  0.8406773309047887\n",
      "Epoch:  597  Loss:  0.7092936248699366  Validation Loss:  0.8401987067410264\n",
      "Epoch:  598  Loss:  0.7088542693267459  Validation Loss:  0.8397208377988874\n",
      "Epoch:  599  Loss:  0.708415684339961  Validation Loss:  0.8392437291669025\n",
      "Epoch:  600  Loss:  0.7079778733500506  Validation Loss:  0.8387673781995756\n",
      "Epoch:  601  Loss:  0.7075408339292462  Validation Loss:  0.8382917682545773\n",
      "Epoch:  602  Loss:  0.7071045815664371  Validation Loss:  0.8378169430365813\n",
      "Epoch:  603  Loss:  0.7066691074954364  Validation Loss:  0.8373428882653082\n",
      "Epoch:  604  Loss:  0.7062344293842472  Validation Loss:  0.8368696100011036\n",
      "Epoch:  605  Loss:  0.705800540573461  Validation Loss:  0.836397125115753\n",
      "Epoch:  606  Loss:  0.7053674503220516  Validation Loss:  0.8359253999601671\n",
      "Epoch:  607  Loss:  0.7049351436158334  Validation Loss:  0.8354544530123256\n",
      "Epoch:  608  Loss:  0.7045036345557536  Validation Loss:  0.8349842874981139\n",
      "Epoch:  609  Loss:  0.7040729149769159  Validation Loss:  0.8345148644774504\n",
      "Epoch:  610  Loss:  0.7036429599234925  Validation Loss:  0.8340462122814379\n",
      "Epoch:  611  Loss:  0.7032137977104019  Validation Loss:  0.8335783078024784\n",
      "Epoch:  612  Loss:  0.7027854130702834  Validation Loss:  0.8331111909929609\n",
      "Epoch:  613  Loss:  0.7023578130875181  Validation Loss:  0.8326448422276239\n",
      "Epoch:  614  Loss:  0.7019309920656667  Validation Loss:  0.8321792393841821\n",
      "Epoch:  615  Loss:  0.7015053813653157  Validation Loss:  0.8317152484846504\n",
      "Epoch:  616  Loss:  0.701081223044436  Validation Loss:  0.831252592831742\n",
      "Epoch:  617  Loss:  0.7006583571777616  Validation Loss:  0.8307912709812323\n",
      "Epoch:  618  Loss:  0.7002368889324078  Validation Loss:  0.8303317864411983\n",
      "Epoch:  619  Loss:  0.6998168783289498  Validation Loss:  0.8298734890674984\n",
      "Epoch:  620  Loss:  0.6993980579738261  Validation Loss:  0.8294164376009417\n",
      "Epoch:  621  Loss:  0.6989804148420836  Validation Loss:  0.8289603278634773\n",
      "Epoch:  622  Loss:  0.6985635707941521  Validation Loss:  0.8285049982233972\n",
      "Epoch:  623  Loss:  0.6981475222946226  Validation Loss:  0.8280504575350146\n",
      "Epoch:  624  Loss:  0.6977322549893729  Validation Loss:  0.827596672270717\n",
      "Epoch:  625  Loss:  0.6973177888249815  Validation Loss:  0.8271436799128634\n",
      "Epoch:  626  Loss:  0.6969041239280362  Validation Loss:  0.8266914443423351\n",
      "Epoch:  627  Loss:  0.6964912455194422  Validation Loss:  0.8262400034194192\n",
      "Epoch:  628  Loss:  0.6960791660228618  Validation Loss:  0.825789329190941\n",
      "Epoch:  629  Loss:  0.6956678768213006  Validation Loss:  0.8253394369359898\n",
      "Epoch:  630  Loss:  0.6952573966723189  Validation Loss:  0.8248903501670861\n",
      "Epoch:  631  Loss:  0.694847715638795  Validation Loss:  0.8244420154884026\n",
      "Epoch:  632  Loss:  0.694438820094485  Validation Loss:  0.8239944642274708\n",
      "Epoch:  633  Loss:  0.6940307156228035  Validation Loss:  0.8235477218269438\n",
      "Epoch:  634  Loss:  0.6936233896735007  Validation Loss:  0.8231016881359012\n",
      "Epoch:  635  Loss:  0.6932168240586604  Validation Loss:  0.8226563761658643\n",
      "Epoch:  636  Loss:  0.6928109691740529  Validation Loss:  0.8222117246655019\n",
      "Epoch:  637  Loss:  0.6924058316248352  Validation Loss:  0.8217678265376152\n",
      "Epoch:  638  Loss:  0.6920014580946814  Validation Loss:  0.8213246884904262\n",
      "Epoch:  639  Loss:  0.6915978445825213  Validation Loss:  0.820882288482634\n",
      "Epoch:  640  Loss:  0.6911950008717628  Validation Loss:  0.820440659744908\n",
      "Epoch:  641  Loss:  0.6907929326904919  Validation Loss:  0.819999735330002\n",
      "Epoch:  642  Loss:  0.6903915844803441  Validation Loss:  0.819559539762744\n",
      "Epoch:  643  Loss:  0.6899909961163926  Validation Loss:  0.8191200918045597\n",
      "Epoch:  644  Loss:  0.6895911777708499  Validation Loss:  0.8186814002152802\n",
      "Epoch:  645  Loss:  0.689192130537794  Validation Loss:  0.8182434695300417\n",
      "Epoch:  646  Loss:  0.6887938879990896  Validation Loss:  0.8178063295916587\n",
      "Epoch:  647  Loss:  0.6883964521575321  Validation Loss:  0.8173699792933421\n",
      "Epoch:  648  Loss:  0.6879998190889081  Validation Loss:  0.816934437531492\n",
      "Epoch:  649  Loss:  0.687604055504848  Validation Loss:  0.8164997733184609\n",
      "Epoch:  650  Loss:  0.6872091478740489  Validation Loss:  0.8160659279134395\n",
      "Epoch:  651  Loss:  0.6868150683924628  Validation Loss:  0.8156328602977421\n",
      "Epoch:  652  Loss:  0.6864217930536681  Validation Loss:  0.8152006357719285\n",
      "Epoch:  653  Loss:  0.686029355227043  Validation Loss:  0.8147691835689804\n",
      "Epoch:  654  Loss:  0.6856377360420031  Validation Loss:  0.8143385458413673\n",
      "Epoch:  655  Loss:  0.6852469406253432  Validation Loss:  0.81390873334654\n",
      "Epoch:  656  Loss:  0.6848569842851133  Validation Loss:  0.8134797174564522\n",
      "Epoch:  657  Loss:  0.6844678515369452  Validation Loss:  0.8130515355994736\n",
      "Epoch:  658  Loss:  0.6840795428238954  Validation Loss:  0.8126241583647071\n",
      "Epoch:  659  Loss:  0.6836920698643526  Validation Loss:  0.8121975911646218\n",
      "Epoch:  660  Loss:  0.6833054219752334  Validation Loss:  0.8117718388582917\n",
      "Epoch:  661  Loss:  0.682919618298381  Validation Loss:  0.8113469013512351\n",
      "Epoch:  662  Loss:  0.6825346333580544  Validation Loss:  0.8109228055843193\n",
      "Epoch:  663  Loss:  0.6821504862282823  Validation Loss:  0.8104995072184913\n",
      "Epoch:  664  Loss:  0.6817671815475937  Validation Loss:  0.8100770330326497\n",
      "Epoch:  665  Loss:  0.6813847261065057  Validation Loss:  0.8096553763995568\n",
      "Epoch:  666  Loss:  0.6810030950350886  Validation Loss:  0.809234546524459\n",
      "Epoch:  667  Loss:  0.6806222990209472  Validation Loss:  0.808814540370435\n",
      "Epoch:  668  Loss:  0.6802423505826845  Validation Loss:  0.8083953636603943\n",
      "Epoch:  669  Loss:  0.6798632396159024  Validation Loss:  0.8079770188238742\n",
      "Epoch:  670  Loss:  0.6794849722510548  Validation Loss:  0.8075594900688832\n",
      "Epoch:  671  Loss:  0.679107556716331  Validation Loss:  0.8071427682981543\n",
      "Epoch:  672  Loss:  0.6787309861760044  Validation Loss:  0.8067269085272066\n",
      "Epoch:  673  Loss:  0.6783552512173875  Validation Loss:  0.8063118757167156\n",
      "Epoch:  674  Loss:  0.6779803801689622  Validation Loss:  0.805897676885344\n",
      "Epoch:  675  Loss:  0.6776063569315067  Validation Loss:  0.805484291759954\n",
      "Epoch:  676  Loss:  0.677233174673815  Validation Loss:  0.8050717742762704\n",
      "Epoch:  677  Loss:  0.6768608346120318  Validation Loss:  0.8046600687708976\n",
      "Epoch:  678  Loss:  0.6764893566836937  Validation Loss:  0.804249190657899\n",
      "Epoch:  679  Loss:  0.676118722334685  Validation Loss:  0.8038391536506622\n",
      "Epoch:  680  Loss:  0.675748945033015  Validation Loss:  0.8034299442787534\n",
      "Epoch:  681  Loss:  0.6753799810788585  Validation Loss:  0.8030215357632741\n",
      "Epoch:  682  Loss:  0.6750118431671369  Validation Loss:  0.802613978287664\n",
      "Epoch:  683  Loss:  0.6746445721358929  Validation Loss:  0.8022072620257952\n",
      "Epoch:  684  Loss:  0.674278189862165  Validation Loss:  0.8018014284147732\n",
      "Epoch:  685  Loss:  0.6739127124270913  Validation Loss:  0.801396503828574\n",
      "Epoch:  686  Loss:  0.6735481515535814  Validation Loss:  0.8009924936661685\n",
      "Epoch:  687  Loss:  0.6731845396480441  Validation Loss:  0.8005894827993884\n",
      "Epoch:  688  Loss:  0.6728218682471988  Validation Loss:  0.8001873148470253\n",
      "Epoch:  689  Loss:  0.6724600583785078  Validation Loss:  0.7997859989873309\n",
      "Epoch:  690  Loss:  0.6720991217920068  Validation Loss:  0.7993855372179246\n",
      "Epoch:  691  Loss:  0.6717390415520923  Validation Loss:  0.7989859122351028\n",
      "Epoch:  692  Loss:  0.671379832894478  Validation Loss:  0.7985871365104896\n",
      "Epoch:  693  Loss:  0.6710214915603978  Validation Loss:  0.7981892320448938\n",
      "Epoch:  694  Loss:  0.6706640070430863  Validation Loss:  0.7977921620173298\n",
      "Epoch:  695  Loss:  0.67030738677504  Validation Loss:  0.7973959494274163\n",
      "Epoch:  696  Loss:  0.6699516430533338  Validation Loss:  0.7970005847729634\n",
      "Epoch:  697  Loss:  0.6695967817823719  Validation Loss:  0.7966060891909443\n",
      "Epoch:  698  Loss:  0.6692427617398281  Validation Loss:  0.7962124489139819\n",
      "Epoch:  699  Loss:  0.6688896267611569  Validation Loss:  0.7958196578952281\n",
      "Epoch:  700  Loss:  0.668537369947338  Validation Loss:  0.7954277275535075\n",
      "Epoch:  701  Loss:  0.6681859855205544  Validation Loss:  0.7950366673100254\n",
      "Epoch:  702  Loss:  0.6678354762928579  Validation Loss:  0.7946464631274559\n",
      "Epoch:  703  Loss:  0.6674858377794328  Validation Loss:  0.794257092681052\n",
      "Epoch:  704  Loss:  0.6671370684702709  Validation Loss:  0.7938686068561198\n",
      "Epoch:  705  Loss:  0.6667891479395691  Validation Loss:  0.7934809219955966\n",
      "Epoch:  706  Loss:  0.6664420750480399  Validation Loss:  0.7930940940058318\n",
      "Epoch:  707  Loss:  0.6660958646064244  Validation Loss:  0.7927081198634013\n",
      "Epoch:  708  Loss:  0.6657504960623326  Validation Loss:  0.792322964987893\n",
      "Epoch:  709  Loss:  0.6654059950678238  Validation Loss:  0.7919386554293443\n",
      "Epoch:  710  Loss:  0.6650623689378494  Validation Loss:  0.7915552368090637\n",
      "Epoch:  711  Loss:  0.6647196407203825  Validation Loss:  0.7911726797566466\n",
      "Epoch:  712  Loss:  0.6643777822677805  Validation Loss:  0.7907909940442314\n",
      "Epoch:  713  Loss:  0.6640368219808612  Validation Loss:  0.7904102045070865\n",
      "Epoch:  714  Loss:  0.6636967458445759  Validation Loss:  0.790030266198775\n",
      "Epoch:  715  Loss:  0.6633575652518029  Validation Loss:  0.7896512162372253\n",
      "Epoch:  716  Loss:  0.663019273701368  Validation Loss:  0.7892730256299609\n",
      "Epoch:  717  Loss:  0.662681870162487  Validation Loss:  0.7888957365969385\n",
      "Epoch:  718  Loss:  0.662345354897377  Validation Loss:  0.7885192771968634\n",
      "Epoch:  719  Loss:  0.6620097397871821  Validation Loss:  0.7881437523587458\n",
      "Epoch:  720  Loss:  0.6616749860147394  Validation Loss:  0.7877690533742957\n",
      "Epoch:  721  Loss:  0.661341111953325  Validation Loss:  0.7873952024872752\n",
      "Epoch:  722  Loss:  0.6610081060292218  Validation Loss:  0.7870222407028727\n",
      "Epoch:  723  Loss:  0.6606759600051977  Validation Loss:  0.7866501042862302\n",
      "Epoch:  724  Loss:  0.6603446807260218  Validation Loss:  0.7862788373469443\n",
      "Epoch:  725  Loss:  0.6600143139711717  Validation Loss:  0.7859084792975066\n",
      "Epoch:  726  Loss:  0.6596848327503766  Validation Loss:  0.7855389770120382\n",
      "Epoch:  727  Loss:  0.6593562563682355  Validation Loss:  0.7851703788383283\n",
      "Epoch:  728  Loss:  0.6590285838120481  Validation Loss:  0.7848026775417553\n",
      "Epoch:  729  Loss:  0.658701813318631  Validation Loss:  0.7844358453716057\n",
      "Epoch:  730  Loss:  0.6583759482968056  Validation Loss:  0.7840699218753455\n",
      "Epoch:  731  Loss:  0.6580509844425957  Validation Loss:  0.7837048576793809\n",
      "Epoch:  732  Loss:  0.6577269041422501  Validation Loss:  0.7833406988909279\n",
      "Epoch:  733  Loss:  0.6574036854689995  Validation Loss:  0.7829773714900881\n",
      "Epoch:  734  Loss:  0.6570813529536996  Validation Loss:  0.7826149341906758\n",
      "Epoch:  735  Loss:  0.6567599022200385  Validation Loss:  0.7822533625623455\n",
      "Epoch:  736  Loss:  0.6564393470298897  Validation Loss:  0.781892681359381\n",
      "Epoch:  737  Loss:  0.6561196986857114  Validation Loss:  0.7815328721172999\n",
      "Epoch:  738  Loss:  0.6558009727125608  Validation Loss:  0.7811740112585434\n",
      "Epoch:  739  Loss:  0.6554831519126169  Validation Loss:  0.7808160063257252\n",
      "Epoch:  740  Loss:  0.6551662276869694  Validation Loss:  0.7804589131442101\n",
      "Epoch:  741  Loss:  0.6548501986160296  Validation Loss:  0.7801026718394048\n",
      "Epoch:  742  Loss:  0.6545350475471865  Validation Loss:  0.7797473235784665\n",
      "Epoch:  743  Loss:  0.6542207649140392  Validation Loss:  0.7793928364534741\n",
      "Epoch:  744  Loss:  0.6539073915049  Validation Loss:  0.7790392480142738\n",
      "Epoch:  745  Loss:  0.6535949415156563  Validation Loss:  0.7786865619861562\n",
      "Epoch:  746  Loss:  0.6532834031736677  Validation Loss:  0.7783347836061232\n",
      "Epoch:  747  Loss:  0.6529727765331859  Validation Loss:  0.7779838875799939\n",
      "Epoch:  748  Loss:  0.6526630240971747  Validation Loss:  0.7776338924532351\n",
      "Epoch:  749  Loss:  0.6523541450247313  Validation Loss:  0.7772847196168226\n",
      "Epoch:  750  Loss:  0.65204617349449  Validation Loss:  0.7769364749175914\n",
      "Epoch:  751  Loss:  0.6517391133312027  Validation Loss:  0.7765891415377458\n",
      "Epoch:  752  Loss:  0.6514329761990065  Validation Loss:  0.7762427066547283\n",
      "Epoch:  753  Loss:  0.6511277240312215  Validation Loss:  0.7758971463510955\n",
      "Epoch:  754  Loss:  0.6508233434095689  Validation Loss:  0.775552458845187\n",
      "Epoch:  755  Loss:  0.650519876180271  Validation Loss:  0.7752086804990751\n",
      "Epoch:  756  Loss:  0.6502173308337342  Validation Loss:  0.774865782401268\n",
      "Epoch:  757  Loss:  0.649915682875271  Validation Loss:  0.7745238146542207\n",
      "Epoch:  758  Loss:  0.6496149361025072  Validation Loss:  0.7741827098517746\n",
      "Epoch:  759  Loss:  0.6493150803432303  Validation Loss:  0.7738425281654665\n",
      "Epoch:  760  Loss:  0.6490161319634  Validation Loss:  0.7735032395770153\n",
      "Epoch:  761  Loss:  0.6487180979705407  Validation Loss:  0.77316480829124\n",
      "Epoch:  762  Loss:  0.6484209334351194  Validation Loss:  0.7728273006884948\n",
      "Epoch:  763  Loss:  0.648124687662981  Validation Loss:  0.7724906829982132\n",
      "Epoch:  764  Loss:  0.6478293479953721  Validation Loss:  0.7721549916904473\n",
      "Epoch:  765  Loss:  0.64753490803058  Validation Loss:  0.7718201640021541\n",
      "Epoch:  766  Loss:  0.6472413610594655  Validation Loss:  0.771486232408147\n",
      "Epoch:  767  Loss:  0.6469486929675184  Validation Loss:  0.7711531934800787\n",
      "Epoch:  768  Loss:  0.6466569488470271  Validation Loss:  0.770821085334688\n",
      "Epoch:  769  Loss:  0.6463660936332444  Validation Loss:  0.7704898545491523\n",
      "Epoch:  770  Loss:  0.6460761013214739  Validation Loss:  0.7701594797975343\n",
      "Epoch:  771  Loss:  0.6457869866049116  Validation Loss:  0.7698299847003343\n",
      "Epoch:  772  Loss:  0.6454987755063378  Validation Loss:  0.7695014071583316\n",
      "Epoch:  773  Loss:  0.6452114205373433  Validation Loss:  0.7691736918320691\n",
      "Epoch:  774  Loss:  0.6449249500083258  Validation Loss:  0.7688468774861615\n",
      "Epoch:  775  Loss:  0.6446393578521257  Validation Loss:  0.7685209237363028\n",
      "Epoch:  776  Loss:  0.6443546360213924  Validation Loss:  0.7681958461585252\n",
      "Epoch:  777  Loss:  0.6440707766676991  Validation Loss:  0.767871648343145\n",
      "Epoch:  778  Loss:  0.6437877492653659  Validation Loss:  0.7675483167387437\n",
      "Epoch:  779  Loss:  0.6435056824092437  Validation Loss:  0.767225997198535\n",
      "Epoch:  780  Loss:  0.6432246948926917  Validation Loss:  0.7669048750422139\n",
      "Epoch:  781  Loss:  0.6429447478714209  Validation Loss:  0.7665847360115984\n",
      "Epoch:  782  Loss:  0.6426658927038023  Validation Loss:  0.7662656993969627\n",
      "Epoch:  783  Loss:  0.6423879649345446  Validation Loss:  0.7659474829130847\n",
      "Epoch:  784  Loss:  0.6421108159860506  Validation Loss:  0.7656301121780837\n",
      "Epoch:  785  Loss:  0.6418344282355268  Validation Loss:  0.7653135187060073\n",
      "Epoch:  786  Loss:  0.6415587445739114  Validation Loss:  0.764997711405158\n",
      "Epoch:  787  Loss:  0.6412837562214547  Validation Loss:  0.76468267251292\n",
      "Epoch:  788  Loss:  0.6410094295782083  Validation Loss:  0.764368319991922\n",
      "Epoch:  789  Loss:  0.6407356442232589  Validation Loss:  0.7640546422073806\n",
      "Epoch:  790  Loss:  0.640462262763922  Validation Loss:  0.763741382924111\n",
      "Epoch:  791  Loss:  0.6401891637304165  Validation Loss:  0.76342862687897\n",
      "Epoch:  792  Loss:  0.6399163001858927  Validation Loss:  0.7631162509754084\n",
      "Epoch:  793  Loss:  0.6396435285891289  Validation Loss:  0.7628042122376137\n",
      "Epoch:  794  Loss:  0.6393707780601475  Validation Loss:  0.7624924598882595\n",
      "Epoch:  795  Loss:  0.6390978584915978  Validation Loss:  0.7621808772555728\n",
      "Epoch:  796  Loss:  0.6388245432465834  Validation Loss:  0.7618693111167438\n",
      "Epoch:  797  Loss:  0.6385506679964008  Validation Loss:  0.7615576275772806\n",
      "Epoch:  798  Loss:  0.6382761246081695  Validation Loss:  0.7612458254224148\n",
      "Epoch:  799  Loss:  0.6380009985736852  Validation Loss:  0.7609339912246534\n",
      "Epoch:  800  Loss:  0.6377256022657729  Validation Loss:  0.7606224228452513\n",
      "Epoch:  801  Loss:  0.6374503770951652  Validation Loss:  0.7603114497834358\n",
      "Epoch:  802  Loss:  0.6371757785418948  Validation Loss:  0.7600013801585073\n",
      "Epoch:  803  Loss:  0.6369021500831524  Validation Loss:  0.7596924830821977\n",
      "Epoch:  804  Loss:  0.6366297298933841  Validation Loss:  0.7593848989277646\n",
      "Epoch:  805  Loss:  0.6363586180852455  Validation Loss:  0.7590787567846153\n",
      "Epoch:  806  Loss:  0.6360889160734358  Validation Loss:  0.7587740319794503\n",
      "Epoch:  807  Loss:  0.6358206594923457  Validation Loss:  0.7584708401042483\n",
      "Epoch:  808  Loss:  0.6355538407648073  Validation Loss:  0.7581691040886916\n",
      "Epoch:  809  Loss:  0.6352884655149238  Validation Loss:  0.7578688348656979\n",
      "Epoch:  810  Loss:  0.6350245263915762  Validation Loss:  0.7575700699581184\n",
      "Epoch:  811  Loss:  0.6347620122912294  Validation Loss:  0.7572727963004423\n",
      "Epoch:  812  Loss:  0.6345009330605853  Validation Loss:  0.756976972779502\n",
      "Epoch:  813  Loss:  0.6342412668813779  Validation Loss:  0.7566825883544009\n",
      "Epoch:  814  Loss:  0.6339829900907805  Validation Loss:  0.7563896530402311\n",
      "Epoch:  815  Loss:  0.6337260800115403  Validation Loss:  0.7560981350910404\n",
      "Epoch:  816  Loss:  0.633470549781635  Validation Loss:  0.7558080223051534\n",
      "Epoch:  817  Loss:  0.6332163719225277  Validation Loss:  0.755519326614297\n",
      "Epoch:  818  Loss:  0.6329635459369103  Validation Loss:  0.7552320374094922\n",
      "Epoch:  819  Loss:  0.632712068497339  Validation Loss:  0.7549461345255807\n",
      "Epoch:  820  Loss:  0.632461928608782  Validation Loss:  0.754661632242842\n",
      "Epoch:  821  Loss:  0.6322131322298958  Validation Loss:  0.7543785198713127\n",
      "Epoch:  822  Loss:  0.6319656605443474  Validation Loss:  0.7540967742224103\n",
      "Epoch:  823  Loss:  0.6317195311116363  Validation Loss:  0.7538164435089498\n",
      "Epoch:  824  Loss:  0.6314747093100715  Validation Loss:  0.7535374787352656\n",
      "Epoch:  825  Loss:  0.6312312282332517  Validation Loss:  0.7532598885937013\n",
      "Epoch:  826  Loss:  0.6309890593447297  Validation Loss:  0.7529836798329717\n",
      "Epoch:  827  Loss:  0.6307482054746412  Validation Loss:  0.7527088501045237\n",
      "Epoch:  828  Loss:  0.6305086611525961  Validation Loss:  0.7524353751939707\n",
      "Epoch:  829  Loss:  0.6302704508823244  Validation Loss:  0.7521632952156706\n",
      "Epoch:  830  Loss:  0.6300335321304145  Validation Loss:  0.7518925735915917\n",
      "Epoch:  831  Loss:  0.6297979296537713  Validation Loss:  0.7516232174483762\n",
      "Epoch:  832  Loss:  0.6295636388862017  Validation Loss:  0.7513552377189415\n",
      "Epoch:  833  Loss:  0.6293306626759253  Validation Loss:  0.7510886383985264\n",
      "Epoch:  834  Loss:  0.6290989859138154  Validation Loss:  0.7508233889829421\n",
      "Epoch:  835  Loss:  0.6288686298394521  Validation Loss:  0.7505595280748346\n",
      "Epoch:  836  Loss:  0.6286395761971045  Validation Loss:  0.7502970275455627\n",
      "Epoch:  837  Loss:  0.6284118297157212  Validation Loss:  0.7500358708202839\n",
      "Epoch:  838  Loss:  0.6281854013541659  Validation Loss:  0.7497761183674785\n",
      "Epoch:  839  Loss:  0.6279602774590688  Validation Loss:  0.7495177076130674\n",
      "Epoch:  840  Loss:  0.6277364532653134  Validation Loss:  0.7492606708428998\n",
      "Epoch:  841  Loss:  0.6275139299212295  Validation Loss:  0.7490050109724203\n",
      "Epoch:  842  Loss:  0.627292697950836  Validation Loss:  0.7487506669392621\n",
      "Epoch:  843  Loss:  0.6270726009009822  Validation Loss:  0.7484974103129428\n",
      "Epoch:  844  Loss:  0.626853576843238  Validation Loss:  0.7482453674293946\n",
      "Epoch:  845  Loss:  0.6266357501860238  Validation Loss:  0.7479946328785972\n",
      "Epoch:  846  Loss:  0.6264191935544164  Validation Loss:  0.7477452729059302\n",
      "Epoch:  847  Loss:  0.6262039410908824  Validation Loss:  0.7474972481528918\n",
      "Epoch:  848  Loss:  0.6259899946942347  Validation Loss:  0.7472506309117096\n",
      "Epoch:  849  Loss:  0.6257773641930912  Validation Loss:  0.7470053543431171\n",
      "Epoch:  850  Loss:  0.625566039451407  Validation Loss:  0.7467614430124345\n",
      "Epoch:  851  Loss:  0.6253560059929936  Validation Loss:  0.7465189069077589\n",
      "Epoch:  852  Loss:  0.6251472890178121  Validation Loss:  0.7462777433296045\n",
      "Epoch:  853  Loss:  0.6249398749629126  Validation Loss:  0.7460379310060239\n",
      "Epoch:  854  Loss:  0.6247337665860948  Validation Loss:  0.7457994494209255\n",
      "Epoch:  855  Loss:  0.6245289755967057  Validation Loss:  0.7455623772913131\n",
      "Epoch:  856  Loss:  0.6243254920395399  Validation Loss:  0.7453266512872516\n",
      "Epoch:  857  Loss:  0.6241233209509728  Validation Loss:  0.7450922891173674\n",
      "Epoch:  858  Loss:  0.6239224451060579  Validation Loss:  0.7448593146451141\n",
      "Epoch:  859  Loss:  0.623722883275918  Validation Loss:  0.744627690239661\n",
      "Epoch:  860  Loss:  0.6235246406416002  Validation Loss:  0.7443974618462549\n",
      "Epoch:  861  Loss:  0.6233277011445715  Validation Loss:  0.7441685923739619\n",
      "Epoch:  862  Loss:  0.6231320847494943  Validation Loss:  0.7439410855480726\n",
      "Epoch:  863  Loss:  0.6229377836531517  Validation Loss:  0.7437149565936862\n",
      "Epoch:  864  Loss:  0.6227447959928981  Validation Loss:  0.7434901976822943\n",
      "Epoch:  865  Loss:  0.6225531193726126  Validation Loss:  0.7432667926169824\n",
      "Epoch:  866  Loss:  0.6223625506012185  Validation Loss:  0.7430444066075311\n",
      "Epoch:  867  Loss:  0.6221729849908247  Validation Loss:  0.7428232184138851\n",
      "Epoch:  868  Loss:  0.6219846794870004  Validation Loss:  0.7426033965379432\n",
      "Epoch:  869  Loss:  0.6217976797697613  Validation Loss:  0.7423849690543569\n",
      "Epoch:  870  Loss:  0.6216120052431683  Validation Loss:  0.7421678981163363\n",
      "Epoch:  871  Loss:  0.6214276499033553  Validation Loss:  0.741952212014492\n",
      "Epoch:  872  Loss:  0.6212446134067277  Validation Loss:  0.7417379111807415\n",
      "Epoch:  873  Loss:  0.6210629083758709  Validation Loss:  0.7415249600898528\n",
      "Epoch:  874  Loss:  0.6208825349735404  Validation Loss:  0.7413134367569633\n",
      "Epoch:  875  Loss:  0.620703493796506  Validation Loss:  0.7411033076544603\n",
      "Epoch:  876  Loss:  0.6205258084804688  Validation Loss:  0.7408945715405802\n",
      "Epoch:  877  Loss:  0.6203494475051327  Validation Loss:  0.740687224690033\n",
      "Epoch:  878  Loss:  0.6201744228239777  Validation Loss:  0.7404812624597031\n",
      "Epoch:  879  Loss:  0.6200004487651066  Validation Loss:  0.7402762356551661\n",
      "Epoch:  880  Loss:  0.6198275909731978  Validation Loss:  0.7400725887197516\n",
      "Epoch:  881  Loss:  0.6196560454961745  Validation Loss:  0.7398703047546787\n",
      "Epoch:  882  Loss:  0.6194858253544685  Validation Loss:  0.7396694223086039\n",
      "Epoch:  883  Loss:  0.6193169355211616  Validation Loss:  0.7394698936546195\n",
      "Epoch:  884  Loss:  0.619149364838467  Validation Loss:  0.7392717345577219\n",
      "Epoch:  885  Loss:  0.6189831115160752  Validation Loss:  0.7390749861040841\n",
      "Epoch:  886  Loss:  0.6188181954824808  Validation Loss:  0.7388796069375847\n",
      "Epoch:  887  Loss:  0.6186543825688293  Validation Loss:  0.7386851722131604\n",
      "Epoch:  888  Loss:  0.6184915720837788  Validation Loss:  0.7384919955570629\n",
      "Epoch:  889  Loss:  0.618330058017836  Validation Loss:  0.7383001896998157\n",
      "Epoch:  890  Loss:  0.6181698530478384  Validation Loss:  0.7381097868732784\n",
      "Epoch:  891  Loss:  0.6180109995625263  Validation Loss:  0.7379207517681778\n",
      "Epoch:  892  Loss:  0.6178534681031715  Validation Loss:  0.7377330405988555\n",
      "Epoch:  893  Loss:  0.6176969244967676  Validation Loss:  0.7375462077342082\n",
      "Epoch:  894  Loss:  0.6175414661976318  Validation Loss:  0.7373607480979484\n",
      "Epoch:  895  Loss:  0.6173873337401637  Validation Loss:  0.7371766694106053\n",
      "Epoch:  896  Loss:  0.617234540777733  Validation Loss:  0.7369939589845962\n",
      "Epoch:  897  Loss:  0.6170828131579079  Validation Loss:  0.7368121448418369\n",
      "Epoch:  898  Loss:  0.6169321059421139  Validation Loss:  0.736631636440322\n",
      "Epoch:  899  Loss:  0.6167827176599248  Validation Loss:  0.7364525344168794\n",
      "Epoch:  900  Loss:  0.616634467960272  Validation Loss:  0.7362743849879589\n",
      "Epoch:  901  Loss:  0.6164872044498481  Validation Loss:  0.7360974852589593\n",
      "Epoch:  902  Loss:  0.6163412345374383  Validation Loss:  0.7359218870600065\n",
      "Epoch:  903  Loss:  0.616196252260972  Validation Loss:  0.735747164250284\n",
      "Epoch:  904  Loss:  0.6160523640082299  Validation Loss:  0.7355738016574279\n",
      "Epoch:  905  Loss:  0.6159094737173574  Validation Loss:  0.7354012657010901\n",
      "Epoch:  906  Loss:  0.6157676484435797  Validation Loss:  0.7352300469858059\n",
      "Epoch:  907  Loss:  0.6156267892858647  Validation Loss:  0.7350597130539624\n",
      "Epoch:  908  Loss:  0.6154868145590847  Validation Loss:  0.7348902394482191\n",
      "Epoch:  909  Loss:  0.6153477103747789  Validation Loss:  0.7347217525584974\n",
      "Epoch:  910  Loss:  0.6152094954679024  Validation Loss:  0.7345542260378167\n",
      "Epoch:  911  Loss:  0.615072038549098  Validation Loss:  0.7343873977121236\n",
      "Epoch:  912  Loss:  0.6149351974243967  Validation Loss:  0.734221246957347\n",
      "Epoch:  913  Loss:  0.6147989582595894  Validation Loss:  0.7340557265324869\n",
      "Epoch:  914  Loss:  0.614663152801759  Validation Loss:  0.7338905867891036\n",
      "Epoch:  915  Loss:  0.6145276089099426  Validation Loss:  0.7337257253087085\n",
      "Epoch:  916  Loss:  0.6143921962893993  Validation Loss:  0.7335610205604546\n",
      "Epoch:  917  Loss:  0.6142566990179633  Validation Loss:  0.7333961446648058\n",
      "Epoch:  918  Loss:  0.6141207618367615  Validation Loss:  0.7332307315175084\n",
      "Epoch:  919  Loss:  0.6139840083468018  Validation Loss:  0.733064416418041\n",
      "Epoch:  920  Loss:  0.6138459755632194  Validation Loss:  0.7328966367395892\n",
      "Epoch:  921  Loss:  0.613706012645248  Validation Loss:  0.7327267434717952\n",
      "Epoch:  922  Loss:  0.6135633966514786  Validation Loss:  0.7325539445855479\n",
      "Epoch:  923  Loss:  0.6134173388330681  Validation Loss:  0.7323774969124276\n",
      "Epoch:  924  Loss:  0.6132671522718032  Validation Loss:  0.7321969175144382\n",
      "Epoch:  925  Loss:  0.6131125716040435  Validation Loss:  0.7320121416579122\n",
      "Epoch:  926  Loss:  0.6129539988717987  Validation Loss:  0.7318239473346351\n",
      "Epoch:  927  Loss:  0.6127924787477382  Validation Loss:  0.7316335373814555\n",
      "Epoch:  928  Loss:  0.6126293936762416  Validation Loss:  0.7314423250331394\n",
      "Epoch:  929  Loss:  0.6124660489556281  Validation Loss:  0.7312513900839764\n",
      "Epoch:  930  Loss:  0.6123033684759753  Validation Loss:  0.7310614378555961\n",
      "Epoch:  931  Loss:  0.6121419254256394  Validation Loss:  0.7308728717591452\n",
      "Epoch:  932  Loss:  0.6119819032118737  Validation Loss:  0.7306858528459418\n",
      "Epoch:  933  Loss:  0.6118236596433861  Validation Loss:  0.7305006596489229\n",
      "Epoch:  934  Loss:  0.6116672702929349  Validation Loss:  0.7303172078901443\n",
      "Epoch:  935  Loss:  0.611512514319524  Validation Loss:  0.7301353856489279\n",
      "Epoch:  936  Loss:  0.6113595122164025  Validation Loss:  0.7299553432326386\n",
      "Epoch:  937  Loss:  0.6112083682555307  Validation Loss:  0.7297771464547386\n",
      "Epoch:  938  Loss:  0.6110590413863798  Validation Loss:  0.7296005841074646\n",
      "Epoch:  939  Loss:  0.610911257438434  Validation Loss:  0.7294256666108317\n",
      "Epoch:  940  Loss:  0.6107652353900439  Validation Loss:  0.7292523259377998\n",
      "Epoch:  941  Loss:  0.6106207164782054  Validation Loss:  0.7290806220709414\n",
      "Epoch:  942  Loss:  0.6104779442392506  Validation Loss:  0.72891047494351\n",
      "Epoch:  943  Loss:  0.6103366626227654  Validation Loss:  0.7287419650001802\n",
      "Epoch:  944  Loss:  0.610197154569973  Validation Loss:  0.7285750049395837\n",
      "Epoch:  945  Loss:  0.6100590762329622  Validation Loss:  0.7284095313777958\n",
      "Epoch:  946  Loss:  0.6099225804390549  Validation Loss:  0.7282456242195938\n",
      "Epoch:  947  Loss:  0.609787670967793  Validation Loss:  0.7280831465470619\n",
      "Epoch:  948  Loss:  0.609654005725407  Validation Loss:  0.7279217708046022\n",
      "Epoch:  949  Loss:  0.6095215601900827  Validation Loss:  0.7277618238999359\n",
      "Epoch:  950  Loss:  0.6093907545962669  Validation Loss:  0.7276033865476864\n",
      "Epoch:  951  Loss:  0.6092614401131868  Validation Loss:  0.7274464251122613\n",
      "Epoch:  952  Loss:  0.6091334652155638  Validation Loss:  0.727290723202885\n",
      "Epoch:  953  Loss:  0.6090069005573259  Validation Loss:  0.7271365604862787\n",
      "Epoch:  954  Loss:  0.6088820169453771  Validation Loss:  0.7269839405257633\n",
      "Epoch:  955  Loss:  0.6087585132460571  Validation Loss:  0.7268325474275195\n",
      "Epoch:  956  Loss:  0.6086362902689906  Validation Loss:  0.72668239960204\n",
      "Epoch:  957  Loss:  0.6085153333481076  Validation Loss:  0.7265334629278252\n",
      "Epoch:  958  Loss:  0.6083957317999555  Validation Loss:  0.7263859632438507\n",
      "Epoch:  959  Loss:  0.6082776274206569  Validation Loss:  0.7262398536330548\n",
      "Epoch:  960  Loss:  0.6081610577705415  Validation Loss:  0.7260951761534249\n",
      "Epoch:  961  Loss:  0.6080458235104107  Validation Loss:  0.7259516855296881\n",
      "Epoch:  962  Loss:  0.6079318447273623  Validation Loss:  0.7258093672386114\n",
      "Epoch:  963  Loss:  0.6078189848696144  Validation Loss:  0.725667904900468\n",
      "Epoch:  964  Loss:  0.6077067396847657  Validation Loss:  0.7255258196289989\n",
      "Epoch:  965  Loss:  0.6075945921169902  Validation Loss:  0.7253843702483869\n",
      "Epoch:  966  Loss:  0.6074832689595743  Validation Loss:  0.7252438966778741\n",
      "Epoch:  967  Loss:  0.607373307034084  Validation Loss:  0.7251046053741289\n",
      "Epoch:  968  Loss:  0.6072647449316331  Validation Loss:  0.7249665013581946\n",
      "Epoch:  969  Loss:  0.607157371558466  Validation Loss:  0.724829313331756\n",
      "Epoch:  970  Loss:  0.6070510736187396  Validation Loss:  0.7246929401180883\n",
      "Epoch:  971  Loss:  0.6069458180188554  Validation Loss:  0.7245573679498141\n",
      "Epoch:  972  Loss:  0.6068415472880729  Validation Loss:  0.7244224098605522\n",
      "Epoch:  973  Loss:  0.6067382005739559  Validation Loss:  0.7242879612722258\n",
      "Epoch:  974  Loss:  0.6066356718865702  Validation Loss:  0.7241538392676823\n",
      "Epoch:  975  Loss:  0.6065338626323105  Validation Loss:  0.7240197912830374\n",
      "Epoch:  976  Loss:  0.6064326157160465  Validation Loss:  0.7238855491513791\n",
      "Epoch:  977  Loss:  0.606331746066803  Validation Loss:  0.7237506985556388\n",
      "Epoch:  978  Loss:  0.6062310509636853  Validation Loss:  0.7236148894265078\n",
      "Epoch:  979  Loss:  0.6061302862916756  Validation Loss:  0.723477653403213\n",
      "Epoch:  980  Loss:  0.6060293750855529  Validation Loss:  0.7233385485799416\n",
      "Epoch:  981  Loss:  0.6059276748412442  Validation Loss:  0.7231969719995623\n",
      "Epoch:  982  Loss:  0.6058249028164495  Validation Loss:  0.7230530321814012\n",
      "Epoch:  983  Loss:  0.6057211127747031  Validation Loss:  0.7229073044398556\n",
      "Epoch:  984  Loss:  0.6056166936290784  Validation Loss:  0.722760700121306\n",
      "Epoch:  985  Loss:  0.605512202943413  Validation Loss:  0.7226140094192132\n",
      "Epoch:  986  Loss:  0.6054081233778914  Validation Loss:  0.7224678591541622\n",
      "Epoch:  987  Loss:  0.6053048560522425  Validation Loss:  0.7223226320052493\n",
      "Epoch:  988  Loss:  0.6052025977015785  Validation Loss:  0.7221785264386646\n",
      "Epoch:  989  Loss:  0.6051015046976723  Validation Loss:  0.7220356538891792\n",
      "Epoch:  990  Loss:  0.605001583894335  Validation Loss:  0.7218940644592479\n",
      "Epoch:  991  Loss:  0.6049029135588303  Validation Loss:  0.7217537889230079\n",
      "Epoch:  992  Loss:  0.6048054819908536  Validation Loss:  0.7216147810652636\n",
      "Epoch:  993  Loss:  0.6047093009087935  Validation Loss:  0.7214770166986231\n",
      "Epoch:  994  Loss:  0.6046143248858094  Validation Loss:  0.7213405572633812\n",
      "Epoch:  995  Loss:  0.6045205969616626  Validation Loss:  0.721205321666987\n",
      "Epoch:  996  Loss:  0.6044280514012552  Validation Loss:  0.7210713230829308\n",
      "Epoch:  997  Loss:  0.6043367439211862  Validation Loss:  0.7209385517930639\n",
      "Epoch:  998  Loss:  0.6042466297637201  Validation Loss:  0.7208069892249246\n",
      "Epoch:  999  Loss:  0.6041577271393781  Validation Loss:  0.7206766450966614\n",
      "Epoch:  1000  Loss:  0.604070070588473  Validation Loss:  0.7205476738188578\n",
      "Epoch:  1001  Loss:  0.6039837670232197  Validation Loss:  0.7204199277836344\n",
      "Epoch:  1002  Loss:  0.6038988530093315  Validation Loss:  0.7202936031896136\n",
      "Epoch:  1003  Loss:  0.6038151826998852  Validation Loss:  0.7201684703645499\n",
      "Epoch:  1004  Loss:  0.6037326747714316  Validation Loss:  0.7200444649527038\n",
      "Epoch:  1005  Loss:  0.603651336222453  Validation Loss:  0.7199215696773668\n",
      "Epoch:  1006  Loss:  0.6035711054409881  Validation Loss:  0.7197997500931007\n",
      "Epoch:  1007  Loss:  0.6034917881875073  Validation Loss:  0.7196787333358889\n",
      "Epoch:  1008  Loss:  0.6034134307207124  Validation Loss:  0.7195587376321572\n",
      "Epoch:  1009  Loss:  0.6033361820160474  Validation Loss:  0.7194398278775422\n",
      "Epoch:  1010  Loss:  0.6032600441712488  Validation Loss:  0.7193220711272695\n",
      "Epoch:  1011  Loss:  0.6031850655970065  Validation Loss:  0.7192054047532703\n",
      "Epoch:  1012  Loss:  0.6031112283721421  Validation Loss:  0.719089858557867\n",
      "Epoch:  1013  Loss:  0.6030385162391998  Validation Loss:  0.718975430165512\n",
      "Epoch:  1014  Loss:  0.6029669555645545  Validation Loss:  0.7188620869664178\n",
      "Epoch:  1015  Loss:  0.6028965105962696  Validation Loss:  0.718749871612459\n",
      "Epoch:  1016  Loss:  0.6028272293110206  Validation Loss:  0.7186387522497039\n",
      "Epoch:  1017  Loss:  0.6027590770780751  Validation Loss:  0.7185287464787995\n",
      "Epoch:  1018  Loss:  0.6026920539516847  Validation Loss:  0.7184197872445204\n",
      "Epoch:  1019  Loss:  0.6026261345781747  Validation Loss:  0.7183119886811229\n",
      "Epoch:  1020  Loss:  0.6025613896114733  Validation Loss:  0.7182052740152332\n",
      "Epoch:  1021  Loss:  0.6024977700079529  Validation Loss:  0.7180996698097907\n",
      "Epoch:  1022  Loss:  0.6024352814821363  Validation Loss:  0.7179950985355653\n",
      "Epoch:  1023  Loss:  0.6023738964017734  Validation Loss:  0.7178916925753372\n",
      "Epoch:  1024  Loss:  0.6023136762341539  Validation Loss:  0.7177893764514854\n",
      "Epoch:  1025  Loss:  0.6022546052462557  Validation Loss:  0.7176881493001744\n",
      "Epoch:  1026  Loss:  0.6021966539431833  Validation Loss:  0.7175880034548648\n",
      "Epoch:  1027  Loss:  0.6021398093587566  Validation Loss:  0.7174889266059019\n",
      "Epoch:  1028  Loss:  0.6020841024888371  Validation Loss:  0.7173909961745359\n",
      "Epoch:  1029  Loss:  0.6020295448167231  Validation Loss:  0.7172941503965337\n",
      "Epoch:  1030  Loss:  0.6019761279153014  Validation Loss:  0.717198399313982\n",
      "Epoch:  1031  Loss:  0.6019237344198435  Validation Loss:  0.7171034790251566\n",
      "Epoch:  1032  Loss:  0.6018721685898536  Validation Loss:  0.7170093736570814\n",
      "Epoch:  1033  Loss:  0.6018216344482691  Validation Loss:  0.7169163662238397\n",
      "Epoch:  1034  Loss:  0.6017722031372843  Validation Loss:  0.7168244622323824\n",
      "Epoch:  1035  Loss:  0.6017239026869964  Validation Loss:  0.7167335043566815\n",
      "Epoch:  1036  Loss:  0.6016765790222918  Validation Loss:  0.7166435193756352\n",
      "Epoch:  1037  Loss:  0.6016302797400835  Validation Loss:  0.716554516683454\n",
      "Epoch:  1038  Loss:  0.601585025962406  Validation Loss:  0.7164665336410204\n",
      "Epoch:  1039  Loss:  0.601540814976669  Validation Loss:  0.7163795881729195\n",
      "Epoch:  1040  Loss:  0.6014977075087214  Validation Loss:  0.716293652528438\n",
      "Epoch:  1041  Loss:  0.6014556361054911  Validation Loss:  0.7162086812482364\n",
      "Epoch:  1042  Loss:  0.6014145996819422  Validation Loss:  0.7161247938655425\n",
      "Epoch:  1043  Loss:  0.6013746591809305  Validation Loss:  0.7160419685685117\n",
      "Epoch:  1044  Loss:  0.6013358309141641  Validation Loss:  0.7159601129267527\n",
      "Epoch:  1045  Loss:  0.601297748320311  Validation Loss:  0.7158788538713386\n",
      "Epoch:  1046  Loss:  0.6012605701401396  Validation Loss:  0.7157986382211464\n",
      "Epoch:  1047  Loss:  0.6012245609415966  Validation Loss:  0.7157196129361788\n",
      "Epoch:  1048  Loss:  0.601189751214194  Validation Loss:  0.715641778556333\n",
      "Epoch:  1049  Loss:  0.6011561885910127  Validation Loss:  0.7155651266592137\n",
      "Epoch:  1050  Loss:  0.6011239156054641  Validation Loss:  0.7154897103706995\n",
      "Epoch:  1051  Loss:  0.6010929018042042  Validation Loss:  0.7154155300147291\n",
      "Epoch:  1052  Loss:  0.6010630650138392  Validation Loss:  0.715342426645583\n",
      "Epoch:  1053  Loss:  0.6010343119574403  Validation Loss:  0.7152702581623326\n",
      "Epoch:  1054  Loss:  0.6010063709058229  Validation Loss:  0.7151988957455193\n",
      "Epoch:  1055  Loss:  0.6009794668231195  Validation Loss:  0.7151286298598069\n",
      "Epoch:  1056  Loss:  0.6009536930224271  Validation Loss:  0.715059429191161\n",
      "Epoch:  1057  Loss:  0.6009290521801676  Validation Loss:  0.7149913294807725\n",
      "Epoch:  1058  Loss:  0.6009055306248873  Validation Loss:  0.7149243178790894\n",
      "Epoch:  1059  Loss:  0.6008830609035145  Validation Loss:  0.7148581146114115\n",
      "Epoch:  1060  Loss:  0.6008613753738334  Validation Loss:  0.7147927527194438\n",
      "Epoch:  1061  Loss:  0.6008407503221799  Validation Loss:  0.7147284553966661\n",
      "Epoch:  1062  Loss:  0.6008212540334869  Validation Loss:  0.7146652967169664\n",
      "Epoch:  1063  Loss:  0.6008028935966561  Validation Loss:  0.7146031174106874\n",
      "Epoch:  1064  Loss:  0.6007853364843188  Validation Loss:  0.7145416415903879\n",
      "Epoch:  1065  Loss:  0.600768766176064  Validation Loss:  0.7144812689959139\n",
      "Epoch:  1066  Loss:  0.6007533447039359  Validation Loss:  0.7144220164720563\n",
      "Epoch:  1067  Loss:  0.6007388090913736  Validation Loss:  0.7143633266290029\n",
      "Epoch:  1068  Loss:  0.6007251794115432  Validation Loss:  0.7143057948653249\n",
      "Epoch:  1069  Loss:  0.6007126800498916  Validation Loss:  0.7142492761646492\n",
      "Epoch:  1070  Loss:  0.6007010135257128  Validation Loss:  0.7141934573866319\n",
      "Epoch:  1071  Loss:  0.6006903368437174  Validation Loss:  0.714138666032881\n",
      "Epoch:  1072  Loss:  0.6006804752407722  Validation Loss:  0.7140845536537792\n",
      "Epoch:  1073  Loss:  0.6006715524109821  Validation Loss:  0.7140313433348269\n",
      "Epoch:  1074  Loss:  0.6006634188002175  Validation Loss:  0.7139789285003275\n",
      "Epoch:  1075  Loss:  0.6006560601221705  Validation Loss:  0.7139270773184472\n",
      "Epoch:  1076  Loss:  0.6006494675880497  Validation Loss:  0.7138759724903798\n",
      "Epoch:  1077  Loss:  0.6006435592053005  Validation Loss:  0.7138254779620447\n",
      "Epoch:  1078  Loss:  0.6006382949722623  Validation Loss:  0.7137755739732065\n",
      "Epoch:  1079  Loss:  0.6006327816149564  Validation Loss:  0.7137234190451927\n",
      "Epoch:  1080  Loss:  0.6006258143455658  Validation Loss:  0.7136710599280786\n",
      "Epoch:  1081  Loss:  0.6006192019914539  Validation Loss:  0.7136189581259437\n",
      "Epoch:  1082  Loss:  0.600612806861551  Validation Loss:  0.7135669682984767\n",
      "Epoch:  1083  Loss:  0.6006065436358591  Validation Loss:  0.7135149932641914\n",
      "Epoch:  1084  Loss:  0.6006001761382066  Validation Loss:  0.7134626774468283\n",
      "Epoch:  1085  Loss:  0.6005934684817652  Validation Loss:  0.713409825079683\n",
      "Epoch:  1086  Loss:  0.6005860996043798  Validation Loss:  0.713356044197428\n",
      "Epoch:  1087  Loss:  0.600577657409374  Validation Loss:  0.7133008217897968\n",
      "Epoch:  1088  Loss:  0.6005676316766484  Validation Loss:  0.7132436653626137\n",
      "Epoch:  1089  Loss:  0.6005554224897935  Validation Loss:  0.7131838284540868\n",
      "Epoch:  1090  Loss:  0.6005403556074332  Validation Loss:  0.7131206970931827\n",
      "Epoch:  1091  Loss:  0.6005218634833989  Validation Loss:  0.7130537897996281\n",
      "Epoch:  1092  Loss:  0.6004997646996697  Validation Loss:  0.7129832173603169\n",
      "Epoch:  1093  Loss:  0.600474386286099  Validation Loss:  0.7129095805727917\n",
      "Epoch:  1094  Loss:  0.6004466448087715  Validation Loss:  0.712834033953107\n",
      "Epoch:  1095  Loss:  0.600417669247655  Validation Loss:  0.7127577554488528\n",
      "Epoch:  1096  Loss:  0.6003885691605725  Validation Loss:  0.7126816999221194\n",
      "Epoch:  1097  Loss:  0.6003600388258985  Validation Loss:  0.7126064227111097\n",
      "Epoch:  1098  Loss:  0.6003326129132104  Validation Loss:  0.712532417713732\n",
      "Epoch:  1099  Loss:  0.6003065439827234  Validation Loss:  0.7124598474390265\n",
      "Epoch:  1100  Loss:  0.6002820235432931  Validation Loss:  0.7123888813067174\n",
      "Epoch:  1101  Loss:  0.6002591255582074  Validation Loss:  0.7123193931968316\n",
      "Epoch:  1102  Loss:  0.6002377534230936  Validation Loss:  0.7122514680891797\n",
      "Epoch:  1103  Loss:  0.6002179393273535  Validation Loss:  0.7121851052279058\n",
      "Epoch:  1104  Loss:  0.600199733254979  Validation Loss:  0.7121203282605046\n",
      "Epoch:  1105  Loss:  0.6001821766128239  Validation Loss:  0.7120540372055509\n",
      "Epoch:  1106  Loss:  0.6001640396934111  Validation Loss:  0.7119887516550396\n",
      "Epoch:  1107  Loss:  0.6001474105400367  Validation Loss:  0.7119248047255088\n",
      "Epoch:  1108  Loss:  0.6001321922951531  Validation Loss:  0.7118624453095422\n",
      "Epoch:  1109  Loss:  0.6001184868074737  Validation Loss:  0.7118013705248418\n",
      "Epoch:  1110  Loss:  0.6001061295132035  Validation Loss:  0.7117418011893397\n",
      "Epoch:  1111  Loss:  0.6000953075448865  Validation Loss:  0.7116835529821507\n",
      "Epoch:  1112  Loss:  0.600085779626682  Validation Loss:  0.7116267153102419\n",
      "Epoch:  1113  Loss:  0.6000778198025181  Validation Loss:  0.7115713197036065\n",
      "Epoch:  1114  Loss:  0.6000711466863896  Validation Loss:  0.7115171053919239\n",
      "Epoch:  1115  Loss:  0.6000656948867932  Validation Loss:  0.7114641219377518\n",
      "Epoch:  1116  Loss:  0.6000609010892007  Validation Loss:  0.7114100592291873\n",
      "Epoch:  1117  Loss:  0.6000554482407362  Validation Loss:  0.711356397556222\n",
      "Epoch:  1118  Loss:  0.6000510848045928  Validation Loss:  0.7113039197697155\n",
      "Epoch:  1119  Loss:  0.6000479663025986  Validation Loss:  0.7112526643103447\n",
      "Epoch:  1120  Loss:  0.6000462077847384  Validation Loss:  0.7112029714212902\n",
      "Epoch:  1121  Loss:  0.6000459722234207  Validation Loss:  0.7111545752571977\n",
      "Epoch:  1122  Loss:  0.6000469587381604  Validation Loss:  0.7111068144440651\n",
      "Epoch:  1123  Loss:  0.6000473458428406  Validation Loss:  0.7110572989652122\n",
      "Epoch:  1124  Loss:  0.6000477426043413  Validation Loss:  0.7110089669409005\n",
      "Epoch:  1125  Loss:  0.6000494151511817  Validation Loss:  0.7109620575455652\n",
      "Epoch:  1126  Loss:  0.6000526616512571  Validation Loss:  0.7109166300599126\n",
      "Epoch:  1127  Loss:  0.6000559986795037  Validation Loss:  0.7108690429856812\n",
      "Epoch:  1128  Loss:  0.6000586740166238  Validation Loss:  0.7108224102336428\n",
      "Epoch:  1129  Loss:  0.6000625274858429  Validation Loss:  0.7107764742728593\n",
      "Epoch:  1130  Loss:  0.6000658126493681  Validation Loss:  0.7107287284688674\n",
      "Epoch:  1131  Loss:  0.6000690741952762  Validation Loss:  0.7106821784290714\n",
      "Epoch:  1132  Loss:  0.6000723926332391  Validation Loss:  0.7106335676018742\n",
      "Epoch:  1133  Loss:  0.6000749274220282  Validation Loss:  0.7105848970620529\n",
      "Epoch:  1134  Loss:  0.6000768569053956  Validation Loss:  0.710535232571588\n",
      "Epoch:  1135  Loss:  0.6000780787644455  Validation Loss:  0.7104834941202316\n",
      "Epoch:  1136  Loss:  0.6000775586705185  Validation Loss:  0.7104295510528744\n",
      "Epoch:  1137  Loss:  0.6000750419656629  Validation Loss:  0.7103726519406706\n",
      "Epoch:  1138  Loss:  0.6000696550873876  Validation Loss:  0.7103116934498152\n",
      "Epoch:  1139  Loss:  0.600060762602438  Validation Loss:  0.7102460808296135\n",
      "Epoch:  1140  Loss:  0.60004730956647  Validation Loss:  0.7101742095057515\n",
      "Epoch:  1141  Loss:  0.6000279532474222  Validation Loss:  0.7100942708227945\n",
      "Epoch:  1142  Loss:  0.6000008809479694  Validation Loss:  0.710004240706347\n",
      "Epoch:  1143  Loss:  0.5999641553001497  Validation Loss:  0.7099013640612796\n",
      "Epoch:  1144  Loss:  0.599915629090036  Validation Loss:  0.7097835428472878\n",
      "Epoch:  1145  Loss:  0.5998536131335693  Validation Loss:  0.7096494352040084\n",
      "Epoch:  1146  Loss:  0.5997776819157947  Validation Loss:  0.7094993902289349\n",
      "Epoch:  1147  Loss:  0.5996886926151596  Validation Loss:  0.7093357797982036\n",
      "Epoch:  1148  Loss:  0.5995896811624175  Validation Loss:  0.7091625853293184\n",
      "Epoch:  1149  Loss:  0.5994841105223281  Validation Loss:  0.7089839398429014\n",
      "Epoch:  1150  Loss:  0.5993756534332789  Validation Loss:  0.7088045179843903\n",
      "Epoch:  1151  Loss:  0.599266672922859  Validation Loss:  0.7086231325199639\n",
      "Epoch:  1152  Loss:  0.5991574924041345  Validation Loss:  0.7084441837193309\n",
      "Epoch:  1153  Loss:  0.5990510587264033  Validation Loss:  0.7082676893990972\n",
      "Epoch:  1154  Loss:  0.5989461120543549  Validation Loss:  0.7080921554479046\n",
      "Epoch:  1155  Loss:  0.598842619041216  Validation Loss:  0.7079197071168734\n",
      "Epoch:  1156  Loss:  0.5987424686985109  Validation Loss:  0.7077497348621271\n",
      "Epoch:  1157  Loss:  0.5986436570732339  Validation Loss:  0.707580986554208\n",
      "Epoch:  1158  Loss:  0.5985474763709364  Validation Loss:  0.7074165810709414\n",
      "Epoch:  1159  Loss:  0.5984537976893406  Validation Loss:  0.70725315787654\n",
      "Epoch:  1160  Loss:  0.5983611332270705  Validation Loss:  0.7070907404025396\n",
      "Epoch:  1161  Loss:  0.5982700272020206  Validation Loss:  0.7069316074468087\n",
      "Epoch:  1162  Loss:  0.5981822566499988  Validation Loss:  0.7067747810396595\n",
      "Epoch:  1163  Loss:  0.5980957667298109  Validation Loss:  0.706618957221508\n",
      "Epoch:  1164  Loss:  0.5980102905949343  Validation Loss:  0.7064641419312229\n",
      "Epoch:  1165  Loss:  0.5979259993193797  Validation Loss:  0.7063115214308103\n",
      "Epoch:  1166  Loss:  0.5978450013451206  Validation Loss:  0.7061626008455304\n",
      "Epoch:  1167  Loss:  0.5977661362984805  Validation Loss:  0.7060148706254752\n",
      "Epoch:  1168  Loss:  0.5976883552389817  Validation Loss:  0.7058681522806486\n",
      "Epoch:  1169  Loss:  0.5976115938963242  Validation Loss:  0.7057224349051282\n",
      "Epoch:  1170  Loss:  0.5975358556341199  Validation Loss:  0.7055777369633965\n",
      "Epoch:  1171  Loss:  0.5974611535089688  Validation Loss:  0.7054340565118237\n",
      "Epoch:  1172  Loss:  0.5973879571967912  Validation Loss:  0.7052935751667921\n",
      "Epoch:  1173  Loss:  0.5973181446055764  Validation Loss:  0.7051555371802786\n",
      "Epoch:  1174  Loss:  0.5972496858137903  Validation Loss:  0.7050185526410738\n",
      "Epoch:  1175  Loss:  0.5971822683310625  Validation Loss:  0.7048825580572736\n",
      "Epoch:  1176  Loss:  0.5971159007653449  Validation Loss:  0.7047476368969765\n",
      "Epoch:  1177  Loss:  0.5970505726279565  Validation Loss:  0.7046137544987858\n",
      "Epoch:  1178  Loss:  0.5969863044260775  Validation Loss:  0.7044809294351633\n",
      "Epoch:  1179  Loss:  0.5969230879857702  Validation Loss:  0.7043491317958072\n",
      "Epoch:  1180  Loss:  0.5968609199795908  Validation Loss:  0.7042182669907376\n",
      "Epoch:  1181  Loss:  0.5967994716054607  Validation Loss:  0.7040878030053084\n",
      "Epoch:  1182  Loss:  0.5967388491969086  Validation Loss:  0.7039584072603695\n",
      "Epoch:  1183  Loss:  0.5966792952233148  Validation Loss:  0.7038303630939429\n",
      "Epoch:  1184  Loss:  0.5966223130744059  Validation Loss:  0.703706373339114\n",
      "Epoch:  1185  Loss:  0.5965679380861879  Validation Loss:  0.7035837490921435\n",
      "Epoch:  1186  Loss:  0.5965147201080345  Validation Loss:  0.7034622160852819\n",
      "Epoch:  1187  Loss:  0.5964625772558948  Validation Loss:  0.7033417391172354\n",
      "Epoch:  1188  Loss:  0.5964115032727278  Validation Loss:  0.7032223667787469\n",
      "Epoch:  1189  Loss:  0.5963615207272825  Validation Loss:  0.7031040422726369\n",
      "Epoch:  1190  Loss:  0.5963125992747187  Validation Loss:  0.7029868109502654\n",
      "Epoch:  1191  Loss:  0.5962647351535778  Validation Loss:  0.7028705892355546\n",
      "Epoch:  1192  Loss:  0.5962179347655727  Validation Loss:  0.7027554434278737\n",
      "Epoch:  1193  Loss:  0.5961721956512882  Validation Loss:  0.7026413525792136\n",
      "Epoch:  1194  Loss:  0.5961275159299952  Validation Loss:  0.7025283071873845\n",
      "Epoch:  1195  Loss:  0.5960838886936313  Validation Loss:  0.7024163195620412\n",
      "Epoch:  1196  Loss:  0.5960413298198899  Validation Loss:  0.7023053976936616\n",
      "Epoch:  1197  Loss:  0.595999833087898  Validation Loss:  0.7021955156671829\n",
      "Epoch:  1198  Loss:  0.5959593938681685  Validation Loss:  0.7020867054445156\n",
      "Epoch:  1199  Loss:  0.5959200252896374  Validation Loss:  0.7019789622745652\n",
      "Epoch:  1200  Loss:  0.5958817188890235  Validation Loss:  0.7018722842137018\n",
      "Epoch:  1201  Loss:  0.5958444843231474  Validation Loss:  0.7017666565767233\n",
      "Epoch:  1202  Loss:  0.5958083079205555  Validation Loss:  0.7016621007435564\n",
      "Epoch:  1203  Loss:  0.5957732070418238  Validation Loss:  0.7015586000853691\n",
      "Epoch:  1204  Loss:  0.5957391753937434  Validation Loss:  0.7014561902353729\n",
      "Epoch:  1205  Loss:  0.5957062131571538  Validation Loss:  0.7013548431189164\n",
      "Epoch:  1206  Loss:  0.595674335558727  Validation Loss:  0.701254586810651\n",
      "Epoch:  1207  Loss:  0.5956435259250761  Validation Loss:  0.7011553796305172\n",
      "Epoch:  1208  Loss:  0.595613798759516  Validation Loss:  0.7010572777278181\n",
      "Epoch:  1209  Loss:  0.5955851449115762  Validation Loss:  0.7009602476289307\n",
      "Epoch:  1210  Loss:  0.5955576655066129  Validation Loss:  0.7008648735025654\n",
      "Epoch:  1211  Loss:  0.5955328304429077  Validation Loss:  0.7007733415002408\n",
      "Epoch:  1212  Loss:  0.5955107962911569  Validation Loss:  0.7006836190171863\n",
      "Epoch:  1213  Loss:  0.5954901067160286  Validation Loss:  0.7005950458671736\n",
      "Epoch:  1214  Loss:  0.5954705283986134  Validation Loss:  0.7005075723796651\n",
      "Epoch:  1215  Loss:  0.5954520341768427  Validation Loss:  0.7004211672406265\n",
      "Epoch:  1216  Loss:  0.5954346274866641  Validation Loss:  0.7003358740737473\n",
      "Epoch:  1217  Loss:  0.5954183041326051  Validation Loss:  0.7002516514149265\n",
      "Epoch:  1218  Loss:  0.5954030761947331  Validation Loss:  0.7001685435357301\n",
      "Epoch:  1219  Loss:  0.5953889401285972  Validation Loss:  0.7000865189061649\n",
      "Epoch:  1220  Loss:  0.5953758926790895  Validation Loss:  0.7000055924273919\n",
      "Epoch:  1221  Loss:  0.595363932182488  Validation Loss:  0.6999257571887278\n",
      "Epoch:  1222  Loss:  0.5953530716953925  Validation Loss:  0.6998470328424288\n",
      "Epoch:  1223  Loss:  0.595343304273573  Validation Loss:  0.6997693923936374\n",
      "Epoch:  1224  Loss:  0.5953346365357487  Validation Loss:  0.6996928796820019\n",
      "Epoch:  1225  Loss:  0.5953270666011907  Validation Loss:  0.6996174584264341\n",
      "Epoch:  1226  Loss:  0.5953205946507385  Validation Loss:  0.6995431456876837\n",
      "Epoch:  1227  Loss:  0.5953152247713608  Validation Loss:  0.6994699213815772\n",
      "Epoch:  1228  Loss:  0.5953109526590815  Validation Loss:  0.6993978241647499\n",
      "Epoch:  1229  Loss:  0.5953077813158336  Validation Loss:  0.6993268253146738\n",
      "Epoch:  1230  Loss:  0.5953057152626006  Validation Loss:  0.6992569535538771\n",
      "Epoch:  1231  Loss:  0.5953047545717179  Validation Loss:  0.6991881784321605\n",
      "Epoch:  1232  Loss:  0.5953049018834401  Validation Loss:  0.6991205332071885\n",
      "Epoch:  1233  Loss:  0.5953061454070424  Validation Loss:  0.6990539930436922\n",
      "Epoch:  1234  Loss:  0.5953085173319266  Validation Loss:  0.6989886078281679\n",
      "Epoch:  1235  Loss:  0.5953120852558358  Validation Loss:  0.6989245250605155\n",
      "Epoch:  1236  Loss:  0.595316901983856  Validation Loss:  0.6988615991844647\n",
      "Epoch:  1237  Loss:  0.595322819914922  Validation Loss:  0.6987998070924178\n",
      "Epoch:  1238  Loss:  0.5953298555054132  Validation Loss:  0.6987391198458879\n",
      "Epoch:  1239  Loss:  0.5953380044875214  Validation Loss:  0.6986795778291813\n",
      "Epoch:  1240  Loss:  0.5953472678739469  Validation Loss:  0.6986211516718933\n",
      "Epoch:  1241  Loss:  0.5953576404203489  Validation Loss:  0.6985638443974481\n",
      "Epoch:  1242  Loss:  0.5953691400659894  Validation Loss:  0.6985076821368673\n",
      "Epoch:  1243  Loss:  0.5953817461951844  Validation Loss:  0.698452639191047\n",
      "Epoch:  1244  Loss:  0.5953954791704428  Validation Loss:  0.6983987298132717\n",
      "Epoch:  1245  Loss:  0.5954103214141814  Validation Loss:  0.698345945365187\n",
      "Epoch:  1246  Loss:  0.5954262940122664  Validation Loss:  0.6982943137054858\n",
      "Epoch:  1247  Loss:  0.5954433793509469  Validation Loss:  0.6982438041680101\n",
      "Epoch:  1248  Loss:  0.5954615916080267  Validation Loss:  0.6981944454752881\n",
      "Epoch:  1249  Loss:  0.5954809281070834  Validation Loss:  0.6981462114962979\n",
      "Epoch:  1250  Loss:  0.5955013893906352  Validation Loss:  0.6980991223152133\n",
      "Epoch:  1251  Loss:  0.5955229735417852  Validation Loss:  0.6980531796597053\n",
      "Epoch:  1252  Loss:  0.5955456859857133  Validation Loss:  0.6980083796425142\n",
      "Epoch:  1253  Loss:  0.595569525818223  Validation Loss:  0.6979647188082986\n",
      "Epoch:  1254  Loss:  0.5955944939796786  Validation Loss:  0.6979222144337668\n",
      "Epoch:  1255  Loss:  0.5956205930741667  Validation Loss:  0.6978808418996092\n",
      "Epoch:  1256  Loss:  0.595647817712675  Validation Loss:  0.6978406383507494\n",
      "Epoch:  1257  Loss:  0.5956761812773145  Validation Loss:  0.6978015657784282\n",
      "Epoch:  1258  Loss:  0.595705678306737  Validation Loss:  0.6977636654307877\n",
      "Epoch:  1259  Loss:  0.595736303267259  Validation Loss:  0.6977269072895464\n",
      "Epoch:  1260  Loss:  0.595768070987706  Validation Loss:  0.6976913146782613\n",
      "Epoch:  1261  Loss:  0.5958009665669168  Validation Loss:  0.6976568482924199\n",
      "Epoch:  1262  Loss:  0.5958350059549207  Validation Loss:  0.6976235914921415\n",
      "Epoch:  1263  Loss:  0.5958701860051132  Validation Loss:  0.6975914371618326\n",
      "Epoch:  1264  Loss:  0.595906511419317  Validation Loss:  0.6975604997596879\n",
      "Epoch:  1265  Loss:  0.595943967079364  Validation Loss:  0.6975306831840156\n",
      "Epoch:  1266  Loss:  0.5959825721903912  Validation Loss:  0.6975020645321279\n",
      "Epoch:  1267  Loss:  0.5960223150340099  Validation Loss:  0.6974745952132819\n",
      "Epoch:  1268  Loss:  0.5960632115602493  Validation Loss:  0.6974483002787051\n",
      "Epoch:  1269  Loss:  0.5961052436490082  Validation Loss:  0.6974231607240179\n",
      "Epoch:  1270  Loss:  0.5961484228378361  Validation Loss:  0.697399204623872\n",
      "Epoch:  1271  Loss:  0.5961927489458936  Validation Loss:  0.6973764267952546\n",
      "Epoch:  1272  Loss:  0.596238217018183  Validation Loss:  0.6973547944124194\n",
      "Epoch:  1273  Loss:  0.5962848383752466  Validation Loss:  0.6973343495873437\n",
      "Epoch:  1274  Loss:  0.5963326059281826  Validation Loss:  0.6973150923200275\n",
      "Epoch:  1275  Loss:  0.596381530527351  Validation Loss:  0.6972969966954079\n",
      "Epoch:  1276  Loss:  0.5964316077602719  Validation Loss:  0.6972800938115604\n",
      "Epoch:  1277  Loss:  0.5964828336123124  Validation Loss:  0.6972643562417099\n",
      "Epoch:  1278  Loss:  0.596535216836096  Validation Loss:  0.6972497928401699\n",
      "Epoch:  1279  Loss:  0.5965887477386345  Validation Loss:  0.6972364381603573\n",
      "Epoch:  1280  Loss:  0.5966434455250652  Validation Loss:  0.6972242414519407\n",
      "Epoch:  1281  Loss:  0.5966993038660114  Validation Loss:  0.6972132338129956\n",
      "Epoch:  1282  Loss:  0.5967563100665518  Validation Loss:  0.6972034113562625\n",
      "Epoch:  1283  Loss:  0.5968144746153679  Validation Loss:  0.6971947732179061\n",
      "Epoch:  1284  Loss:  0.5968738094840235  Validation Loss:  0.6971873444491539\n",
      "Epoch:  1285  Loss:  0.5969342906570551  Validation Loss:  0.6971810833699461\n",
      "Epoch:  1286  Loss:  0.5969959460560558  Validation Loss:  0.6971760320922603\n",
      "Epoch:  1287  Loss:  0.5970587552100131  Validation Loss:  0.6971721649169922\n",
      "Epoch:  1288  Loss:  0.5971227282097618  Validation Loss:  0.6971694850835247\n",
      "Epoch:  1289  Loss:  0.5971878696486209  Validation Loss:  0.6971680012302123\n",
      "Epoch:  1290  Loss:  0.5972541764884898  Validation Loss:  0.6971677304178044\n",
      "Epoch:  1291  Loss:  0.5973216416766343  Validation Loss:  0.6971686333417892\n",
      "Epoch:  1292  Loss:  0.5973902813077552  Validation Loss:  0.697170762696128\n",
      "Epoch:  1293  Loss:  0.5974600825422597  Validation Loss:  0.6971740567165873\n",
      "Epoch:  1294  Loss:  0.5975310613301773  Validation Loss:  0.697178579326989\n",
      "Epoch:  1295  Loss:  0.597603205121258  Validation Loss:  0.6971842892791914\n",
      "Epoch:  1296  Loss:  0.5976765189790031  Validation Loss:  0.697191219182982\n",
      "Epoch:  1297  Loss:  0.5977510083647608  Validation Loss:  0.6971993554329526\n",
      "Epoch:  1298  Loss:  0.5978266714339696  Validation Loss:  0.6972086816162303\n",
      "Epoch:  1299  Loss:  0.5979034991808307  Validation Loss:  0.6972192277510961\n",
      "Epoch:  1300  Loss:  0.597981514825115  Validation Loss:  0.6972309767768003\n",
      "Epoch:  1301  Loss:  0.5980606771716215  Validation Loss:  0.6972439060176628\n",
      "Epoch:  1302  Loss:  0.5981410240519394  Validation Loss:  0.697258060609085\n",
      "Epoch:  1303  Loss:  0.5982225508004138  Validation Loss:  0.6972734455181204\n",
      "Epoch:  1304  Loss:  0.598305257019198  Validation Loss:  0.6972900298626526\n",
      "Epoch:  1305  Loss:  0.5983891404658845  Validation Loss:  0.6973078423652096\n",
      "Epoch:  1306  Loss:  0.5984742012489768  Validation Loss:  0.6973268679086713\n",
      "Epoch:  1307  Loss:  0.598560454812154  Validation Loss:  0.6973471101643383\n",
      "Epoch:  1308  Loss:  0.5986478939941786  Validation Loss:  0.6973685980706975\n",
      "Epoch:  1309  Loss:  0.5987365108742876  Validation Loss:  0.6973912914594015\n",
      "Epoch:  1310  Loss:  0.5988263214025104  Validation Loss:  0.6974152322264685\n",
      "Epoch:  1311  Loss:  0.5989173115818824  Validation Loss:  0.6974403685417728\n",
      "Epoch:  1312  Loss:  0.5990094997133445  Validation Loss:  0.6974667688642723\n",
      "Epoch:  1313  Loss:  0.5991028684363203  Validation Loss:  0.697494372293569\n",
      "Epoch:  1314  Loss:  0.5991974289990166  Validation Loss:  0.6975232185660929\n",
      "Epoch:  1315  Loss:  0.5992931875861386  Validation Loss:  0.6975532917008884\n",
      "Epoch:  1316  Loss:  0.5993901321899544  Validation Loss:  0.6975846091906229\n",
      "Epoch:  1317  Loss:  0.5994882612552458  Validation Loss:  0.6976171449042748\n",
      "Epoch:  1318  Loss:  0.5995875887428094  Validation Loss:  0.6976509079121161\n",
      "Epoch:  1319  Loss:  0.5996881060446929  Validation Loss:  0.6976859198100325\n",
      "Epoch:  1320  Loss:  0.5997898112439993  Validation Loss:  0.6977221801661063\n",
      "Epoch:  1321  Loss:  0.5998927196397364  Validation Loss:  0.6977596306714459\n",
      "Epoch:  1322  Loss:  0.5999968196581869  Validation Loss:  0.6977983592213064\n",
      "Epoch:  1323  Loss:  0.6001021137225975  Validation Loss:  0.6978382999482362\n",
      "Epoch:  1324  Loss:  0.600208603352019  Validation Loss:  0.697879514184551\n",
      "Epoch:  1325  Loss:  0.6003162939354633  Validation Loss:  0.6979219280723212\n",
      "Epoch:  1326  Loss:  0.6004251737545416  Validation Loss:  0.6979656238918719\n",
      "Epoch:  1327  Loss:  0.6005352565530434  Validation Loss:  0.6980105444141056\n",
      "Epoch:  1328  Loss:  0.600646538714182  Validation Loss:  0.6980567090753196\n",
      "Epoch:  1329  Loss:  0.6007590202379574  Validation Loss:  0.6981041247861973\n",
      "Epoch:  1330  Loss:  0.6008727021370698  Validation Loss:  0.6981527928424918\n",
      "Epoch:  1331  Loss:  0.6009875911025746  Validation Loss:  0.6982027009345483\n",
      "Epoch:  1332  Loss:  0.6011036744757184  Validation Loss:  0.6982538628837337\n",
      "Epoch:  1333  Loss:  0.601220967555509  Validation Loss:  0.6983062711314879\n",
      "Epoch:  1334  Loss:  0.6013394612999796  Validation Loss:  0.6983599369076715\n",
      "Epoch:  1335  Loss:  0.6014591610619744  Validation Loss:  0.6984148476866708\n",
      "Epoch:  1336  Loss:  0.6015800703497767  Validation Loss:  0.6984710315431374\n",
      "Epoch:  1337  Loss:  0.6017021795065658  Validation Loss:  0.6985284467970115\n",
      "Epoch:  1338  Loss:  0.6018254858197518  Validation Loss:  0.698587066669395\n",
      "Epoch:  1339  Loss:  0.6019498871512783  Validation Loss:  0.6986466155967851\n",
      "Epoch:  1340  Loss:  0.6020750452954213  Validation Loss:  0.6987070639928182\n",
      "Epoch:  1341  Loss:  0.6022011338217744  Validation Loss:  0.698768487011177\n",
      "Epoch:  1342  Loss:  0.6023281919001375  Validation Loss:  0.6988311621589937\n",
      "Epoch:  1343  Loss:  0.6024569071539976  Validation Loss:  0.6988962616609491\n",
      "Epoch:  1344  Loss:  0.602587971149139  Validation Loss:  0.6989638950081839\n",
      "Epoch:  1345  Loss:  0.602721225868151  Validation Loss:  0.6990335972412772\n",
      "Epoch:  1346  Loss:  0.6028559848810863  Validation Loss:  0.6991045738475911\n",
      "Epoch:  1347  Loss:  0.602991961268256  Validation Loss:  0.6991767963205558\n",
      "Epoch:  1348  Loss:  0.6031291508341877  Validation Loss:  0.6992502892794816\n",
      "Epoch:  1349  Loss:  0.6032674238447425  Validation Loss:  0.6993247750012771\n",
      "Epoch:  1350  Loss:  0.6034066080323701  Validation Loss:  0.6994001871865728\n",
      "Epoch:  1351  Loss:  0.6035466264680173  Validation Loss:  0.69947633276815\n",
      "Epoch:  1352  Loss:  0.6036874594040287  Validation Loss:  0.6995535799558612\n",
      "Epoch:  1353  Loss:  0.6038293561455116  Validation Loss:  0.6996320432079011\n",
      "Epoch:  1354  Loss:  0.6039724584705043  Validation Loss:  0.6997117637724116\n",
      "Epoch:  1355  Loss:  0.6041167888392522  Validation Loss:  0.6997927684282911\n",
      "Epoch:  1356  Loss:  0.6042623353886951  Validation Loss:  0.6998750310445178\n",
      "Epoch:  1357  Loss:  0.604409094863725  Validation Loss:  0.6999585695456767\n",
      "Epoch:  1358  Loss:  0.6045570734490469  Validation Loss:  0.7000433945137522\n",
      "Epoch:  1359  Loss:  0.6047062635855768  Validation Loss:  0.7001294817613519\n",
      "Epoch:  1360  Loss:  0.6048566774980536  Validation Loss:  0.7002168541801148\n",
      "Epoch:  1361  Loss:  0.6050083002129805  Validation Loss:  0.7003054575643678\n",
      "Epoch:  1362  Loss:  0.6051611357088228  Validation Loss:  0.7003953510868377\n",
      "Epoch:  1363  Loss:  0.605315202901375  Validation Loss:  0.7004865572072457\n",
      "Epoch:  1364  Loss:  0.6054705242870502  Validation Loss:  0.7005790824043578\n",
      "Epoch:  1365  Loss:  0.6056271007700452  Validation Loss:  0.7006728906130445\n",
      "Epoch:  1366  Loss:  0.6057849165450022  Validation Loss:  0.7007680423017861\n",
      "Epoch:  1367  Loss:  0.6059440035481476  Validation Loss:  0.7008645068044248\n",
      "Epoch:  1368  Loss:  0.6061043805506044  Validation Loss:  0.7009623042051343\n",
      "Epoch:  1369  Loss:  0.6062660256708131  Validation Loss:  0.7010614364475444\n",
      "Epoch:  1370  Loss:  0.6064289496144624  Validation Loss:  0.7011619078508322\n",
      "Epoch:  1371  Loss:  0.6065931138989417  Validation Loss:  0.7012636663689129\n",
      "Epoch:  1372  Loss:  0.6067585034784183  Validation Loss:  0.7013666990442552\n",
      "Epoch:  1373  Loss:  0.6069251136872374  Validation Loss:  0.70147103783877\n",
      "Epoch:  1374  Loss:  0.6070929516504691  Validation Loss:  0.7015766557576\n",
      "Epoch:  1375  Loss:  0.607262018453149  Validation Loss:  0.7016835633827292\n",
      "Epoch:  1376  Loss:  0.6074323208948362  Validation Loss:  0.70179174516512\n",
      "Epoch:  1377  Loss:  0.6076038544545475  Validation Loss:  0.7019012639487999\n",
      "Epoch:  1378  Loss:  0.6077766116093664  Validation Loss:  0.7020120402609092\n",
      "Epoch:  1379  Loss:  0.6079506107687371  Validation Loss:  0.7021241412646528\n",
      "Epoch:  1380  Loss:  0.6081258399972638  Validation Loss:  0.7022375213927117\n",
      "Epoch:  1381  Loss:  0.6083023071795413  Validation Loss:  0.7023522400337717\n",
      "Epoch:  1382  Loss:  0.6084800124964089  Validation Loss:  0.7024682380151057\n",
      "Epoch:  1383  Loss:  0.6086589530182694  Validation Loss:  0.7025855218154796\n",
      "Epoch:  1384  Loss:  0.6088391362318715  Validation Loss:  0.7027041344107061\n",
      "Epoch:  1385  Loss:  0.6090205515400299  Validation Loss:  0.7028240390877792\n",
      "Epoch:  1386  Loss:  0.6092032041870853  Validation Loss:  0.7029452675926513\n",
      "Epoch:  1387  Loss:  0.6093871041192013  Validation Loss:  0.7030677801888922\n",
      "Epoch:  1388  Loss:  0.609572237122406  Validation Loss:  0.7031915960968405\n",
      "Epoch:  1389  Loss:  0.609758605836954  Validation Loss:  0.703316713804784\n",
      "Epoch:  1390  Loss:  0.6099462024144178  Validation Loss:  0.7034431572841562\n",
      "Epoch:  1391  Loss:  0.6101350456620883  Validation Loss:  0.703570874488872\n",
      "Epoch:  1392  Loss:  0.610325124331759  Validation Loss:  0.7036999315023422\n",
      "Epoch:  1393  Loss:  0.6105164390382836  Validation Loss:  0.7038302559783494\n",
      "Epoch:  1394  Loss:  0.6107089952791779  Validation Loss:  0.7039619019066078\n",
      "Epoch:  1395  Loss:  0.6109027858570363  Validation Loss:  0.7040948492029439\n",
      "Epoch:  1396  Loss:  0.6110978122185735  Validation Loss:  0.704229112336601\n",
      "Epoch:  1397  Loss:  0.6112940809463413  Validation Loss:  0.7043646975703861\n",
      "Epoch:  1398  Loss:  0.6114915594530915  Validation Loss:  0.7045015193845915\n",
      "Epoch:  1399  Loss:  0.6116902262551113  Validation Loss:  0.7046395933282548\n",
      "Epoch:  1400  Loss:  0.6118901113355623  Validation Loss:  0.7047789604335591\n",
      "Epoch:  1401  Loss:  0.6120912163943342  Validation Loss:  0.7049196083908496\n",
      "Epoch:  1402  Loss:  0.6122935509797439  Validation Loss:  0.7050615348245787\n",
      "Epoch:  1403  Loss:  0.6124970528107245  Validation Loss:  0.7052046922237977\n",
      "Epoch:  1404  Loss:  0.6127017772241125  Validation Loss:  0.7053491691316384\n",
      "Epoch:  1405  Loss:  0.6129077394465798  Validation Loss:  0.7054949366096137\n",
      "Epoch:  1406  Loss:  0.6131149268917089  Validation Loss:  0.7056420123663502\n",
      "Epoch:  1407  Loss:  0.613323359270987  Validation Loss:  0.7057903933784236\n",
      "Epoch:  1408  Loss:  0.6135330335463135  Validation Loss:  0.7059400772702866\n",
      "Epoch:  1409  Loss:  0.6137439221939416  Validation Loss:  0.7060910407183827\n",
      "Epoch:  1410  Loss:  0.6139560315794158  Validation Loss:  0.7062433225953061\n",
      "Epoch:  1411  Loss:  0.6141693856458641  Validation Loss:  0.7063969088637311\n",
      "Epoch:  1412  Loss:  0.6143839951713108  Validation Loss:  0.7065518252227617\n",
      "Epoch:  1413  Loss:  0.6145998358147816  Validation Loss:  0.7067080520201421\n",
      "Epoch:  1414  Loss:  0.6148169136524779  Validation Loss:  0.70686558774416\n",
      "Epoch:  1415  Loss:  0.6150352600057727  Validation Loss:  0.7070244721312454\n",
      "Epoch:  1416  Loss:  0.6152548608777014  Validation Loss:  0.7071847034537274\n",
      "Epoch:  1417  Loss:  0.6154757156172423  Validation Loss:  0.707346233120863\n",
      "Epoch:  1418  Loss:  0.6156978073340018  Validation Loss:  0.7075091056201769\n",
      "Epoch:  1419  Loss:  0.615921150061112  Validation Loss:  0.7076733215995457\n",
      "Epoch:  1420  Loss:  0.6161457496577675  Validation Loss:  0.7078388665897258\n",
      "Epoch:  1421  Loss:  0.6163716031220353  Validation Loss:  0.7080057462056478\n",
      "Epoch:  1422  Loss:  0.6165986996397231  Validation Loss:  0.708173973188884\n",
      "Epoch:  1423  Loss:  0.616827074293662  Validation Loss:  0.7083435214084127\n",
      "Epoch:  1424  Loss:  0.617056689288431  Validation Loss:  0.7085144239059393\n",
      "Epoch:  1425  Loss:  0.617287553593661  Validation Loss:  0.7086866444003754\n",
      "Epoch:  1426  Loss:  0.6175196510784834  Validation Loss:  0.7088601707980253\n",
      "Epoch:  1427  Loss:  0.6177529972589132  Validation Loss:  0.709035028366075\n",
      "Epoch:  1428  Loss:  0.6179875886990028  Validation Loss:  0.7092112220715785\n",
      "Epoch:  1429  Loss:  0.6182234310409398  Validation Loss:  0.7093887350697449\n",
      "Epoch:  1430  Loss:  0.6184605181361865  Validation Loss:  0.709567596083102\n",
      "Epoch:  1431  Loss:  0.6186988552652516  Validation Loss:  0.7097477545772773\n",
      "Epoch:  1432  Loss:  0.6189384425004709  Validation Loss:  0.7099292714526688\n",
      "Epoch:  1433  Loss:  0.6191792745613357  Validation Loss:  0.7101121112920236\n",
      "Epoch:  1434  Loss:  0.6194213383550783  Validation Loss:  0.7102961954863175\n",
      "Epoch:  1435  Loss:  0.6196644003819494  Validation Loss:  0.710481081103933\n",
      "Epoch:  1436  Loss:  0.6199081013503583  Validation Loss:  0.7106665653595026\n",
      "Epoch:  1437  Loss:  0.6201524764154721  Validation Loss:  0.7108530648376631\n",
      "Epoch:  1438  Loss:  0.620397776654623  Validation Loss:  0.7110407162403715\n",
      "Epoch:  1439  Loss:  0.6206442504687216  Validation Loss:  0.7112296601568443\n",
      "Epoch:  1440  Loss:  0.6208919629599284  Validation Loss:  0.7114199572715206\n",
      "Epoch:  1441  Loss:  0.6211409385777215  Validation Loss:  0.7116115434446196\n",
      "Epoch:  1442  Loss:  0.6213911718245849  Validation Loss:  0.7118044994447542\n",
      "Epoch:  1443  Loss:  0.6216426411444701  Validation Loss:  0.7119987753854282\n",
      "Epoch:  1444  Loss:  0.6218953807521792  Validation Loss:  0.7121943870316381\n",
      "Epoch:  1445  Loss:  0.62214936677692  Validation Loss:  0.7123913225056469\n",
      "Epoch:  1446  Loss:  0.622404609996717  Validation Loss:  0.7125896152810774\n",
      "Epoch:  1447  Loss:  0.6226611106285771  Validation Loss:  0.7127892290768416\n",
      "Epoch:  1448  Loss:  0.6229184973008425  Validation Loss:  0.7129893149586691\n",
      "Epoch:  1449  Loss:  0.6231764133260088  Validation Loss:  0.713190187362657\n",
      "Epoch:  1450  Loss:  0.6234351715561256  Validation Loss:  0.7133923041215842\n",
      "Epoch:  1451  Loss:  0.6236951813391112  Validation Loss:  0.713595731102902\n",
      "Epoch:  1452  Loss:  0.6239564321139484  Validation Loss:  0.7138005218644073\n",
      "Epoch:  1453  Loss:  0.6242189417475635  Validation Loss:  0.7140066263036452\n",
      "Epoch:  1454  Loss:  0.624482708793242  Validation Loss:  0.7142140873964282\n",
      "Epoch:  1455  Loss:  0.6247477198688729  Validation Loss:  0.7144228569839312\n",
      "Epoch:  1456  Loss:  0.6250139986282414  Validation Loss:  0.7146330037410709\n",
      "Epoch:  1457  Loss:  0.6252815286511356  Validation Loss:  0.7148444553216299\n",
      "Epoch:  1458  Loss:  0.6255503095758771  Validation Loss:  0.7150572637716929\n",
      "Epoch:  1459  Loss:  0.6258203460319528  Validation Loss:  0.7152714003687319\n",
      "Epoch:  1460  Loss:  0.6260916396830846  Validation Loss:  0.7154868918916454\n",
      "Epoch:  1461  Loss:  0.6263641817043129  Validation Loss:  0.7157037130732468\n",
      "Epoch:  1462  Loss:  0.6266379893115424  Validation Loss:  0.7159218794625738\n",
      "Epoch:  1463  Loss:  0.6269130507863842  Validation Loss:  0.7161413880362026\n",
      "Epoch:  1464  Loss:  0.6271893633077446  Validation Loss:  0.7163622368505036\n",
      "Epoch:  1465  Loss:  0.6274669430788281  Validation Loss:  0.7165844289289005\n",
      "Epoch:  1466  Loss:  0.627745764203442  Validation Loss:  0.7168079552011214\n",
      "Epoch:  1467  Loss:  0.6280258603177025  Validation Loss:  0.7170328266810679\n",
      "Epoch:  1468  Loss:  0.6283072040063663  Validation Loss:  0.7172590511432593\n",
      "Epoch:  1469  Loss:  0.6285898061197939  Validation Loss:  0.717486607639686\n",
      "Epoch:  1470  Loss:  0.6288736647772557  Validation Loss:  0.7177155205736989\n",
      "Epoch:  1471  Loss:  0.6291587811361239  Validation Loss:  0.7179457618706468\n",
      "Epoch:  1472  Loss:  0.6294451358827572  Validation Loss:  0.7181773228921752\n",
      "Epoch:  1473  Loss:  0.6297327063760711  Validation Loss:  0.7184101563432942\n",
      "Epoch:  1474  Loss:  0.6300214697579736  Validation Loss:  0.7186442771251651\n",
      "Epoch:  1475  Loss:  0.6303113980345356  Validation Loss:  0.718879651548206\n",
      "Epoch:  1476  Loss:  0.6306025071196186  Validation Loss:  0.7191163722587668\n",
      "Epoch:  1477  Loss:  0.6308947889116204  Validation Loss:  0.7193543267422828\n",
      "Epoch:  1478  Loss:  0.6311880881057202  Validation Loss:  0.7195931392303412\n",
      "Epoch:  1479  Loss:  0.6314819133252774  Validation Loss:  0.7198323106420212\n",
      "Epoch:  1480  Loss:  0.6317762177690719  Validation Loss:  0.720072424714116\n",
      "Epoch:  1481  Loss:  0.6320713950158323  Validation Loss:  0.7203137416770493\n",
      "Epoch:  1482  Loss:  0.6323678202710106  Validation Loss:  0.7205563857071642\n",
      "Epoch:  1483  Loss:  0.6326655195031351  Validation Loss:  0.7208004222399946\n",
      "Epoch:  1484  Loss:  0.6329644944482636  Validation Loss:  0.721045811323152\n",
      "Epoch:  1485  Loss:  0.6332647298435563  Validation Loss:  0.7212925698014273\n",
      "Epoch:  1486  Loss:  0.6335662498491482  Validation Loss:  0.7215406838534535\n",
      "Epoch:  1487  Loss:  0.6338690277008177  Validation Loss:  0.7217901685963506\n",
      "Epoch:  1488  Loss:  0.6341730757679754  Validation Loss:  0.7220410207907358\n",
      "Epoch:  1489  Loss:  0.63447839983748  Validation Loss:  0.7222932300705841\n",
      "Epoch:  1490  Loss:  0.634784988335614  Validation Loss:  0.7225468199754107\n",
      "Epoch:  1491  Loss:  0.635092851751059  Validation Loss:  0.7228017544400864\n",
      "Epoch:  1492  Loss:  0.6354016482974719  Validation Loss:  0.7230572085017744\n",
      "Epoch:  1493  Loss:  0.6357108907213489  Validation Loss:  0.7233133855937184\n",
      "Epoch:  1494  Loss:  0.6360209909023591  Validation Loss:  0.7235708219417627\n",
      "Epoch:  1495  Loss:  0.6363323735597642  Validation Loss:  0.7238296756277913\n",
      "Epoch:  1496  Loss:  0.6366450775740216  Validation Loss:  0.7240898831599001\n",
      "Epoch:  1497  Loss:  0.6369590606648945  Validation Loss:  0.7243514544721963\n",
      "Epoch:  1498  Loss:  0.6372742988169193  Validation Loss:  0.724614371424136\n",
      "Epoch:  1499  Loss:  0.6375908466797431  Validation Loss:  0.7248787597037744\n",
      "Training session:  7\n",
      "2021_1_8_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2021_1_8_MV1_run\n",
      "Epoch:  0  Loss:  0.6582576096989214  Validation Loss:  0.6661347957948843\n",
      "Epoch:  1  Loss:  0.6581727562705055  Validation Loss:  0.6661700210361569\n",
      "Epoch:  2  Loss:  0.6580872952006758  Validation Loss:  0.6662056622681795\n",
      "Epoch:  3  Loss:  0.6580025452189148  Validation Loss:  0.666243514046073\n",
      "Epoch:  4  Loss:  0.6579187577357516  Validation Loss:  0.6662814170812015\n",
      "Epoch:  5  Loss:  0.6578336912672966  Validation Loss:  0.6663182838647453\n",
      "Epoch:  6  Loss:  0.657747996179387  Validation Loss:  0.6663553574019008\n",
      "Epoch:  7  Loss:  0.6576625046785921  Validation Loss:  0.666392649696381\n",
      "Epoch:  8  Loss:  0.6575772111769765  Validation Loss:  0.6664301396382076\n",
      "Epoch:  9  Loss:  0.6574921771418303  Validation Loss:  0.6664675901195517\n",
      "Epoch:  10  Loss:  0.6574064766988158  Validation Loss:  0.6665033976788874\n",
      "Epoch:  11  Loss:  0.6573199522215873  Validation Loss:  0.6665390875466444\n",
      "Epoch:  12  Loss:  0.6572335976175964  Validation Loss:  0.6665750021045959\n",
      "Epoch:  13  Loss:  0.6571476352401078  Validation Loss:  0.666611824253643\n",
      "Epoch:  14  Loss:  0.6570622726110742  Validation Loss:  0.6666494426489981\n",
      "Epoch:  15  Loss:  0.6569772729417309  Validation Loss:  0.6666872568290543\n",
      "Epoch:  16  Loss:  0.6568924724590033  Validation Loss:  0.6667252936986862\n",
      "Epoch:  17  Loss:  0.6568079007556662  Validation Loss:  0.6667635355282713\n",
      "Epoch:  18  Loss:  0.6567235207883642  Validation Loss:  0.6668019873538503\n",
      "Epoch:  19  Loss:  0.6566393497167156  Validation Loss:  0.6668406525557792\n",
      "Epoch:  20  Loss:  0.656555378739722  Validation Loss:  0.6668795051260127\n",
      "Epoch:  21  Loss:  0.6564716011052951  Validation Loss:  0.666918594804075\n",
      "Epoch:  22  Loss:  0.6563880340894684  Validation Loss:  0.6669576921396785\n",
      "Epoch:  23  Loss:  0.6563043975969777  Validation Loss:  0.6669965419504378\n",
      "Epoch:  24  Loss:  0.656220877962187  Validation Loss:  0.6670355874079245\n",
      "Epoch:  25  Loss:  0.6561375547433272  Validation Loss:  0.6670748505879331\n",
      "Epoch:  26  Loss:  0.6560544391162694  Validation Loss:  0.6671143151405785\n",
      "Epoch:  27  Loss:  0.6559715194394812  Validation Loss:  0.6671539841012822\n",
      "Epoch:  28  Loss:  0.6558888036990538  Validation Loss:  0.6671938711294422\n",
      "Epoch:  29  Loss:  0.655806295783259  Validation Loss:  0.6672339386272209\n",
      "Epoch:  30  Loss:  0.6557239725720138  Validation Loss:  0.6672742148102434\n",
      "Epoch:  31  Loss:  0.6556418730411678  Validation Loss:  0.6673147178910397\n",
      "Epoch:  32  Loss:  0.6555599736515433  Validation Loss:  0.6673554086850749\n",
      "Epoch:  33  Loss:  0.655478289606981  Validation Loss:  0.6673963532817585\n",
      "Epoch:  34  Loss:  0.6553968055173754  Validation Loss:  0.6674374793138769\n",
      "Epoch:  35  Loss:  0.6553155436413363  Validation Loss:  0.6674788456272196\n",
      "Epoch:  36  Loss:  0.6552344887284562  Validation Loss:  0.6675204201428978\n",
      "Epoch:  37  Loss:  0.6551536531420424  Validation Loss:  0.6675622001014374\n",
      "Epoch:  38  Loss:  0.6550730171380564  Validation Loss:  0.6676041972995909\n",
      "Epoch:  39  Loss:  0.6549925981322303  Validation Loss:  0.6676464163594775\n",
      "Epoch:  40  Loss:  0.6549123901873827  Validation Loss:  0.6676888471400296\n",
      "Epoch:  41  Loss:  0.6548323891824112  Validation Loss:  0.6677314749470463\n",
      "Epoch:  42  Loss:  0.6547526052221656  Validation Loss:  0.6677743425523793\n",
      "Epoch:  43  Loss:  0.6546730254311115  Validation Loss:  0.6678174312605902\n",
      "Epoch:  44  Loss:  0.6545936650596559  Validation Loss:  0.6678607198237269\n",
      "Epoch:  45  Loss:  0.6545145189156756  Validation Loss:  0.6679042130708694\n",
      "Epoch:  46  Loss:  0.6544355841819197  Validation Loss:  0.6679479593618048\n",
      "Epoch:  47  Loss:  0.6543568557826802  Validation Loss:  0.6679918759123042\n",
      "Epoch:  48  Loss:  0.6542783452663571  Validation Loss:  0.6680360302605011\n",
      "Epoch:  49  Loss:  0.6542000382672996  Validation Loss:  0.6680804109545769\n",
      "Epoch:  50  Loss:  0.6541219495236874  Validation Loss:  0.6681250103369907\n",
      "Epoch:  51  Loss:  0.6540440700482577  Validation Loss:  0.6681697746669805\n",
      "Epoch:  52  Loss:  0.6539663878269494  Validation Loss:  0.6682147024958222\n",
      "Epoch:  53  Loss:  0.6538888693088666  Validation Loss:  0.6682596806850698\n",
      "Epoch:  54  Loss:  0.6538114379858598  Validation Loss:  0.6683047813949762\n",
      "Epoch:  55  Loss:  0.6537340844748541  Validation Loss:  0.6683498161534468\n",
      "Epoch:  56  Loss:  0.6536568936193362  Validation Loss:  0.6683950251727192\n",
      "Epoch:  57  Loss:  0.6535799070261419  Validation Loss:  0.6684403855491567\n",
      "Epoch:  58  Loss:  0.6535030620638281  Validation Loss:  0.6684858458185637\n",
      "Epoch:  59  Loss:  0.6534263716544956  Validation Loss:  0.6685314211580489\n",
      "Epoch:  60  Loss:  0.6533498368458822  Validation Loss:  0.6685771750355208\n",
      "Epoch:  61  Loss:  0.6532734708394855  Validation Loss:  0.6686230810290134\n",
      "Epoch:  62  Loss:  0.6531972248340026  Validation Loss:  0.6686690153761042\n",
      "Epoch:  63  Loss:  0.6531211264897138  Validation Loss:  0.6687150670698395\n",
      "Epoch:  64  Loss:  0.6530452067730949  Validation Loss:  0.6687613048211292\n",
      "Epoch:  65  Loss:  0.6529694909928366  Validation Loss:  0.6688077562247161\n",
      "Epoch:  66  Loss:  0.6528939937474206  Validation Loss:  0.6688544367336564\n",
      "Epoch:  67  Loss:  0.6528187059331685  Validation Loss:  0.6689012966084259\n",
      "Epoch:  68  Loss:  0.6527436792617664  Validation Loss:  0.6689485070744047\n",
      "Epoch:  69  Loss:  0.6526691468199715  Validation Loss:  0.6689961983787792\n",
      "Epoch:  70  Loss:  0.6525953331263736  Validation Loss:  0.6690442728361597\n",
      "Epoch:  71  Loss:  0.6525222762720659  Validation Loss:  0.6690928584861534\n",
      "Epoch:  72  Loss:  0.6524495697580278  Validation Loss:  0.6691416802781599\n",
      "Epoch:  73  Loss:  0.6523770880885422  Validation Loss:  0.6691907014421843\n",
      "Epoch:  74  Loss:  0.6523048137081787  Validation Loss:  0.6692399508837197\n",
      "Epoch:  75  Loss:  0.6522327562794089  Validation Loss:  0.6692894270850552\n",
      "Epoch:  76  Loss:  0.6521609084215015  Validation Loss:  0.6693391163178064\n",
      "Epoch:  77  Loss:  0.6520892802160233  Validation Loss:  0.6693890230661189\n",
      "Epoch:  78  Loss:  0.6520178450271488  Validation Loss:  0.6694390157720557\n",
      "Epoch:  79  Loss:  0.6519465722376481  Validation Loss:  0.6694891168563454\n",
      "Epoch:  80  Loss:  0.6518753779353574  Validation Loss:  0.6695392807876622\n",
      "Epoch:  81  Loss:  0.6518042545765639  Validation Loss:  0.6695893980838634\n",
      "Epoch:  82  Loss:  0.6517332904972136  Validation Loss:  0.6696397293083094\n",
      "Epoch:  83  Loss:  0.6516625426709652  Validation Loss:  0.6696902708046966\n",
      "Epoch:  84  Loss:  0.6515920127043501  Validation Loss:  0.6697410048434028\n",
      "Epoch:  85  Loss:  0.6515216876752674  Validation Loss:  0.6697920106213402\n",
      "Epoch:  86  Loss:  0.6514515802962706  Validation Loss:  0.6698431948682776\n",
      "Epoch:  87  Loss:  0.6513816849794238  Validation Loss:  0.6698946062889364\n",
      "Epoch:  88  Loss:  0.6513120095711201  Validation Loss:  0.6699462390884205\n",
      "Epoch:  89  Loss:  0.6512425328837708  Validation Loss:  0.669998087471834\n",
      "Epoch:  90  Loss:  0.6511732861865311  Validation Loss:  0.670050140194319\n",
      "Epoch:  91  Loss:  0.6511042384197936  Validation Loss:  0.6701024461675573\n",
      "Epoch:  92  Loss:  0.6510354191996157  Validation Loss:  0.670154947442589\n",
      "Epoch:  93  Loss:  0.6509668059879914  Validation Loss:  0.6702076660262214\n",
      "Epoch:  94  Loss:  0.6508984158048406  Validation Loss:  0.6702605912944785\n",
      "Epoch:  95  Loss:  0.6508302224799991  Validation Loss:  0.6703137579477496\n",
      "Epoch:  96  Loss:  0.6507622643839568  Validation Loss:  0.6703671407368448\n",
      "Epoch:  97  Loss:  0.650694509409368  Validation Loss:  0.6704207481471477\n",
      "Epoch:  98  Loss:  0.6506269618403167  Validation Loss:  0.6704744050900141\n",
      "Epoch:  99  Loss:  0.6505595220485703  Validation Loss:  0.6705281586144809\n",
      "Epoch:  100  Loss:  0.6504920707084239  Validation Loss:  0.6705817493989512\n",
      "Epoch:  101  Loss:  0.6504247883567587  Validation Loss:  0.6706355574920222\n",
      "Epoch:  102  Loss:  0.6503576988121494  Validation Loss:  0.6706895859291157\n",
      "Epoch:  103  Loss:  0.6502908353460952  Validation Loss:  0.6707438144280955\n",
      "Epoch:  104  Loss:  0.6502241962822154  Validation Loss:  0.670798280103891\n",
      "Epoch:  105  Loss:  0.6501577578717843  Validation Loss:  0.670852960811721\n",
      "Epoch:  106  Loss:  0.6500915439566597  Validation Loss:  0.6709078626914157\n",
      "Epoch:  107  Loss:  0.6500255377497524  Validation Loss:  0.6709630083016775\n",
      "Epoch:  108  Loss:  0.6499597545480356  Validation Loss:  0.6710183315530971\n",
      "Epoch:  109  Loss:  0.6498941838042811  Validation Loss:  0.6710738988110313\n",
      "Epoch:  110  Loss:  0.6498288294067607  Validation Loss:  0.6711296929667393\n",
      "Epoch:  111  Loss:  0.6497636806685477  Validation Loss:  0.6711857142271819\n",
      "Epoch:  112  Loss:  0.6496987566584721  Validation Loss:  0.6712419280989302\n",
      "Epoch:  113  Loss:  0.6496340365381912  Validation Loss:  0.6712982446921093\n",
      "Epoch:  114  Loss:  0.6495694599347189  Validation Loss:  0.6713546644896269\n",
      "Epoch:  115  Loss:  0.6495048501295969  Validation Loss:  0.6714108659437409\n",
      "Epoch:  116  Loss:  0.6494403858669102  Validation Loss:  0.6714672920190625\n",
      "Epoch:  117  Loss:  0.6493761347839608  Validation Loss:  0.671523963894557\n",
      "Epoch:  118  Loss:  0.649312102701515  Validation Loss:  0.6715808419717683\n",
      "Epoch:  119  Loss:  0.6492482819361612  Validation Loss:  0.6716379307348419\n",
      "Epoch:  120  Loss:  0.6491841461509467  Validation Loss:  0.6716943125206011\n",
      "Epoch:  121  Loss:  0.6491194480564445  Validation Loss:  0.671750693478518\n",
      "Epoch:  122  Loss:  0.6490548815578222  Validation Loss:  0.671807291124154\n",
      "Epoch:  123  Loss:  0.6489905352937058  Validation Loss:  0.671864131534541\n",
      "Epoch:  124  Loss:  0.6489264133386314  Validation Loss:  0.6719211699372089\n",
      "Epoch:  125  Loss:  0.6488624983932822  Validation Loss:  0.6719783803241121\n",
      "Epoch:  126  Loss:  0.6487987574422732  Validation Loss:  0.6720356541789241\n",
      "Epoch:  127  Loss:  0.6487350187031552  Validation Loss:  0.6720928506994689\n",
      "Epoch:  128  Loss:  0.6486714985687285  Validation Loss:  0.6721504397552323\n",
      "Epoch:  129  Loss:  0.648608310194686  Validation Loss:  0.6722084052722763\n",
      "Epoch:  130  Loss:  0.648545371578075  Validation Loss:  0.6722666331463389\n",
      "Epoch:  131  Loss:  0.6484826777596027  Validation Loss:  0.6723251223426174\n",
      "Epoch:  132  Loss:  0.6484202660853043  Validation Loss:  0.6723839421929033\n",
      "Epoch:  133  Loss:  0.6483581566018983  Validation Loss:  0.6724431294671915\n",
      "Epoch:  134  Loss:  0.6482963613700121  Validation Loss:  0.6725027377682703\n",
      "Epoch:  135  Loss:  0.648234828398563  Validation Loss:  0.6725624868715251\n",
      "Epoch:  136  Loss:  0.6481734716333449  Validation Loss:  0.672622366015006\n",
      "Epoch:  137  Loss:  0.6481121200602502  Validation Loss:  0.6726821505775055\n",
      "Epoch:  138  Loss:  0.648050939431414  Validation Loss:  0.6727421685915302\n",
      "Epoch:  139  Loss:  0.647990018944256  Validation Loss:  0.6728025017375195\n",
      "Epoch:  140  Loss:  0.6479293627897278  Validation Loss:  0.6728631151081236\n",
      "Epoch:  141  Loss:  0.6478689564391971  Validation Loss:  0.6729240087033422\n",
      "Epoch:  142  Loss:  0.6478088172385469  Validation Loss:  0.672985179901675\n",
      "Epoch:  143  Loss:  0.6477489362470805  Validation Loss:  0.6730466033159582\n",
      "Epoch:  144  Loss:  0.6476892721373588  Validation Loss:  0.6731080670185663\n",
      "Epoch:  145  Loss:  0.6476295390632003  Validation Loss:  0.6731693228637731\n",
      "Epoch:  146  Loss:  0.6475699632661417  Validation Loss:  0.6732307971903572\n",
      "Epoch:  147  Loss:  0.6475106284720823  Validation Loss:  0.6732925519485164\n",
      "Epoch:  148  Loss:  0.6474515041802078  Validation Loss:  0.6733544898667821\n",
      "Epoch:  149  Loss:  0.6473926218925043  Validation Loss:  0.6734166609606257\n",
      "Epoch:  150  Loss:  0.6473339674063027  Validation Loss:  0.6734790083848767\n",
      "Epoch:  151  Loss:  0.6472754845162854  Validation Loss:  0.6735413684337227\n",
      "Epoch:  152  Loss:  0.6472169452346861  Validation Loss:  0.6736035696058361\n",
      "Epoch:  153  Loss:  0.6471585605759174  Validation Loss:  0.6736659818777332\n",
      "Epoch:  154  Loss:  0.6471003947546705  Validation Loss:  0.6737286015931103\n",
      "Epoch:  155  Loss:  0.6470424595754594  Validation Loss:  0.6737914839414535\n",
      "Epoch:  156  Loss:  0.6469847194617614  Validation Loss:  0.6738543360735532\n",
      "Epoch:  157  Loss:  0.646926262951456  Validation Loss:  0.6739162161808323\n",
      "Epoch:  158  Loss:  0.6468672459479421  Validation Loss:  0.6739779137488868\n",
      "Epoch:  159  Loss:  0.6468083785613998  Validation Loss:  0.6740398582898908\n",
      "Epoch:  160  Loss:  0.6467497354838997  Validation Loss:  0.6741020197945612\n",
      "Epoch:  161  Loss:  0.6466913228156045  Validation Loss:  0.6741644162684679\n",
      "Epoch:  162  Loss:  0.6466330994153395  Validation Loss:  0.6742267820432231\n",
      "Epoch:  163  Loss:  0.646574765141122  Validation Loss:  0.6742889320270883\n",
      "Epoch:  164  Loss:  0.6465165779227391  Validation Loss:  0.6743512963531194\n",
      "Epoch:  165  Loss:  0.646458626142703  Validation Loss:  0.674413817624251\n",
      "Epoch:  166  Loss:  0.6464007733156905  Validation Loss:  0.6744761354531403\n",
      "Epoch:  167  Loss:  0.6463427259586751  Validation Loss:  0.6745382946122576\n",
      "Epoch:  168  Loss:  0.6462843740591779  Validation Loss:  0.6746000147390144\n",
      "Epoch:  169  Loss:  0.646226137666963  Validation Loss:  0.6746619332029864\n",
      "Epoch:  170  Loss:  0.646168107772246  Validation Loss:  0.6747239258968167\n",
      "Epoch:  171  Loss:  0.6461100687505678  Validation Loss:  0.6747857931035536\n",
      "Epoch:  172  Loss:  0.6460515731945634  Validation Loss:  0.6748467660336582\n",
      "Epoch:  173  Loss:  0.645992435212247  Validation Loss:  0.6749077891861951\n",
      "Epoch:  174  Loss:  0.645933460094966  Validation Loss:  0.6749687474910859\n",
      "Epoch:  175  Loss:  0.6458743818104267  Validation Loss:  0.675029524291555\n",
      "Epoch:  176  Loss:  0.6458154348889366  Validation Loss:  0.6750904959798963\n",
      "Epoch:  177  Loss:  0.6457566956523806  Validation Loss:  0.6751514607005649\n",
      "Epoch:  178  Loss:  0.6456978463567793  Validation Loss:  0.6752122153562529\n",
      "Epoch:  179  Loss:  0.645639144279994  Validation Loss:  0.6752731905629238\n",
      "Epoch:  180  Loss:  0.6455806046025827  Validation Loss:  0.6753338252504667\n",
      "Epoch:  181  Loss:  0.6455210802610963  Validation Loss:  0.6753931050361307\n",
      "Epoch:  182  Loss:  0.6454611301189288  Validation Loss:  0.6754522269108781\n",
      "Epoch:  183  Loss:  0.6454011199064553  Validation Loss:  0.67551099833239\n",
      "Epoch:  184  Loss:  0.6453411082504317  Validation Loss:  0.6755697696159283\n",
      "Epoch:  185  Loss:  0.6452812581788748  Validation Loss:  0.6756284622544492\n",
      "Epoch:  186  Loss:  0.6452209406532348  Validation Loss:  0.6756861890079798\n",
      "Epoch:  187  Loss:  0.6451597751118243  Validation Loss:  0.6757435054966697\n",
      "Epoch:  188  Loss:  0.6450984372757376  Validation Loss:  0.6758006372385554\n",
      "Epoch:  189  Loss:  0.645037246728316  Validation Loss:  0.6758577265535239\n",
      "Epoch:  190  Loss:  0.6449754679109901  Validation Loss:  0.6759137049731281\n",
      "Epoch:  191  Loss:  0.644912887061946  Validation Loss:  0.6759693094839653\n",
      "Epoch:  192  Loss:  0.644850147725083  Validation Loss:  0.6760246116254065\n",
      "Epoch:  193  Loss:  0.6447866010013967  Validation Loss:  0.6760785580371265\n",
      "Epoch:  194  Loss:  0.644722437299788  Validation Loss:  0.6761323831699513\n",
      "Epoch:  195  Loss:  0.6446577456314116  Validation Loss:  0.6761849954448365\n",
      "Epoch:  196  Loss:  0.6445919628953561  Validation Loss:  0.6762370384401746\n",
      "Epoch:  197  Loss:  0.6445254703518003  Validation Loss:  0.6762877822060276\n",
      "Epoch:  198  Loss:  0.6444579805247486  Validation Loss:  0.6763375958910695\n",
      "Epoch:  199  Loss:  0.6443892495008186  Validation Loss:  0.6763861693993762\n",
      "Epoch:  200  Loss:  0.6443192108534277  Validation Loss:  0.6764331662130577\n",
      "Epoch:  201  Loss:  0.6442475620657205  Validation Loss:  0.6764784477375172\n",
      "Epoch:  202  Loss:  0.6441740952199325  Validation Loss:  0.6765218797243304\n",
      "Epoch:  203  Loss:  0.6440985798835754  Validation Loss:  0.6765632102334941\n",
      "Epoch:  204  Loss:  0.6440206247149035  Validation Loss:  0.6766020591474242\n",
      "Epoch:  205  Loss:  0.6439398368354887  Validation Loss:  0.6766379385220783\n",
      "Epoch:  206  Loss:  0.6438556262291968  Validation Loss:  0.6766703962175934\n",
      "Epoch:  207  Loss:  0.6437675989000127  Validation Loss:  0.6766991786382817\n",
      "Epoch:  208  Loss:  0.6436751291155816  Validation Loss:  0.6767234166187269\n",
      "Epoch:  209  Loss:  0.6435776248108596  Validation Loss:  0.6767429236874536\n",
      "Epoch:  210  Loss:  0.6434745603008196  Validation Loss:  0.6767571040049747\n",
      "Epoch:  211  Loss:  0.6433656983543188  Validation Loss:  0.6767659508105781\n",
      "Epoch:  212  Loss:  0.6432513172505423  Validation Loss:  0.6767698004841805\n",
      "Epoch:  213  Loss:  0.6431319092167541  Validation Loss:  0.6767691424185479\n",
      "Epoch:  214  Loss:  0.6430082243634387  Validation Loss:  0.676764476078528\n",
      "Epoch:  215  Loss:  0.6428810885874554  Validation Loss:  0.6767561071448855\n",
      "Epoch:  216  Loss:  0.6427512258756906  Validation Loss:  0.6767443561995471\n",
      "Epoch:  217  Loss:  0.6426195241976529  Validation Loss:  0.6767304739052499\n",
      "Epoch:  218  Loss:  0.6424862414598465  Validation Loss:  0.676713873045864\n",
      "Epoch:  219  Loss:  0.6423514990834519  Validation Loss:  0.6766947453358659\n",
      "Epoch:  220  Loss:  0.6422152071027085  Validation Loss:  0.6766726101438204\n",
      "Epoch:  221  Loss:  0.642076960275881  Validation Loss:  0.6766469730409207\n",
      "Epoch:  222  Loss:  0.6419364598579704  Validation Loss:  0.6766172847538082\n",
      "Epoch:  223  Loss:  0.6417938462691382  Validation Loss:  0.6765838940110471\n",
      "Epoch:  224  Loss:  0.6416490017902106  Validation Loss:  0.6765452766859973\n",
      "Epoch:  225  Loss:  0.6415006213122979  Validation Loss:  0.6765003150535954\n",
      "Epoch:  226  Loss:  0.641348150675185  Validation Loss:  0.6764482185934428\n",
      "Epoch:  227  Loss:  0.6411916862009093  Validation Loss:  0.6763875872172691\n",
      "Epoch:  228  Loss:  0.6410295583540574  Validation Loss:  0.6763166082953965\n",
      "Epoch:  229  Loss:  0.6408605371369049  Validation Loss:  0.6762335787492769\n",
      "Epoch:  230  Loss:  0.6406834953464567  Validation Loss:  0.6761366525595939\n",
      "Epoch:  231  Loss:  0.6404978869017214  Validation Loss:  0.6760238733280588\n",
      "Epoch:  232  Loss:  0.6403015792137012  Validation Loss:  0.6758918937433649\n",
      "Epoch:  233  Loss:  0.6400929188355804  Validation Loss:  0.6757388499185994\n",
      "Epoch:  234  Loss:  0.6398710512090474  Validation Loss:  0.6755641805766909\n",
      "Epoch:  235  Loss:  0.6396357554243878  Validation Loss:  0.675369063185321\n",
      "Epoch:  236  Loss:  0.6393889625556767  Validation Loss:  0.6751561764351748\n",
      "Epoch:  237  Loss:  0.6391331208171322  Validation Loss:  0.6749295431568667\n",
      "Epoch:  238  Loss:  0.6388700198847801  Validation Loss:  0.6746923928321512\n",
      "Epoch:  239  Loss:  0.6386019699973986  Validation Loss:  0.6744489276574718\n",
      "Epoch:  240  Loss:  0.6383311614161358  Validation Loss:  0.6742016524076462\n",
      "Epoch:  241  Loss:  0.638059145421721  Validation Loss:  0.6739531598157353\n",
      "Epoch:  242  Loss:  0.6377870447002352  Validation Loss:  0.6737043265667226\n",
      "Epoch:  243  Loss:  0.6375154591165483  Validation Loss:  0.6734559137236189\n",
      "Epoch:  244  Loss:  0.6372449373127893  Validation Loss:  0.6732089408431892\n",
      "Epoch:  245  Loss:  0.6369765408802778  Validation Loss:  0.6729634059938016\n",
      "Epoch:  246  Loss:  0.6367095751455054  Validation Loss:  0.6727189896973195\n",
      "Epoch:  247  Loss:  0.6364438965218142  Validation Loss:  0.6724753550909184\n",
      "Epoch:  248  Loss:  0.6361793919932097  Validation Loss:  0.6722323784121761\n",
      "Epoch:  249  Loss:  0.6359159853542223  Validation Loss:  0.6719898662219445\n",
      "Epoch:  250  Loss:  0.635653683054261  Validation Loss:  0.6717482049845986\n",
      "Epoch:  251  Loss:  0.6353925022762269  Validation Loss:  0.6715073009469995\n",
      "Epoch:  252  Loss:  0.6351324164541439  Validation Loss:  0.6712673702449711\n",
      "Epoch:  253  Loss:  0.6348733988357708  Validation Loss:  0.6710283446505114\n",
      "Epoch:  254  Loss:  0.6346154001541435  Validation Loss:  0.6707907370119183\n",
      "Epoch:  255  Loss:  0.6343585531692952  Validation Loss:  0.6705545169749746\n",
      "Epoch:  256  Loss:  0.6341028121998533  Validation Loss:  0.6703195697455494\n",
      "Epoch:  257  Loss:  0.6338480730541051  Validation Loss:  0.6700862420515882\n",
      "Epoch:  258  Loss:  0.6335944555699825  Validation Loss:  0.6698544001965611\n",
      "Epoch:  259  Loss:  0.6333422011462971  Validation Loss:  0.6696247655760359\n",
      "Epoch:  260  Loss:  0.6330918109044432  Validation Loss:  0.6693969916000411\n",
      "Epoch:  261  Loss:  0.6328425048850477  Validation Loss:  0.6691708100476751\n",
      "Epoch:  262  Loss:  0.6325942034600303  Validation Loss:  0.6689459153071597\n",
      "Epoch:  263  Loss:  0.6323467988986522  Validation Loss:  0.6687221767173873\n",
      "Epoch:  264  Loss:  0.6321002331795171  Validation Loss:  0.6684995470913472\n",
      "Epoch:  265  Loss:  0.6318544789683074  Validation Loss:  0.6682779694458952\n",
      "Epoch:  266  Loss:  0.6316094720037654  Validation Loss:  0.668057560644768\n",
      "Epoch:  267  Loss:  0.6313653135206551  Validation Loss:  0.6678385037100978\n",
      "Epoch:  268  Loss:  0.6311219902476296  Validation Loss:  0.6676205449772102\n",
      "Epoch:  269  Loss:  0.6308789273258298  Validation Loss:  0.6674030148596676\n",
      "Epoch:  270  Loss:  0.6306364266667515  Validation Loss:  0.6671861617101563\n",
      "Epoch:  271  Loss:  0.6303946087835357  Validation Loss:  0.666970451603885\n",
      "Epoch:  272  Loss:  0.6301535412902013  Validation Loss:  0.6667556730961358\n",
      "Epoch:  273  Loss:  0.6299131641397253  Validation Loss:  0.6665415719703391\n",
      "Epoch:  274  Loss:  0.629673444852233  Validation Loss:  0.666328607334031\n",
      "Epoch:  275  Loss:  0.6294343773275614  Validation Loss:  0.6661161192589335\n",
      "Epoch:  276  Loss:  0.6291959394235164  Validation Loss:  0.6659047851269996\n",
      "Epoch:  277  Loss:  0.6289581479271874  Validation Loss:  0.6656941038176969\n",
      "Epoch:  278  Loss:  0.6287210398353636  Validation Loss:  0.6654847444345554\n",
      "Epoch:  279  Loss:  0.628484621993266  Validation Loss:  0.6652761165190626\n",
      "Epoch:  280  Loss:  0.6282488706288859  Validation Loss:  0.665068705048826\n",
      "Epoch:  281  Loss:  0.6280137587571517  Validation Loss:  0.6648617169509331\n",
      "Epoch:  282  Loss:  0.6277791803469881  Validation Loss:  0.664655581737558\n",
      "Epoch:  283  Loss:  0.6275452406378463  Validation Loss:  0.6644501770950026\n",
      "Epoch:  284  Loss:  0.627311815158464  Validation Loss:  0.6642452203151252\n",
      "Epoch:  285  Loss:  0.6270789962261916  Validation Loss:  0.6640413797426002\n",
      "Epoch:  286  Loss:  0.6268468089168892  Validation Loss:  0.6638378715487542\n",
      "Epoch:  287  Loss:  0.6266148326685652  Validation Loss:  0.6636345091931246\n",
      "Epoch:  288  Loss:  0.6263830426847562  Validation Loss:  0.6634318720963266\n",
      "Epoch:  289  Loss:  0.6261518074898049  Validation Loss:  0.6632296997639868\n",
      "Epoch:  290  Loss:  0.625921008689329  Validation Loss:  0.6630279854353931\n",
      "Epoch:  291  Loss:  0.6256909021176398  Validation Loss:  0.6628277292820038\n",
      "Epoch:  292  Loss:  0.6254622323671356  Validation Loss:  0.6626285216598599\n",
      "Epoch:  293  Loss:  0.6252343916567042  Validation Loss:  0.6624298904918962\n",
      "Epoch:  294  Loss:  0.6250070464098826  Validation Loss:  0.6622319184243679\n",
      "Epoch:  295  Loss:  0.62478031758219  Validation Loss:  0.6620348770585325\n",
      "Epoch:  296  Loss:  0.6245541612850503  Validation Loss:  0.6618382770016238\n",
      "Epoch:  297  Loss:  0.6243284304859117  Validation Loss:  0.6616421470211612\n",
      "Epoch:  298  Loss:  0.6241031549172475  Validation Loss:  0.6614464134391811\n",
      "Epoch:  299  Loss:  0.6238779625389725  Validation Loss:  0.6612510250674354\n",
      "Epoch:  300  Loss:  0.6236532007111236  Validation Loss:  0.661056079591314\n",
      "Epoch:  301  Loss:  0.6234288627514616  Validation Loss:  0.6608616255775646\n",
      "Epoch:  302  Loss:  0.6232049600919709  Validation Loss:  0.6606676411573533\n",
      "Epoch:  303  Loss:  0.6229816424194723  Validation Loss:  0.6604746263474226\n",
      "Epoch:  304  Loss:  0.6227589376037941  Validation Loss:  0.6602822087567162\n",
      "Epoch:  305  Loss:  0.6225367167964577  Validation Loss:  0.6600903147762572\n",
      "Epoch:  306  Loss:  0.6223150178324431  Validation Loss:  0.6598986965362672\n",
      "Epoch:  307  Loss:  0.6220935030607506  Validation Loss:  0.6597070838152258\n",
      "Epoch:  308  Loss:  0.621872520702891  Validation Loss:  0.6595164456715187\n",
      "Epoch:  309  Loss:  0.6216523337643594  Validation Loss:  0.659326794453793\n",
      "Epoch:  310  Loss:  0.6214330336544662  Validation Loss:  0.6591378938130759\n",
      "Epoch:  311  Loss:  0.6212143339216709  Validation Loss:  0.6589496453741083\n",
      "Epoch:  312  Loss:  0.6209961463231594  Validation Loss:  0.6587617021329977\n",
      "Epoch:  313  Loss:  0.6207779178395867  Validation Loss:  0.6585739050060511\n",
      "Epoch:  314  Loss:  0.6205601163208485  Validation Loss:  0.6583868464523995\n",
      "Epoch:  315  Loss:  0.6203429415356367  Validation Loss:  0.6582006449224772\n",
      "Epoch:  316  Loss:  0.6201262737391516  Validation Loss:  0.658014632485531\n",
      "Epoch:  317  Loss:  0.6199095172574743  Validation Loss:  0.6578285296068147\n",
      "Epoch:  318  Loss:  0.6196930506732314  Validation Loss:  0.6576429048070201\n",
      "Epoch:  319  Loss:  0.61947700639721  Validation Loss:  0.6574577275249693\n",
      "Epoch:  320  Loss:  0.6192612938350066  Validation Loss:  0.6572725350658098\n",
      "Epoch:  321  Loss:  0.6190455753356219  Validation Loss:  0.6570877072711786\n",
      "Epoch:  322  Loss:  0.6188304079230875  Validation Loss:  0.6569036882784631\n",
      "Epoch:  323  Loss:  0.6186154218390584  Validation Loss:  0.6567193874744354\n",
      "Epoch:  324  Loss:  0.6184004077920691  Validation Loss:  0.6565353971112657\n",
      "Epoch:  325  Loss:  0.6181857399642467  Validation Loss:  0.6563514676634912\n",
      "Epoch:  326  Loss:  0.6179709861287848  Validation Loss:  0.6561675962336637\n",
      "Epoch:  327  Loss:  0.6177564968820661  Validation Loss:  0.6559837045217002\n",
      "Epoch:  328  Loss:  0.617541937623173  Validation Loss:  0.6557999448505817\n",
      "Epoch:  329  Loss:  0.617327576642856  Validation Loss:  0.6556160882529285\n",
      "Epoch:  330  Loss:  0.6171133619733155  Validation Loss:  0.6554326215000065\n",
      "Epoch:  331  Loss:  0.6168991754529998  Validation Loss:  0.6552487879439637\n",
      "Epoch:  332  Loss:  0.6166847422951832  Validation Loss:  0.655064466236918\n",
      "Epoch:  333  Loss:  0.6164700082503259  Validation Loss:  0.6548796162975056\n",
      "Epoch:  334  Loss:  0.6162549161585048  Validation Loss:  0.6546943528508699\n",
      "Epoch:  335  Loss:  0.6160395127022639  Validation Loss:  0.6545085838685433\n",
      "Epoch:  336  Loss:  0.6158236138988287  Validation Loss:  0.6543220179500403\n",
      "Epoch:  337  Loss:  0.6156069735530764  Validation Loss:  0.6541342929143596\n",
      "Epoch:  338  Loss:  0.6153896019794047  Validation Loss:  0.6539455130006429\n",
      "Epoch:  339  Loss:  0.6151714256498962  Validation Loss:  0.6537557945897182\n",
      "Epoch:  340  Loss:  0.6149524018866941  Validation Loss:  0.6535649478987411\n",
      "Epoch:  341  Loss:  0.6147320621181279  Validation Loss:  0.653372315413974\n",
      "Epoch:  342  Loss:  0.6145101360045373  Validation Loss:  0.6531776251892248\n",
      "Epoch:  343  Loss:  0.6142863782122732  Validation Loss:  0.6529804139087597\n",
      "Epoch:  344  Loss:  0.6140603156993165  Validation Loss:  0.6527801008412132\n",
      "Epoch:  345  Loss:  0.6138314905343577  Validation Loss:  0.6525761921786599\n",
      "Epoch:  346  Loss:  0.6135994313284755  Validation Loss:  0.6523680402724831\n",
      "Epoch:  347  Loss:  0.613363616541028  Validation Loss:  0.6521550665299097\n",
      "Epoch:  348  Loss:  0.6131235973676666  Validation Loss:  0.651936806048508\n",
      "Epoch:  349  Loss:  0.6128791495924816  Validation Loss:  0.6517132225411909\n",
      "Epoch:  350  Loss:  0.6126304146600887  Validation Loss:  0.6514846508701643\n",
      "Epoch:  351  Loss:  0.6123778969515115  Validation Loss:  0.6512521410153972\n",
      "Epoch:  352  Loss:  0.6121224913047627  Validation Loss:  0.6510167657915089\n",
      "Epoch:  353  Loss:  0.6118650584481656  Validation Loss:  0.6507795211617593\n",
      "Epoch:  354  Loss:  0.6116065329639241  Validation Loss:  0.6505412440057154\n",
      "Epoch:  355  Loss:  0.611347487103194  Validation Loss:  0.6503027125641152\n",
      "Epoch:  356  Loss:  0.6110885781003162  Validation Loss:  0.6500645751754442\n",
      "Epoch:  357  Loss:  0.6108300446532666  Validation Loss:  0.6498269182112482\n",
      "Epoch:  358  Loss:  0.6105724071618169  Validation Loss:  0.6495906135274304\n",
      "Epoch:  359  Loss:  0.6103157076751813  Validation Loss:  0.6493550879811799\n",
      "Epoch:  360  Loss:  0.6100598643301055  Validation Loss:  0.6491208448316212\n",
      "Epoch:  361  Loss:  0.609805093659088  Validation Loss:  0.6488874446324728\n",
      "Epoch:  362  Loss:  0.6095512756612151  Validation Loss:  0.6486554912946842\n",
      "Epoch:  363  Loss:  0.6092984173679724  Validation Loss:  0.6484243006755909\n",
      "Epoch:  364  Loss:  0.6090465520974249  Validation Loss:  0.6481944943467776\n",
      "Epoch:  365  Loss:  0.6087957610609009  Validation Loss:  0.6479659335756743\n",
      "Epoch:  366  Loss:  0.6085461425594986  Validation Loss:  0.647738667756871\n",
      "Epoch:  367  Loss:  0.6082974330987782  Validation Loss:  0.6475125996878853\n",
      "Epoch:  368  Loss:  0.608049794100225  Validation Loss:  0.647287566628721\n",
      "Epoch:  369  Loss:  0.6078029022552073  Validation Loss:  0.6470632671068112\n",
      "Epoch:  370  Loss:  0.6075572720263154  Validation Loss:  0.6468408127073888\n",
      "Epoch:  371  Loss:  0.6073128677206114  Validation Loss:  0.646619024583035\n",
      "Epoch:  372  Loss:  0.6070691883098334  Validation Loss:  0.6463982663634751\n",
      "Epoch:  373  Loss:  0.6068265000125393  Validation Loss:  0.6461785627460038\n",
      "Epoch:  374  Loss:  0.6065845564007759  Validation Loss:  0.6459595416844995\n",
      "Epoch:  375  Loss:  0.6063432155642658  Validation Loss:  0.64574120366187\n",
      "Epoch:  376  Loss:  0.6061028385069221  Validation Loss:  0.6455242467561254\n",
      "Epoch:  377  Loss:  0.6058633525390178  Validation Loss:  0.645307927702864\n",
      "Epoch:  378  Loss:  0.6056244595209137  Validation Loss:  0.6450922414660454\n",
      "Epoch:  379  Loss:  0.6053862065542489  Validation Loss:  0.6448773393338477\n",
      "Epoch:  380  Loss:  0.6051488948753103  Validation Loss:  0.6446637358792402\n",
      "Epoch:  381  Loss:  0.6049124576849862  Validation Loss:  0.6444507880757252\n",
      "Epoch:  382  Loss:  0.6046766100451351  Validation Loss:  0.6442385086858714\n",
      "Epoch:  383  Loss:  0.6044414579169824  Validation Loss:  0.6440270883203657\n",
      "Epoch:  384  Loss:  0.6042070260504261  Validation Loss:  0.643816598104658\n",
      "Epoch:  385  Loss:  0.6039735929341987  Validation Loss:  0.6436075786197627\n",
      "Epoch:  386  Loss:  0.6037411051103845  Validation Loss:  0.6433991982981011\n",
      "Epoch:  387  Loss:  0.6035092220176012  Validation Loss:  0.6431914841825211\n",
      "Epoch:  388  Loss:  0.6032779419329017  Validation Loss:  0.6429844056428583\n",
      "Epoch:  389  Loss:  0.6030472556361929  Validation Loss:  0.6427780011737788\n",
      "Epoch:  390  Loss:  0.6028171800542623  Validation Loss:  0.6425722247610489\n",
      "Epoch:  391  Loss:  0.6025878290878609  Validation Loss:  0.6423674676981237\n",
      "Epoch:  392  Loss:  0.6023594154976308  Validation Loss:  0.6421637200508956\n",
      "Epoch:  393  Loss:  0.6021317509701476  Validation Loss:  0.6419606348154722\n",
      "Epoch:  394  Loss:  0.6019046939909458  Validation Loss:  0.6417581819825702\n",
      "Epoch:  395  Loss:  0.6016782352467999  Validation Loss:  0.6415563908026174\n",
      "Epoch:  396  Loss:  0.6014523790450766  Validation Loss:  0.641355220987289\n",
      "Epoch:  397  Loss:  0.6012271146290005  Validation Loss:  0.641154738832955\n",
      "Epoch:  398  Loss:  0.6010024689836427  Validation Loss:  0.640954866108519\n",
      "Epoch:  399  Loss:  0.6007784270215779  Validation Loss:  0.6407558490970621\n",
      "Epoch:  400  Loss:  0.6005552041810006  Validation Loss:  0.6405578694409795\n",
      "Epoch:  401  Loss:  0.6003329486120492  Validation Loss:  0.640361210262334\n",
      "Epoch:  402  Loss:  0.6001115932594985  Validation Loss:  0.6401652230156792\n",
      "Epoch:  403  Loss:  0.5998908365145326  Validation Loss:  0.6399698655500456\n",
      "Epoch:  404  Loss:  0.5996706729754806  Validation Loss:  0.6397751477995405\n",
      "Epoch:  405  Loss:  0.5994511097203941  Validation Loss:  0.6395810916329976\n",
      "Epoch:  406  Loss:  0.5992321546655148  Validation Loss:  0.639387653450723\n",
      "Epoch:  407  Loss:  0.5990137930260971  Validation Loss:  0.6391949042401932\n",
      "Epoch:  408  Loss:  0.5987960368394851  Validation Loss:  0.6390027541805197\n",
      "Epoch:  409  Loss:  0.5985788709018379  Validation Loss:  0.6388112795711668\n",
      "Epoch:  410  Loss:  0.5983623191481456  Validation Loss:  0.6386204397788754\n",
      "Epoch:  411  Loss:  0.5981463572941721  Validation Loss:  0.638430218729708\n",
      "Epoch:  412  Loss:  0.597931002220139  Validation Loss:  0.6382406790637307\n",
      "Epoch:  413  Loss:  0.5977162418887019  Validation Loss:  0.6380517732489992\n",
      "Epoch:  414  Loss:  0.5975020813755691  Validation Loss:  0.6378635004576709\n",
      "Epoch:  415  Loss:  0.5972887611482293  Validation Loss:  0.6376763959587725\n",
      "Epoch:  416  Loss:  0.5970762716606259  Validation Loss:  0.6374901142661218\n",
      "Epoch:  417  Loss:  0.5968644672306255  Validation Loss:  0.6373044134428104\n",
      "Epoch:  418  Loss:  0.5966531589394435  Validation Loss:  0.6371192985938655\n",
      "Epoch:  419  Loss:  0.5964424242498353  Validation Loss:  0.6369348209075354\n",
      "Epoch:  420  Loss:  0.5962322912644595  Validation Loss:  0.6367510050121281\n",
      "Epoch:  421  Loss:  0.5960227652452886  Validation Loss:  0.6365678335229555\n",
      "Epoch:  422  Loss:  0.5958138360176235  Validation Loss:  0.6363852932635281\n",
      "Epoch:  423  Loss:  0.5956055064918473  Validation Loss:  0.6362033896148205\n",
      "Epoch:  424  Loss:  0.5953977786470205  Validation Loss:  0.6360221443076929\n",
      "Epoch:  425  Loss:  0.5951906546950341  Validation Loss:  0.63584153857772\n",
      "Epoch:  426  Loss:  0.5949841237626969  Validation Loss:  0.6356615654572293\n",
      "Epoch:  427  Loss:  0.5947782142786309  Validation Loss:  0.6354822573010568\n",
      "Epoch:  428  Loss:  0.5945728887338191  Validation Loss:  0.6353035649905602\n",
      "Epoch:  429  Loss:  0.5943681678501889  Validation Loss:  0.6351255275033139\n",
      "Epoch:  430  Loss:  0.5941640546778217  Validation Loss:  0.6349481424247777\n",
      "Epoch:  431  Loss:  0.5939605348510668  Validation Loss:  0.6347713889209209\n",
      "Epoch:  432  Loss:  0.5937576215481386  Validation Loss:  0.6345952974839343\n",
      "Epoch:  433  Loss:  0.5935553228016943  Validation Loss:  0.6344198373456796\n",
      "Epoch:  434  Loss:  0.5933536117896437  Validation Loss:  0.6342450102308282\n",
      "Epoch:  435  Loss:  0.5931525102816522  Validation Loss:  0.6340708462866368\n",
      "Epoch:  436  Loss:  0.5929520157864318  Validation Loss:  0.6338973207468236\n",
      "Epoch:  437  Loss:  0.5927521171513945  Validation Loss:  0.6337244347151783\n",
      "Epoch:  438  Loss:  0.5925528274849057  Validation Loss:  0.6335522000574403\n",
      "Epoch:  439  Loss:  0.5923542720964179  Validation Loss:  0.6333808934109079\n",
      "Epoch:  440  Loss:  0.5921565549448132  Validation Loss:  0.6332105695511456\n",
      "Epoch:  441  Loss:  0.5919596054591238  Validation Loss:  0.633040945770012\n",
      "Epoch:  442  Loss:  0.5917632829165086  Validation Loss:  0.6328719452851348\n",
      "Epoch:  443  Loss:  0.5915675546973944  Validation Loss:  0.632703578306569\n",
      "Epoch:  444  Loss:  0.5913724274141714  Validation Loss:  0.6325358544924745\n",
      "Epoch:  445  Loss:  0.5911779111716896  Validation Loss:  0.6323687663922707\n",
      "Epoch:  446  Loss:  0.5909839828731492  Validation Loss:  0.6322023407728584\n",
      "Epoch:  447  Loss:  0.5907906756270677  Validation Loss:  0.6320365597666414\n",
      "Epoch:  448  Loss:  0.590597960492596  Validation Loss:  0.631871406264879\n",
      "Epoch:  449  Loss:  0.5904058550018817  Validation Loss:  0.6317069008256551\n",
      "Epoch:  450  Loss:  0.5902143648359924  Validation Loss:  0.6315430384129286\n",
      "Epoch:  451  Loss:  0.5900234507396818  Validation Loss:  0.6313798149564752\n",
      "Epoch:  452  Loss:  0.5898331613978371  Validation Loss:  0.6312172372859938\n",
      "Epoch:  453  Loss:  0.58964347273577  Validation Loss:  0.6310553067122344\n",
      "Epoch:  454  Loss:  0.5894543777219952  Validation Loss:  0.630894000676495\n",
      "Epoch:  455  Loss:  0.5892658878816291  Validation Loss:  0.630733335390687\n",
      "Epoch:  456  Loss:  0.5890780045418069  Validation Loss:  0.6305733207889177\n",
      "Epoch:  457  Loss:  0.5888908230932429  Validation Loss:  0.630414225437023\n",
      "Epoch:  458  Loss:  0.5887043850496412  Validation Loss:  0.6302560378141977\n",
      "Epoch:  459  Loss:  0.5885186074534431  Validation Loss:  0.6300986161524499\n",
      "Epoch:  460  Loss:  0.5883334785467014  Validation Loss:  0.6299420147444363\n",
      "Epoch:  461  Loss:  0.5881490201922134  Validation Loss:  0.629786192887911\n",
      "Epoch:  462  Loss:  0.5879652313655243  Validation Loss:  0.6296309948795371\n",
      "Epoch:  463  Loss:  0.5877820439636707  Validation Loss:  0.62947644803811\n",
      "Epoch:  464  Loss:  0.5875994611997157  Validation Loss:  0.629322549328208\n",
      "Epoch:  465  Loss:  0.5874174817930907  Validation Loss:  0.6291692782607343\n",
      "Epoch:  466  Loss:  0.5872361015994102  Validation Loss:  0.6290166645000378\n",
      "Epoch:  467  Loss:  0.5870553276501596  Validation Loss:  0.6288646834178103\n",
      "Epoch:  468  Loss:  0.5868751550558955  Validation Loss:  0.6287133249419706\n",
      "Epoch:  469  Loss:  0.586695590056479  Validation Loss:  0.6285626103894578\n",
      "Epoch:  470  Loss:  0.5865166269708425  Validation Loss:  0.6284125254110053\n",
      "Epoch:  471  Loss:  0.5863382724346593  Validation Loss:  0.6282631103639249\n",
      "Epoch:  472  Loss:  0.5861605136888102  Validation Loss:  0.6281143213725753\n",
      "Epoch:  473  Loss:  0.5859833621885627  Validation Loss:  0.6279661738210254\n",
      "Epoch:  474  Loss:  0.585806823335588  Validation Loss:  0.6278186546017727\n",
      "Epoch:  475  Loss:  0.5856308794347569  Validation Loss:  0.6276717989671009\n",
      "Epoch:  476  Loss:  0.5854555490193889  Validation Loss:  0.6275255675945017\n",
      "Epoch:  477  Loss:  0.5852808240335434  Validation Loss:  0.6273799760060178\n",
      "Epoch:  478  Loss:  0.5851066946284845  Validation Loss:  0.6272350200624378\n",
      "Epoch:  479  Loss:  0.5849331718869507  Validation Loss:  0.6270906887948513\n",
      "Epoch:  480  Loss:  0.5847602610709146  Validation Loss:  0.6269470166966871\n",
      "Epoch:  481  Loss:  0.5845879542408511  Validation Loss:  0.626803977690913\n",
      "Epoch:  482  Loss:  0.5844162572175264  Validation Loss:  0.6266615897830989\n",
      "Epoch:  483  Loss:  0.5842451562639326  Validation Loss:  0.6265198391068865\n",
      "Epoch:  484  Loss:  0.5840745667228475  Validation Loss:  0.6263786516393777\n",
      "Epoch:  485  Loss:  0.5839042366715148  Validation Loss:  0.6262380322096525\n",
      "Epoch:  486  Loss:  0.5837344884173945  Validation Loss:  0.6260980838840758\n",
      "Epoch:  487  Loss:  0.5835653417510912  Validation Loss:  0.6259587430567654\n",
      "Epoch:  488  Loss:  0.5833968009566888  Validation Loss:  0.6258200896834886\n",
      "Epoch:  489  Loss:  0.5832289980957285  Validation Loss:  0.6256822909883879\n",
      "Epoch:  490  Loss:  0.5830619670450687  Validation Loss:  0.6255453797402205\n",
      "Epoch:  491  Loss:  0.5828956600511447  Validation Loss:  0.6254092127912574\n",
      "Epoch:  492  Loss:  0.5827300443314016  Validation Loss:  0.6252736752783811\n",
      "Epoch:  493  Loss:  0.5825650320388377  Validation Loss:  0.6251388081107978\n",
      "Epoch:  494  Loss:  0.5824006415670737  Validation Loss:  0.6250045636875762\n",
      "Epoch:  495  Loss:  0.5822369215311483  Validation Loss:  0.624871004441822\n",
      "Epoch:  496  Loss:  0.5820738894632086  Validation Loss:  0.6247380883605392\n",
      "Epoch:  497  Loss:  0.5819115167949349  Validation Loss:  0.6246058391062198\n",
      "Epoch:  498  Loss:  0.5817497795214877  Validation Loss:  0.6244742157006705\n",
      "Epoch:  499  Loss:  0.5815887302160263  Validation Loss:  0.6243432531202281\n",
      "Epoch:  500  Loss:  0.5814283522544429  Validation Loss:  0.6242129591604074\n",
      "Epoch:  501  Loss:  0.5812686224002391  Validation Loss:  0.6240832848405397\n",
      "Epoch:  502  Loss:  0.5811095331562683  Validation Loss:  0.6239542723115947\n",
      "Epoch:  503  Loss:  0.5809510752093047  Validation Loss:  0.6238259130192024\n",
      "Epoch:  504  Loss:  0.5807932172203436  Validation Loss:  0.6236981807483567\n",
      "Epoch:  505  Loss:  0.5806359753478318  Validation Loss:  0.6235711011621687\n",
      "Epoch:  506  Loss:  0.5804793478921055  Validation Loss:  0.6234446361798931\n",
      "Epoch:  507  Loss:  0.5803233243525028  Validation Loss:  0.6233188233303802\n",
      "Epoch:  508  Loss:  0.5801679083611816  Validation Loss:  0.6231936477814559\n",
      "Epoch:  509  Loss:  0.5800131012452766  Validation Loss:  0.6230691195362144\n",
      "Epoch:  510  Loss:  0.5798589016543702  Validation Loss:  0.6229452274187848\n",
      "Epoch:  511  Loss:  0.5797053166199475  Validation Loss:  0.6228219683247583\n",
      "Epoch:  512  Loss:  0.5795523364329711  Validation Loss:  0.6226993683311675\n",
      "Epoch:  513  Loss:  0.5793999812565744  Validation Loss:  0.622577385287042\n",
      "Epoch:  514  Loss:  0.5792482205433771  Validation Loss:  0.6224560495465994\n",
      "Epoch:  515  Loss:  0.579097073734738  Validation Loss:  0.6223353557978515\n",
      "Epoch:  516  Loss:  0.5789465343113989  Validation Loss:  0.622215311008471\n",
      "Epoch:  517  Loss:  0.5787966120289638  Validation Loss:  0.6220958774426469\n",
      "Epoch:  518  Loss:  0.5786473010666668  Validation Loss:  0.621977102563337\n",
      "Epoch:  519  Loss:  0.5784985983744264  Validation Loss:  0.6218589513252178\n",
      "Epoch:  520  Loss:  0.578350510308519  Validation Loss:  0.6217414511850586\n",
      "Epoch:  521  Loss:  0.5782030271133408  Validation Loss:  0.6216245862068953\n",
      "Epoch:  522  Loss:  0.5780561571475118  Validation Loss:  0.6215083612887947\n",
      "Epoch:  523  Loss:  0.5779099046951159  Validation Loss:  0.6213927742921643\n",
      "Epoch:  524  Loss:  0.5777642495930195  Validation Loss:  0.6212778317707556\n",
      "Epoch:  525  Loss:  0.5776192203164101  Validation Loss:  0.6211635375188457\n",
      "Epoch:  526  Loss:  0.5774748023832217  Validation Loss:  0.6210498661492709\n",
      "Epoch:  527  Loss:  0.5773309860611334  Validation Loss:  0.6209368357365882\n",
      "Epoch:  528  Loss:  0.577187788579613  Validation Loss:  0.6208244497991271\n",
      "Epoch:  529  Loss:  0.5770451952470467  Validation Loss:  0.6207126885376595\n",
      "Epoch:  530  Loss:  0.5769032265990972  Validation Loss:  0.6206015998980513\n",
      "Epoch:  531  Loss:  0.5767618734156713  Validation Loss:  0.6204911235168025\n",
      "Epoch:  532  Loss:  0.5766211389098317  Validation Loss:  0.6203813115479769\n",
      "Epoch:  533  Loss:  0.5764810241525993  Validation Loss:  0.6202721260488033\n",
      "Epoch:  534  Loss:  0.5763415219029412  Validation Loss:  0.6201635951659193\n",
      "Epoch:  535  Loss:  0.576202641427517  Validation Loss:  0.6200557055158747\n",
      "Epoch:  536  Loss:  0.5760643849847839  Validation Loss:  0.6199484502689706\n",
      "Epoch:  537  Loss:  0.5759267403976992  Validation Loss:  0.6198418443263681\n",
      "Epoch:  538  Loss:  0.5757897111587227  Validation Loss:  0.6197358695445238\n",
      "Epoch:  539  Loss:  0.575653302972205  Validation Loss:  0.6196305520004697\n",
      "Epoch:  540  Loss:  0.5755175195634366  Validation Loss:  0.6195258647203445\n",
      "Epoch:  541  Loss:  0.5753823354141787  Validation Loss:  0.6194218352299046\n",
      "Epoch:  542  Loss:  0.5752477870322764  Validation Loss:  0.6193184535950422\n",
      "Epoch:  543  Loss:  0.5751138453604654  Validation Loss:  0.6192156811141305\n",
      "Epoch:  544  Loss:  0.574980523949489  Validation Loss:  0.6191135614558503\n",
      "Epoch:  545  Loss:  0.5748478229856119  Validation Loss:  0.6190120959999384\n",
      "Epoch:  546  Loss:  0.5747157349716872  Validation Loss:  0.6189112615668111\n",
      "Epoch:  547  Loss:  0.574584270012565  Validation Loss:  0.6188110618817585\n",
      "Epoch:  548  Loss:  0.5744534216122702  Validation Loss:  0.6187115139845345\n",
      "Epoch:  549  Loss:  0.5743231902131811  Validation Loss:  0.618612585865237\n",
      "Epoch:  550  Loss:  0.574193571973592  Validation Loss:  0.6185143242279688\n",
      "Epoch:  551  Loss:  0.5740645876619965  Validation Loss:  0.6184167101703308\n",
      "Epoch:  552  Loss:  0.5739362257299945  Validation Loss:  0.618319728239267\n",
      "Epoch:  553  Loss:  0.5738084920449182  Validation Loss:  0.6182233989928607\n",
      "Epoch:  554  Loss:  0.5736813650932163  Validation Loss:  0.618127726915258\n",
      "Epoch:  555  Loss:  0.5735548628494144  Validation Loss:  0.6180326621289607\n",
      "Epoch:  556  Loss:  0.5734289785381407  Validation Loss:  0.6179382625139422\n",
      "Epoch:  557  Loss:  0.5733037143945694  Validation Loss:  0.6178444955084059\n",
      "Epoch:  558  Loss:  0.5731790740508587  Validation Loss:  0.617751365803458\n",
      "Epoch:  559  Loss:  0.5730550511740148  Validation Loss:  0.6176588990622096\n",
      "Epoch:  560  Loss:  0.5729316436918452  Validation Loss:  0.6175670371287398\n",
      "Epoch:  561  Loss:  0.5728088560746982  Validation Loss:  0.6174758458854975\n",
      "Epoch:  562  Loss:  0.572686693072319  Validation Loss:  0.6173852857340265\n",
      "Epoch:  563  Loss:  0.5725651463028043  Validation Loss:  0.6172953761976074\n",
      "Epoch:  564  Loss:  0.5724442225880921  Validation Loss:  0.6172061049275928\n",
      "Epoch:  565  Loss:  0.5723239215789363  Validation Loss:  0.6171174572297821\n",
      "Epoch:  566  Loss:  0.572204236104153  Validation Loss:  0.6170294598020889\n",
      "Epoch:  567  Loss:  0.5720851904712617  Validation Loss:  0.6169421259589769\n",
      "Epoch:  568  Loss:  0.5719667446333915  Validation Loss:  0.6168554007869076\n",
      "Epoch:  569  Loss:  0.5718488821294159  Validation Loss:  0.6167691623171171\n",
      "Epoch:  570  Loss:  0.5717314953217283  Validation Loss:  0.6166835711510094\n",
      "Epoch:  571  Loss:  0.5716146816732361  Validation Loss:  0.6165985502302647\n",
      "Epoch:  572  Loss:  0.5714984436985105  Validation Loss:  0.6165141368767729\n",
      "Epoch:  573  Loss:  0.5713827644707635  Validation Loss:  0.6164302916990386\n",
      "Epoch:  574  Loss:  0.5712676849681884  Validation Loss:  0.6163470682998499\n",
      "Epoch:  575  Loss:  0.5711532281478867  Validation Loss:  0.6162645203509817\n",
      "Epoch:  576  Loss:  0.5710394046967849  Validation Loss:  0.6161825976300018\n",
      "Epoch:  577  Loss:  0.5709262117743492  Validation Loss:  0.6161013295942986\n",
      "Epoch:  578  Loss:  0.5708136497996747  Validation Loss:  0.6160207078274753\n",
      "Epoch:  579  Loss:  0.5707017116015777  Validation Loss:  0.6159407261207148\n",
      "Epoch:  580  Loss:  0.570590389193967  Validation Loss:  0.6158613799898712\n",
      "Epoch:  581  Loss:  0.570479702972807  Validation Loss:  0.615782667434326\n",
      "Epoch:  582  Loss:  0.5703696475131437  Validation Loss:  0.615704616393756\n",
      "Epoch:  583  Loss:  0.5702602102421224  Validation Loss:  0.6156272027917482\n",
      "Epoch:  584  Loss:  0.5701513920910657  Validation Loss:  0.6155504232479466\n",
      "Epoch:  585  Loss:  0.5700432048179209  Validation Loss:  0.6154742814186547\n",
      "Epoch:  586  Loss:  0.5699356333585456  Validation Loss:  0.615398792411994\n",
      "Epoch:  587  Loss:  0.5698286958504468  Validation Loss:  0.6153239475356208\n",
      "Epoch:  588  Loss:  0.5697223572758958  Validation Loss:  0.6152497254036091\n",
      "Epoch:  589  Loss:  0.569616689090617  Validation Loss:  0.6151762538486056\n",
      "Epoch:  590  Loss:  0.5695116664748638  Validation Loss:  0.6151035599824455\n",
      "Epoch:  591  Loss:  0.569407338812016  Validation Loss:  0.6150316862320458\n",
      "Epoch:  592  Loss:  0.5693036749493331  Validation Loss:  0.6149605025571806\n",
      "Epoch:  593  Loss:  0.5692006674362347  Validation Loss:  0.614890064354296\n",
      "Epoch:  594  Loss:  0.5690983598819003  Validation Loss:  0.6148204509582784\n",
      "Epoch:  595  Loss:  0.5689968336839228  Validation Loss:  0.6147515779292142\n",
      "Epoch:  596  Loss:  0.5688960450468585  Validation Loss:  0.6146834554771582\n",
      "Epoch:  597  Loss:  0.5687959706643596  Validation Loss:  0.6146160818774391\n",
      "Epoch:  598  Loss:  0.5686965660424903  Validation Loss:  0.6145493471650062\n",
      "Epoch:  599  Loss:  0.5685977685730904  Validation Loss:  0.6144832426475154\n",
      "Epoch:  600  Loss:  0.5684995902702212  Validation Loss:  0.6144177628060182\n",
      "Epoch:  601  Loss:  0.5684020396787673  Validation Loss:  0.6143529286125192\n",
      "Epoch:  602  Loss:  0.5683051065541804  Validation Loss:  0.6142887222684092\n",
      "Epoch:  603  Loss:  0.5682087912689895  Validation Loss:  0.6142251657115089\n",
      "Epoch:  604  Loss:  0.5681130898417905  Validation Loss:  0.6141622113408866\n",
      "Epoch:  605  Loss:  0.5680180186405778  Validation Loss:  0.6140999289022552\n",
      "Epoch:  606  Loss:  0.5679235631134361  Validation Loss:  0.6140382546517584\n",
      "Epoch:  607  Loss:  0.5678297252394259  Validation Loss:  0.6139772257733124\n",
      "Epoch:  608  Loss:  0.5677365130512044  Validation Loss:  0.6139168248132423\n",
      "Epoch:  609  Loss:  0.5676439147209749  Validation Loss:  0.6138570606018658\n",
      "Epoch:  610  Loss:  0.5675519437063485  Validation Loss:  0.6137979305176823\n",
      "Epoch:  611  Loss:  0.567460587550886  Validation Loss:  0.6137394233158341\n",
      "Epoch:  612  Loss:  0.5673698457889259  Validation Loss:  0.6136815679018144\n",
      "Epoch:  613  Loss:  0.5672797365812585  Validation Loss:  0.613624348960541\n",
      "Epoch:  614  Loss:  0.5671902422793209  Validation Loss:  0.6135677577306827\n",
      "Epoch:  615  Loss:  0.5671013633022085  Validation Loss:  0.6135117845540797\n",
      "Epoch:  616  Loss:  0.5670131121994928  Validation Loss:  0.6134564792392431\n",
      "Epoch:  617  Loss:  0.5669254899956286  Validation Loss:  0.6134017831473438\n",
      "Epoch:  618  Loss:  0.5668384812539443  Validation Loss:  0.6133477162845709\n",
      "Epoch:  619  Loss:  0.5667520906310528  Validation Loss:  0.6132942827901354\n",
      "Epoch:  620  Loss:  0.5666663232957945  Validation Loss:  0.6132414985310148\n",
      "Epoch:  621  Loss:  0.5665811799699441  Validation Loss:  0.613189339361809\n",
      "Epoch:  622  Loss:  0.566496661468409  Validation Loss:  0.6131378176311651\n",
      "Epoch:  623  Loss:  0.5664127585710957  Validation Loss:  0.6130869398238482\n",
      "Epoch:  624  Loss:  0.5663294808240608  Validation Loss:  0.6130366719983242\n",
      "Epoch:  625  Loss:  0.5662468320922927  Validation Loss:  0.6129870620314721\n",
      "Epoch:  626  Loss:  0.5661647936562076  Validation Loss:  0.6129379809868557\n",
      "Epoch:  627  Loss:  0.5660833216272294  Validation Loss:  0.6128892021736613\n",
      "Epoch:  628  Loss:  0.5660023426637053  Validation Loss:  0.6128409816711037\n",
      "Epoch:  629  Loss:  0.565921916696243  Validation Loss:  0.612793261875157\n",
      "Epoch:  630  Loss:  0.5658419797895476  Validation Loss:  0.6127458892210766\n",
      "Epoch:  631  Loss:  0.5657625930383802  Validation Loss:  0.6126989818833493\n",
      "Epoch:  632  Loss:  0.5656838189810515  Validation Loss:  0.612652727023319\n",
      "Epoch:  633  Loss:  0.5656056714942679  Validation Loss:  0.6126070935968999\n",
      "Epoch:  634  Loss:  0.5655281441751867  Validation Loss:  0.6125621016792677\n",
      "Epoch:  635  Loss:  0.5654512457083911  Validation Loss:  0.6125177486489216\n",
      "Epoch:  636  Loss:  0.5653749766992405  Validation Loss:  0.6124740238128988\n",
      "Epoch:  637  Loss:  0.5652993299067021  Validation Loss:  0.6124309584222458\n",
      "Epoch:  638  Loss:  0.565224323165603  Validation Loss:  0.6123885086703079\n",
      "Epoch:  639  Loss:  0.5651499291416258  Validation Loss:  0.6123466949771952\n",
      "Epoch:  640  Loss:  0.5650761608732864  Validation Loss:  0.6123055254143698\n",
      "Epoch:  641  Loss:  0.5650030171032995  Validation Loss:  0.61226497169722\n",
      "Epoch:  642  Loss:  0.5649304433725775  Validation Loss:  0.6122249073038498\n",
      "Epoch:  643  Loss:  0.5648583240108564  Validation Loss:  0.6121853514815923\n",
      "Epoch:  644  Loss:  0.5647867151070386  Validation Loss:  0.6121463830134383\n",
      "Epoch:  645  Loss:  0.5647154837613926  Validation Loss:  0.612107836054983\n",
      "Epoch:  646  Loss:  0.5646448856219649  Validation Loss:  0.6120699989023032\n",
      "Epoch:  647  Loss:  0.5645749839255586  Validation Loss:  0.6120329239854106\n",
      "Epoch:  648  Loss:  0.5645057577174157  Validation Loss:  0.6119965150676392\n",
      "Epoch:  649  Loss:  0.5644371862523258  Validation Loss:  0.6119607922241643\n",
      "Epoch:  650  Loss:  0.5643692152807489  Validation Loss:  0.6119255667759312\n",
      "Epoch:  651  Loss:  0.5643017247552052  Validation Loss:  0.6118909767656414\n",
      "Epoch:  652  Loss:  0.5642347671091557  Validation Loss:  0.6118569068472695\n",
      "Epoch:  653  Loss:  0.5641683880472556  Validation Loss:  0.6118234563618898\n",
      "Epoch:  654  Loss:  0.5641026429831981  Validation Loss:  0.6117906362094261\n",
      "Epoch:  655  Loss:  0.564037525258027  Validation Loss:  0.6117584279014004\n",
      "Epoch:  656  Loss:  0.5639730313327164  Validation Loss:  0.611726861861017\n",
      "Epoch:  657  Loss:  0.5639091615797952  Validation Loss:  0.6116959470565673\n",
      "Epoch:  658  Loss:  0.5638459209352732  Validation Loss:  0.6116656507882807\n",
      "Epoch:  659  Loss:  0.563783306768164  Validation Loss:  0.6116359973395312\n",
      "Epoch:  660  Loss:  0.563721320242621  Validation Loss:  0.6116069676699462\n",
      "Epoch:  661  Loss:  0.5636599553283304  Validation Loss:  0.6115785519144049\n",
      "Epoch:  662  Loss:  0.5635992269264534  Validation Loss:  0.6115507822207831\n",
      "Epoch:  663  Loss:  0.5635391153628007  Validation Loss:  0.6115236564504879\n",
      "Epoch:  664  Loss:  0.5634796431753785  Validation Loss:  0.6114971588745162\n",
      "Epoch:  665  Loss:  0.5634207832859829  Validation Loss:  0.611471275281575\n",
      "Epoch:  666  Loss:  0.563362557743676  Validation Loss:  0.6114460355429737\n",
      "Epoch:  667  Loss:  0.5633049622643739  Validation Loss:  0.6114214249645118\n",
      "Epoch:  668  Loss:  0.5632479971740395  Validation Loss:  0.6113974476164138\n",
      "Epoch:  669  Loss:  0.5631916536018252  Validation Loss:  0.6113741155713797\n",
      "Epoch:  670  Loss:  0.5631359366001562  Validation Loss:  0.6113514003378374\n",
      "Epoch:  671  Loss:  0.5630808504996822  Validation Loss:  0.611329314885316\n",
      "Epoch:  672  Loss:  0.5630263940896839  Validation Loss:  0.6113077099952433\n",
      "Epoch:  673  Loss:  0.5629724929807708  Validation Loss:  0.6112864745987786\n",
      "Epoch:  674  Loss:  0.5629190669162198  Validation Loss:  0.6112656707840937\n",
      "Epoch:  675  Loss:  0.5628660907270386  Validation Loss:  0.6112450741369415\n",
      "Epoch:  676  Loss:  0.5628137194085866  Validation Loss:  0.6112251377630012\n",
      "Epoch:  677  Loss:  0.5627619844628498  Validation Loss:  0.6112058299973055\n",
      "Epoch:  678  Loss:  0.5627108843065798  Validation Loss:  0.6111871559448816\n",
      "Epoch:  679  Loss:  0.5626603975426405  Validation Loss:  0.6111691074652804\n",
      "Epoch:  680  Loss:  0.5626105488510802  Validation Loss:  0.6111517027020454\n",
      "Epoch:  681  Loss:  0.562561339745298  Validation Loss:  0.611134920200264\n",
      "Epoch:  682  Loss:  0.5625127595616505  Validation Loss:  0.6111187768617162\n",
      "Epoch:  683  Loss:  0.5624647686490789  Validation Loss:  0.6111031029787328\n",
      "Epoch:  684  Loss:  0.562417201185599  Validation Loss:  0.6110879834051486\n",
      "Epoch:  685  Loss:  0.5623701501404866  Validation Loss:  0.6110733736444403\n",
      "Epoch:  686  Loss:  0.562323687132448  Validation Loss:  0.6110593811091449\n",
      "Epoch:  687  Loss:  0.5622778634075075  Validation Loss:  0.6110460200105552\n",
      "Epoch:  688  Loss:  0.5622326739365235  Validation Loss:  0.6110333093200568\n",
      "Epoch:  689  Loss:  0.562188112968579  Validation Loss:  0.611021230135251\n",
      "Epoch:  690  Loss:  0.5621441884897649  Validation Loss:  0.6110097849396644\n",
      "Epoch:  691  Loss:  0.5621008832473308  Validation Loss:  0.6109985449109916\n",
      "Epoch:  692  Loss:  0.5620580087183044  Validation Loss:  0.610987748398825\n",
      "Epoch:  693  Loss:  0.5620156018296256  Validation Loss:  0.6109771744382603\n",
      "Epoch:  694  Loss:  0.5619738097069785  Validation Loss:  0.6109672713748835\n",
      "Epoch:  695  Loss:  0.5619326477637514  Validation Loss:  0.6109579951950798\n",
      "Epoch:  696  Loss:  0.5618921248940751  Validation Loss:  0.6109493474855467\n",
      "Epoch:  697  Loss:  0.561852247430943  Validation Loss:  0.6109413564619091\n",
      "Epoch:  698  Loss:  0.5618130011716858  Validation Loss:  0.6109339776276438\n",
      "Epoch:  699  Loss:  0.561774380505085  Validation Loss:  0.6109272336104402\n",
      "Epoch:  700  Loss:  0.5617364070611075  Validation Loss:  0.6109210883301718\n",
      "Epoch:  701  Loss:  0.5616989886853844  Validation Loss:  0.6109149909267823\n",
      "Epoch:  702  Loss:  0.5616616622311994  Validation Loss:  0.610908889591142\n",
      "Epoch:  703  Loss:  0.5616248309146613  Validation Loss:  0.6109033273877921\n",
      "Epoch:  704  Loss:  0.5615886183222756  Validation Loss:  0.6108984171792313\n",
      "Epoch:  705  Loss:  0.5615530349314213  Validation Loss:  0.6108941471687069\n",
      "Epoch:  706  Loss:  0.5615181046072394  Validation Loss:  0.6108905216334043\n",
      "Epoch:  707  Loss:  0.5614838019246235  Validation Loss:  0.6108870597349273\n",
      "Epoch:  708  Loss:  0.5614498144248501  Validation Loss:  0.6108837457442725\n",
      "Epoch:  709  Loss:  0.5614164165686816  Validation Loss:  0.6108810388379626\n",
      "Epoch:  710  Loss:  0.5613836623961106  Validation Loss:  0.6108789707499521\n",
      "Epoch:  711  Loss:  0.5613515506265685  Validation Loss:  0.6108771510146283\n",
      "Epoch:  712  Loss:  0.5613197334809229  Validation Loss:  0.6108752287648342\n",
      "Epoch:  713  Loss:  0.5612883369205519  Validation Loss:  0.610873907390568\n",
      "Epoch:  714  Loss:  0.561257409118116  Validation Loss:  0.6108726699043203\n",
      "Epoch:  715  Loss:  0.5612267985241488  Validation Loss:  0.6108715005770877\n",
      "Epoch:  716  Loss:  0.561196769401431  Validation Loss:  0.6108707916681413\n",
      "Epoch:  717  Loss:  0.5611672818195075  Validation Loss:  0.6108703304220129\n",
      "Epoch:  718  Loss:  0.5611382045550272  Validation Loss:  0.6108698973225223\n",
      "Epoch:  719  Loss:  0.5611095948610455  Validation Loss:  0.6108696437268345\n",
      "Epoch:  720  Loss:  0.5610814053798094  Validation Loss:  0.6108691842743644\n",
      "Epoch:  721  Loss:  0.5610532413702458  Validation Loss:  0.610868279442743\n",
      "Epoch:  722  Loss:  0.5610253351507708  Validation Loss:  0.6108671730315244\n",
      "Epoch:  723  Loss:  0.5609977715881541  Validation Loss:  0.610865753971868\n",
      "Epoch:  724  Loss:  0.5609704939415678  Validation Loss:  0.6108638889811657\n",
      "Epoch:  725  Loss:  0.5609434494748712  Validation Loss:  0.6108616056541601\n",
      "Epoch:  726  Loss:  0.5609166060108691  Validation Loss:  0.6108583011836918\n",
      "Epoch:  727  Loss:  0.5608894794946536  Validation Loss:  0.610853701002068\n",
      "Epoch:  728  Loss:  0.5608622815925628  Validation Loss:  0.6108477853790477\n",
      "Epoch:  729  Loss:  0.5608349750516937  Validation Loss:  0.6108401279758524\n",
      "Epoch:  730  Loss:  0.5608073831303045  Validation Loss:  0.610830285206989\n",
      "Epoch:  731  Loss:  0.5607790865469724  Validation Loss:  0.6108176989687814\n",
      "Epoch:  732  Loss:  0.5607502387138084  Validation Loss:  0.6108025661497204\n",
      "Epoch:  733  Loss:  0.5607208750676363  Validation Loss:  0.6107846005923219\n",
      "Epoch:  734  Loss:  0.5606909211492166  Validation Loss:  0.6107639875952844\n",
      "Epoch:  735  Loss:  0.5606602787738666  Validation Loss:  0.6107409779948217\n",
      "Epoch:  736  Loss:  0.5606293530901894  Validation Loss:  0.6107163633461352\n",
      "Epoch:  737  Loss:  0.5605982459150255  Validation Loss:  0.6106904378091847\n",
      "Epoch:  738  Loss:  0.5605672224424779  Validation Loss:  0.6106641669240263\n",
      "Epoch:  739  Loss:  0.5605366143165156  Validation Loss:  0.6106380225607643\n",
      "Epoch:  740  Loss:  0.5605063216527923  Validation Loss:  0.6106121017149201\n",
      "Epoch:  741  Loss:  0.560476708621718  Validation Loss:  0.6105867529080974\n",
      "Epoch:  742  Loss:  0.5604475719854236  Validation Loss:  0.6105619499252902\n",
      "Epoch:  743  Loss:  0.5604189522331581  Validation Loss:  0.610537685315918\n",
      "Epoch:  744  Loss:  0.5603910431498662  Validation Loss:  0.6105143361621432\n",
      "Epoch:  745  Loss:  0.5603636838961392  Validation Loss:  0.6104920024949091\n",
      "Epoch:  746  Loss:  0.5603368749609217  Validation Loss:  0.6104700501870226\n",
      "Epoch:  747  Loss:  0.5603105132002384  Validation Loss:  0.610448621765331\n",
      "Epoch:  748  Loss:  0.5602846622467041  Validation Loss:  0.6104282699525356\n",
      "Epoch:  749  Loss:  0.5602593471528963  Validation Loss:  0.6104084723801525\n",
      "Epoch:  750  Loss:  0.5602344332262874  Validation Loss:  0.6103889422008285\n",
      "Epoch:  751  Loss:  0.5602097171358764  Validation Loss:  0.6103697399850245\n",
      "Epoch:  752  Loss:  0.5601852353662252  Validation Loss:  0.610351346295189\n",
      "Epoch:  753  Loss:  0.5601609682664275  Validation Loss:  0.6103330338718714\n",
      "Epoch:  754  Loss:  0.5601366456365213  Validation Loss:  0.6103146462528793\n",
      "Epoch:  755  Loss:  0.560112145775929  Validation Loss:  0.610296009177411\n",
      "Epoch:  756  Loss:  0.5600873125484214  Validation Loss:  0.6102771176784126\n",
      "Epoch:  757  Loss:  0.5600619918201118  Validation Loss:  0.6102581849252736\n",
      "Epoch:  758  Loss:  0.560035990527831  Validation Loss:  0.610238561199771\n",
      "Epoch:  759  Loss:  0.5600089718587696  Validation Loss:  0.6102178007088326\n",
      "Epoch:  760  Loss:  0.5599805726436898  Validation Loss:  0.6101956195025532\n",
      "Epoch:  761  Loss:  0.5599505233345553  Validation Loss:  0.6101717267323423\n",
      "Epoch:  762  Loss:  0.5599185657920316  Validation Loss:  0.610146015468571\n",
      "Epoch:  763  Loss:  0.5598846550332383  Validation Loss:  0.6101185079250071\n",
      "Epoch:  764  Loss:  0.559848917927593  Validation Loss:  0.6100897547547464\n",
      "Epoch:  765  Loss:  0.5598116611363366  Validation Loss:  0.610060051911407\n",
      "Epoch:  766  Loss:  0.5597733774920925  Validation Loss:  0.6100295192941472\n",
      "Epoch:  767  Loss:  0.5597345573129132  Validation Loss:  0.6099987264584612\n",
      "Epoch:  768  Loss:  0.5596955648623407  Validation Loss:  0.6099679784642326\n",
      "Epoch:  769  Loss:  0.5596569193061441  Validation Loss:  0.6099376761251025\n",
      "Epoch:  770  Loss:  0.5596188887022435  Validation Loss:  0.6099081211895855\n",
      "Epoch:  771  Loss:  0.559581691166386  Validation Loss:  0.6098793976836734\n",
      "Epoch:  772  Loss:  0.5595454325433821  Validation Loss:  0.609851669382166\n",
      "Epoch:  773  Loss:  0.5595102148596197  Validation Loss:  0.6098248301832764\n",
      "Epoch:  774  Loss:  0.5594760212348774  Validation Loss:  0.6097990973956056\n",
      "Epoch:  775  Loss:  0.559442953648977  Validation Loss:  0.6097744768140493\n",
      "Epoch:  776  Loss:  0.5594110242789612  Validation Loss:  0.6097513649750639\n",
      "Epoch:  777  Loss:  0.5593802386894822  Validation Loss:  0.6097295095247252\n",
      "Epoch:  778  Loss:  0.5593506111530587  Validation Loss:  0.6097086876354836\n",
      "Epoch:  779  Loss:  0.5593220417387783  Validation Loss:  0.6096888802669667\n",
      "Epoch:  780  Loss:  0.5592945498414338  Validation Loss:  0.6096700551333251\n",
      "Epoch:  781  Loss:  0.5592680383706465  Validation Loss:  0.6096522097510321\n",
      "Epoch:  782  Loss:  0.5592426079325378  Validation Loss:  0.6096353521225629\n",
      "Epoch:  783  Loss:  0.5592181168496608  Validation Loss:  0.6096193383413332\n",
      "Epoch:  784  Loss:  0.5591946389758959  Validation Loss:  0.6096044283498216\n",
      "Epoch:  785  Loss:  0.5591721704695374  Validation Loss:  0.6095903365424385\n",
      "Epoch:  786  Loss:  0.5591506480006501  Validation Loss:  0.6095772515292521\n",
      "Epoch:  787  Loss:  0.5591301858425141  Validation Loss:  0.6095651189486185\n",
      "Epoch:  788  Loss:  0.5591106294188648  Validation Loss:  0.6095537991711387\n",
      "Epoch:  789  Loss:  0.5590919719776138  Validation Loss:  0.6095433443508766\n",
      "Epoch:  790  Loss:  0.5590743172680959  Validation Loss:  0.6095339796609349\n",
      "Epoch:  791  Loss:  0.5590576614020393  Validation Loss:  0.6095254188058553\n",
      "Epoch:  792  Loss:  0.5590418517123907  Validation Loss:  0.6095176514376093\n",
      "Epoch:  793  Loss:  0.5590269463602453  Validation Loss:  0.6095107480607651\n",
      "Epoch:  794  Loss:  0.5590130299096927  Validation Loss:  0.609504958131799\n",
      "Epoch:  795  Loss:  0.5590001267381013  Validation Loss:  0.6094999470644527\n",
      "Epoch:  796  Loss:  0.558988067600876  Validation Loss:  0.6094957828797676\n",
      "Epoch:  797  Loss:  0.5589768836041913  Validation Loss:  0.6094925313912056\n",
      "Epoch:  798  Loss:  0.5589666419662536  Validation Loss:  0.6094904450906647\n",
      "Epoch:  799  Loss:  0.5589574222220108  Validation Loss:  0.6094895260477508\n",
      "Epoch:  800  Loss:  0.5589492319617421  Validation Loss:  0.6094896849934701\n",
      "Epoch:  801  Loss:  0.5589419541647658  Validation Loss:  0.6094906487398677\n",
      "Epoch:  802  Loss:  0.5589355204021558  Validation Loss:  0.6094924068009412\n",
      "Epoch:  803  Loss:  0.5589299284853041  Validation Loss:  0.6094949612462962\n",
      "Epoch:  804  Loss:  0.5589251697529107  Validation Loss:  0.6094983068329317\n",
      "Epoch:  805  Loss:  0.5589213249273598  Validation Loss:  0.6095025393146055\n",
      "Epoch:  806  Loss:  0.5589184514479711  Validation Loss:  0.6095078203965116\n",
      "Epoch:  807  Loss:  0.5589165732963011  Validation Loss:  0.6095138926196981\n",
      "Epoch:  808  Loss:  0.558915524603799  Validation Loss:  0.6095207621929822\n",
      "Epoch:  809  Loss:  0.5589153018081561  Validation Loss:  0.6095283278436573\n",
      "Epoch:  810  Loss:  0.5589157282374799  Validation Loss:  0.6095364306260038\n",
      "Epoch:  811  Loss:  0.5589165038894862  Validation Loss:  0.6095451195206907\n",
      "Epoch:  812  Loss:  0.558918023086153  Validation Loss:  0.6095546990357064\n",
      "Epoch:  813  Loss:  0.5589203551411629  Validation Loss:  0.6095650949411922\n",
      "Epoch:  814  Loss:  0.5589235136052594  Validation Loss:  0.609576326691442\n",
      "Epoch:  815  Loss:  0.5589276073500514  Validation Loss:  0.6095885507486485\n",
      "Epoch:  816  Loss:  0.5589326636865735  Validation Loss:  0.609601732481409\n",
      "Epoch:  817  Loss:  0.5589386112987995  Validation Loss:  0.6096157232920328\n",
      "Epoch:  818  Loss:  0.5589453705819324  Validation Loss:  0.609630513108439\n",
      "Epoch:  819  Loss:  0.5589529455639421  Validation Loss:  0.6096461008268373\n",
      "Epoch:  820  Loss:  0.5589613680494949  Validation Loss:  0.6096624745814888\n",
      "Epoch:  821  Loss:  0.5589706162456423  Validation Loss:  0.609679647065975\n",
      "Epoch:  822  Loss:  0.5589806917589157  Validation Loss:  0.6096975777160238\n",
      "Epoch:  823  Loss:  0.5589916052762419  Validation Loss:  0.6097163279299382\n",
      "Epoch:  824  Loss:  0.5590033442946151  Validation Loss:  0.6097358608687365\n",
      "Epoch:  825  Loss:  0.5590159246930853  Validation Loss:  0.6097561591477306\n",
      "Epoch:  826  Loss:  0.5590293332468719  Validation Loss:  0.609777247602189\n",
      "Epoch:  827  Loss:  0.5590435677208007  Validation Loss:  0.6097991149182673\n",
      "Epoch:  828  Loss:  0.559058629674837  Validation Loss:  0.6098217561289117\n",
      "Epoch:  829  Loss:  0.5590745917987079  Validation Loss:  0.6098452620208263\n",
      "Epoch:  830  Loss:  0.559091477189213  Validation Loss:  0.609869765324725\n",
      "Epoch:  831  Loss:  0.5591093403054401  Validation Loss:  0.6098950721875385\n",
      "Epoch:  832  Loss:  0.5591280524618923  Validation Loss:  0.6099211903357947\n",
      "Epoch:  833  Loss:  0.5591476036002859  Validation Loss:  0.6099480866558022\n",
      "Epoch:  834  Loss:  0.5591679763048887  Validation Loss:  0.609975743210978\n",
      "Epoch:  835  Loss:  0.5591891833115369  Validation Loss:  0.6100041893897233\n",
      "Epoch:  836  Loss:  0.5592112114885822  Validation Loss:  0.6100334140161673\n",
      "Epoch:  837  Loss:  0.5592340725939721  Validation Loss:  0.6100634285421284\n",
      "Epoch:  838  Loss:  0.5592577553819865  Validation Loss:  0.6100942146171022\n",
      "Epoch:  839  Loss:  0.5592822720995173  Validation Loss:  0.610125772792984\n",
      "Epoch:  840  Loss:  0.5593076080316678  Validation Loss:  0.6101581032077471\n",
      "Epoch:  841  Loss:  0.5593337685335428  Validation Loss:  0.6101912542901657\n",
      "Epoch:  842  Loss:  0.5593607666669413  Validation Loss:  0.6102251375990885\n",
      "Epoch:  843  Loss:  0.5593885786132887  Validation Loss:  0.6102598110834757\n",
      "Epoch:  844  Loss:  0.559417152008973  Validation Loss:  0.6102949556101251\n",
      "Epoch:  845  Loss:  0.5594459825428203  Validation Loss:  0.6103305411007669\n",
      "Epoch:  846  Loss:  0.5594755491241813  Validation Loss:  0.610366926011112\n",
      "Epoch:  847  Loss:  0.5595059397397563  Validation Loss:  0.6104040736401523\n",
      "Epoch:  848  Loss:  0.5595371599076315  Validation Loss:  0.6104419641196728\n",
      "Epoch:  849  Loss:  0.5595691933762282  Validation Loss:  0.6104806425670782\n",
      "Epoch:  850  Loss:  0.5596020573517307  Validation Loss:  0.6105201066368156\n",
      "Epoch:  851  Loss:  0.5596357502508909  Validation Loss:  0.6105603188000344\n",
      "Epoch:  852  Loss:  0.5596702508861199  Validation Loss:  0.6106013080312146\n",
      "Epoch:  853  Loss:  0.5597056300612167  Validation Loss:  0.6106431793283533\n",
      "Epoch:  854  Loss:  0.5597418909426779  Validation Loss:  0.610685927586423\n",
      "Epoch:  855  Loss:  0.5597790802363306  Validation Loss:  0.6107297407256232\n",
      "Epoch:  856  Loss:  0.5598172096302733  Validation Loss:  0.6107746965631291\n",
      "Epoch:  857  Loss:  0.5598562545375898  Validation Loss:  0.6108206975515242\n",
      "Epoch:  858  Loss:  0.5598961559589952  Validation Loss:  0.610867501133018\n",
      "Epoch:  859  Loss:  0.5599368118913844  Validation Loss:  0.610914849848659\n",
      "Epoch:  860  Loss:  0.5599777237512171  Validation Loss:  0.6109627632907143\n",
      "Epoch:  861  Loss:  0.5600193684920669  Validation Loss:  0.6110114836030536\n",
      "Epoch:  862  Loss:  0.5600618525641039  Validation Loss:  0.6110609480076366\n",
      "Epoch:  863  Loss:  0.5601051468634978  Validation Loss:  0.6111111945852086\n",
      "Epoch:  864  Loss:  0.5601492600049823  Validation Loss:  0.6111622243015854\n",
      "Epoch:  865  Loss:  0.5601941922446713  Validation Loss:  0.6112140134252884\n",
      "Epoch:  866  Loss:  0.5602399282623083  Validation Loss:  0.6112665666474236\n",
      "Epoch:  867  Loss:  0.5602864923421293  Validation Loss:  0.6113198653415397\n",
      "Epoch:  868  Loss:  0.560333680268377  Validation Loss:  0.6113734453640602\n",
      "Epoch:  869  Loss:  0.5603811563225463  Validation Loss:  0.6114276363341896\n",
      "Epoch:  870  Loss:  0.560429418948479  Validation Loss:  0.611482590160988\n",
      "Epoch:  871  Loss:  0.5604785081231967  Validation Loss:  0.611538311811509\n",
      "Epoch:  872  Loss:  0.5605284082936123  Validation Loss:  0.6115948039072531\n",
      "Epoch:  873  Loss:  0.5605790336849168  Validation Loss:  0.6116517031634295\n",
      "Epoch:  874  Loss:  0.5606299143750221  Validation Loss:  0.6117090400722291\n",
      "Epoch:  875  Loss:  0.560681520961225  Validation Loss:  0.6117671594299652\n",
      "Epoch:  876  Loss:  0.560733940708451  Validation Loss:  0.6118260060471518\n",
      "Epoch:  877  Loss:  0.5607870403910056  Validation Loss:  0.6118852083605749\n",
      "Epoch:  878  Loss:  0.5608403808437288  Validation Loss:  0.6119449178653734\n",
      "Epoch:  879  Loss:  0.5608944927342236  Validation Loss:  0.6120053943660524\n",
      "Epoch:  880  Loss:  0.5609492210438475  Validation Loss:  0.6120661072157048\n",
      "Epoch:  881  Loss:  0.561004228121601  Validation Loss:  0.6121274363939408\n",
      "Epoch:  882  Loss:  0.5610599055187777  Validation Loss:  0.6121890823598262\n",
      "Epoch:  883  Loss:  0.5611158217536285  Validation Loss:  0.6122512472448526\n",
      "Epoch:  884  Loss:  0.561172230122611  Validation Loss:  0.6123136025336053\n",
      "Epoch:  885  Loss:  0.5612288978882134  Validation Loss:  0.6123762515683969\n",
      "Epoch:  886  Loss:  0.5612857719417661  Validation Loss:  0.6124391481280327\n",
      "Epoch:  887  Loss:  0.5613427978241816  Validation Loss:  0.6125021365781625\n",
      "Epoch:  888  Loss:  0.5613999017048628  Validation Loss:  0.612565176492488\n",
      "Epoch:  889  Loss:  0.5614569809753448  Validation Loss:  0.6126281848108327\n",
      "Epoch:  890  Loss:  0.5615139174740762  Validation Loss:  0.6126910043811357\n",
      "Epoch:  891  Loss:  0.5615704630035907  Validation Loss:  0.6127534098923206\n",
      "Epoch:  892  Loss:  0.5616264315787702  Validation Loss:  0.6128152080432132\n",
      "Epoch:  893  Loss:  0.561681593186222  Validation Loss:  0.6128762198819054\n",
      "Epoch:  894  Loss:  0.5617356366943568  Validation Loss:  0.6129360935754247\n",
      "Epoch:  895  Loss:  0.5617882763966918  Validation Loss:  0.6129946312694637\n",
      "Epoch:  896  Loss:  0.5618392214644701  Validation Loss:  0.6130515549469877\n",
      "Epoch:  897  Loss:  0.5618882148060947  Validation Loss:  0.6131066925547741\n",
      "Epoch:  898  Loss:  0.5619351785397158  Validation Loss:  0.6131600664445648\n",
      "Epoch:  899  Loss:  0.5619802385801449  Validation Loss:  0.6132118953046976\n",
      "Epoch:  900  Loss:  0.5620236928341911  Validation Loss:  0.6132625317959873\n",
      "Epoch:  901  Loss:  0.5620660475688055  Validation Loss:  0.613312503805867\n",
      "Epoch:  902  Loss:  0.5621078517055139  Validation Loss:  0.6133622311883502\n",
      "Epoch:  903  Loss:  0.5621495662024245  Validation Loss:  0.6134120617751722\n",
      "Epoch:  904  Loss:  0.562191690527834  Validation Loss:  0.6134624535010921\n",
      "Epoch:  905  Loss:  0.5622344200033694  Validation Loss:  0.6135134451367237\n",
      "Epoch:  906  Loss:  0.5622779532335699  Validation Loss:  0.6135653908605929\n",
      "Epoch:  907  Loss:  0.5623225170420483  Validation Loss:  0.613618280324671\n",
      "Epoch:  908  Loss:  0.5623680255375803  Validation Loss:  0.613671972795769\n",
      "Epoch:  909  Loss:  0.5624143880326301  Validation Loss:  0.6137264652384652\n",
      "Epoch:  910  Loss:  0.5624618619447574  Validation Loss:  0.6137822796073225\n",
      "Epoch:  911  Loss:  0.562510630255565  Validation Loss:  0.613838937409498\n",
      "Epoch:  912  Loss:  0.5625601947307587  Validation Loss:  0.6138962839764578\n",
      "Epoch:  913  Loss:  0.5626105781877413  Validation Loss:  0.6139545344092228\n",
      "Epoch:  914  Loss:  0.562662225170061  Validation Loss:  0.614014037091423\n",
      "Epoch:  915  Loss:  0.5627149068983271  Validation Loss:  0.6140742660672577\n",
      "Epoch:  916  Loss:  0.5627683824626729  Validation Loss:  0.6141352232683588\n",
      "Epoch:  917  Loss:  0.5628226650878787  Validation Loss:  0.6141970266622526\n",
      "Epoch:  918  Loss:  0.5628782142885029  Validation Loss:  0.6142601325280137\n",
      "Epoch:  919  Loss:  0.5629348152317106  Validation Loss:  0.6143239274345063\n",
      "Epoch:  920  Loss:  0.5629922082880512  Validation Loss:  0.6143884629838996\n",
      "Epoch:  921  Loss:  0.56305038605351  Validation Loss:  0.6144537031650543\n",
      "Epoch:  922  Loss:  0.5631093554897234  Validation Loss:  0.6145196591538412\n",
      "Epoch:  923  Loss:  0.5631691322196275  Validation Loss:  0.6145865248033294\n",
      "Epoch:  924  Loss:  0.5632302219048142  Validation Loss:  0.6146545807520548\n",
      "Epoch:  925  Loss:  0.5632922979537398  Validation Loss:  0.6147233598210193\n",
      "Epoch:  926  Loss:  0.5633551519131288  Validation Loss:  0.6147928399344286\n",
      "Epoch:  927  Loss:  0.5634187864838168  Validation Loss:  0.6148630548958425\n",
      "Epoch:  928  Loss:  0.5634832260897383  Validation Loss:  0.6149340064989196\n",
      "Epoch:  929  Loss:  0.5635484454454854  Validation Loss:  0.6150057119903741\n",
      "Epoch:  930  Loss:  0.5636144524207338  Validation Loss:  0.6150781258388802\n",
      "Epoch:  931  Loss:  0.5636812650598586  Validation Loss:  0.6151513820169149\n",
      "Epoch:  932  Loss:  0.5637492863927036  Validation Loss:  0.6152259148657322\n",
      "Epoch:  933  Loss:  0.5638184163952247  Validation Loss:  0.6153012068459282\n",
      "Epoch:  934  Loss:  0.5638883354375139  Validation Loss:  0.6153771960073047\n",
      "Epoch:  935  Loss:  0.5639590408187359  Validation Loss:  0.6154539116002895\n",
      "Epoch:  936  Loss:  0.5640305422013625  Validation Loss:  0.6155313398275111\n",
      "Epoch:  937  Loss:  0.5641028186306357  Validation Loss:  0.6156095060761329\n",
      "Epoch:  938  Loss:  0.5641758947633206  Validation Loss:  0.6156883846830439\n",
      "Epoch:  939  Loss:  0.564249768317677  Validation Loss:  0.6157679666799528\n",
      "Epoch:  940  Loss:  0.5643244122387842  Validation Loss:  0.6158482858704196\n",
      "Epoch:  941  Loss:  0.5643998534185812  Validation Loss:  0.6159293219723083\n",
      "Epoch:  942  Loss:  0.5644760790280998  Validation Loss:  0.6160110675350383\n",
      "Epoch:  943  Loss:  0.5645530932117253  Validation Loss:  0.6160935236623993\n",
      "Epoch:  944  Loss:  0.5646308923372999  Validation Loss:  0.6161767211225297\n",
      "Epoch:  945  Loss:  0.5647094812011346  Validation Loss:  0.616260591066546\n",
      "Epoch:  946  Loss:  0.5647888558451086  Validation Loss:  0.6163453145159615\n",
      "Epoch:  947  Loss:  0.5648694728733972  Validation Loss:  0.6164312914565757\n",
      "Epoch:  948  Loss:  0.5649511673720553  Validation Loss:  0.6165180037970897\n",
      "Epoch:  949  Loss:  0.565033644461073  Validation Loss:  0.6166054076618619\n",
      "Epoch:  950  Loss:  0.5651169079588726  Validation Loss:  0.6166935547910355\n",
      "Epoch:  951  Loss:  0.565200961730443  Validation Loss:  0.6167823673674354\n",
      "Epoch:  952  Loss:  0.5652857988839969  Validation Loss:  0.6168719301069224\n",
      "Epoch:  953  Loss:  0.5653714152285829  Validation Loss:  0.6169621720910072\n",
      "Epoch:  954  Loss:  0.5654578206129373  Validation Loss:  0.6170531395408843\n",
      "Epoch:  955  Loss:  0.5655449996003881  Validation Loss:  0.6171448051377579\n",
      "Epoch:  956  Loss:  0.5656329674413427  Validation Loss:  0.6172371586715734\n",
      "Epoch:  957  Loss:  0.5657217173371464  Validation Loss:  0.6173302149055181\n",
      "Epoch:  958  Loss:  0.5658112464705483  Validation Loss:  0.6174240022621773\n",
      "Epoch:  959  Loss:  0.565901561663486  Validation Loss:  0.6175184596191954\n",
      "Epoch:  960  Loss:  0.5659926468040795  Validation Loss:  0.6176136456154011\n",
      "Epoch:  961  Loss:  0.5660845284815877  Validation Loss:  0.6177094875386467\n",
      "Epoch:  962  Loss:  0.5661771770566701  Validation Loss:  0.617805998634409\n",
      "Epoch:  963  Loss:  0.5662705856608227  Validation Loss:  0.6179032062214834\n",
      "Epoch:  964  Loss:  0.566364722000435  Validation Loss:  0.618001105332816\n",
      "Epoch:  965  Loss:  0.5664595098933205  Validation Loss:  0.618099696520302\n",
      "Epoch:  966  Loss:  0.5665549983968958  Validation Loss:  0.618198980887731\n",
      "Epoch:  967  Loss:  0.5666512125870213  Validation Loss:  0.6182989166290672\n",
      "Epoch:  968  Loss:  0.5667481388198212  Validation Loss:  0.6183995190593932\n",
      "Epoch:  969  Loss:  0.5668457655468956  Validation Loss:  0.6185007812800231\n",
      "Epoch:  970  Loss:  0.5669441343285143  Validation Loss:  0.6186027318515159\n",
      "Epoch:  971  Loss:  0.5670432571088895  Validation Loss:  0.6187053234488876\n",
      "Epoch:  972  Loss:  0.5671431541908533  Validation Loss:  0.6188085919453038\n",
      "Epoch:  973  Loss:  0.5672438061330467  Validation Loss:  0.6189125178864708\n",
      "Epoch:  974  Loss:  0.5673452186631038  Validation Loss:  0.619017095339519\n",
      "Epoch:  975  Loss:  0.5674473910592497  Validation Loss:  0.6191223194753682\n",
      "Epoch:  976  Loss:  0.567550328024663  Validation Loss:  0.6192281900180711\n",
      "Epoch:  977  Loss:  0.5676540163811297  Validation Loss:  0.6193346999309681\n",
      "Epoch:  978  Loss:  0.5677584608551115  Validation Loss:  0.6194418289319232\n",
      "Epoch:  979  Loss:  0.5678636516677216  Validation Loss:  0.6195496174472349\n",
      "Epoch:  980  Loss:  0.5679695852566511  Validation Loss:  0.6196581370852612\n",
      "Epoch:  981  Loss:  0.5680767053272575  Validation Loss:  0.6197679074550116\n",
      "Epoch:  982  Loss:  0.5681848411913961  Validation Loss:  0.6198783333378809\n",
      "Epoch:  983  Loss:  0.5682937036966905  Validation Loss:  0.6199893951416016\n",
      "Epoch:  984  Loss:  0.5684032844379544  Validation Loss:  0.6201010314678704\n",
      "Epoch:  985  Loss:  0.5685135819716379  Validation Loss:  0.6202132478356361\n",
      "Epoch:  986  Loss:  0.5686245788121596  Validation Loss:  0.6203260351386335\n",
      "Epoch:  987  Loss:  0.5687362551223487  Validation Loss:  0.6204394051046284\n",
      "Epoch:  988  Loss:  0.5688486259663478  Validation Loss:  0.6205532208636955\n",
      "Epoch:  989  Loss:  0.5689616795862094  Validation Loss:  0.6206675095966568\n",
      "Epoch:  990  Loss:  0.5690754097886384  Validation Loss:  0.6207821422980891\n",
      "Epoch:  991  Loss:  0.5691897780168802  Validation Loss:  0.6208970948225923\n",
      "Epoch:  992  Loss:  0.569304792652838  Validation Loss:  0.6210123186034185\n",
      "Epoch:  993  Loss:  0.569420354324393  Validation Loss:  0.6211272429812837\n",
      "Epoch:  994  Loss:  0.5695363414241001  Validation Loss:  0.6212417389507647\n",
      "Epoch:  995  Loss:  0.5696527434978634  Validation Loss:  0.6213555771995474\n",
      "Epoch:  996  Loss:  0.5697694949572906  Validation Loss:  0.6214686843256155\n",
      "Epoch:  997  Loss:  0.5698865746613592  Validation Loss:  0.6215812819147551\n",
      "Epoch:  998  Loss:  0.570004062447697  Validation Loss:  0.6216935169089723\n",
      "Epoch:  999  Loss:  0.5701219598064199  Validation Loss:  0.6218053279099641\n",
      "Epoch:  1000  Loss:  0.5702402255963535  Validation Loss:  0.6219166187500512\n",
      "Epoch:  1001  Loss:  0.5703588561387732  Validation Loss:  0.6220273723204931\n",
      "Epoch:  1002  Loss:  0.5704778774408623  Validation Loss:  0.6221377134875015\n",
      "Epoch:  1003  Loss:  0.5705973429605364  Validation Loss:  0.6222477473870471\n",
      "Epoch:  1004  Loss:  0.5707173205679282  Validation Loss:  0.6223577774233289\n",
      "Epoch:  1005  Loss:  0.5708379275165498  Validation Loss:  0.622467997311442\n",
      "Epoch:  1006  Loss:  0.5709592455765232  Validation Loss:  0.6225786460218606\n",
      "Epoch:  1007  Loss:  0.5710813488811255  Validation Loss:  0.6226898507663498\n",
      "Epoch:  1008  Loss:  0.5712042935658246  Validation Loss:  0.6228017743538927\n",
      "Epoch:  1009  Loss:  0.5713281058473513  Validation Loss:  0.6229144943257173\n",
      "Epoch:  1010  Loss:  0.5714528096606954  Validation Loss:  0.6230280153729297\n",
      "Epoch:  1011  Loss:  0.571578441397287  Validation Loss:  0.6231424335252356\n",
      "Epoch:  1012  Loss:  0.5717049846891313  Validation Loss:  0.6232577348472895\n",
      "Epoch:  1013  Loss:  0.571832466032356  Validation Loss:  0.6233739350680951\n",
      "Epoch:  1014  Loss:  0.5719608833547681  Validation Loss:  0.6234910430179702\n",
      "Epoch:  1015  Loss:  0.5720902198692783  Validation Loss:  0.6236090279287763\n",
      "Epoch:  1016  Loss:  0.5722204794175922  Validation Loss:  0.6237279116003601\n",
      "Epoch:  1017  Loss:  0.5723516635131091  Validation Loss:  0.6238476996896444\n",
      "Epoch:  1018  Loss:  0.5724837758811191  Validation Loss:  0.6239683527361464\n",
      "Epoch:  1019  Loss:  0.5726168148685247  Validation Loss:  0.624089905647216\n",
      "Epoch:  1020  Loss:  0.5727507645264268  Validation Loss:  0.6242123322078476\n",
      "Epoch:  1021  Loss:  0.5728856341214851  Validation Loss:  0.6243355983385334\n",
      "Epoch:  1022  Loss:  0.5730214130831882  Validation Loss:  0.6244597007279042\n",
      "Epoch:  1023  Loss:  0.5731580862309784  Validation Loss:  0.6245846687643616\n",
      "Epoch:  1024  Loss:  0.5732956527033821  Validation Loss:  0.6247104280800732\n",
      "Epoch:  1025  Loss:  0.5734341188101097  Validation Loss:  0.6248369995090697\n",
      "Epoch:  1026  Loss:  0.5735734687419608  Validation Loss:  0.6249644157511217\n",
      "Epoch:  1027  Loss:  0.5737136785872281  Validation Loss:  0.6250922922734861\n",
      "Epoch:  1028  Loss:  0.5738545362604782  Validation Loss:  0.6252195319091832\n",
      "Epoch:  1029  Loss:  0.5739959852769971  Validation Loss:  0.6253468376342897\n",
      "Epoch:  1030  Loss:  0.5741382034029812  Validation Loss:  0.6254749557486287\n",
      "Epoch:  1031  Loss:  0.5742813183460385  Validation Loss:  0.6256038957723865\n",
      "Epoch:  1032  Loss:  0.5744253190467135  Validation Loss:  0.6257336864040958\n",
      "Epoch:  1033  Loss:  0.5745702187297865  Validation Loss:  0.6258642790770089\n",
      "Epoch:  1034  Loss:  0.5747160030994565  Validation Loss:  0.6259956953150255\n",
      "Epoch:  1035  Loss:  0.5748626758111641  Validation Loss:  0.6261279251840379\n",
      "Epoch:  1036  Loss:  0.575010241405107  Validation Loss:  0.6262609484019103\n",
      "Epoch:  1037  Loss:  0.5751586970174685  Validation Loss:  0.6263948095341524\n",
      "Epoch:  1038  Loss:  0.5753080322872848  Validation Loss:  0.6265294713278612\n",
      "Epoch:  1039  Loss:  0.5754580644425005  Validation Loss:  0.6266634896121643\n",
      "Epoch:  1040  Loss:  0.5756086056819185  Validation Loss:  0.626797076176714\n",
      "Epoch:  1041  Loss:  0.5757598381256684  Validation Loss:  0.6269314243561692\n",
      "Epoch:  1042  Loss:  0.5759118930902332  Validation Loss:  0.6270666192803118\n",
      "Epoch:  1043  Loss:  0.5760647678514943  Validation Loss:  0.6272027228993399\n",
      "Epoch:  1044  Loss:  0.576218484621495  Validation Loss:  0.627339731487963\n",
      "Epoch:  1045  Loss:  0.5763727398589253  Validation Loss:  0.6274751671762379\n",
      "Epoch:  1046  Loss:  0.576527391327545  Validation Loss:  0.6276112592054738\n",
      "Epoch:  1047  Loss:  0.576682880660519  Validation Loss:  0.6277481296824085\n",
      "Epoch:  1048  Loss:  0.576839247206226  Validation Loss:  0.6278858056498898\n",
      "Epoch:  1049  Loss:  0.5769961558980867  Validation Loss:  0.6280214160128876\n",
      "Epoch:  1050  Loss:  0.5771525265648961  Validation Loss:  0.628156251653477\n",
      "Epoch:  1051  Loss:  0.5773089475464076  Validation Loss:  0.6282894281601464\n",
      "Epoch:  1052  Loss:  0.5774657652713359  Validation Loss:  0.6284231022000313\n",
      "Epoch:  1053  Loss:  0.5776231148280203  Validation Loss:  0.6285550568114828\n",
      "Epoch:  1054  Loss:  0.5777806898579001  Validation Loss:  0.6286856086441764\n",
      "Epoch:  1055  Loss:  0.5779385871952399  Validation Loss:  0.6288155274534667\n",
      "Epoch:  1056  Loss:  0.5780968080507591  Validation Loss:  0.6289435401558876\n",
      "Epoch:  1057  Loss:  0.578255004901439  Validation Loss:  0.6290685442034845\n",
      "Epoch:  1058  Loss:  0.578413087921217  Validation Loss:  0.6291912934846349\n",
      "Epoch:  1059  Loss:  0.5785709806950763  Validation Loss:  0.6293099594336969\n",
      "Epoch:  1060  Loss:  0.5787284775869921  Validation Loss:  0.62942527372528\n",
      "Epoch:  1061  Loss:  0.5788855466526002  Validation Loss:  0.6295362545384301\n",
      "Epoch:  1062  Loss:  0.5790420694509522  Validation Loss:  0.6296430882756356\n",
      "Epoch:  1063  Loss:  0.579198136832565  Validation Loss:  0.6297461791998811\n",
      "Epoch:  1064  Loss:  0.5793539720121771  Validation Loss:  0.6298469226393435\n",
      "Epoch:  1065  Loss:  0.57950969573576  Validation Loss:  0.6299454387691286\n",
      "Epoch:  1066  Loss:  0.5796650602249429  Validation Loss:  0.6300424238046011\n",
      "Epoch:  1067  Loss:  0.5798203899525106  Validation Loss:  0.6301392246451643\n",
      "Epoch:  1068  Loss:  0.5799759226851166  Validation Loss:  0.6302355129133772\n",
      "Epoch:  1069  Loss:  0.580131797469221  Validation Loss:  0.6303323657700309\n",
      "Epoch:  1070  Loss:  0.580288497172296  Validation Loss:  0.6304301194570683\n",
      "Epoch:  1071  Loss:  0.5804461108753458  Validation Loss:  0.6305289846603517\n",
      "Epoch:  1072  Loss:  0.5806047247024253  Validation Loss:  0.6306293224570928\n",
      "Epoch:  1073  Loss:  0.5807643793756142  Validation Loss:  0.6307310157076076\n",
      "Epoch:  1074  Loss:  0.5809250356862321  Validation Loss:  0.6308340495107351\n",
      "Epoch:  1075  Loss:  0.5810866058571265  Validation Loss:  0.6309377840823598\n",
      "Epoch:  1076  Loss:  0.5812490134499967  Validation Loss:  0.6310422850979699\n",
      "Epoch:  1077  Loss:  0.5814122465904802  Validation Loss:  0.6311474337621972\n",
      "Epoch:  1078  Loss:  0.581576211634092  Validation Loss:  0.6312539812039446\n",
      "Epoch:  1079  Loss:  0.581741087930277  Validation Loss:  0.6313623069889016\n",
      "Epoch:  1080  Loss:  0.5819070109399036  Validation Loss:  0.6314721284089265\n",
      "Epoch:  1081  Loss:  0.5820732427295298  Validation Loss:  0.6315815034839842\n",
      "Epoch:  1082  Loss:  0.5822393940761685  Validation Loss:  0.6316913095889268\n",
      "Epoch:  1083  Loss:  0.5824063300853595  Validation Loss:  0.6318017500970099\n",
      "Epoch:  1084  Loss:  0.5825740298489108  Validation Loss:  0.6319128051400185\n",
      "Epoch:  1085  Loss:  0.5827424296643585  Validation Loss:  0.6320247266579557\n",
      "Epoch:  1086  Loss:  0.5829114925814792  Validation Loss:  0.6321375610099899\n",
      "Epoch:  1087  Loss:  0.583081261953339  Validation Loss:  0.6322509111077698\n",
      "Epoch:  1088  Loss:  0.583251760317944  Validation Loss:  0.6323648945049003\n",
      "Epoch:  1089  Loss:  0.583423034939915  Validation Loss:  0.6324796375853045\n",
      "Epoch:  1090  Loss:  0.5835949790431186  Validation Loss:  0.6325960079277003\n",
      "Epoch:  1091  Loss:  0.5837677249452099  Validation Loss:  0.6327132425374455\n",
      "Epoch:  1092  Loss:  0.5839403484947979  Validation Loss:  0.6328299009689579\n",
      "Epoch:  1093  Loss:  0.5841130105312914  Validation Loss:  0.6329472870738418\n",
      "Epoch:  1094  Loss:  0.5842861408833414  Validation Loss:  0.6330651798182063\n",
      "Epoch:  1095  Loss:  0.5844597695628181  Validation Loss:  0.6331832273690788\n",
      "Epoch:  1096  Loss:  0.5846337478142232  Validation Loss:  0.6333017136763643\n",
      "Epoch:  1097  Loss:  0.5848080122144893  Validation Loss:  0.6334196229775747\n",
      "Epoch:  1098  Loss:  0.5849813145352527  Validation Loss:  0.6335364646381803\n",
      "Epoch:  1099  Loss:  0.5851545098470524  Validation Loss:  0.6336530769864718\n",
      "Epoch:  1100  Loss:  0.5853277940768749  Validation Loss:  0.6337696131732728\n",
      "Epoch:  1101  Loss:  0.5855003551347181  Validation Loss:  0.6338846079177327\n",
      "Epoch:  1102  Loss:  0.5856720040086657  Validation Loss:  0.63399955354355\n",
      "Epoch:  1103  Loss:  0.5858435056870803  Validation Loss:  0.6341139848033587\n",
      "Epoch:  1104  Loss:  0.586013894341886  Validation Loss:  0.6342279756510699\n",
      "Epoch:  1105  Loss:  0.5861837124917656  Validation Loss:  0.6343415111855224\n",
      "Epoch:  1106  Loss:  0.5863524245098233  Validation Loss:  0.6344550434086058\n",
      "Epoch:  1107  Loss:  0.5865199261112138  Validation Loss:  0.6345681641940717\n",
      "Epoch:  1108  Loss:  0.5866858166409656  Validation Loss:  0.6346809417009354\n",
      "Epoch:  1109  Loss:  0.5868498105090112  Validation Loss:  0.6347932531325905\n",
      "Epoch:  1110  Loss:  0.5870113900862635  Validation Loss:  0.6349048090201838\n",
      "Epoch:  1111  Loss:  0.5871699564391747  Validation Loss:  0.6350149363279343\n",
      "Epoch:  1112  Loss:  0.5873250634409487  Validation Loss:  0.6351237473664461\n",
      "Epoch:  1113  Loss:  0.5874764200532809  Validation Loss:  0.6352307564682431\n",
      "Epoch:  1114  Loss:  0.5876239594072104  Validation Loss:  0.6353358659479353\n",
      "Epoch:  1115  Loss:  0.5877678923308849  Validation Loss:  0.6354392587586686\n",
      "Epoch:  1116  Loss:  0.5879088462796063  Validation Loss:  0.635540836111263\n",
      "Epoch:  1117  Loss:  0.5880476369056851  Validation Loss:  0.6356414934551274\n",
      "Epoch:  1118  Loss:  0.5881849964614958  Validation Loss:  0.6357414970795313\n",
      "Epoch:  1119  Loss:  0.5883221348049119  Validation Loss:  0.6358413806668034\n",
      "Epoch:  1120  Loss:  0.5884583722101524  Validation Loss:  0.6359409985167009\n",
      "Epoch:  1121  Loss:  0.5885944942478091  Validation Loss:  0.6360411914410414\n",
      "Epoch:  1122  Loss:  0.5887309261364863  Validation Loss:  0.6361425679039072\n",
      "Epoch:  1123  Loss:  0.5888679932337254  Validation Loss:  0.6362447548243735\n",
      "Epoch:  1124  Loss:  0.5890058987075463  Validation Loss:  0.6363478482321456\n",
      "Epoch:  1125  Loss:  0.5891454618657008  Validation Loss:  0.6364536475804117\n",
      "Epoch:  1126  Loss:  0.5892866728827357  Validation Loss:  0.6365602215131124\n",
      "Epoch:  1127  Loss:  0.589428651984781  Validation Loss:  0.6366672739386559\n",
      "Epoch:  1128  Loss:  0.5895713263424114  Validation Loss:  0.636774844593472\n",
      "Epoch:  1129  Loss:  0.5897146222181618  Validation Loss:  0.6368827657015236\n",
      "Epoch:  1130  Loss:  0.5898587144678459  Validation Loss:  0.6369911015585616\n",
      "Epoch:  1131  Loss:  0.5900034326827154  Validation Loss:  0.6371000221482029\n",
      "Epoch:  1132  Loss:  0.5901495846454055  Validation Loss:  0.6372113603132742\n",
      "Epoch:  1133  Loss:  0.5902973111951724  Validation Loss:  0.6373232023583518\n",
      "Epoch:  1134  Loss:  0.5904457736294717  Validation Loss:  0.6374355237241145\n",
      "Epoch:  1135  Loss:  0.5905949626350775  Validation Loss:  0.6375483216510879\n",
      "Epoch:  1136  Loss:  0.5907447865931317  Validation Loss:  0.6376616921689775\n",
      "Epoch:  1137  Loss:  0.5908952142810449  Validation Loss:  0.6377756231360965\n",
      "Epoch:  1138  Loss:  0.5910462699364871  Validation Loss:  0.6378902083745709\n",
      "Epoch:  1139  Loss:  0.5911982960999012  Validation Loss:  0.6380055143877312\n",
      "Epoch:  1140  Loss:  0.5913512705359608  Validation Loss:  0.6381215273782059\n",
      "Epoch:  1141  Loss:  0.5915051198331639  Validation Loss:  0.6382380503195303\n",
      "Epoch:  1142  Loss:  0.5916596736526116  Validation Loss:  0.6383551651680911\n",
      "Epoch:  1143  Loss:  0.5918149262433872  Validation Loss:  0.6384733923607402\n",
      "Epoch:  1144  Loss:  0.5919719985220582  Validation Loss:  0.6385935751928223\n",
      "Epoch:  1145  Loss:  0.5921300912974402  Validation Loss:  0.6387143135070801\n",
      "Epoch:  1146  Loss:  0.5922888030996546  Validation Loss:  0.638835628827413\n",
      "Epoch:  1147  Loss:  0.5924478229135275  Validation Loss:  0.6389572970845081\n",
      "Epoch:  1148  Loss:  0.5926066843559965  Validation Loss:  0.639079160436436\n",
      "Epoch:  1149  Loss:  0.5927658451488241  Validation Loss:  0.6392015246329484\n",
      "Epoch:  1150  Loss:  0.5929257563780993  Validation Loss:  0.6393243173758189\n",
      "Epoch:  1151  Loss:  0.5930862862151116  Validation Loss:  0.6394476506997038\n",
      "Epoch:  1152  Loss:  0.5932474166853353  Validation Loss:  0.6395715629612958\n",
      "Epoch:  1153  Loss:  0.5934091499773786  Validation Loss:  0.6396960022824781\n",
      "Epoch:  1154  Loss:  0.5935714666731655  Validation Loss:  0.6398210257843688\n",
      "Epoch:  1155  Loss:  0.5937343971803785  Validation Loss:  0.6399466127709106\n",
      "Epoch:  1156  Loss:  0.5938979241764173  Validation Loss:  0.6400727527561011\n",
      "Epoch:  1157  Loss:  0.5940620434470475  Validation Loss:  0.6401994716789987\n",
      "Epoch:  1158  Loss:  0.5942267598817125  Validation Loss:  0.6403267251120673\n",
      "Epoch:  1159  Loss:  0.5943920607445762  Validation Loss:  0.6404545091920428\n",
      "Epoch:  1160  Loss:  0.5945579478750005  Validation Loss:  0.6405828399238763\n",
      "Epoch:  1161  Loss:  0.5947244235314428  Validation Loss:  0.6407117338644134\n",
      "Epoch:  1162  Loss:  0.5948914581676945  Validation Loss:  0.6408411198192172\n",
      "Epoch:  1163  Loss:  0.5950582612771541  Validation Loss:  0.6409706191884147\n",
      "Epoch:  1164  Loss:  0.5952249598456547  Validation Loss:  0.6411006039491406\n",
      "Epoch:  1165  Loss:  0.5953923267545178  Validation Loss:  0.6412310796203436\n",
      "Epoch:  1166  Loss:  0.5955603604670614  Validation Loss:  0.6413620663461862\n",
      "Epoch:  1167  Loss:  0.5957291157683358  Validation Loss:  0.6414934951398108\n",
      "Epoch:  1168  Loss:  0.5958984993165359  Validation Loss:  0.6416254959724568\n",
      "Epoch:  1169  Loss:  0.596068479376845  Validation Loss:  0.6417580368342223\n",
      "Epoch:  1170  Loss:  0.596239046473056  Validation Loss:  0.6418911461476926\n",
      "Epoch:  1171  Loss:  0.5964102041441948  Validation Loss:  0.6420248145306552\n",
      "Epoch:  1172  Loss:  0.5965819510398432  Validation Loss:  0.6421590519172174\n",
      "Epoch:  1173  Loss:  0.5967534207273275  Validation Loss:  0.6422933596703742\n",
      "Epoch:  1174  Loss:  0.5969247221481055  Validation Loss:  0.6424282077285979\n",
      "Epoch:  1175  Loss:  0.5970965951913968  Validation Loss:  0.6425636016108371\n",
      "Epoch:  1176  Loss:  0.5972690396709368  Validation Loss:  0.6426995391095126\n",
      "Epoch:  1177  Loss:  0.5974424036452547  Validation Loss:  0.6428372324616821\n",
      "Epoch:  1178  Loss:  0.5976176314521581  Validation Loss:  0.6429762293895086\n",
      "Epoch:  1179  Loss:  0.5977935607777909  Validation Loss:  0.6431157660705072\n",
      "Epoch:  1180  Loss:  0.5979691901477053  Validation Loss:  0.6432553916065781\n",
      "Epoch:  1181  Loss:  0.5981446349760517  Validation Loss:  0.6433955453060292\n",
      "Epoch:  1182  Loss:  0.598320632101968  Validation Loss:  0.64353624758897\n",
      "Epoch:  1183  Loss:  0.5984971915371716  Validation Loss:  0.6436775036984019\n",
      "Epoch:  1184  Loss:  0.5986743105808273  Validation Loss:  0.6438192777611591\n",
      "Epoch:  1185  Loss:  0.5988511612871662  Validation Loss:  0.6439611630307304\n",
      "Epoch:  1186  Loss:  0.5990277600008994  Validation Loss:  0.6441035565954668\n",
      "Epoch:  1187  Loss:  0.5992048992076888  Validation Loss:  0.6442465081259057\n",
      "Epoch:  1188  Loss:  0.599382584867999  Validation Loss:  0.6443900057563076\n",
      "Epoch:  1189  Loss:  0.5995599998859689  Validation Loss:  0.6445335734773565\n",
      "Epoch:  1190  Loss:  0.5997371242148801  Validation Loss:  0.6446777041311618\n",
      "Epoch:  1191  Loss:  0.5999147773021832  Validation Loss:  0.6448223883355105\n",
      "Epoch:  1192  Loss:  0.6000924395630136  Validation Loss:  0.644967228450157\n",
      "Epoch:  1193  Loss:  0.6002695406088605  Validation Loss:  0.6451125258096942\n",
      "Epoch:  1194  Loss:  0.6004471136722713  Validation Loss:  0.6452584136967305\n",
      "Epoch:  1195  Loss:  0.600624330015853  Validation Loss:  0.6454043885072073\n",
      "Epoch:  1196  Loss:  0.6008012751117349  Validation Loss:  0.645550946118655\n",
      "Epoch:  1197  Loss:  0.6009779149666429  Validation Loss:  0.6456976292861832\n",
      "Epoch:  1198  Loss:  0.6011541956104338  Validation Loss:  0.6458449278164793\n",
      "Epoch:  1199  Loss:  0.601330077694729  Validation Loss:  0.64599233534601\n",
      "Epoch:  1200  Loss:  0.6015055878087878  Validation Loss:  0.6461403074639814\n",
      "Epoch:  1201  Loss:  0.6016804446466267  Validation Loss:  0.6462884655705204\n",
      "Epoch:  1202  Loss:  0.6018543093465268  Validation Loss:  0.6464368416755287\n",
      "Epoch:  1203  Loss:  0.6020270867971703  Validation Loss:  0.6465854073564211\n",
      "Epoch:  1204  Loss:  0.6021987478015944  Validation Loss:  0.6467341107350809\n",
      "Epoch:  1205  Loss:  0.6023690595524386  Validation Loss:  0.6468829694721434\n",
      "Epoch:  1206  Loss:  0.6025378146907314  Validation Loss:  0.6470319653550783\n",
      "Epoch:  1207  Loss:  0.6027047948446125  Validation Loss:  0.6471810614069303\n",
      "Epoch:  1208  Loss:  0.602869553072378  Validation Loss:  0.6473301784307869\n",
      "Epoch:  1209  Loss:  0.6030315733281896  Validation Loss:  0.6474792857964834\n",
      "Epoch:  1210  Loss:  0.6031903505092486  Validation Loss:  0.6476283040311601\n",
      "Epoch:  1211  Loss:  0.6033454230520874  Validation Loss:  0.6477771224798979\n",
      "Epoch:  1212  Loss:  0.6034960388904438  Validation Loss:  0.6479254362207872\n",
      "Epoch:  1213  Loss:  0.6036414748756215  Validation Loss:  0.6480728898335386\n",
      "Epoch:  1214  Loss:  0.6037808507680893  Validation Loss:  0.648219086781696\n",
      "Epoch:  1215  Loss:  0.6039130035787821  Validation Loss:  0.6483633096019427\n",
      "Epoch:  1216  Loss:  0.6040366241009906  Validation Loss:  0.6485050315106357\n",
      "Epoch:  1217  Loss:  0.6041501320898532  Validation Loss:  0.6486434608145997\n",
      "Epoch:  1218  Loss:  0.6042525155236944  Validation Loss:  0.6487782528554952\n",
      "Epoch:  1219  Loss:  0.6043426209827885  Validation Loss:  0.6489091681109534\n",
      "Epoch:  1220  Loss:  0.6044200723059475  Validation Loss:  0.6490361602218063\n",
      "Epoch:  1221  Loss:  0.6044853927800432  Validation Loss:  0.6491595509427565\n",
      "Epoch:  1222  Loss:  0.6045399138471111  Validation Loss:  0.6492798320121236\n",
      "Epoch:  1223  Loss:  0.6045857835561037  Validation Loss:  0.6493978315481433\n",
      "Epoch:  1224  Loss:  0.6046253447420895  Validation Loss:  0.6495143081302996\n",
      "Epoch:  1225  Loss:  0.6046609549783171  Validation Loss:  0.6496299977103869\n",
      "Epoch:  1226  Loss:  0.6046943652210757  Validation Loss:  0.6497453878875132\n",
      "Epoch:  1227  Loss:  0.6047273372067139  Validation Loss:  0.6498610614626495\n",
      "Epoch:  1228  Loss:  0.60476068793796  Validation Loss:  0.6499770841112843\n",
      "Epoch:  1229  Loss:  0.6047946532489732  Validation Loss:  0.6500936156069791\n",
      "Epoch:  1230  Loss:  0.6048300825525075  Validation Loss:  0.650210767156548\n",
      "Epoch:  1231  Loss:  0.6048665826907381  Validation Loss:  0.6503285326891475\n",
      "Epoch:  1232  Loss:  0.6049047227716073  Validation Loss:  0.6504469591158407\n",
      "Epoch:  1233  Loss:  0.6049439010210336  Validation Loss:  0.6505660207735168\n",
      "Epoch:  1234  Loss:  0.604984753835015  Validation Loss:  0.6506857902363494\n",
      "Epoch:  1235  Loss:  0.6050270876847208  Validation Loss:  0.6508062341146998\n",
      "Epoch:  1236  Loss:  0.6050706793786957  Validation Loss:  0.6509273010823462\n",
      "Epoch:  1237  Loss:  0.6051159128779545  Validation Loss:  0.6510490786146235\n",
      "Epoch:  1238  Loss:  0.6051620504586026  Validation Loss:  0.6511714080417598\n",
      "Epoch:  1239  Loss:  0.60520970383659  Validation Loss:  0.6512943986389372\n",
      "Epoch:  1240  Loss:  0.6052581870695576  Validation Loss:  0.6514177636967765\n",
      "Epoch:  1241  Loss:  0.6053074122639373  Validation Loss:  0.6515418100688193\n",
      "Epoch:  1242  Loss:  0.6053582151886076  Validation Loss:  0.6516664207533553\n",
      "Epoch:  1243  Loss:  0.6054096936015412  Validation Loss:  0.6517915113104714\n",
      "Epoch:  1244  Loss:  0.6054623792879283  Validation Loss:  0.6519172266125679\n",
      "Epoch:  1245  Loss:  0.6055161591619254  Validation Loss:  0.6520434041266088\n",
      "Epoch:  1246  Loss:  0.6055704070953652  Validation Loss:  0.6521699138813548\n",
      "Epoch:  1247  Loss:  0.6056253344286233  Validation Loss:  0.65229706355819\n",
      "Epoch:  1248  Loss:  0.6056818292476237  Validation Loss:  0.6524247844462041\n",
      "Epoch:  1249  Loss:  0.6057389103109017  Validation Loss:  0.6525528632380344\n",
      "Epoch:  1250  Loss:  0.6057963943807408  Validation Loss:  0.6526812596453561\n",
      "Epoch:  1251  Loss:  0.6058544777566567  Validation Loss:  0.652810120748149\n",
      "Epoch:  1252  Loss:  0.6059141403762623  Validation Loss:  0.652939561340544\n",
      "Epoch:  1253  Loss:  0.6059744664700701  Validation Loss:  0.653069373358179\n",
      "Epoch:  1254  Loss:  0.6060351975960657  Validation Loss:  0.6531995256189946\n",
      "Epoch:  1255  Loss:  0.6060963232303038  Validation Loss:  0.6533300559277888\n",
      "Epoch:  1256  Loss:  0.6061580178327859  Validation Loss:  0.6534611293011241\n",
      "Epoch:  1257  Loss:  0.6062211775453761  Validation Loss:  0.6535928370776\n",
      "Epoch:  1258  Loss:  0.6062851447379216  Validation Loss:  0.6537249667776955\n",
      "Epoch:  1259  Loss:  0.6063495179871097  Validation Loss:  0.6538574463791318\n",
      "Epoch:  1260  Loss:  0.6064142796676606  Validation Loss:  0.6539902653959062\n",
      "Epoch:  1261  Loss:  0.6064794497331605  Validation Loss:  0.654123457217658\n",
      "Epoch:  1262  Loss:  0.6065450093476101  Validation Loss:  0.6542569829357995\n",
      "Epoch:  1263  Loss:  0.6066111147170886  Validation Loss:  0.6543911011130722\n",
      "Epoch:  1264  Loss:  0.6066782595822587  Validation Loss:  0.6545256588746\n",
      "Epoch:  1265  Loss:  0.6067464946536347  Validation Loss:  0.6546607906067813\n",
      "Epoch:  1266  Loss:  0.6068152906605974  Validation Loss:  0.6547962954198873\n",
      "Epoch:  1267  Loss:  0.6068844719789922  Validation Loss:  0.6549321559292299\n",
      "Epoch:  1268  Loss:  0.6069540462223812  Validation Loss:  0.6550683713069668\n",
      "Epoch:  1269  Loss:  0.6070240165339783  Validation Loss:  0.6552049401733611\n",
      "Epoch:  1270  Loss:  0.6070943857077509  Validation Loss:  0.6553418779814685\n",
      "Epoch:  1271  Loss:  0.6071651405654848  Validation Loss:  0.655479165966864\n",
      "Epoch:  1272  Loss:  0.6072362880222499  Validation Loss:  0.655616802473863\n",
      "Epoch:  1273  Loss:  0.607307908963412  Validation Loss:  0.6557549196812842\n",
      "Epoch:  1274  Loss:  0.6073803342645988  Validation Loss:  0.6558935711229289\n",
      "Epoch:  1275  Loss:  0.6074541096808389  Validation Loss:  0.6560328031579653\n",
      "Epoch:  1276  Loss:  0.6075284805847332  Validation Loss:  0.6561724204156134\n",
      "Epoch:  1277  Loss:  0.6076032385230065  Validation Loss:  0.6563123754329152\n",
      "Epoch:  1278  Loss:  0.607678389805369  Validation Loss:  0.6564526980121931\n",
      "Epoch:  1279  Loss:  0.6077539240941405  Validation Loss:  0.6565933782193396\n",
      "Epoch:  1280  Loss:  0.6078298592008651  Validation Loss:  0.6567344304036211\n",
      "Epoch:  1281  Loss:  0.6079061819938942  Validation Loss:  0.6568758462866148\n",
      "Epoch:  1282  Loss:  0.6079828924732282  Validation Loss:  0.6570176095874222\n",
      "Epoch:  1283  Loss:  0.6080599980894477  Validation Loss:  0.6571597208579382\n",
      "Epoch:  1284  Loss:  0.608137498004362  Validation Loss:  0.6573022132118543\n",
      "Epoch:  1285  Loss:  0.6082153741735965  Validation Loss:  0.657445067608798\n",
      "Epoch:  1286  Loss:  0.6082936609396711  Validation Loss:  0.6575882887398755\n",
      "Epoch:  1287  Loss:  0.6083723330404609  Validation Loss:  0.6577318473546593\n",
      "Epoch:  1288  Loss:  0.6084513971582055  Validation Loss:  0.6578758198905874\n",
      "Epoch:  1289  Loss:  0.6085310119437054  Validation Loss:  0.6580202954786795\n",
      "Epoch:  1290  Loss:  0.6086115562589839  Validation Loss:  0.6581652374179275\n",
      "Epoch:  1291  Loss:  0.6086932316422462  Validation Loss:  0.6583107883731524\n",
      "Epoch:  1292  Loss:  0.6087755037238821  Validation Loss:  0.6584567024751946\n",
      "Epoch:  1293  Loss:  0.6088581687537953  Validation Loss:  0.6586029750329477\n",
      "Epoch:  1294  Loss:  0.6089412203989923  Validation Loss:  0.6587496192918884\n",
      "Epoch:  1295  Loss:  0.6090246592648327  Validation Loss:  0.6588966286292782\n",
      "Epoch:  1296  Loss:  0.6091084892628714  Validation Loss:  0.6590439862123242\n",
      "Epoch:  1297  Loss:  0.6091927067609504  Validation Loss:  0.6591917287420344\n",
      "Epoch:  1298  Loss:  0.6092773188604041  Validation Loss:  0.6593398242085068\n",
      "Epoch:  1299  Loss:  0.609362317295745  Validation Loss:  0.6594882905483246\n",
      "Epoch:  1300  Loss:  0.6094477145466953  Validation Loss:  0.6596371172754852\n",
      "Epoch:  1301  Loss:  0.6095334857469424  Validation Loss:  0.6597863074254107\n",
      "Epoch:  1302  Loss:  0.6096196571132169  Validation Loss:  0.6599358389223063\n",
      "Epoch:  1303  Loss:  0.6097062192391605  Validation Loss:  0.6600857371533358\n",
      "Epoch:  1304  Loss:  0.6097931595752015  Validation Loss:  0.660235996875498\n",
      "Epoch:  1305  Loss:  0.6098804835928604  Validation Loss:  0.6603866429240616\n",
      "Epoch:  1306  Loss:  0.6099682062864303  Validation Loss:  0.660537630043648\n",
      "Epoch:  1307  Loss:  0.6100563218351454  Validation Loss:  0.6606889789303144\n",
      "Epoch:  1308  Loss:  0.6101448152214288  Validation Loss:  0.660840675510742\n",
      "Epoch:  1309  Loss:  0.6102337057935074  Validation Loss:  0.6609927589694659\n",
      "Epoch:  1310  Loss:  0.6103229721309618  Validation Loss:  0.6611451953649521\n",
      "Epoch:  1311  Loss:  0.6104126283200457  Validation Loss:  0.6612979976667298\n",
      "Epoch:  1312  Loss:  0.6105026851873845  Validation Loss:  0.6614511573204288\n",
      "Epoch:  1313  Loss:  0.6105931106954813  Validation Loss:  0.6616046597008352\n",
      "Epoch:  1314  Loss:  0.6106839327374474  Validation Loss:  0.661758546476011\n",
      "Epoch:  1315  Loss:  0.6107751440722495  Validation Loss:  0.6619127897752656\n",
      "Epoch:  1316  Loss:  0.6108667452586815  Validation Loss:  0.6620673945656529\n",
      "Epoch:  1317  Loss:  0.6109589110594242  Validation Loss:  0.6622225426965289\n",
      "Epoch:  1318  Loss:  0.6110519795911387  Validation Loss:  0.662378117442131\n",
      "Epoch:  1319  Loss:  0.611146165500395  Validation Loss:  0.6625342967885511\n",
      "Epoch:  1320  Loss:  0.611240930436179  Validation Loss:  0.6626908343147349\n",
      "Epoch:  1321  Loss:  0.6113360823597759  Validation Loss:  0.6628477258814706\n",
      "Epoch:  1322  Loss:  0.6114316160324961  Validation Loss:  0.663004990529131\n",
      "Epoch:  1323  Loss:  0.6115275385091081  Validation Loss:  0.6631626045262372\n",
      "Epoch:  1324  Loss:  0.6116238508373499  Validation Loss:  0.6633205786347389\n",
      "Epoch:  1325  Loss:  0.6117205559741705  Validation Loss:  0.663478925548218\n",
      "Epoch:  1326  Loss:  0.61181763287168  Validation Loss:  0.663637640023673\n",
      "Epoch:  1327  Loss:  0.6119151026243344  Validation Loss:  0.6637966870157807\n",
      "Epoch:  1328  Loss:  0.6120129551040009  Validation Loss:  0.6639561007420222\n",
      "Epoch:  1329  Loss:  0.61211119487416  Validation Loss:  0.6641158947238216\n",
      "Epoch:  1330  Loss:  0.6122098116902635  Validation Loss:  0.6642760333639605\n",
      "Epoch:  1331  Loss:  0.6123088353080675  Validation Loss:  0.6644365472926034\n",
      "Epoch:  1332  Loss:  0.6124082264956087  Validation Loss:  0.6645974216085894\n",
      "Epoch:  1333  Loss:  0.6125079989898949  Validation Loss:  0.6647586267855432\n",
      "Epoch:  1334  Loss:  0.6126081739086657  Validation Loss:  0.6649202246356893\n",
      "Epoch:  1335  Loss:  0.6127087234985084  Validation Loss:  0.6650821693517543\n",
      "Epoch:  1336  Loss:  0.6128096507862211  Validation Loss:  0.6652444739032675\n",
      "Epoch:  1337  Loss:  0.6129109820351004  Validation Loss:  0.6654071636773922\n",
      "Epoch:  1338  Loss:  0.6130126905161888  Validation Loss:  0.6655701870719591\n",
      "Epoch:  1339  Loss:  0.6131147813051939  Validation Loss:  0.665733575269028\n",
      "Epoch:  1340  Loss:  0.6132172539830207  Validation Loss:  0.6658973238534398\n",
      "Epoch:  1341  Loss:  0.6133201150689274  Validation Loss:  0.6660614491060928\n",
      "Epoch:  1342  Loss:  0.6134233612101525  Validation Loss:  0.6662259231562968\n",
      "Epoch:  1343  Loss:  0.6135269926395267  Validation Loss:  0.6663907573178962\n",
      "Epoch:  1344  Loss:  0.6136309949681162  Validation Loss:  0.6665559504871015\n",
      "Epoch:  1345  Loss:  0.6137354007456451  Validation Loss:  0.666721506803124\n",
      "Epoch:  1346  Loss:  0.6138401870150119  Validation Loss:  0.6668874199191729\n",
      "Epoch:  1347  Loss:  0.6139453482814133  Validation Loss:  0.6670536959060916\n",
      "Epoch:  1348  Loss:  0.614050907548517  Validation Loss:  0.667220327589247\n",
      "Epoch:  1349  Loss:  0.614156857226044  Validation Loss:  0.6673873326292744\n",
      "Epoch:  1350  Loss:  0.6142632141709328  Validation Loss:  0.6675546387279475\n",
      "Epoch:  1351  Loss:  0.6143700092099607  Validation Loss:  0.6677223016266469\n",
      "Epoch:  1352  Loss:  0.6144772249273955  Validation Loss:  0.6678903006293155\n",
      "Epoch:  1353  Loss:  0.6145848540123552  Validation Loss:  0.6680586387713751\n",
      "Epoch:  1354  Loss:  0.6146928968373686  Validation Loss:  0.6682273320577763\n",
      "Epoch:  1355  Loss:  0.6148013485595584  Validation Loss:  0.6683963586886724\n",
      "Epoch:  1356  Loss:  0.6149102106690407  Validation Loss:  0.6685657534334395\n",
      "Epoch:  1357  Loss:  0.6150194792076945  Validation Loss:  0.6687354848340705\n",
      "Epoch:  1358  Loss:  0.6151291811373085  Validation Loss:  0.6689054226433789\n",
      "Epoch:  1359  Loss:  0.6152392352931202  Validation Loss:  0.6690755914206858\n",
      "Epoch:  1360  Loss:  0.6153495441190898  Validation Loss:  0.6692459735053556\n",
      "Epoch:  1361  Loss:  0.6154601726680994  Validation Loss:  0.6694165597911235\n",
      "Epoch:  1362  Loss:  0.6155711491126568  Validation Loss:  0.6695875232970273\n",
      "Epoch:  1363  Loss:  0.6156825171317906  Validation Loss:  0.6697588325650604\n",
      "Epoch:  1364  Loss:  0.6157942772842944  Validation Loss:  0.6699304989090672\n",
      "Epoch:  1365  Loss:  0.615906404517591  Validation Loss:  0.6701025297796285\n",
      "Epoch:  1366  Loss:  0.616018912801519  Validation Loss:  0.6702749080680035\n",
      "Epoch:  1367  Loss:  0.6161317948251963  Validation Loss:  0.6704476696473581\n",
      "Epoch:  1368  Loss:  0.6162450802512467  Validation Loss:  0.6706207673306819\n",
      "Epoch:  1369  Loss:  0.6163587348535657  Validation Loss:  0.6707942325759817\n",
      "Epoch:  1370  Loss:  0.6164728620555252  Validation Loss:  0.6709681492712762\n",
      "Epoch:  1371  Loss:  0.616587946144864  Validation Loss:  0.6711425646035759\n",
      "Epoch:  1372  Loss:  0.6167035360820592  Validation Loss:  0.6713173549484324\n",
      "Epoch:  1373  Loss:  0.6168195084668696  Validation Loss:  0.6714924778099414\n",
      "Epoch:  1374  Loss:  0.6169358638580889  Validation Loss:  0.6716679685093738\n",
      "Epoch:  1375  Loss:  0.6170525929890573  Validation Loss:  0.6718438223556236\n",
      "Epoch:  1376  Loss:  0.6171697127632797  Validation Loss:  0.6720200189285808\n",
      "Epoch:  1377  Loss:  0.6172872084192932  Validation Loss:  0.6721966062430982\n",
      "Epoch:  1378  Loss:  0.6174050838220865  Validation Loss:  0.6723735202793721\n",
      "Epoch:  1379  Loss:  0.6175233305431902  Validation Loss:  0.6725508079484657\n",
      "Epoch:  1380  Loss:  0.6176419589668513  Validation Loss:  0.6727284435872678\n",
      "Epoch:  1381  Loss:  0.6177609663456678  Validation Loss:  0.6729064487196781\n",
      "Epoch:  1382  Loss:  0.6178803593385964  Validation Loss:  0.6730847816776346\n",
      "Epoch:  1383  Loss:  0.6180001399014146  Validation Loss:  0.6732635073087834\n",
      "Epoch:  1384  Loss:  0.6181202796287835  Validation Loss:  0.6734425632490052\n",
      "Epoch:  1385  Loss:  0.6182408117689192  Validation Loss:  0.6736220002726272\n",
      "Epoch:  1386  Loss:  0.6183617127127945  Validation Loss:  0.6738017880254321\n",
      "Epoch:  1387  Loss:  0.6184829839505255  Validation Loss:  0.6739819085708371\n",
      "Epoch:  1388  Loss:  0.6186046116519719  Validation Loss:  0.6741623787416352\n",
      "Epoch:  1389  Loss:  0.6187266007065773  Validation Loss:  0.6743431977099843\n",
      "Epoch:  1390  Loss:  0.6188489449210465  Validation Loss:  0.6745243580253036\n",
      "Epoch:  1391  Loss:  0.6189716573804617  Validation Loss:  0.6747058726571225\n",
      "Epoch:  1392  Loss:  0.6190947321243584  Validation Loss:  0.6748877421573356\n",
      "Epoch:  1393  Loss:  0.6192181749735027  Validation Loss:  0.6750699568677831\n",
      "Epoch:  1394  Loss:  0.619341995427385  Validation Loss:  0.6752525236871507\n",
      "Epoch:  1395  Loss:  0.6194661715533585  Validation Loss:  0.6754354646912327\n",
      "Epoch:  1396  Loss:  0.6195907153654844  Validation Loss:  0.6756187324170713\n",
      "Epoch:  1397  Loss:  0.6197156363166869  Validation Loss:  0.6758023646694643\n",
      "Epoch:  1398  Loss:  0.6198409299366177  Validation Loss:  0.6759864558224324\n",
      "Epoch:  1399  Loss:  0.6199669065419584  Validation Loss:  0.676171505064876\n",
      "Epoch:  1400  Loss:  0.6200934518128633  Validation Loss:  0.6763569083478715\n",
      "Epoch:  1401  Loss:  0.6202203842811287  Validation Loss:  0.6765426700865781\n",
      "Epoch:  1402  Loss:  0.6203476891387254  Validation Loss:  0.6767288062859464\n",
      "Epoch:  1403  Loss:  0.6204753843136132  Validation Loss:  0.6769152912828658\n",
      "Epoch:  1404  Loss:  0.6206034517847001  Validation Loss:  0.6771021499126045\n",
      "Epoch:  1405  Loss:  0.6207319017499685  Validation Loss:  0.6772893642385801\n",
      "Epoch:  1406  Loss:  0.6208607393782586  Validation Loss:  0.6774769384000037\n",
      "Epoch:  1407  Loss:  0.6209899445995688  Validation Loss:  0.6776649005435131\n",
      "Epoch:  1408  Loss:  0.6211194593459368  Validation Loss:  0.6778531126953937\n",
      "Epoch:  1409  Loss:  0.6212484528310597  Validation Loss:  0.6780410958109079\n",
      "Epoch:  1410  Loss:  0.6213770139962435  Validation Loss:  0.6782291854421297\n",
      "Epoch:  1411  Loss:  0.6215056318324059  Validation Loss:  0.6784176685743861\n",
      "Epoch:  1412  Loss:  0.6216347450390458  Validation Loss:  0.6786065303065159\n",
      "Epoch:  1413  Loss:  0.621764419414103  Validation Loss:  0.6787958048560001\n",
      "Epoch:  1414  Loss:  0.6218946614302695  Validation Loss:  0.6789854960861029\n",
      "Epoch:  1415  Loss:  0.6220253481063992  Validation Loss:  0.6791755463238116\n",
      "Epoch:  1416  Loss:  0.6221564042381942  Validation Loss:  0.6793659583286003\n",
      "Epoch:  1417  Loss:  0.6222878494299948  Validation Loss:  0.6795567235460988\n",
      "Epoch:  1418  Loss:  0.622419663425535  Validation Loss:  0.6797478568774683\n",
      "Epoch:  1419  Loss:  0.6225518600549549  Validation Loss:  0.6799393334874401\n",
      "Epoch:  1420  Loss:  0.6226844305638224  Validation Loss:  0.6801311955959709\n",
      "Epoch:  1421  Loss:  0.6228173804935068  Validation Loss:  0.6803233869097851\n",
      "Epoch:  1422  Loss:  0.6229507081210613  Validation Loss:  0.6805159286768349\n",
      "Epoch:  1423  Loss:  0.6230844171252101  Validation Loss:  0.6807088498716001\n",
      "Epoch:  1424  Loss:  0.6232184744440019  Validation Loss:  0.6809020265936852\n",
      "Epoch:  1425  Loss:  0.6233528345357626  Validation Loss:  0.681095499407362\n",
      "Epoch:  1426  Loss:  0.6234874904621392  Validation Loss:  0.681289218918041\n",
      "Epoch:  1427  Loss:  0.6236224965658039  Validation Loss:  0.6814832979882205\n",
      "Epoch:  1428  Loss:  0.6237578951288014  Validation Loss:  0.681677747103903\n",
      "Epoch:  1429  Loss:  0.6238936556503176  Validation Loss:  0.6818725477766108\n",
      "Epoch:  1430  Loss:  0.6240297898184508  Validation Loss:  0.6820676966949746\n",
      "Epoch:  1431  Loss:  0.6241663075983525  Validation Loss:  0.682263207104471\n",
      "Epoch:  1432  Loss:  0.6243032020516693  Validation Loss:  0.6824590621723069\n",
      "Epoch:  1433  Loss:  0.6244404679629951  Validation Loss:  0.682655296391911\n",
      "Epoch:  1434  Loss:  0.6245781085919588  Validation Loss:  0.6828518609205881\n",
      "Epoch:  1435  Loss:  0.6247161235194654  Validation Loss:  0.6830488043250861\n",
      "Epoch:  1436  Loss:  0.624854521267116  Validation Loss:  0.6832460915600812\n",
      "Epoch:  1437  Loss:  0.6249932853970677  Validation Loss:  0.6834437444254204\n",
      "Epoch:  1438  Loss:  0.6251324356533587  Validation Loss:  0.6836417590578397\n",
      "Epoch:  1439  Loss:  0.6252719463780523  Validation Loss:  0.6838401166929139\n",
      "Epoch:  1440  Loss:  0.6254118382465095  Validation Loss:  0.6840388140192738\n",
      "Epoch:  1441  Loss:  0.6255521101411432  Validation Loss:  0.6842378891176648\n",
      "Epoch:  1442  Loss:  0.6256927408277988  Validation Loss:  0.6844373287426101\n",
      "Epoch:  1443  Loss:  0.6258337577339261  Validation Loss:  0.6846371235118972\n",
      "Epoch:  1444  Loss:  0.6259751501493156  Validation Loss:  0.6848372505218895\n",
      "Epoch:  1445  Loss:  0.6261164639610797  Validation Loss:  0.6850373344840827\n",
      "Epoch:  1446  Loss:  0.6262568544130772  Validation Loss:  0.6852372145211255\n",
      "Epoch:  1447  Loss:  0.6263970136176795  Validation Loss:  0.6854374240393992\n",
      "Epoch:  1448  Loss:  0.6265375551301986  Validation Loss:  0.6856380013955964\n",
      "Epoch:  1449  Loss:  0.6266784607898443  Validation Loss:  0.6858389418986108\n",
      "Epoch:  1450  Loss:  0.6268197418190539  Validation Loss:  0.6860402325789133\n",
      "Epoch:  1451  Loss:  0.6269614005926997  Validation Loss:  0.6862418894414548\n",
      "Epoch:  1452  Loss:  0.6271034344099462  Validation Loss:  0.6864438890307037\n",
      "Epoch:  1453  Loss:  0.6272458348423242  Validation Loss:  0.686646269151458\n",
      "Epoch:  1454  Loss:  0.6273886170703917  Validation Loss:  0.6868489699231254\n",
      "Epoch:  1455  Loss:  0.6275317730847746  Validation Loss:  0.6870520437757174\n",
      "Epoch:  1456  Loss:  0.6276752759702504  Validation Loss:  0.6872553588063629\n",
      "Epoch:  1457  Loss:  0.6278190475422889  Validation Loss:  0.687458947300911\n",
      "Epoch:  1458  Loss:  0.627963101491332  Validation Loss:  0.6876628109150462\n",
      "Epoch:  1459  Loss:  0.6281074828933925  Validation Loss:  0.6878669995952535\n",
      "Epoch:  1460  Loss:  0.6282522098626941  Validation Loss:  0.6880715111339534\n",
      "Epoch:  1461  Loss:  0.6283960896078498  Validation Loss:  0.6882753893733025\n",
      "Epoch:  1462  Loss:  0.6285391892772167  Validation Loss:  0.6884796492479466\n",
      "Epoch:  1463  Loss:  0.6286826541647315  Validation Loss:  0.6886842278418718\n",
      "Epoch:  1464  Loss:  0.6288264639675617  Validation Loss:  0.6888891626839284\n",
      "Epoch:  1465  Loss:  0.6289706460200251  Validation Loss:  0.6890944410805349\n",
      "Epoch:  1466  Loss:  0.6291151934303343  Validation Loss:  0.6893000688265871\n",
      "Epoch:  1467  Loss:  0.6292601107154041  Validation Loss:  0.6895060809674086\n",
      "Epoch:  1468  Loss:  0.629405404208228  Validation Loss:  0.6897124214856712\n",
      "Epoch:  1469  Loss:  0.6295506522990764  Validation Loss:  0.689918666250176\n",
      "Epoch:  1470  Loss:  0.6296948084142059  Validation Loss:  0.6901247512411188\n",
      "Epoch:  1471  Loss:  0.6298388756811619  Validation Loss:  0.6903311693006091\n",
      "Epoch:  1472  Loss:  0.62998331268318  Validation Loss:  0.6905379678916048\n",
      "Epoch:  1473  Loss:  0.6301281268242747  Validation Loss:  0.6907451108649925\n",
      "Epoch:  1474  Loss:  0.6302733185235411  Validation Loss:  0.6909526318863586\n",
      "Epoch:  1475  Loss:  0.6304177334997803  Validation Loss:  0.6911595298184289\n",
      "Epoch:  1476  Loss:  0.6305613268166781  Validation Loss:  0.691366779031577\n",
      "Epoch:  1477  Loss:  0.6307052933145314  Validation Loss:  0.6915743988421228\n",
      "Epoch:  1478  Loss:  0.6308496441226452  Validation Loss:  0.6917823183315771\n",
      "Epoch:  1479  Loss:  0.6309930914081633  Validation Loss:  0.6919896737844856\n",
      "Epoch:  1480  Loss:  0.6311358451843262  Validation Loss:  0.6921973766552078\n",
      "Epoch:  1481  Loss:  0.6312789604533464  Validation Loss:  0.6924053204280359\n",
      "Epoch:  1482  Loss:  0.6314210068900138  Validation Loss:  0.6926126333850401\n",
      "Epoch:  1483  Loss:  0.6315623769070953  Validation Loss:  0.6928201698594623\n",
      "Epoch:  1484  Loss:  0.6317028588615358  Validation Loss:  0.6930270882116424\n",
      "Epoch:  1485  Loss:  0.631842559017241  Validation Loss:  0.6932342146281842\n",
      "Epoch:  1486  Loss:  0.6319811655208468  Validation Loss:  0.6934408774530446\n",
      "Epoch:  1487  Loss:  0.6321184715721756  Validation Loss:  0.6936470866203308\n",
      "Epoch:  1488  Loss:  0.6322541092988103  Validation Loss:  0.6938528413022006\n",
      "Epoch:  1489  Loss:  0.6323879550676793  Validation Loss:  0.6940580291880502\n",
      "Epoch:  1490  Loss:  0.6325197970494628  Validation Loss:  0.6942625539722266\n",
      "Epoch:  1491  Loss:  0.6326493652537465  Validation Loss:  0.6944662558811682\n",
      "Epoch:  1492  Loss:  0.6327760651241988  Validation Loss:  0.6946688023982225\n",
      "Epoch:  1493  Loss:  0.6328992818947882  Validation Loss:  0.6948700343017225\n",
      "Epoch:  1494  Loss:  0.6330184079241008  Validation Loss:  0.6950696193509631\n",
      "Epoch:  1495  Loss:  0.6331325731705875  Validation Loss:  0.6952671839131249\n",
      "Epoch:  1496  Loss:  0.6332409027032554  Validation Loss:  0.6954623615300214\n",
      "Epoch:  1497  Loss:  0.6333424388896673  Validation Loss:  0.6956547956775736\n",
      "Epoch:  1498  Loss:  0.6334364169277251  Validation Loss:  0.695844177018713\n",
      "Epoch:  1499  Loss:  0.6335221834480762  Validation Loss:  0.6960302988688151\n"
     ]
    }
   ],
   "source": [
    "loss_total = []\n",
    "valid_loss_total = []\n",
    "for i in range(len(label_paths)):\n",
    "    print('Training session: ', i)\n",
    "    print (label_paths[i] + ' ' + neural_data_paths[i])\n",
    "    with open(label_paths[i], 'rb') as f:\n",
    "        labels = pickle.load(f)\n",
    "\n",
    "    # load the data\n",
    "    data, names = import_data(neural_data_paths[i], lambda x: x, min = 0, max = 0.15)\n",
    "    validation_data, validation_names  = import_data(neural_data_paths[i], lambda x: x, min = 0.15, max = 0.2)\n",
    "\n",
    "    # generate embeddings\n",
    "    embeddings = []\n",
    "    for vid in data:\n",
    "        single_embeddings = generate_CEBRA_embeddings(model_group, vid, i, offset = (2,3))\n",
    "        embeddings.append(single_embeddings)\n",
    "\n",
    "    validation_embeddings = []\n",
    "    for vid in validation_data:\n",
    "        single_embeddings = generate_CEBRA_embeddings(model_group, vid, i, offset = (2,3))\n",
    "        validation_embeddings.append(single_embeddings)\n",
    "\n",
    "    loss = []\n",
    "    valid_loss = []\n",
    "    for epoch in range(1500): \n",
    "        loss.append(single_epoch(embeddings, names, labels, classifiers, criterion, optimizer, i))\n",
    "        valid_loss.append(validation_run(validation_embeddings, validation_names, labels, classifiers, criterion, i))\n",
    "        print('Epoch: ', epoch, ' Loss: ', loss[-1], ' Validation Loss: ', valid_loss[-1])\n",
    "    loss_total.append(loss)\n",
    "    valid_loss_total.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# sort the paths \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sorted_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(\u001b[39mzip\u001b[39;49m(neural_data_paths, behavior_data_paths, dino_paths, label_paths), key \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m] )\n",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# sort the paths \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sorted_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mzip\u001b[39m(neural_data_paths, behavior_data_paths, dino_paths, label_paths), key \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# sort the paths \n",
    "sorted_paths = sorted(zip(neural_data_paths, behavior_data_paths, dino_paths, label_paths), key = lambda x: x.split('/')[-1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all the losses\n",
    "for i in range(len(loss_total)):\n",
    "    plt.plot(valid_loss_total[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb9f2d89710>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers[-1]\n",
    "\n",
    "classifiers[-1][0].weight.data.normal_(0.0, 0.01)\n",
    "classifiers[-1][0].bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifiers, 'models/cebra_classifier_complete.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group = torch.load('models/cebra_model_complete.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group = model_group.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training session:  0\n",
      "2020_11_17_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_17_MV1_run\n",
      "Training session:  1\n",
      "2020_11_23_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_23_MV1_run\n",
      "Training session:  2\n",
      "2020_11_2_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_2_MV1_run\n",
      "Training session:  3\n",
      "2020_11_9_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_11_9_MV1_run\n",
      "Training session:  4\n",
      "2020_12_10_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_12_10_MV1_run\n",
      "Training session:  5\n",
      "2020_12_4_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2020_12_4_MV1_run\n",
      "Training session:  6\n",
      "2021_1_12_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2021_1_12_MV1_run\n",
      "Training session:  7\n",
      "2021_1_8_MV1_runlabels.pickle /mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/brain/2021_1_8_MV1_run\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "for i in range(len(label_paths)):\n",
    "    print('Training session: ', i)\n",
    "    print (label_paths[i] + ' ' + neural_data_paths[i])\n",
    "\n",
    "    with open(label_paths[i], 'rb') as f:\n",
    "        labels = pickle.load(f)\n",
    "    validation_data, names  = import_data(neural_data_paths[i], lambda x: x, min = 0.15, max = 0.2)\n",
    "\n",
    "    validation_embeddings = []\n",
    "    for vid in validation_data:\n",
    "        single_embeddings = generate_CEBRA_embeddings(model_group, vid, i, offset = (2,3))\n",
    "        validation_embeddings.append(single_embeddings)\n",
    "\n",
    "    for data, names in zip(validation_embeddings, names):\n",
    "        # check if the data is labelled\n",
    "        if names in labels:\n",
    "            # do a forward pass\n",
    "            output = classifiers[i](torch.from_numpy(data).float())\n",
    "            true_label = np.argmax(labels[names])\n",
    "            vid_label = np.argmax(np.sum(output.detach().numpy(), axis= 0))\n",
    "            ## take the argmax of which class it is\n",
    "            \n",
    "            true_labels.append(true_label)\n",
    "            predicted_labels.append(vid_label)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(true_labels, predicted_labels)\n",
    "# plot the confusion matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, labels):\n",
    "    # Normalize the confusion matrix\n",
    "    normalized_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(normalized_matrix, cmap='Blues')\n",
    "\n",
    "    # Set colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel('Normalized', rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Set ticks and labels\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    # Rotate the tick labels and set alignment\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{confusion_matrix[i, j]}', ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    # Set labels for the x-axis, y-axis, and title\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(confusion, ['Still', 'Sniffing', 'Running', 'Grooming'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

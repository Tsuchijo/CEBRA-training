{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth, OPTICS\n",
    "from cebra_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Name convolutional-model-offset11 is already registered for class (<class '__main__.ConvulotionalModel1'>, None).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m      8\u001b[0m         \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mmovedim(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)  \u001b[39m# Permute dimensions 1 and 2\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39m@cebra\u001b[39;49m\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mregister(\u001b[39m\"\u001b[39;49m\u001b[39mconvolutional-model-offset11\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mConvulotionalModel1\u001b[39;49;00m(_OffsetModel, ConvolutionalModelMixin):\n\u001b[1;32m     13\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, num_neurons, num_units, num_output, normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m):\n\u001b[1;32m     14\u001b[0m         \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     15\u001b[0m             \u001b[39m## create a model which goes from a 128 x 128 image to a 1d vector\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m             \u001b[39m## of length num_output\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m             normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[1;32m     30\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/cebra-env/lib/python3.11/site-packages/cebra/registry.py:170\u001b[0m, in \u001b[0;36madd_helper_functions.<locals>.register.<locals>._register\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_register\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[0;32m--> 170\u001b[0m     _Registry\u001b[39m.\u001b[39;49madd(module,\n\u001b[1;32m    171\u001b[0m                   name,\n\u001b[1;32m    172\u001b[0m                   \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m                   base\u001b[39m=\u001b[39;49mbase,\n\u001b[1;32m    174\u001b[0m                   override\u001b[39m=\u001b[39;49moverride,\n\u001b[1;32m    175\u001b[0m                   deprecated\u001b[39m=\u001b[39;49mdeprecated)\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cebra-env/lib/python3.11/site-packages/cebra/registry.py:78\u001b[0m, in \u001b[0;36m_Registry.add\u001b[0;34m(cls, module, name, value, base, override, deprecated)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[39mdel\u001b[39;00m instance[name]\n\u001b[1;32m     77\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mName \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is already registered for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclass \u001b[39m\u001b[39m{\u001b[39;00minstance[name]\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m (value, base) \u001b[39min\u001b[39;00m instance\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deprecated:\n",
      "\u001b[0;31mValueError\u001b[0m: Name convolutional-model-offset11 is already registered for class (<class '__main__.ConvulotionalModel1'>, None)."
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import cebra.models\n",
    "import cebra.data\n",
    "from cebra.models.model import _OffsetModel, ConvolutionalModelMixin\n",
    "\n",
    "class ChangeOrderLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.movedim(-2,1)  # Permute dimensions 1 and 2\n",
    "\n",
    "@cebra.models.register(\"convolutional-model-offset11\")\n",
    "class ConvulotionalModel1(_OffsetModel, ConvolutionalModelMixin):\n",
    "\n",
    "    def __init__(self, num_neurons, num_units, num_output, normalize=True):\n",
    "        super().__init__(\n",
    "            ## create a model which goes from a 128 x 128 image to a 1d vector\n",
    "            ## of length num_output\n",
    "            ChangeOrderLayer(),\n",
    "            nn.Conv2d(5, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, num_output),\n",
    "\n",
    "            num_input=num_neurons,\n",
    "            num_output=num_output,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "\n",
    "    # ... and you can also redefine the forward method,\n",
    "    # as you would for a typical pytorch model\n",
    "\n",
    "    def get_offset(self):\n",
    "        return cebra.data.Offset(2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_model_path = 'models/cebra_model_complete.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/'\n",
    "neural_data_paths = [ data_directory + 'brain/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "behavior_data_paths = [  data_directory + 'camera1/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "dino_paths = [ data_directory + 'dino/' + \\\n",
    "                        file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "output_folder_paths = [ data_directory + 'output3/' + \\\n",
    "                        file for file in os.listdir(data_directory + 'brain/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_frame_to_embeddings(predicted_embedding, embedding_train, image_train):\n",
    "  cos_dist = np.matmul(embedding_train, predicted_embedding.T)\n",
    "  index_list = np.argmax(cos_dist, axis=0)\n",
    "  return image_train[index_list]\n",
    "\n",
    "def predict_embeddings(neural_path, behavior_path,dino_path, validation_cutoff, valid_size, model, label_model, session):\n",
    "    # Load data\n",
    "    print('Loading data')\n",
    "    brain_data, name_data = import_data(neural_path, lambda x: x, max=validation_cutoff)\n",
    "    behavior_data, _ = import_data(behavior_path, lambda x: x, max=validation_cutoff)\n",
    "    dino_data, _ = import_data(dino_path, lambda x: x, max=validation_cutoff)\n",
    "    # Generate embeddings\n",
    "    print('Generating embeddings')\n",
    "    embeddings = [generate_CEBRA_embeddings(model, brain_data_vid, session) for brain_data_vid in brain_data]\n",
    "\n",
    "    print('Loading test data')\n",
    "    # Load the test set of data\n",
    "    brain_data_test, name_data_test = import_data(neural_path, lambda x: x, min = validation_cutoff, max=validation_cutoff + valid_size)\n",
    "    behavior_data_test, _ = import_data(behavior_path, lambda x: x, min = validation_cutoff, max=validation_cutoff + valid_size)\n",
    "    dino_data_test, _ = import_data(dino_path, lambda x: x, min = validation_cutoff, max= validation_cutoff + valid_size)\n",
    "    # Generate embeddings\n",
    "    print('Generating test embeddings')\n",
    "    embeddings_test = [generate_CEBRA_embeddings(model, vid_test, session) for vid_test in brain_data_test]\n",
    "\n",
    "    # Flatten Data\n",
    "    embeddings_flat = flatten_data(embeddings).squeeze()\n",
    "    behavior_flat = flatten_data(behavior_data).squeeze()\n",
    "    dino_flat = flatten_data(dino_data).squeeze()\n",
    "    embedding_test_flat = flatten_data(embeddings_test).squeeze()\n",
    "    dino_test_flat = flatten_data(dino_data_test).squeeze()\n",
    "\n",
    "    print('Running KNN')\n",
    "    # Create KNN decoder\n",
    "    decoder = cebra.KNNDecoder(n_neighbors=20, metric=\"cosine\")\n",
    "    decoder.fit(embeddings_flat, dino_flat)\n",
    "\n",
    "    # predict\n",
    "    predicted_dino = decoder.predict(embedding_test_flat)\n",
    "\n",
    "    # normalize predicted embeddings\n",
    "    predicted_dino = normalize_array(predicted_dino)\n",
    "\n",
    "    print('generating videos')\n",
    "    # Match predicted embeddings to images\n",
    "    predicted_images = match_frame_to_embeddings(predicted_dino, dino_flat, behavior_flat)\n",
    "    reshaped_predicted_images = reshape_frames(predicted_images, brain_data_test)\n",
    "\n",
    "    print('Running Clustering')\n",
    "    #run Agglomerative clustering to predict class labels\n",
    "    predicted_labels_flat = label_model(torch.from_numpy(embedding_test_flat)).detach().numpy()\n",
    "    # turn one hot encoding into labels\n",
    "    predicted_labels_flat = np.argmax(predicted_labels_flat, axis=1)\n",
    "    #reshape predicted labels\n",
    "    predicted_labels = reshape_frames(predicted_labels_flat, brain_data_test)\n",
    "\n",
    "    return reshaped_predicted_images, name_data_test, predicted_labels, behavior_data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frames_as_video(frames, ground_truth, frame_rate, name, labels, label_dict, output_folder_path):\n",
    "    fontScale = 0.5\n",
    "    org = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    thickness = 1\n",
    "    # Get the dimensions of the frames\n",
    "    frame_height, frame_width = frames[0].shape\n",
    "    # Classify video based on median label of all frames\n",
    "    label = np.round(np.median(labels))\n",
    "    label_class = label_dict[label]\n",
    "    # Create a VideoWriter object to write the frames into a video file\n",
    "    video_writer = cv2.VideoWriter(output_folder_path + '/'+ str(label_class) + '_' + name +'.mp4',\n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                   frame_rate,\n",
    "                                   (frame_width, 2 * frame_height))\n",
    "\n",
    "    # Display frames\n",
    "    for iter, frame in enumerate(zip(frames, ground_truth, labels)):\n",
    "        # Write the current frame to the video file\n",
    "        color_frame = cv2.cvtColor(((frame[0]/2 + frames[iter - 1]/2)).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        color_truth = cv2.cvtColor(frame[1].astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        combined = np.concatenate((color_frame, color_truth))\n",
    "\n",
    "        # write corresponding label to video corner\n",
    "        combined  = cv2.putText(combined, str(frame[2]) , org, font, \n",
    "                   fontScale, (0,0,255), thickness, cv2.LINE_AA)\n",
    "        video_writer.write(combined)\n",
    "\n",
    "    # Release the VideoWriter and close the window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_behavior = {\n",
    "    0: 'still',\n",
    "    1: 'sniffing',\n",
    "    2: 'walking',\n",
    "    3: 'grooming',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating videos\n",
      "Running Clustering\n"
     ]
    }
   ],
   "source": [
    "solver = torch.load('models/cebra_model_complete.pt')\n",
    "model = solver.model.eval()\n",
    "label_model = torch.load('models/cebra_classifier_complete.pt')\n",
    "for i, _ in enumerate(zip(neural_data_paths, behavior_data_paths, dino_paths)):\n",
    "    pred_images, names, labels, predict_behavior = predict_embeddings(neural_data_paths[i], behavior_data_paths[i], dino_paths[i], 0.8, 0.2, model, label_model[i], i)\n",
    "    for data in zip(labels, pred_images, names, predict_behavior):\n",
    "        windowed_labels = choose_random_window(30, data[2], data[0])\n",
    "        windowed_frames = choose_random_window(30, data[2], data[1])\n",
    "        windowed_truth = choose_random_window(30, data[2], data[3])\n",
    "        display_frames_as_video(windowed_frames, windowed_truth, 30, data[2], windowed_labels, key_behavior, output_folder_paths[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

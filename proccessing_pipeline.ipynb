{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '2020_11_9_MV1_run_brain'\n",
    "behavior_path = '2020_11_9_MV1_run_behavior'\n",
    "feature_label_path = 'feature_labels'\n",
    "cebra_model_path = 'cebra_multi_model2.pt'\n",
    "output_folder_path = 'output_videos4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_separate_test_set = True\n",
    "# If use_separate_test_set is false then the following is used to define the cutoff between training and test sets\n",
    "test_set_size = 0.2\n",
    "# Otherwise load the test set from these paths\n",
    "brain_path_test = '2020_12_4_MV1_run_brain'\n",
    "behavior_path_test = '2020_12_4_MV1_run_behavior'\n",
    "#define cutoff for loading test set to save memory\n",
    "test_cutoff = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_brain(brain_seq):\n",
    "  try:\n",
    "    brain_seq = np.array(brain_seq)\n",
    "    brain_mask = (np.sum(brain_seq, axis=0) > 0)\n",
    "    flat_seq = (brain_seq[:, brain_mask])\n",
    "    return flat_seq.astype(float)\n",
    "  except:\n",
    "    print(np.shape(brain_seq))\n",
    "\n",
    "def import_data(filepath, processor, max = -1):\n",
    "    output_data = []\n",
    "    output_name = []\n",
    "    for iter, file in enumerate(os.listdir(filepath)):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".tif\"):\n",
    "         out = cv2.imreadmulti(filepath + '/' + filename)[1]\n",
    "         output_data.append(processor(out))\n",
    "         output_name.append(filename)\n",
    "         if iter > max and max > 0: break\n",
    "         continue\n",
    "     else:\n",
    "         continue\n",
    "    return output_data, output_name\n",
    "\n",
    "def flatten_data(data):\n",
    "    data_flat = np.squeeze(data[0])\n",
    "    for x in data[1::]:\n",
    "        data_flat = np.concatenate((data_flat, np.squeeze(x)))\n",
    "    return data_flat\n",
    "\n",
    "def generate_CEBRA_embeddings(neural, name, model, session = 'run'):\n",
    "    embedding = []\n",
    "    failed = []\n",
    "    for run, data in enumerate(neural):\n",
    "        try:\n",
    "            if session == 'run':\n",
    "                embedding.append(model.transform(data, session_id=run))\n",
    "            else:\n",
    "                embedding.append(model.transform(data, session_id=1))\n",
    "        except:\n",
    "            failed.append(run)\n",
    "            print(run)\n",
    "    failed.reverse()\n",
    "    for index in failed:\n",
    "        del name[index]\n",
    "        del neural[index]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load brain and behavior data\n",
    "brain_data, name_data = import_data(brain_path, process_brain)\n",
    "behavior_data, _ = import_data(behavior_path, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_separate_test_set:\n",
    "    brain_data_test, name_data_test = import_data(brain_path_test, process_brain, max=test_cutoff)\n",
    "    behavior_data_test, _ = import_data(behavior_path_test, lambda x: x, max=test_cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load feature labels\n",
    "with open(feature_label_path, 'rb') as f:\n",
    "    feature_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neural embeddings using cebra model\n",
    "model = cebra.CEBRA.load(cebra_model_path)\n",
    "neural_embeddings = generate_CEBRA_embeddings(brain_data, name_data, model, session = 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_separate_test_set:\n",
    "    neural_embeddings_test = generate_CEBRA_embeddings(brain_data_test, name_data_test, model, session = 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_separate_test_set == False:\n",
    "    train_cutoff = int(len(neural_embeddings) * (1 - test_set_size))\n",
    "    train_neural_embeddings = neural_embeddings[:train_cutoff]\n",
    "    train_names = name_data[:train_cutoff]\n",
    "    train_behavior = behavior_data[:train_cutoff]\n",
    "    train_feature_labels = feature_labels[:train_cutoff]\n",
    "    predict_neural_embeddings = neural_embeddings[train_cutoff:]\n",
    "    predict_names = name_data[train_cutoff:]\n",
    "    predict_behavior = behavior_data[train_cutoff:]\n",
    "else:\n",
    "    train_cutoff = int(len(neural_embeddings) * (1 - test_set_size))\n",
    "    train_neural_embeddings = neural_embeddings[:train_cutoff]\n",
    "    train_names = name_data[:train_cutoff]\n",
    "    train_behavior = behavior_data[:train_cutoff]\n",
    "    train_feature_labels = feature_labels[:train_cutoff]\n",
    "    predict_neural_embeddings = neural_embeddings_test\n",
    "    predict_names = name_data_test\n",
    "    predict_behavior = behavior_data_test\n",
    "    del behavior_data_test\n",
    "    del behavior_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into train and predict groups, and flatten data\n",
    "train_neural_embeddings_flat = flatten_data(train_neural_embeddings)\n",
    "train_behavior_flat = flatten_data(train_behavior)\n",
    "train_feature_labels_flat = flatten_data(train_feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_neural_embeddings_flat = flatten_data(predict_neural_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit kNN regressor to flattened training data\n",
    "image_decoder = cebra.KNNDecoder(n_neighbors=20, metric=\"cosine\")\n",
    "image_decoder.fit(train_neural_embeddings_flat, train_feature_labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict feature label vector from neural embedding\n",
    "predict_feature_labels_flat = image_decoder.predict(predict_neural_embeddings_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(in_array):\n",
    "    return np.array([x / np.linalg.norm(x) for x in in_array])\n",
    "\n",
    "def match_frame_to_embeddings(predicted_embedding, embedding_train, image_train):\n",
    "  cos_dist = np.matmul(embedding_train, predicted_embedding.T)\n",
    "  index_list = np.argmax(cos_dist, axis=0)\n",
    "  return image_train[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize predicted feature label vector and train feature label vector\\\n",
    "predict_feature_labels_flat = normalize_array(predict_feature_labels_flat)\n",
    "train_feature_labels_flat = normalize_array(train_feature_labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate series of predicted images\n",
    "predicted_frames = match_frame_to_embeddings(predict_feature_labels_flat, train_feature_labels_flat, train_behavior_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Agglomerative clustering to predict class labels\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(n_clusters=3, metric='cosine', linkage='average' ).fit(predict_neural_embeddings_flat)\n",
    "predicted_labels_flat = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_frames(frames, shape_ref):\n",
    "    shape_list = [np.shape(x)[0] for x in shape_ref]\n",
    "    gen_video_list = []\n",
    "    index = 0\n",
    "    for shape in shape_list:\n",
    "        gen_video_list.append((frames[index : index + shape]))\n",
    "        index += shape\n",
    "    return gen_video_list\n",
    "\n",
    "#choose a random window of set size from the data deterministically based on seed\n",
    "def choose_random_window( window_size, seed, data):\n",
    "    random.seed(seed)\n",
    "    start = random.randint(0, len(data) - window_size)\n",
    "    return data[start:start+window_size]\n",
    "\n",
    "\n",
    "def display_frames_as_video(frames, ground_truth, frame_rate, name, labels, label_dict):\n",
    "    fontScale = 1\n",
    "    org = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    thickness = 2\n",
    "    # Get the dimensions of the frames\n",
    "    frame_height, frame_width = frames[0].shape\n",
    "    # Classify video based on median label of all frames\n",
    "    label = np.round(np.median(labels))\n",
    "    label_class = label_dict[label]\n",
    "    # Create a VideoWriter object to write the frames into a video file\n",
    "    video_writer = cv2.VideoWriter(output_folder_path + '/'+ label_class + '_' + name +'.mp4',\n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                   frame_rate,\n",
    "                                   (frame_width, 2 * frame_height))\n",
    "\n",
    "    # Display frames\n",
    "    for iter, frame in enumerate(zip(frames, ground_truth, labels)):\n",
    "        # Write the current frame to the video file\n",
    "        color_frame = cv2.cvtColor(((frame[0]/2 + frames[iter - 1]/2)).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        color_truth = cv2.cvtColor(frame[1].astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        combined = np.concatenate((color_frame, color_truth))\n",
    "\n",
    "        # write corresponding label to video corner\n",
    "        combined  = cv2.putText(combined, str(label_dict[frame[2]]), org, font, \n",
    "                   fontScale, (0,0,255), thickness, cv2.LINE_AA)\n",
    "        video_writer.write(combined)\n",
    "\n",
    "    # Release the VideoWriter and close the window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vid_list  = reshape_frames(predicted_frames, predict_behavior)\n",
    "pred_labels= reshape_frames(predicted_labels_flat, predict_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = {0 : 'Still', 1 : 'Running', 2 : 'Sniffing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in zip(pred_labels, pred_vid_list, predict_names, predict_behavior):\n",
    "    windowed_labels = choose_random_window(30, data[2], data[0])\n",
    "    windowed_frames = choose_random_window(30, data[2], data[1])\n",
    "    windowed_truth = choose_random_window(30, data[2], data[3])\n",
    "    display_frames_as_video(windowed_frames, windowed_truth, 30, data[2], windowed_labels, label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.manifold import TSNE\n",
    "tsne_embedding = TSNE(n_components=2, n_iter=5000, learning_rate='auto', metric='cosine',\n",
    "                   init='random', perplexity=30).fit_transform(predict_neural_embeddings_flat)\n",
    "colors = ListedColormap(['r','b','g'])\n",
    "classes = ['still', 'running', 'sniffing']\n",
    "#plot tsne plot as a scatterplot with labels\n",
    "scatter = plt.scatter(tsne_embedding[:,0], tsne_embedding[:,1], c=predicted_labels_flat, cmap=colors)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

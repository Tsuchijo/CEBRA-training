{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_path = '2020_11_9_MV1_run_brain'\n",
    "behavior_path = '2020_11_9_MV1_run_behavior'\n",
    "feature_label_path = 'feature_labels'\n",
    "cebra_model_path = 'cebra_multi_model2.pt'\n",
    "output_folder_path = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_brain(brain_seq):\n",
    "  try:\n",
    "    brain_seq = np.array(brain_seq)\n",
    "    brain_mask = (np.sum(brain_seq, axis=0) > 0)\n",
    "    flat_seq = (brain_seq[:, brain_mask])\n",
    "    return flat_seq.astype(float)\n",
    "  except:\n",
    "    print(np.shape(brain_seq))\n",
    "\n",
    "def import_data(filepath, processor, max = -1):\n",
    "    output_data = []\n",
    "    output_name = []\n",
    "    for iter, file in enumerate(os.listdir(filepath)):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".tif\"):\n",
    "         out = cv2.imreadmulti(filepath + '/' + filename)[1]\n",
    "         output_data.append(processor(out))\n",
    "         output_name.append(filename)\n",
    "         if iter > max and max > 0: break\n",
    "         continue\n",
    "     else:\n",
    "         continue\n",
    "    return output_data, output_name\n",
    "\n",
    "def flatten_data(data):\n",
    "    data_flat = np.squeeze(data[0])\n",
    "    for x in data[1::]:\n",
    "        data_flat = np.concatenate((data_flat, np.squeeze(x)))\n",
    "    return data_flat\n",
    "\n",
    "def generate_CEBRA_embeddings(neural, name, model, session = 'run'):\n",
    "    embedding = []\n",
    "    failed = []\n",
    "    for run, data in enumerate(neural):\n",
    "        try:\n",
    "            if session == 'run':\n",
    "                embedding.append(model.transform(data, session_id=run))\n",
    "            else:\n",
    "                embedding.append(model.transform(data, session_id=1))\n",
    "        except:\n",
    "            failed.append(run)\n",
    "            print(run)\n",
    "    failed.reverse()\n",
    "    for index in failed:\n",
    "        del name[index]\n",
    "        del neural[index]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load brain and behavior data\n",
    "brain_data, name_data = import_data(brain_path, process_brain)\n",
    "behavior_data, _ = import_data(behavior_path, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load feature labels\n",
    "with open(feature_label_path, 'rb') as f:\n",
    "    feature_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neural embeddings using cebra model\n",
    "model = cebra.CEBRA.load(cebra_model_path)\n",
    "neural_embeddings = generate_CEBRA_embeddings(brain_data, name_data, model, session = 'run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepaarate into train and predict groups, and flatten data\n",
    "train_cutoff = int(len(neural_embeddings) * 0.8)\n",
    "train_neural_embeddings = neural_embeddings[:train_cutoff]\n",
    "train_names = name_data[:train_cutoff]\n",
    "train_behavior = behavior_data[:train_cutoff]\n",
    "train_feature_labels = feature_labels[:train_cutoff]\n",
    "train_neural_embeddings_flat = flatten_data(train_neural_embeddings)\n",
    "train_behavior_flat = flatten_data(train_behavior)\n",
    "train_feature_labels_flat = flatten_data(train_feature_labels)\n",
    "\n",
    "predict_neural_embeddings = neural_embeddings[train_cutoff:]\n",
    "predict_names = name_data[train_cutoff:]\n",
    "predict_behavior = behavior_data[train_cutoff:]\n",
    "predict_neural_embeddings_flat = flatten_data(predict_neural_embeddings)\n",
    "predict_behavior_flat = flatten_data(predict_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit kNN regressor to flattened training data\n",
    "image_decoder = cebra.KNNDecoder(n_neighbors=20, metric=\"cosine\")\n",
    "image_decoder.fit(train_neural_embeddings_flat, train_feature_labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict feature label vector from neural embedding\n",
    "predict_feature_labels_flat = image_decoder.predict(predict_neural_embeddings_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(in_array):\n",
    "    return np.array([x / np.linalg.norm(x) for x in in_array])\n",
    "\n",
    "def match_frame_to_embeddings(predicted_embedding, embedding_train, image_train):\n",
    "  cos_dist = np.matmul(embedding_train, predicted_embedding.T)\n",
    "  index_list = np.argmax(cos_dist, axis=0)\n",
    "  return image_train[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize predicted feature label vector and train feature label vector\\\n",
    "predict_feature_labels_flat = normalize_array(predict_feature_labels_flat)\n",
    "train_feature_labels_flat = normalize_array(train_feature_labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate series of predicted images\n",
    "predicted_frames = match_frame_to_embeddings(predict_feature_labels_flat, train_feature_labels_flat, train_behavior_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Agglomerative clustering to predict class labels\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(n_clusters=3).fit(predict_neural_embeddings_flat)\n",
    "predicted_labels_flat = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_frames(frames, shape_ref):\n",
    "    shape_list = [np.shape(x)[0] for x in shape_ref]\n",
    "    gen_video_list = []\n",
    "    index = 0\n",
    "    for shape in shape_list:\n",
    "        gen_video_list.append((frames[index : index + shape]))\n",
    "        index += shape\n",
    "    return gen_video_list\n",
    "\n",
    "def display_frames_as_video(frames, ground_truth, frame_rate, name, labels):\n",
    "    fontScale = 1\n",
    "    org = (50, 50)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    thickness = 2\n",
    "    # Get the dimensions of the frames\n",
    "    frame_height, frame_width = frames[0].shape\n",
    "\n",
    "    # Create a VideoWriter object to write the frames into a video file\n",
    "    video_writer = cv2.VideoWriter(output_folder_path + name +'.mp4',\n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                   frame_rate,\n",
    "                                   (frame_width, 2 * frame_height))\n",
    "\n",
    "    # Display frames\n",
    "    for iter, frame in enumerate(zip(frames, ground_truth, labels)):\n",
    "        # Write the current frame to the video file\n",
    "        color_frame = cv2.cvtColor(((frame[0]/2 + frames[iter - 1]/2)).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        color_truth = cv2.cvtColor(frame[1].astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        combined = np.concatenate((color_frame, color_truth))\n",
    "\n",
    "        # write corresponding label to video corner\n",
    "        combined  = cv2.putText(combined, str(frame[2]), org, font, \n",
    "                   fontScale, (0,0,255), thickness, cv2.LINE_AA)\n",
    "        video_writer.write(combined)\n",
    "\n",
    "    # Release the VideoWriter and close the window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

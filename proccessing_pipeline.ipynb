{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth, OPTICS\n",
    "from cebra_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_model_path = 'models/cebra_model_flattened_offset1.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_model_id = { \n",
    "    '2021_1_8_MV1_run' : 0,\n",
    "    '2020_11_23_MV1_run' : 1,\n",
    "    '2020_12_4_MV1_run' : 2,\n",
    "    '2020_11_2_MV1_run' : 3,\n",
    "    '2021_1_12_MV1_run' : 4,\n",
    "    '2020_12_10_MV1_run' : 5,\n",
    "    '2020_11_9_MV1_run' : 6,\n",
    "    '2020_11_17_MV1_run' : 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/mnt/teams/Tsuchitori/MV1_run_30hz_30frame_brain2behav_DFF_new/'\n",
    "neural_data_paths = [ data_directory + 'brain/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "behavior_data_paths = [  data_directory + 'camera1/' + \\\n",
    "                     file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "dino_paths = [ data_directory + 'dino/' + \\\n",
    "                        file for file in os.listdir(data_directory + 'brain/')]\n",
    "\n",
    "output_folder_paths = [ data_directory + 'output4/' + \\\n",
    "                        file for file in os.listdir(data_directory + 'brain/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_frame_to_embeddings(predicted_embedding, embedding_train, image_train):\n",
    "  cos_dist = np.matmul(embedding_train, predicted_embedding.T)\n",
    "  index_list = np.argmax(cos_dist, axis=0)\n",
    "  return image_train[index_list]\n",
    "\n",
    "def predict_embeddings(neural_path, behavior_path,dino_path, validation_cutoff, valid_size, model, label_model, session):\n",
    "    # Load data\n",
    "    print('Loading data')\n",
    "    brain_data, name_data = import_data(neural_path, lambda x: process_brain(x), max=validation_cutoff)\n",
    "    behavior_data, _ = import_data(behavior_path, lambda x: x, max=validation_cutoff)\n",
    "    dino_data, _ = import_data(dino_path, lambda x: x, max=validation_cutoff)\n",
    "    # Generate embeddings\n",
    "    print('Generating embeddings')\n",
    "    embeddings = [model[session](torch.from_numpy(np.array(x)).float().to('cuda')).to('cpu').detach().numpy() for i, x in enumerate(brain_data)]\n",
    "\n",
    "\n",
    "    print('Loading test data')\n",
    "    # Load the test set of data\n",
    "    brain_data_test, name_data_test = import_data(neural_path, lambda x: process_brain(x), min = validation_cutoff, max=validation_cutoff + valid_size)\n",
    "    behavior_data_test, _ = import_data(behavior_path, lambda x: x, min = validation_cutoff, max=validation_cutoff + valid_size)\n",
    "    dino_data_test, _ = import_data(dino_path, lambda x: x, min = validation_cutoff, max= validation_cutoff + valid_size)\n",
    "    # Generate embeddings\n",
    "    print('Generating test embeddings')\n",
    "    embeddings_test = [model[session](torch.from_numpy(np.array(x)).float().to('cuda')).to('cpu').detach().numpy() for i, x in enumerate(brain_data_test)]\n",
    "\n",
    "    # Flatten Data\n",
    "    embeddings_flat = flatten_data(embeddings).squeeze()\n",
    "    behavior_flat = flatten_data(behavior_data).squeeze()\n",
    "    dino_flat = flatten_data(dino_data).squeeze()\n",
    "    embedding_test_flat = flatten_data(embeddings_test).squeeze()\n",
    "    dino_test_flat = flatten_data(dino_data_test).squeeze()\n",
    "\n",
    "    print('Running KNN')\n",
    "    # Create KNN decoder\n",
    "    decoder = cebra.KNNDecoder(n_neighbors=20, metric=\"cosine\")\n",
    "    decoder.fit(embeddings_flat, dino_flat)\n",
    "\n",
    "    # predict\n",
    "    predicted_dino = decoder.predict(embedding_test_flat)\n",
    "\n",
    "    # normalize predicted embeddings\n",
    "    predicted_dino = normalize_array(predicted_dino)\n",
    "\n",
    "    print('generating labels')\n",
    "    labels = []\n",
    "    for label, data in zip(name_data, brain_data):\n",
    "        if label.split('_')[0] == 'move':\n",
    "            labels.extend(np.tile(np.array([0, 1]),[len(data), 1]))\n",
    "        else:\n",
    "            labels.extend(np.tile(np.array([1, 0]),[len(data), 1]))\n",
    "    labels = np.array(labels)\n",
    "    decoder = cebra.KNNDecoder(n_neighbors=72, metric='cosine')\n",
    "    decoder.fit(embeddings_flat, labels)\n",
    "    predicted_labels = np.argmax(decoder.predict(embedding_test_flat), axis=1)\n",
    "    predicted_labels = reshape_frames(predicted_labels, embeddings_test)\n",
    "    print('generating videos')\n",
    "    # Match predicted embeddings to images\n",
    "    predicted_images = match_frame_to_embeddings(predicted_dino, dino_flat, behavior_flat)\n",
    "    reshaped_predicted_images = reshape_frames(predicted_images, brain_data_test)\n",
    "\n",
    "    return reshaped_predicted_images, name_data_test, behavior_data_test, predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frames_as_video(frames, ground_truth, frame_rate, name, output_folder_path):\n",
    "    # Get the dimensions of the frames\n",
    "    frame_height, frame_width = frames[0].shape\n",
    "    # Classify video based on median label of all frames\n",
    "    # Create a VideoWriter object to write the frames into a video file\n",
    "    video_writer = cv2.VideoWriter(output_folder_path + '/' +  name +'.mp4',\n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                   frame_rate,\n",
    "                                   (frame_width, 2 * frame_height))\n",
    "\n",
    "    # Display frames\n",
    "    for iter, frame in enumerate(zip(frames, ground_truth)):\n",
    "        # Write the current frame to the video file\n",
    "        color_frame = cv2.cvtColor(frame[0].astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        color_truth = cv2.cvtColor(frame[1].astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        combined = np.concatenate((color_frame, color_truth))\n",
    "        video_writer.write(combined)\n",
    "\n",
    "    # Release the VideoWriter and close the window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_generated_video(vid, name, output_folder_path):\n",
    "    video_writer = cv2.VideoWriter(output_folder_path + '/' + name +'.mp4',\n",
    "                                   cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                                   24,\n",
    "                                   (64, 64))\n",
    "    # downsample video to 64x64\n",
    "    vid_low = [cv2.resize(frame, (64, 64)) for frame in vid]\n",
    "    for frame in vid_low:\n",
    "        color_frame = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "        video_writer.write(color_frame)\n",
    "    video_writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_behavior = {\n",
    "    0: 'still',\n",
    "    1: 'sniffing',\n",
    "    2: 'walking',\n",
    "    3: 'grooming',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n",
      "Loading data\n",
      "Generating embeddings\n",
      "Loading test data\n",
      "Generating test embeddings\n",
      "Running KNN\n",
      "generating labels\n",
      "generating videos\n"
     ]
    }
   ],
   "source": [
    "solver = torch.load('models/cebra_model_flattened_offset1.pt')\n",
    "model = solver.model.eval().to('cuda')\n",
    "label_model = torch.load('models/cebra_classifier_complete.pt')\n",
    "for i, _ in enumerate(zip(neural_data_paths, behavior_data_paths, dino_paths)):\n",
    "    pred_images, names, predict_behavior, pred_labels = predict_embeddings(neural_data_paths[i], behavior_data_paths[i], dino_paths[i], 0.8, 0.2, model, label_model[i], name_to_model_id[neural_data_paths[i].split('/')[-1]])\n",
    "    for vid, name, ground_truth, label in zip(pred_images, names, predict_behavior, pred_labels):\n",
    "        windowed_frames = choose_first_second(30, vid)\n",
    "        windowed_truth = choose_first_second(30, ground_truth)\n",
    "        windowed_labels = choose_first_second(30, label)\n",
    "        label = np.round(np.median(windowed_labels))\n",
    "        if label == 0:\n",
    "            name = name + '_pred_no_move'\n",
    "        else:\n",
    "            name = name + '_pred_move'\n",
    "        display_frames_as_video(windowed_frames, windowed_truth, 24, name, output_folder_paths[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cebra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
